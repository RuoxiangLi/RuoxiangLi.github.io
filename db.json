{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/photo.jpg","path":"images/photo.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/weixin.jpg","path":"images/weixin.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/uploads/hexo.jpg","path":"uploads/hexo.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/hexo.jpg","path":"images/hexo.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/zhifubao.jpg","path":"images/zhifubao.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/1703706832.jpg","path":"images/1703706832.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/wo.png","path":"images/wo.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.gitattributes","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.gitignore","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.hound.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.javascript_ignore","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.jshintrc","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.stylintrc","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.travis.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/LICENSE","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/README.cn.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/README.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/bower.json","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/gulpfile.coffee","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"source/CNAME","hash":"24062db3e3d34eaed7cc5b97dc0a79757c798b74","modified":1559219366239},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1559219366315},{"_id":"themes/next/README-NSConflict-ruoxianglee.md","hash":"44b28d995681a7c48bfe3d0577d6203812d07e59","modified":1559219366315},{"_id":"themes/next/README.cn-NSConflict-ruoxianglee.md","hash":"5d8af3d8de8d3926126a738519e97c8442b0effe","modified":1559219366315},{"_id":"themes/next/_config-NSConflict-ruoxianglee.yml","hash":"70b5cccf602b66c36ee7a457204f4a9b71326e5e","modified":1559219366315},{"_id":"themes/next/_config.yml","hash":"09fb35e1fac21c34bd4385ecdff5f6ea75486fdf","modified":1559219366315},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1559219366319},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.github/browserstack_logo.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/_config-NSConflict5200-ruoxianglee.yml","hash":"e29e86985dc7d1798578d8e034a5bf7080649935","modified":1559219366315},{"_id":"themes/next/languages/de.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/default.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/en.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/fr-FR.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/id.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/it.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/ja.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/ko.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1559219366315},{"_id":"themes/next/languages/nl-NL.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/pt-BR.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/pt.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/zh-hk.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"themes/next/languages/zh-tw-NSConflict-ruoxianglee.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366315},{"_id":"source/baidu_verify_aia7zPmTuu.html","hash":"6f8de94230bde50d3b6337947939cf7ba24a2c99","modified":1559219366307},{"_id":"source/_posts/C++学习之const关键字.md","hash":"05b6bc518fd73db10b37141711616a636dfb6ef0","modified":1559219366239},{"_id":"source/_posts/C++学习之不常用的重要关键字.md","hash":"bd38fcfa1d9f65971f7dec39108997ebc3577637","modified":1559219366239},{"_id":"source/_posts/C++中使用YAML语言.md","hash":"bef60f8317a0f83ad55e69c66e191a1b100a2c5e","modified":1559219366239},{"_id":"source/_posts/C++学习之基础概念.md","hash":"b4b7107e77d9c333cd3eadabca2d1a6d1ca95829","modified":1559219366239},{"_id":"source/_posts/C++学习之复制构造函数.md","hash":"01192dd1d8be071fb31e040542280296142cd3d1","modified":1559219366239},{"_id":"source/_posts/C++学习之成员变量的初始化顺序.md","hash":"925db0bf09dbc8d2097aef0809350c6d294c398d","modified":1559219366239},{"_id":"source/_posts/C++学习之字符和字符串.md","hash":"0f39b1454e13b1824878ae5dd77fe68651418d87","modified":1559219366239},{"_id":"source/_posts/C++学习之智能指针.md","hash":"f67399c45224d8e8774824a0a90ff782aaa94243","modified":1559219366239},{"_id":"source/_posts/CMake编译调试.md","hash":"2df3594b02cf1d3025ec9e25680bffe1bea0691d","modified":1559219366239},{"_id":"source/_posts/CMake学习之查找链接库-find-package使用方法.md","hash":"395f645b49ca50e719e8b889b1958d4a98efedd5","modified":1559219366239},{"_id":"source/_posts/Caffe的CPU模式安装.md","hash":"d44a7b3ce449f966103287b71983428140dc279e","modified":1559219366239},{"_id":"source/_posts/Caffe的GPU模式安装.md","hash":"51432c7d87fdee8ea52f336c6bc70c5cfc330d6c","modified":1559219366239},{"_id":"source/_posts/Cartographer学习一论文阅读.md","hash":"599799e8d58433b6bfe63cbfc87d196e2814dbc7","modified":1559219366267},{"_id":"source/_posts/Cartographer学习三源码分析之ROS应用.md","hash":"8e461efdb69939a564fa48e5dec9caa1556dc837","modified":1559219366271},{"_id":"source/_posts/Cartographer学习二源码分析之核心代码.md","hash":"158d9bb9ef508d1ef8fd811bd067f3c8eff53566","modified":1559219366275},{"_id":"source/_posts/Docker学习之基础知识.md","hash":"a692f97d6de08f1d20bd83ee1bde80b09916f669","modified":1559219366279},{"_id":"source/_posts/Event-based特征追踪评估方法.md","hash":"143ea87d2cf4423857f0efad6ab32a77135e6c74","modified":1565747570472},{"_id":"source/_posts/Linux设置环境变量.md","hash":"4f8812c82565f7a2253f3b09a9953fc28e3fa090","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析九-ORB特征匹配.md","hash":"57fa63120aa77dbe12450a89270ce05b331fa9f3","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析七-LocalClosing.md","hash":"05456a48d2ff23bbcedc9a6b88a63d7aaa7458dc","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化.md","hash":"71df245ac20ebfebf1199d5f91cebb020139642a","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析五-一个变量引发的探索.md","hash":"011c2c534043b1b6c51e3131bbebaeabf2964583","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析八-单目初始化再学习.md","hash":"4ff2c1725608ea2f2b7505da8578130402174075","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析六-LocalMapping.md","hash":"fdb66a0d2591a71545a69da510d9f5bfece670f0","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析四-ORB特征及其提取.md","hash":"f6ad8e8f218a95c6a00ad6a595c40f95e49b0a5b","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案.md","hash":"bbb312e5504ba5bea1f49c9b8db540d074966dd9","modified":1559219366287},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪.md","hash":"a6e4ff61467404eff03b2f6fb27bdb7aff4cbf1a","modified":1559219366291},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化.md","hash":"6b42262e229abf38e11c97164b9f25729525a3f7","modified":1559219366295},{"_id":"source/_posts/ORB_SLAM2学习之运行ROS模块.md","hash":"fe164bbeceb5dbab68d1df34189fa7de2c00eeed","modified":1559219366295},{"_id":"source/_posts/ROS学习之Timer类.md","hash":"e557c610925be2309ea609577c818d82ef3f9ff5","modified":1559219366295},{"_id":"source/_posts/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge.md","hash":"886d765cc7743f59fb268a7028bdd40ecd81fe7f","modified":1559219366295},{"_id":"source/_posts/ROS学习之actionlib库（１）-actionlib库的介绍.md","hash":"5b0409f0ee5b5a2b2f53796f0aad45ab13245239","modified":1559219366295},{"_id":"source/_posts/ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器.md","hash":"ca449814504a14c91125495c8342ad7ace6b7461","modified":1559219366295},{"_id":"source/_posts/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器.md","hash":"e34fdf990cf60e534bafd34b354cb9be25547e78","modified":1559219366299},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形.md","hash":"fbaf15f01c925e6abbcff5f6ecdeff06d185cb67","modified":1559219366299},{"_id":"source/_posts/ROS学习之nodelet.md","hash":"eb10bec3fda0d9d4fa2f3c424d26c41c27eec5c3","modified":1559219366299},{"_id":"source/_posts/ROS学习之pluginlib.md","hash":"af670425925f784b0766c0ed1e15d1b6dd0f4ed7","modified":1559219366299},{"_id":"source/_posts/ROS学习之catkin CMakeList.txt介绍（译）.md","hash":"7adb824be0ccdbf8939c83f482721ae9de6d3555","modified":1559219366299},{"_id":"source/_posts/ROS学习之roslaunch.md","hash":"32923e6d9cbc72466d332605fdc130d850f4a578","modified":1559219366303},{"_id":"source/_posts/ROS学习之基于arbotix和rviz进行简单的机器人仿真.md","hash":"f61b842b5e0ef89415e8bc63b444887c5cafb359","modified":1559219366303},{"_id":"source/_posts/ROS学习之tf.md","hash":"78d6e9ae4247bce76c35716ab57c9df989869ed6","modified":1559219366303},{"_id":"source/_posts/ROS学习之创建工作空间、软件包.md","hash":"1ef5f89c8bec4e543bd03e6deeae1c5dc0088f2d","modified":1559219366303},{"_id":"source/_posts/ROS学习之基本概念和命令.md","hash":"d17b9997985922033aadf4f9df7507ae9b6a94bf","modified":1559219366303},{"_id":"source/_posts/ROS学习之消息过滤器messsage-filters.md","hash":"37b23a9bae9ff585da0ed1453c770bbdd1e57504","modified":1559219366303},{"_id":"source/_posts/ROS学习之编写简单的消息发布器和订阅器.md","hash":"26e7a7116cc27142fa51a155fe9132a2083de3e4","modified":1559219366303},{"_id":"source/_posts/ROS学习之编写简单的服务器和客户端.md","hash":"52fc6657b73b304443871f43c082055e13b886b2","modified":1559219366303},{"_id":"source/_posts/VSCode调试C-代码.md","hash":"4c29a2e9c0f3df82492d47c40bf38a58a2931a0f","modified":1559219366303},{"_id":"source/_posts/Tensorflow学习笔记.md","hash":"32024b8b55185b4ebfbbc1fb6fccb892738efa1b","modified":1560407217217},{"_id":"source/_posts/coding-net-git.md","hash":"1d965a1ad9e8538c3d69474343f0e9a4e9cb6f56","modified":1559219366303},{"_id":"source/_posts/Zotero基于坚果云实现多机同步.md","hash":"8a462234f819d57b5be88a2eda1a82f1fb4efc3f","modified":1559219366303},{"_id":"source/_posts/lightweight_mapping学习之MapDrawer.md","hash":"74232f8b3ce6b363b02df23a56a1e246755a60f1","modified":1559219366303},{"_id":"source/_posts/python学习记录.md","hash":"728aa3ebb117e9fdad3b1ed4047069d586be25f4","modified":1565916658228},{"_id":"source/_posts/lightweight_mapping学习之LocalMeshing.md","hash":"fb9bd2d3ad2deaef18988834207f76f5516747b3","modified":1559219366303},{"_id":"source/_posts/ubuntu16.04 Hexo+github+Typora搭建博客.md","hash":"fa49a054f7c327487bb233f32f7642156866e1db","modified":1559219366303},{"_id":"source/_posts/ubuntu一些方便的命令.md","hash":"f58ec6c18f267eba576f1fc7624a579bb720dc6e","modified":1559219366303},{"_id":"source/_posts/ubuntu学习之update和upgrade.md","hash":"d55165578468ec39319dfc7c735dd603463fcca7","modified":1559219366303},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决.md","hash":"1dc6a06ccb99f2c0b2c4a9862c5603ba456abe71","modified":1559219366303},{"_id":"source/_posts/图像处理之基础知识.md","hash":"78542146956f5c7bdcb4b303a638d6a30fb47313","modified":1559219366303},{"_id":"source/_posts/当前开源SLAM方案一览.md","hash":"36a8219a21031a6a627e8375170fce79e4b3310c","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记一.md","hash":"6a4ce8a31f0409cce1245d10645ac5b58c2233d4","modified":1559219366303},{"_id":"source/_posts/test.md","hash":"67b005c5e5aa9609e5fc6668e13112336fb5ae8a","modified":1559220218939},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记七-双目相机模型.md","hash":"653360c54c64305fdfb471ad0fc5ba9cd2ae66fd","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何.md","hash":"1d99b017ac92d4b60e443c590027df5ee2689970","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记二-SLAM的数学表述.md","hash":"e8971fb9e0bc8a1afca1e20065f9ffbdf8c5f125","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记五-图优化与g2o基础.md","hash":"52454437c1d899c12acd2f776a90642f35992146","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记八-图像表示与存储.md","hash":"f6e87c8f6b582c709202cd46a18c184232a67e50","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型.md","hash":"282e2d146389ca699acd65d83213894ebbd7135c","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记四-三角测量.md","hash":"1d865dd4d67e66d4e6e8bd7b47df6e23d32ec0ad","modified":1559219366307},{"_id":"source/_posts/论文阅读之《DTAM-Dense-Tracking-and-Mapping-in-Real-Time》.md","hash":"fc8b2171a01357314ff65fc6aab6ea290da45aba","modified":1559219366307},{"_id":"source/_posts/论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》.md","hash":"8afd27acf2d8c4e5c7e183500269b887560a29be","modified":1559219366307},{"_id":"source/_posts/视觉SLAM基础学习之非线性最小二乘问题求解方法.md","hash":"04166428987a95fc132bf2ec42acc5cf89953bdc","modified":1559219366307},{"_id":"source/_posts/论文阅读之主流VSLAM算法初始化总结.md","hash":"78b55772341d5508e860bb79cf8815bbd6c359c8","modified":1559219366307},{"_id":"source/_posts/论文阅读之《Past, Present, and Future of SLAM》.md","hash":"cfef3bdf876390c28e28e771d79ee4f5303b608c","modified":1559219366307},{"_id":"source/_posts/跨平台可视化库Pangolin.md","hash":"ea53db9e74bceae92d2f00975d82d49730a2ef15","modified":1559219366307},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1559219366315},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1559219366315},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1559219366315},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1559219366315},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1559219366315},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1559219366319},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1559219366319},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1559219366319},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1559219366319},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1559219366319},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1559219366319},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1559219366319},{"_id":"themes/next/scripts/fold.js","hash":"5b1043f098740b97268b809e5651d11baad537cf","modified":1559219366319},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1559219366319},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1559219366319},{"_id":"themes/next/scripts/tags.js","hash":"1856eb597206957085c7fdd1c9115ed4b9bcd50a","modified":1559219366319},{"_id":"source/about/index.md","hash":"4ff3f261754e2285b59ef8db59e06a3596718b2b","modified":1559219366307},{"_id":"source/categories/index.md","hash":"29a443f31e81d982011df5ba61f97bebbae59062","modified":1559219366307},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》.md","hash":"10b99a0765a31230a07ac8bf66314f1509fc2e25","modified":1559219366307},{"_id":"source/tags/index.md","hash":"714997c6799fd2a975e98176fdc14cac5d8997c0","modified":1559219366307},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1559219366335},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1559219366335},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1559219366335},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366323},{"_id":"source/_posts/C++学习之STL sort排序.md","hash":"0413a39bd66f33e5dd0d8d3b0825fdba7ea0ccf0","modified":1559219366239},{"_id":"source/_posts/C++学习之explicit关键字详解.md","hash":"04a1de5f8e6aca20c5878ce9d61c411bc6c6c4fa","modified":1559219366239},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA.png","hash":"80ff063007c469a4e6fd72df2fc685083c8c0b12","modified":1559219366243},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA和驱动版本对应.png","hash":"758c48aad359c7c1700b9d997efd44371a585ea0","modified":1559219366247},{"_id":"source/_posts/Cartographer学习一论文阅读/submap.png","hash":"cf85d9450d7c2ad066b5b67aefb3f6021b9ba2c8","modified":1559219366267},{"_id":"source/_posts/Cartographer学习一论文阅读/系统图.png","hash":"deaf09581d5e9af412d7a4e571dbdf0d4ab2abb9","modified":1559219366271},{"_id":"source/_posts/Cartographer学习一论文阅读/网格点和相关像素.png","hash":"8c482cc94e5befe6bc51dec50b86067449770511","modified":1559219366271},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA测试.png","hash":"a8857a5159cb9d53931958566e72341cd33a55c7","modified":1559219366247},{"_id":"source/_posts/Cartographer学习三源码分析之ROS应用/ROS框架.png","hash":"41d438c831f23e231ee5b3e3d0843d97d11194f8","modified":1559219366271},{"_id":"source/_posts/Docker学习之基础知识/docker-filesystems-multilayer.png","hash":"9c9d10d57c4ed3bd676ff02f5ed04f58be7d9000","modified":1559219366283},{"_id":"source/_posts/Docker学习之基础知识/flocker.jpg","hash":"dae43774323f3636331689dd9aeb603bf2a1a29f","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析七-LocalClosing/LocalClosing.png","hash":"8e9cc79212fcad41b5c4236db67ad3d2b75bfa8a","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析九-ORB特征匹配/直方图.png","hash":"a121dbe26767bf04bdf2ada0cf7e6be032da71b1","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化/ExtractORB.png","hash":"5149deccc2c90a1fdfd3c1197a12566f36333a7d","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化/双目初始化.png","hash":"0f435ae3c9fd4dc4e01439ced8f2761c9264d5ee","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析八-单目初始化再学习/模型打分公式.png","hash":"310e2d480624a93ca1b5be6dbd8b3619782ffc0d","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析八-单目初始化再学习/得分计算公式.png","hash":"8348eae0e457f43b66979201884bc9261aa30fd3","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/ORB世界坐标系.png","hash":"ada65645f49c0f731eff2ed5e01533dc80dbd614","modified":1559219366287},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/Rviz世界坐标系.png","hash":"a75645ad9689fca62db6a50fe4baf3036e806af9","modified":1559219366287},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/相机坐标系.png","hash":"74d21815fc2f2fee35222f84a677fb064fc8da42","modified":1559219366287},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/Sim3上的位姿优化.png","hash":"8d5051e3cf33ad9910d9195ac80dca0095cd5016","modified":1559219366295},{"_id":"source/_posts/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/git.png","hash":"572b0c208292d4aef7981d7fad104d4df533fd21","modified":1559219366295},{"_id":"source/_posts/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/git2.png","hash":"7d84029e4a2c050b58c0352cbec94864bd3cefe3","modified":1559219366295},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形/五边形.png","hash":"4693571b85a008402d1d44f071a53fbf3bcb82fb","modified":1559219366299},{"_id":"source/_posts/lightweight_mapping学习之LocalMeshing/Delanunay三角剖分.png","hash":"49c67b529f47a33abe614c662d534975134c509d","modified":1559219366303},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/删除前.png","hash":"1761ef86648e3a44201ac5bfe0feed9f11657175","modified":1559219366303},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/错误提示.png","hash":"c846b1f5b7bc4b686432a29662d7717a35c1f1a7","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何/对极几何约束.png","hash":"24e94bf4a4564382611e5395fb1b990cc2cfec68","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何/归一化坐标.png","hash":"8ad5b31495b0b96949513699ffb19343bbaf515f","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何/本质矩阵的解.png","hash":"1f229fc6be7cd10f5a4a18b1ae39dfa6d819c1eb","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记二-SLAM的数学表述/视觉SLAM经典框架.png","hash":"6047a25202050c0f0eb5473bcfa0169d34d4f7a3","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记八-图像表示与存储/表示和存储.png","hash":"bf73cc967f0b89fde71fc25473dc4580caf00544","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型/像素坐标系.png","hash":"dc86db52df1121ec249d6e1e2f29c027c4251d10","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型/相机坐标系.png","hash":"b32513c1ef3a9ecfac309f859d4ceef6dc054fe1","modified":1559219366307},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/删除后.png","hash":"c3a1c97af068727d23aecee5ffdc8a10ea52cf15","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记四-三角测量/三角测量.png","hash":"610ee2aa02a3e6ab00d62174b3e0ed5c1095f133","modified":1559219366307},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记四-三角测量/三角测量的矛盾.png","hash":"8e30f3cb712ffdeab1e081bd1b10dae28cca05b6","modified":1559219366307},{"_id":"source/_posts/视觉SLAM基础学习之非线性最小二乘问题求解方法/newton.png","hash":"b0e56bd9e9509c17a446f191cbcaa073ff6b2119","modified":1559219366307},{"_id":"source/_posts/论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》/patchsearch.png","hash":"359990887d688c687b88b07d52274da2fad801be","modified":1559219366307},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/a.png","hash":"2f377973a2544a5e498cc0930b1fedc6f05072c2","modified":1559219366307},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/b.png","hash":"476d1386a8197cc9e7d1f544609e7a5a3db41012","modified":1559219366307},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/c.png","hash":"a0b45134314ed0426afb82010c858c48a0468766","modified":1559219366307},{"_id":"source/_posts/跨平台可视化库Pangolin/三角形.png","hash":"936530736f1d50d90f1d34dad49d30d641f62fd4","modified":1559219366307},{"_id":"themes/next/layout/_partials/footer.swig","hash":"4d482139b398080dc51ad7d775e9bde89d4579ff","modified":1559219366319},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1559219366319},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1559219366319},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1559219366319},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1559219366319},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1559219366319},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1559219366319},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1559219366319},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1559219366319},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1559219366319},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1559219366319},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1559219366319},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1559219366319},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1559219366319},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1559219366319},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1559219366319},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1559219366319},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1559219366319},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1559219366319},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1559219366319},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1559219366319},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1559219366319},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1559219366319},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1559219366319},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1559219366319},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1559219366319},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1559219366315},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1559219366315},{"_id":"themes/next/layout/_macro/my-copyright.swig","hash":"89c49d739624dc7ed41adfa76b4f07c742072588","modified":1559219366315},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1559219366323},{"_id":"themes/next/layout/_macro/passage-end-tag.swig","hash":"560f043e8f4353fa0101014748e40a58d2d57506","modified":1559219366315},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1559219366315},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1559219366315},{"_id":"themes/next/layout/_macro/post.swig","hash":"2bdc3e6c54f781c3d6dba838c21d4af8f941141d","modified":1559219366319},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1559219366319},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1559219366319},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1559219366319},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1559219366323},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1559219366323},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1559219366323},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1559219366323},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1559219366323},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1559219366323},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1559219366323},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1559219366323},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1559219366323},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1559219366323},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1559219366323},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1559219366323},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1559219366323},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1559219366323},{"_id":"themes/next/source/images/photo.jpg","hash":"3d833470d8f35a46e69a3a8e637da4f7af01eb1e","modified":1559219366323},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1559219366323},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1559219366323},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1559219366323},{"_id":"themes/next/source/images/weixin.jpg","hash":"a8883595c472d9588f2e6a7a15ed247d4ed5aa6d","modified":1559219366323},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1559219366323},{"_id":"source/_posts/Caffe的GPU模式安装/nvidia安装成功.png","hash":"21ca1a24d0e9393856d37b001d671558daa8b0e8","modified":1559219366251},{"_id":"source/_posts/Caffe的GPU模式安装/cuDNN.png","hash":"a933b853174b7bd61c60c7c6c24c58e77ef085e7","modified":1559219366251},{"_id":"source/_posts/Cartographer学习一论文阅读/暴力搜索.png","hash":"e4074a3f7a5fd088104bdabc61aadaadfb41948c","modified":1559219366267},{"_id":"source/_posts/Cartographer学习一论文阅读/算法2.png","hash":"6afd71b309bfc73a78d9d75c4d5cb790e6ca77ca","modified":1559219366271},{"_id":"source/_posts/Cartographer学习一论文阅读/算法3.png","hash":"87e71d16138969160f8b591adb41fd19755ec0e7","modified":1559219366271},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化/单目初始化.png","hash":"315344ff87fc3ca7458ea8e5f5bb3e0b312ebab3","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析六-LocalMapping/LocalMapping.png","hash":"4f7178afd52a46883cade54e945585a521288210","modified":1559219366283},{"_id":"source/_posts/ORB-SLAM2学习之源码分析六-LocalMapping/slam框架.png","hash":"59ce8d2a245def44e30c6c2aa13abba5c71d641e","modified":1559219366283},{"_id":"source/_posts/ORBSLAM2学习之运行ROS模块/2.png","hash":"ff82eeb71650a109001db98bd1ed5c13f82a26dc","modified":1559219366287},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/SLAM视觉里程计.png","hash":"75a24ac2619b9795d404b95e9a82c13b28b85427","modified":1559219366291},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/Track.png","hash":"837abc3519effb6f2335367003cbd6708737ead4","modified":1559219366291},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/Tracking重点环节.png","hash":"fb1f769d0d4119019f55d271cfa707e00d5a35ad","modified":1559219366291},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/局部地图示意图.png","hash":"3da34210ca1fa3a88acf10a773c98268c3b39154","modified":1559219366295},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/全局优化.png","hash":"2f9d5e0abfce80908f0abd5146af4ea468d4d12b","modified":1559219366295},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/闭环处优化.png","hash":"dd009e6a51c7cc378153e0caa6166ee0bb9a974d","modified":1559219366295},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/局部优化.png","hash":"3da34210ca1fa3a88acf10a773c98268c3b39154","modified":1559219366295},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形/交互图.png","hash":"26d1a7798d1b42cbf597bc910ce30b0ee5476096","modified":1559219366299},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/磁盘分析.png","hash":"f25f0d500463b082cb288a8947ecaad97ed39163","modified":1559219366303},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记八-图像表示与存储/图像坐标示意图.png","hash":"bf9b5a6fc4ad928d8b4cff93169775812573ea41","modified":1559219366307},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/SVO追踪与建图.png","hash":"c0e92061a63b90473f14003dae9949163c61522b","modified":1559219366307},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366319},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366319},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366319},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366319},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366319},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366323},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1559219366323},{"_id":"themes/next/source/uploads/hexo.jpg","hash":"238b746202196a285f4ecac50dda0490e5ce8de9","modified":1559219366335},{"_id":"themes/next/source/images/hexo.jpg","hash":"238b746202196a285f4ecac50dda0490e5ce8de9","modified":1559219366323},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/Tracking跟踪模型.png","hash":"b45e6d9dbec829c37e982d010f2279fbe08a96ce","modified":1559219366291},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型/针孔相机模型.png","hash":"65d35e5e6450c51f2a4493994eb90d75e8bdba46","modified":1559219366307},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1559219366319},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1559219366319},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1559219366319},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1559219366319},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1559219366319},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1559219366319},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1559219366319},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1559219366319},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1559219366319},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1559219366319},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1559219366319},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1559219366319},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1559219366319},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1559219366319},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1559219366319},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1559219366319},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1559219366319},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1559219366319},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"1e48ed146cde22553e2754a2293a8d3b79d26514","modified":1559219366319},{"_id":"themes/next/source/images/zhifubao.jpg","hash":"e9c2c9611fd3fd19d38cc49148690a6072cc2f0d","modified":1559219366323},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1559219366319},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1559219366319},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1559219366319},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1559219366323},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1559219366323},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1559219366323},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1559219366323},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1559219366327},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1559219366327},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1559219366327},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1559219366327},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1559219366327},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1559219366327},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1559219366327},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1559219366331},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1559219366331},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1559219366331},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1559219366331},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1559219366331},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1559219366331},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1559219366331},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1559219366331},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1559219366331},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1559219366331},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1559219366331},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1559219366331},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1559219366331},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1559219366331},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1559219366323},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1559219366323},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1559219366323},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1559219366323},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1559219366323},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1559219366323},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1559219366323},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1559219366323},{"_id":"themes/next/source/js/src/post-details.js","hash":"8bb973f5f74070c31f3338a744df33469bf008ff","modified":1559219366323},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1559219366323},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1559219366323},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1559219366335},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1559219366335},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1559219366335},{"_id":"themes/next/source/images/1703706832.jpg","hash":"e010f5adee6c55ad1b9d5ff6c6b6ebf56e1d59de","modified":1559219366323},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1559219366335},{"_id":"source/_posts/Cartographer学习二源码分析之核心代码/Cartographer系统框架图.png","hash":"cdb5b65ea332f81e9d68cf06fa7fddb2ecd54997","modified":1559219366275},{"_id":"source/_posts/ORBSLAM2学习之运行ROS模块/1.png","hash":"3ddbb32a36d378496773bd25b10331657c9d7660","modified":1559219366287},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1559219366335},{"_id":"source/_posts/ROS学习之actionlib库（１）-actionlib库的介绍/节点图.png","hash":"094caf5c063a30b0996a7d17ebf790f81cc1d13e","modified":1559219366295},{"_id":"source/_posts/ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器/节点图.png","hash":"b9ecd6a8731cc674f049c22d4350adc2307a3d5e","modified":1559219366299},{"_id":"source/_posts/ROS学习之pluginlib/pluginlib.png","hash":"e4295d05b85a22610ec2f33095bc123e50959d15","modified":1559219366303},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1559219366319},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1559219366331},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/pcl点云显示.png","hash":"b31752180dee6ebd9c6d275a2daa4645f0fff1a8","modified":1559219366287},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/运行结果.png","hash":"915a2f5d0fd76845beb09e5652a162dfe724c85e","modified":1559219366287},{"_id":"source/_posts/ORBSLAM2学习之运行ROS模块/3.png","hash":"99e0e0082bea7f18897318ddc3d662ab31c2962f","modified":1559219366291},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形/节点图.png","hash":"816c18ac3d7833e9024d128037622fd564dc2552","modified":1559219366299},{"_id":"source/_posts/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器/节点图.png","hash":"a742d72ab6900d8993742be069efdd8a769587f3","modified":1559219366299},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1559219366319},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1559219366319},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1559219366319},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1559219366319},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1559219366319},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1559219366319},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1559219366319},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1559219366319},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1559219366319},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1559219366319},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1559219366323},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1559219366327},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1559219366327},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1559219366327},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1559219366319},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1559219366323},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1559219366335},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1559219366335},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/SLAM视觉里程计特征点法.png","hash":"fd627ac5267142ea3ccf20b1d97efb19ddb76abc","modified":1559219366291},{"_id":"source/_posts/Cartographer学习三源码分析之ROS应用/cartographer_old.png","hash":"e58d70b8482ffaee0c66e8fb0c658a8c2d3a501c","modified":1559219366275},{"_id":"source/_posts/Docker学习之基础知识/bootfs.jpg","hash":"01142f86f5635ec2c041a775ded3f9d1b666fdb0","modified":1559219366279},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1559219366323},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1559219366327},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1559219366331},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1559219366331},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1559219366327},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1559219366335},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA9安装.png","hash":"dfcb681be29d2d9b21936a31043cda65e989d8ce","modified":1559219366247},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/my-post-copyright.styl","hash":"1a510f995e665b28d85ba4d169b824276c40e4f3","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"718453f2053841ebc26f5079425b2e0fd0542d58","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1559219366319},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1559219366323},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1559219366323},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1559219366327},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1559219366323},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1559219366323},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1559219366323},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1559219366323},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1559219366323},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1559219366327},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1559219366327},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1559219366319},{"_id":"source/_posts/Caffe的GPU模式安装/samples.png","hash":"ffff9be0c2d2583118bee582841a29b3b0419c0f","modified":1559219366255},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1559219366319},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1559219366319},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1559219366331},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1559219366331},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1559219366327},{"_id":"themes/next/source/images/wo.png","hash":"4e42daf0173bbd7a3d4c8587c37d965de7a7c657","modified":1559219366323},{"_id":"source/_posts/Cartographer学习二源码分析之核心代码/整体流程.png","hash":"027095fcba9e8469340c2efbee24be29bb290363","modified":1559219366279},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1559219366335},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1559219366331},{"_id":"public/search.xml","hash":"b23e678c0517efa6529a1110df2eacae07fcafa9","modified":1565916704221},{"_id":"public/atom.xml","hash":"656c0126d752813bb55a54625f930c3ba29269ff","modified":1565916704221},{"_id":"public/baidu_verify_aia7zPmTuu.html","hash":"595466bbf50ef64997df9e3cedd69c808e65b9b1","modified":1565916708142},{"_id":"public/tags/index.html","hash":"68fbd49a30555a92125abfc5420effdee81db39d","modified":1565916708142},{"_id":"public/categories/index.html","hash":"bfc708ec7207d0588716dcee8b784c62a7e83942","modified":1565916708175},{"_id":"public/2019/05/27/视觉SLAM基础学习之非线性最小二乘问题求解方法/index.html","hash":"c51a83423154b772730764926ebb75d9b43411aa","modified":1565916708175},{"_id":"public/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/index.html","hash":"5f4f5d7346e9e7aab3ef56521941087cbc047ce8","modified":1565916708175},{"_id":"public/about/index.html","hash":"3e82b8fffac6be0bcacc0e32758db090df20c67c","modified":1565916708175},{"_id":"public/2019/05/20/论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》/index.html","hash":"5ffb26759be7ccec88c04c988ae3df80d966734e","modified":1565916708175},{"_id":"public/2019/05/30/test/index.html","hash":"d9d762889d0a14a48e26854ccd66c897d74addcc","modified":1565916708175},{"_id":"public/2019/05/24/论文阅读之《DTAM-Dense-Tracking-and-Mapping-in-Real-Time》/index.html","hash":"eff1975f6fe57cae21b9620a0039a880a33e02f5","modified":1565916708175},{"_id":"public/2018/10/14/ORB-SLAM2系统Rviz可视化方案/index.html","hash":"ee86429260f8c96c0bcd16ee2f52905bd4460327","modified":1565916708175},{"_id":"public/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/index.html","hash":"713dd47e76585679045578df40ce62724a682576","modified":1565916708175},{"_id":"public/2019/05/23/论文阅读之主流VSLAM算法初始化总结/index.html","hash":"8b5a66eed5d528b268a95306d9a17a2528433434","modified":1565916708175},{"_id":"public/2018/09/19/Cartographer学习三源码分析之ROS应用/index.html","hash":"fed0939b06b0401339104554b75d00cc05d4319a","modified":1565916708175},{"_id":"public/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/index.html","hash":"931bf2be027d95fdd6bdc2c75611f31a0ca65bcc","modified":1565916708175},{"_id":"public/2018/09/16/Cartographer学习二源码分析之核心代码/index.html","hash":"23f462283fccb5f633dfafc0013eee882d44803f","modified":1565916708176},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/index.html","hash":"9da0874f52071091e5d3625f944f7a789332f692","modified":1565916708176},{"_id":"public/2018/09/08/Caffe的GPU模式安装/index.html","hash":"f2c5b23936cd6e284ba87d46a82e06b8ebb6dad0","modified":1565916708176},{"_id":"public/2019/04/29/VSCode调试C-代码/index.html","hash":"a4d1dacc70d2d20222f37c46da83edc9e11aaf97","modified":1565916708176},{"_id":"public/2018/09/05/跨平台可视化库Pangolin/index.html","hash":"d3b95feb44908f535c0178a68b34c20668975a92","modified":1565916708176},{"_id":"public/2018/09/04/lightweight_mapping学习之LocalMeshing/index.html","hash":"8de528235ecf43bbbfae4199ff3e8b779b3190ee","modified":1565916708176},{"_id":"public/2018/10/17/论文阅读之《Past, Present, and Future of SLAM》/index.html","hash":"951380820186eb8954d2660cd673808cbd6b7b67","modified":1565916708176},{"_id":"public/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/index.html","hash":"1fa76fd4418abf39b695ea1d0a18c014e6ea3f89","modified":1565916708176},{"_id":"public/2018/09/26/当前开源SLAM方案一览/index.html","hash":"ca595c69f483c324440e5506529fd1f711e1b452","modified":1565916708176},{"_id":"public/2018/08/30/ORB-SLAM2学习之源码分析九-ORB特征匹配/index.html","hash":"5815ea7decc975d0157d586705e126f90cad1469","modified":1565916708176},{"_id":"public/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/index.html","hash":"4a8600401692e4e1dc204a72a6705a54b06b3d89","modified":1565916708176},{"_id":"public/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/index.html","hash":"d096c8afe630bb3986f91309259def853be4168d","modified":1565916708176},{"_id":"public/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/index.html","hash":"21fc7e6293ad88244ca1ee7553f253d9e9641fa6","modified":1565916708176},{"_id":"public/2018/08/23/ORB-SLAM2学习之源码分析七-LocalClosing/index.html","hash":"ee0174808ed2f834079bc9f4bfe1b80ffd60931f","modified":1565916708176},{"_id":"public/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/index.html","hash":"7230bdf1304d48cddace714ec484be22efd08033","modified":1565916708176},{"_id":"public/2018/09/06/lightweight_mapping学习之MapDrawer/index.html","hash":"1c3a6f017c2429f9d44d7fa0e1c30c9e63d5ae27","modified":1565916708176},{"_id":"public/2018/09/01/视觉SLAM十四讲阅读笔记七-双目相机模型/index.html","hash":"3b41b788c674503ba3206e3b88cced39f51c2428","modified":1565916708176},{"_id":"public/2018/08/18/ORB_SLAM2学习之源码分析三-优化/index.html","hash":"2d0714bf0e7faad7d6e9d1b2a1fcb18af41eadf2","modified":1565916708176},{"_id":"public/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/index.html","hash":"d77f791b65f6e570a0b929a267a6130884df61ea","modified":1565916708177},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/index.html","hash":"16a5bd3bafe7c88269f239e7f40cda5e3cae93e4","modified":1565916708177},{"_id":"public/2018/08/31/视觉SLAM十四讲阅读笔记五-图优化与g2o基础/index.html","hash":"d2b6963122698e36bc7ef8142a709062dd45737b","modified":1565916708177},{"_id":"public/2018/08/11/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/index.html","hash":"589ae355b9f6f27d8dcf7fda457d9ea92be92148","modified":1565916708177},{"_id":"public/2018/08/20/ORB-SLAM2学习之源码分析五-一个变量引发的探索/index.html","hash":"a7a305aff4ce289e7c819151268f99aedf7fc6e1","modified":1565916708177},{"_id":"public/2018/08/19/ORB-SLAM2学习之源码分析四-ORB特征及其提取/index.html","hash":"f7108f5eca113c3afb3c5918dc498f6ddf83bab0","modified":1565916708177},{"_id":"public/2018/08/12/ORB_SLAM2学习之运行ROS模块/index.html","hash":"91ca0bd52bc77290f9f078c21c2d51637d7aa6c8","modified":1565916708177},{"_id":"public/2018/08/05/视觉SLAM十四讲阅读笔记二-SLAM的数学表述/index.html","hash":"0143fc843be55c15095873df185f8144fe48401b","modified":1565916708177},{"_id":"public/2018/08/10/Zotero基于坚果云实现多机同步/index.html","hash":"ecd71eeaa0fdc1591d58764725429712e58bcf00","modified":1565916708177},{"_id":"public/2018/08/08/ROS学习之消息过滤器messsage-filters/index.html","hash":"b9b17487dcce0a7ae39e39a2a78a440d01c11e1e","modified":1565916708177},{"_id":"public/2018/08/07/Linux设置环境变量/index.html","hash":"ee500fa825a821dca3fe8bbaa045aecb81536325","modified":1565916708177},{"_id":"public/2018/08/04/视觉SLAM十四讲阅读笔记一/index.html","hash":"5ae86e62ecf134c6568b0ca54f9eb76922eac996","modified":1565916708177},{"_id":"public/2018/08/03/CMake学习之查找链接库-find-package使用方法/index.html","hash":"4694aaac388a7e4726652242a07524663eb6b7ea","modified":1565916708177},{"_id":"public/2018/08/02/coding-net-git/index.html","hash":"b208b50aaf94dccbceebbaf09bc819119f73126d","modified":1565916708177},{"_id":"public/2018/05/13/Docker学习之基础知识/index.html","hash":"1e1ce9626a2b146b30ddc504da96d6ac389fde31","modified":1565916708177},{"_id":"public/2018/06/21/图像处理之基础知识/index.html","hash":"ab311f3e3c36af139059f7e691529d3efdbc1300","modified":1565916708178},{"_id":"public/2018/05/24/ROS学习之roslaunch/index.html","hash":"95a648f8d59254fb38fa6b07994e7ab76068a302","modified":1565916708178},{"_id":"public/2018/05/23/C++中使用YAML语言/index.html","hash":"e06b3f4fe40cc5146675134e20a956c8695df6d8","modified":1565916708178},{"_id":"public/2018/05/10/ROS学习之创建工作空间、软件包/index.html","hash":"e244f97f58f3033a108c1fbd3364fb0fb37c2f5b","modified":1565916708178},{"_id":"public/2018/05/09/C++学习之智能指针/index.html","hash":"0cea1ce4bb4274a8c503929efefb09d35aa3087c","modified":1565916708178},{"_id":"public/2018/05/09/C++学习之explicit关键字详解/index.html","hash":"a2cb03c679063513d396d5795d5df9432ee78f05","modified":1565916708178},{"_id":"public/2018/04/29/CMake编译调试/index.html","hash":"676d93af9e87fdd0eb2baadde49a624ff94471a8","modified":1565916708178},{"_id":"public/2018/04/21/Caffe的CPU模式安装/index.html","hash":"5fc9e4c1d51e4ab6c4c3a087a801a47b5f43075b","modified":1565916708178},{"_id":"public/2018/04/21/ubuntu一些方便的命令/index.html","hash":"29c0122cb0612fafdb595ed1fa4795c692962478","modified":1565916708178},{"_id":"public/2018/04/16/C++学习之复制构造函数/index.html","hash":"a5c454bdeeadd290651a896f5eb84ee153b0209e","modified":1565916708178},{"_id":"public/2018/04/12/C++学习之STL sort排序/index.html","hash":"a55559c7912dd964c585ccf331fc604fd9bee43f","modified":1565916708178},{"_id":"public/2018/04/03/ROS学习之pluginlib/index.html","hash":"fbf5fe63001f3d3adddfaad83a27615d58f673a2","modified":1565916708178},{"_id":"public/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/index.html","hash":"474861b41fd66f022a12ba943a7919942aa9f067","modified":1565916708178},{"_id":"public/2018/03/30/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器/index.html","hash":"6103f1af67f90686309b0c6e492d8d7448a2cab2","modified":1565916708178},{"_id":"public/2018/03/30/ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器/index.html","hash":"6884b02b49ca2672784008859fa21228b8dda454","modified":1565916708178},{"_id":"public/2018/03/29/ROS学习之actionlib库（１）-actionlib库的介绍/index.html","hash":"dd8f4e5ef5a288739bc1622a0bd348897886ba4e","modified":1565916708178},{"_id":"public/2018/04/04/ROS学习之tf/index.html","hash":"61bd0d7fd8e14a1b5a6ff639bd02b68cf803e9f5","modified":1565916708179},{"_id":"public/2018/04/11/C++学习之基础概念/index.html","hash":"a2ff4bbd76bff2b6ae4d4dbb54cb010a374b3c22","modified":1565916708179},{"_id":"public/2018/04/04/ROS学习之nodelet/index.html","hash":"cf5e942a221c3c1cba7bdb2a921f221f8d39ff08","modified":1565916708179},{"_id":"public/2018/03/29/C++学习之不常用的重要关键字/index.html","hash":"1b8606448caf163254cb359e0b5224616c8701c6","modified":1565916708179},{"_id":"public/2018/03/28/ROS学习之编写简单的服务器和客户端/index.html","hash":"1741fb45962444bcbb29291aefde24b359cb4f68","modified":1565916708179},{"_id":"public/2018/03/29/ROS学习之Timer类/index.html","hash":"724258eabdf8383df3d5e4d18b049852efd7f5de","modified":1565916708179},{"_id":"public/2018/03/28/ROS学习之编写简单的消息发布器和订阅器/index.html","hash":"99ca3045bcfc71ad0d89f61ca12aba5f4b9d28c1","modified":1565916708179},{"_id":"public/2018/03/27/ROS学习之基于arbotix和rviz进行简单的机器人仿真/index.html","hash":"1c749d4b889625539e7980ffc372bdfa45437b87","modified":1565916708179},{"_id":"public/2018/03/28/C++学习之成员变量的初始化顺序/index.html","hash":"9f1529988043ccfa0110ba4386c23ec2be72e9e3","modified":1565916708179},{"_id":"public/2018/03/23/C++学习之const关键字/index.html","hash":"e9acd4ded74ad73c40b6182f2c3d767a3770bb07","modified":1565916708179},{"_id":"public/2018/03/27/ubuntu学习之update和upgrade/index.html","hash":"13f2fb78190fa6247e940837f16068fa909759de","modified":1565916708179},{"_id":"public/2018/03/23/C++学习之字符和字符串/index.html","hash":"c24c13d12bb239cfe607159f41544ce5da6b5df8","modified":1565916708179},{"_id":"public/archives/index.html","hash":"d79cec2cb6e0280dad5faf2f7b9b38a5df537bff","modified":1565916708179},{"_id":"public/2018/03/22/ROS学习之基本概念和命令/index.html","hash":"0334509a7113c9bf15a436b0d28a70226a577a0b","modified":1565916708179},{"_id":"public/2018/03/21/ubuntu16.04 Hexo+github+Typora搭建博客/index.html","hash":"50816cb76e89b46f1faa78a6135d4f149c6a9543","modified":1565916708179},{"_id":"public/2018/03/21/ROS学习之catkin CMakeList.txt介绍（译）/index.html","hash":"d6b0567a5a322b3f8c926a4ac59bcdc7158b811c","modified":1565916708179},{"_id":"public/archives/page/2/index.html","hash":"abeca14baafac6645b56c7f26ba87d7215b90f18","modified":1565916708179},{"_id":"public/archives/page/3/index.html","hash":"84caa7085c7b256afaef96793e7e7332c03f2e12","modified":1565916708179},{"_id":"public/archives/page/4/index.html","hash":"ade8b44eb1c42cb72d0276719bd1ec3fe147436e","modified":1565916708180},{"_id":"public/archives/page/6/index.html","hash":"8797ac7cf72426cb76229eadee2aac016c4504b3","modified":1565916708180},{"_id":"public/archives/2018/index.html","hash":"6f3bea23e95172171bb56523671a02b5e2481558","modified":1565916708180},{"_id":"public/archives/page/7/index.html","hash":"e037e351a995f188132696a95afc425f022d4a2d","modified":1565916708180},{"_id":"public/archives/page/8/index.html","hash":"ef4d7c0d68e161f38027ca9bea0135e38cb69245","modified":1565916708180},{"_id":"public/archives/2018/page/2/index.html","hash":"7ac1f0c0d2f18126e0dda23db16f7039d46c1bc0","modified":1565916708180},{"_id":"public/archives/2018/page/3/index.html","hash":"833fc3848ed0eeab536311849429d48b0f5b4f5f","modified":1565916708180},{"_id":"public/archives/2018/page/4/index.html","hash":"84c2610e097347196a1c4e542d99b4ab8e6b8eb4","modified":1565916708180},{"_id":"public/archives/2018/page/5/index.html","hash":"08798552b0332f15c34a3ccca862d7d8e0bb0249","modified":1565916708180},{"_id":"public/archives/2018/03/index.html","hash":"309a3ce83269ce6316f05a626e642f001f325bda","modified":1565916708180},{"_id":"public/archives/2018/page/6/index.html","hash":"131fe90949106737962c388077dee34adf7271c7","modified":1565916708180},{"_id":"public/archives/2018/page/7/index.html","hash":"f6b18e200821f9c1cead6ab14b34193cb0bf3910","modified":1565916708180},{"_id":"public/archives/2018/03/page/2/index.html","hash":"274baa47b5f79227a93453c20975a687ffa6b54f","modified":1565916708180},{"_id":"public/archives/2018/04/index.html","hash":"35334810ab10ac316c7537cca1db27ab5831c0c8","modified":1565916708180},{"_id":"public/archives/2018/08/index.html","hash":"61cbc76f49c57ed4370c9487acb781671faaa236","modified":1565916708180},{"_id":"public/archives/2018/08/page/2/index.html","hash":"7cf95ff6a5c62ac756fb219e48f69d7752c08958","modified":1565916708180},{"_id":"public/archives/2018/08/page/3/index.html","hash":"b9104427172c4148f75fb36c1575e7077696d2c6","modified":1565916708180},{"_id":"public/archives/2018/09/index.html","hash":"e02631ea5fedad5b4ed648853e41b50734488f3c","modified":1565916708180},{"_id":"public/archives/2018/09/page/2/index.html","hash":"e9c1e053d25bb7a3d1ad7eab35860a72947301e1","modified":1565916708180},{"_id":"public/2019/06/13/Tensorflow学习笔记/index.html","hash":"441016a6f221ec2b6c4b6cff825a8b2b3cb1814e","modified":1565916708462},{"_id":"public/2019/06/13/Event-based特征追踪评估方法/index.html","hash":"543779bd244e413ac7308a2b6705103b7a003b43","modified":1565916708462},{"_id":"public/2019/06/03/python学习记录/index.html","hash":"b364a5aae15f32687e3942561889aed9a18a471f","modified":1565916708472},{"_id":"public/archives/page/5/index.html","hash":"3d80970864fb1409322cb7e208a699b210c9a31f","modified":1565916708472},{"_id":"public/archives/2019/index.html","hash":"3c3d00e4fe6f72a9462510ccb4759508f44fd89a","modified":1565916708472},{"_id":"public/archives/2018/06/index.html","hash":"12aeca6b723393bedb9fc7db60ab3b34df41b024","modified":1565916708472},{"_id":"public/archives/2018/05/index.html","hash":"a1c2ded430635dbbf3e1ecdddf7d85c9c42e9553","modified":1565916708472},{"_id":"public/index.html","hash":"fb8a75781eb80ff9439c71d7b318cfce80e2bff2","modified":1565916708472},{"_id":"public/archives/2018/10/index.html","hash":"3d1be9e22bc479d6bf2eecd517d764475dc9a942","modified":1565916708472},{"_id":"public/archives/2019/04/index.html","hash":"4d9465d4a90c66d1e865b0ef3868c9db6fc4d397","modified":1565916708472},{"_id":"public/archives/2019/05/index.html","hash":"7073a0970adcd8d8882d55e7554e74035b92aff7","modified":1565916708472},{"_id":"public/page/3/index.html","hash":"305398cad0824ba8cbaed5023dc3308239eb2a63","modified":1565916708472},{"_id":"public/page/2/index.html","hash":"26d74de631d72d4e9bb27f4e323a76849695418c","modified":1565916708472},{"_id":"public/page/4/index.html","hash":"ab023907e93ab08f3189f117b5fddbff56f65eac","modified":1565916708472},{"_id":"public/page/6/index.html","hash":"12fac413a5ec4d8ec14bfc7f10eab5c1586661bc","modified":1565916708472},{"_id":"public/categories/语言/index.html","hash":"44db055ad064bb0b13de451b904c61baab16bd0d","modified":1565916708472},{"_id":"public/page/7/index.html","hash":"df2e7dda703c84b21ec3de114beecb1d44baa219","modified":1565916708472},{"_id":"public/categories/工具/index.html","hash":"efaf36e1019662c96dd1da1ac6ca3d77fc9b699a","modified":1565916708472},{"_id":"public/categories/深度学习/index.html","hash":"b52b79ac8fe255ceeef4b872d592b8b08e5925ec","modified":1565916708472},{"_id":"public/categories/机器人/index.html","hash":"0ab7e666a4eb858df4983663bdf5746fc42b7154","modified":1565916708473},{"_id":"public/page/5/index.html","hash":"99aa29f624a994dade7299e7ec264c28543b0868","modified":1565916708473},{"_id":"public/page/8/index.html","hash":"4d45cd29fc0e9a3d28da5782e40c9cc87282eb6e","modified":1565916708473},{"_id":"public/categories/机器人/page/2/index.html","hash":"7d2d76a0f3f288042fa2bac52aa0812b5ab09fe5","modified":1565916708473},{"_id":"public/categories/机器人/page/3/index.html","hash":"754a087ef6d7b6a145b42070d3eda7f1ef9e0c38","modified":1565916708473},{"_id":"public/categories/机器人/page/4/index.html","hash":"eb40cd3b89760c21bcce4945682badad0ec374b0","modified":1565916708473},{"_id":"public/categories/系统/index.html","hash":"fc48c6fc46d2ff8bc119ef2ceb3568bb744e0163","modified":1565916708473},{"_id":"public/categories/Docker/index.html","hash":"f3b676ff9e2a3f6e45ac032f71452e3fa4d720e7","modified":1565916708473},{"_id":"public/categories/机器人/page/5/index.html","hash":"bd92d072ff3434c09e1d998fd219baac16fc90b5","modified":1565916708473},{"_id":"public/categories/深度学习/Caffe/index.html","hash":"596a5d1810071986120e180a352c963b6ec3b7f4","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/index.html","hash":"d114573f4a488c7311c512889c95b5d856fb9288","modified":1565916708473},{"_id":"public/categories/工具/CMake/index.html","hash":"173d9f43c5b3eb441fd10ecdd38c25de711c0bf2","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/page/2/index.html","hash":"38a28c695892d871e2fa1bc62b15c4b2d76c54e4","modified":1565916708473},{"_id":"public/categories/工具/VSCode/index.html","hash":"e38ff676f2ee383a2b098d5e2b22d0cc7d9036b4","modified":1565916708473},{"_id":"public/categories/机器人/ROS/index.html","hash":"8aecf4308957101970785daa6140bdc7f2b7cd98","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/page/3/index.html","hash":"a1706619051170249ae3fbf0deca03d794d4a54f","modified":1565916708473},{"_id":"public/categories/机器人/ROS/page/2/index.html","hash":"a16a96936595d740f649a635ed09e1a365cc55f9","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/page/4/index.html","hash":"bf1edacc18550e31954aeaf64510d6463a06648c","modified":1565916708473},{"_id":"public/categories/系统/ubuntu/index.html","hash":"d77fe7b6af25232e6f754628f6cdbe00928f9df0","modified":1565916708473},{"_id":"public/categories/图像处理/index.html","hash":"1809f237bfacfff543162b789621e0eeafca6b5a","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/ORB-SLAM2/index.html","hash":"81492e8b6d6c1fce73b4b1129736cb1d51f06fc7","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/Cartographer/index.html","hash":"de80e5d428b945648690ed07bbcfe41439ac927d","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/navigation/index.html","hash":"42bbb84b10bf2227164bf1a03b19a652c56d985a","modified":1565916708473},{"_id":"public/categories/机器人/SLAM/ORB-SLAM2/page/2/index.html","hash":"9777b737749ff092e833e3a4c329e144993ded49","modified":1565916708474},{"_id":"public/categories/机器人/SLAM/读书笔记/index.html","hash":"1af33a08d19f2f3fa01cc1828f8f5bfe992a77a0","modified":1565916708474},{"_id":"public/categories/机器人/SLAM/论文阅读/index.html","hash":"2f2617efe61549a7b40d29ec92f2162da7cc0fd2","modified":1565916708474},{"_id":"public/categories/机器人/SLAM/基础学习/index.html","hash":"f0347ecfff32b4f4d30becbe903a5dd69f172dc6","modified":1565916708474},{"_id":"public/categories/语言/C/index.html","hash":"23aee125cc51bf81654683afde20b12c5ae68d89","modified":1565916708474},{"_id":"public/tags/C/index.html","hash":"e03db1c3faeba2f320e67a9083b1d475088f4c56","modified":1565916708474},{"_id":"public/categories/语言/YAML/index.html","hash":"f677e52571df8af5476217fdd55bba30b63e3f61","modified":1565916708474},{"_id":"public/categories/机器人/SLAM/可视化库/index.html","hash":"ecf0105e028f76f3a9ca160066b3dec3b1afdd28","modified":1565916708474},{"_id":"public/categories/机器人/SLAM/其他/index.html","hash":"de0a1052d517b2c9e6119969f0f8f87e7fec6a38","modified":1565916708474},{"_id":"public/tags/C/page/2/index.html","hash":"558963578a3806b08a24d4fde58accf2535dbbaa","modified":1565916708474},{"_id":"public/tags/Caffe/index.html","hash":"d03f7ec05774f1e4cb6f8be03248e3959e41b204","modified":1565916708474},{"_id":"public/tags/面试/index.html","hash":"29bd043615ff9cd9215d8c943628b23978182fac","modified":1565916708474},{"_id":"public/tags/Lidar-SLAM/index.html","hash":"cafefda3a95f58ba80842c69c6d027dd490c5d4f","modified":1565916708474},{"_id":"public/tags/CMake/index.html","hash":"e55bd5d74f60be3fe9d7f3e156fe7e37b1a71c3d","modified":1565916708474},{"_id":"public/tags/Cartographer/index.html","hash":"53aa604334f0ceeeb102ed6a3303494c3ae289ab","modified":1565916708475},{"_id":"public/tags/ORB-SLAM2/index.html","hash":"7afd855d8242f832159bb7e0970503f22af64c79","modified":1565916708475},{"_id":"public/tags/Docker/index.html","hash":"7131a9f7d374ab7159158fe21fb07836343294ba","modified":1565916708475},{"_id":"public/tags/rviz/index.html","hash":"93d412644b59d5498ad332b93abb8d6a1d20387b","modified":1565916708475},{"_id":"public/tags/ROS/index.html","hash":"8357d83e00f7b588db2f5c892841fb71641a90f2","modified":1565916708475},{"_id":"public/tags/ubuntu/index.html","hash":"2438a7b0d207d899350b517bc156388b72dfc515","modified":1565916708475},{"_id":"public/tags/ORB-SLAM2/page/2/index.html","hash":"3974a2328d874cb93ece560ffd4d3079844b75a1","modified":1565916708475},{"_id":"public/tags/Rviz/index.html","hash":"5d7f49957207a00c289498c73ec6d11c29a162de","modified":1565916708475},{"_id":"public/tags/ROS/page/2/index.html","hash":"f4eeb51dce673068a4b5540a5ca470b202579d88","modified":1565916708475},{"_id":"public/tags/catkin/index.html","hash":"126a84d643f5a72cbb2ed0334402050257f71e81","modified":1565916708475},{"_id":"public/tags/ROS消息发布器/index.html","hash":"46020b7b6af2c2082d475573b2af9001b713b23e","modified":1565916708475},{"_id":"public/tags/ROS消息订阅器/index.html","hash":"e22253a43a2a192acde29a93096866a1d48dd507","modified":1565916708475},{"_id":"public/tags/VSCode/index.html","hash":"08cd9126d243f0e3b21e15e41a8b2c8490c77ff3","modified":1565916708475},{"_id":"public/tags/Debug/index.html","hash":"37cafd6b27c900aba3e23b3dc348239ba247e924","modified":1565916708475},{"_id":"public/tags/Git/index.html","hash":"fdace70f50df1be068471c15a43d829e767bc3f1","modified":1565916708475},{"_id":"public/tags/Zotero/index.html","hash":"7e6dc09cb4af47b9bfafa4914a903d82f6a36e81","modified":1565916708475},{"_id":"public/tags/lightweight-mapping/index.html","hash":"47905d33de69c0d2daf8f9417fe01971b8843aec","modified":1565916708475},{"_id":"public/tags/ROS服务器/index.html","hash":"b494e6f01791340b7db4d090d7e6fd91537fb277","modified":1565916708475},{"_id":"public/tags/ROS客户端/index.html","hash":"ace450ec120f311e15125b73bb4495f0b1485f88","modified":1565916708476},{"_id":"public/tags/cmake/index.html","hash":"d2b8e6f9a9ce718ef26a074724d4f6034e286220","modified":1565916708476},{"_id":"public/tags/vscode/index.html","hash":"275a2f34743dd55c0f908f931aab723f260540f2","modified":1565916708476},{"_id":"public/tags/debug/index.html","hash":"8b81cd81a54116269e2249a35b4dd7af70d2b687","modified":1565916708476},{"_id":"public/tags/图像处理/index.html","hash":"299fc7e763974994dea93d7dba39b7d9ff0b3e23","modified":1565916708476},{"_id":"public/tags/SLAM基础/index.html","hash":"349e560413fd9eb03da9059c87a36a37c2171483","modified":1565916708476},{"_id":"public/tags/读书笔记/index.html","hash":"b99a66af9ce84c8d949d984fdd53d64363d2cbe6","modified":1565916708476},{"_id":"public/tags/双目/index.html","hash":"19f1d228cc3a8d0b807a9fa90c44c1163aadeabf","modified":1565916708476},{"_id":"public/tags/ubuntu16-04/index.html","hash":"6b4277e712a18537284694dd20f4e99a0a97dcf8","modified":1565916708476},{"_id":"public/tags/Hexo/index.html","hash":"d2e4f091d15c1b6ec52c02d7e018b6e3c755569a","modified":1565916708476},{"_id":"public/tags/Github/index.html","hash":"94d8822706372209981481f0e9bf603f6b24fffd","modified":1565916708476},{"_id":"public/tags/Typora/index.html","hash":"68252cc2d81ca42e7469e1c0f5dee531be518c15","modified":1565916708476},{"_id":"public/tags/图优化/index.html","hash":"1d888a85301b11cd9e37f9c447ef9909145a23dc","modified":1565916708476},{"_id":"public/tags/g2o/index.html","hash":"d13f6128b027d3458eb198f5977b5d8f277d6078","modified":1565916708476},{"_id":"public/tags/单目SLAM/index.html","hash":"2c33b9681c9cf77f167b6ace3a9b64d09299a9d9","modified":1565916708476},{"_id":"public/tags/SLAM/index.html","hash":"b6f8cf3644bdf387d9be95fa7f7582eb723afa78","modified":1565916708476},{"_id":"public/tags/PTAM/index.html","hash":"66242746bcd95fb08db3e3d63e1b34cd59c4cec0","modified":1565916708476},{"_id":"public/tags/直接法SLAM/index.html","hash":"0af130a765aab0623fdad88ce9103aad03d119c5","modified":1565916708476},{"_id":"public/tags/最小二乘/index.html","hash":"524d38079df824c0b317209a0469fd88f0208a20","modified":1565916708476},{"_id":"public/tags/Pangolin/index.html","hash":"9f4bcff09e959d57c21ed7cf29edcd893a0a9c63","modified":1565916708476},{"_id":"public/tags/SVO/index.html","hash":"842fbec8bfc0ca54e8b06416482fa2e6e3cab313","modified":1565916708477},{"_id":"public/tags/半直接法SLAM/index.html","hash":"0a49a9c08ee357e5dc9888ef4e68aa4eb52286a4","modified":1565916708477},{"_id":"public/tags/YAML/index.html","hash":"360ca877550c471a7c7dfd65d094dfedbbb39576","modified":1565916708477},{"_id":"public/tags/OpenCV/index.html","hash":"17e34fd7264b775621dfa68e888b12b86e381a52","modified":1565916708477},{"_id":"public/tags/roslaunch/index.html","hash":"6d01ea3ad99169e68c646a5f811eb4ded798423b","modified":1565916708477},{"_id":"public/tags/Delaunay三角剖分/index.html","hash":"cd40b90a931f77953306158c00089cf4c730ffca","modified":1565916708477},{"_id":"public/tags/对极几何/index.html","hash":"2a382c7d4556d66269098d0592f28269f3b58456","modified":1565916708477},{"_id":"public/tags/单目/index.html","hash":"46be22c9f412f366b3ebe83d6eb446a5ddc56e52","modified":1565916708477},{"_id":"public/tags/2D-2D/index.html","hash":"c1a84cf4e602c5303d76fd66c61b4ef38a5ee23f","modified":1565916708477},{"_id":"public/tags/特征法SLAM/index.html","hash":"32feb27765936ee6e7fb217b8655dac4ccae3d75","modified":1565916708477},{"_id":"public/tags/STL/index.html","hash":"8098b4f5d9edfe838f4d0cdbae1ca0909996058a","modified":1565916708477},{"_id":"public/archives/2019/06/index.html","hash":"b268f3e7ad5600cc3d2e3e43c0de871463a6f9f8","modified":1565916708493},{"_id":"public/categories/语言/page/2/index.html","hash":"d5756f508a74365db3e1a94ed58cd3a1c325a306","modified":1565916708493},{"_id":"public/categories/语言/Python/index.html","hash":"67b9ceffe8b41141c6965eac1fe841d42091033e","modified":1565916708493},{"_id":"public/categories/深度学习/Tensorflow/index.html","hash":"2ae1d147c4fd6ccc5139b99702276b6af8d1ccf1","modified":1565916708493},{"_id":"public/categories/机器人/SLAM/Event-Camera/index.html","hash":"e37d9af62deb410091afd1be1bb10efe13faba84","modified":1565916708493},{"_id":"public/tags/Event-based-Feature/index.html","hash":"5675616d6f11696fca7500b470b433a8904fd8fa","modified":1565916708494},{"_id":"public/tags/Event-Camera/index.html","hash":"e58a63d9ae5ce6c98a764ece558ca6a5fbed0b70","modified":1565916708494},{"_id":"public/tags/Python/index.html","hash":"6a57c65410d3f2875c092d2a806dc954ff378eaf","modified":1565916708494},{"_id":"public/tags/Tensorflow/index.html","hash":"2faad4b9b7ab07dfd59db900ff12052c0fd72846","modified":1565916708494},{"_id":"public/CNAME","hash":"24062db3e3d34eaed7cc5b97dc0a79757c798b74","modified":1565916708494},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1565916708494},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1565916708494},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1565916708494},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1565916708494},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1565916708494},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1565916708494},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1565916708494},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1565916708494},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1565916708494},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1565916708494},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1565916708494},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1565916708494},{"_id":"public/images/photo.jpg","hash":"3d833470d8f35a46e69a3a8e637da4f7af01eb1e","modified":1565916708494},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1565916708494},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1565916708494},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1565916708494},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1565916708495},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1565916708495},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1565916708495},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1565916708495},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1565916708495},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1565916708495},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1565916708495},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1565916708495},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1565916708495},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1565916708495},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1565916708495},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1565916708495},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1565916708495},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1565916708495},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1565916708495},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1565916708495},{"_id":"public/2018/09/05/跨平台可视化库Pangolin/三角形.png","hash":"936530736f1d50d90f1d34dad49d30d641f62fd4","modified":1565916708495},{"_id":"public/2018/09/19/Cartographer学习三源码分析之ROS应用/ROS框架.png","hash":"41d438c831f23e231ee5b3e3d0843d97d11194f8","modified":1565916708495},{"_id":"public/2018/08/11/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/git.png","hash":"572b0c208292d4aef7981d7fad104d4df533fd21","modified":1565916708495},{"_id":"public/2018/08/11/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/git2.png","hash":"7d84029e4a2c050b58c0352cbec94864bd3cefe3","modified":1565916708495},{"_id":"public/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/表示和存储.png","hash":"bf73cc967f0b89fde71fc25473dc4580caf00544","modified":1565916708495},{"_id":"public/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/三角测量.png","hash":"610ee2aa02a3e6ab00d62174b3e0ed5c1095f133","modified":1565916708495},{"_id":"public/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/三角测量的矛盾.png","hash":"8e30f3cb712ffdeab1e081bd1b10dae28cca05b6","modified":1565916708495},{"_id":"public/2018/05/13/Docker学习之基础知识/flocker.jpg","hash":"dae43774323f3636331689dd9aeb603bf2a1a29f","modified":1565916708495},{"_id":"public/2018/05/13/Docker学习之基础知识/docker-filesystems-multilayer.png","hash":"9c9d10d57c4ed3bd676ff02f5ed04f58be7d9000","modified":1565916708496},{"_id":"public/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/错误提示.png","hash":"c846b1f5b7bc4b686432a29662d7717a35c1f1a7","modified":1565916708496},{"_id":"public/2018/10/14/ORB-SLAM2系统Rviz可视化方案/ORB世界坐标系.png","hash":"ada65645f49c0f731eff2ed5e01533dc80dbd614","modified":1565916708496},{"_id":"public/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/删除后.png","hash":"c3a1c97af068727d23aecee5ffdc8a10ea52cf15","modified":1565916708496},{"_id":"public/2018/10/14/ORB-SLAM2系统Rviz可视化方案/Rviz世界坐标系.png","hash":"a75645ad9689fca62db6a50fe4baf3036e806af9","modified":1565916708496},{"_id":"public/2018/10/14/ORB-SLAM2系统Rviz可视化方案/相机坐标系.png","hash":"74d21815fc2f2fee35222f84a677fb064fc8da42","modified":1565916708496},{"_id":"public/2018/08/30/ORB-SLAM2学习之源码分析九-ORB特征匹配/直方图.png","hash":"a121dbe26767bf04bdf2ada0cf7e6be032da71b1","modified":1565916708496},{"_id":"public/2018/08/05/视觉SLAM十四讲阅读笔记二-SLAM的数学表述/视觉SLAM经典框架.png","hash":"6047a25202050c0f0eb5473bcfa0169d34d4f7a3","modified":1565916708496},{"_id":"public/2018/09/04/lightweight_mapping学习之LocalMeshing/Delanunay三角剖分.png","hash":"49c67b529f47a33abe614c662d534975134c509d","modified":1565916708496},{"_id":"public/2019/05/20/论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》/patchsearch.png","hash":"359990887d688c687b88b07d52274da2fad801be","modified":1565916708496},{"_id":"public/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/模型打分公式.png","hash":"310e2d480624a93ca1b5be6dbd8b3619782ffc0d","modified":1565916708496},{"_id":"public/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/得分计算公式.png","hash":"8348eae0e457f43b66979201884bc9261aa30fd3","modified":1565916708496},{"_id":"public/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/五边形.png","hash":"4693571b85a008402d1d44f071a53fbf3bcb82fb","modified":1565916708496},{"_id":"public/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/交互图.png","hash":"26d1a7798d1b42cbf597bc910ce30b0ee5476096","modified":1565916708496},{"_id":"public/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/双目初始化.png","hash":"0f435ae3c9fd4dc4e01439ced8f2761c9264d5ee","modified":1565916708496},{"_id":"public/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/ExtractORB.png","hash":"5149deccc2c90a1fdfd3c1197a12566f36333a7d","modified":1565916708496},{"_id":"public/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/本质矩阵的解.png","hash":"1f229fc6be7cd10f5a4a18b1ae39dfa6d819c1eb","modified":1565916708496},{"_id":"public/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/归一化坐标.png","hash":"8ad5b31495b0b96949513699ffb19343bbaf515f","modified":1565916708496},{"_id":"public/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/对极几何约束.png","hash":"24e94bf4a4564382611e5395fb1b990cc2cfec68","modified":1565916708496},{"_id":"public/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/相机坐标系.png","hash":"b32513c1ef3a9ecfac309f859d4ceef6dc054fe1","modified":1565916708496},{"_id":"public/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/像素坐标系.png","hash":"dc86db52df1121ec249d6e1e2f29c027c4251d10","modified":1565916708496},{"_id":"public/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/b.png","hash":"476d1386a8197cc9e7d1f544609e7a5a3db41012","modified":1565916708496},{"_id":"public/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/a.png","hash":"2f377973a2544a5e498cc0930b1fedc6f05072c2","modified":1565916708496},{"_id":"public/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/c.png","hash":"a0b45134314ed0426afb82010c858c48a0468766","modified":1565916708496},{"_id":"public/2018/08/18/ORB_SLAM2学习之源码分析三-优化/Sim3上的位姿优化.png","hash":"8d5051e3cf33ad9910d9195ac80dca0095cd5016","modified":1565916708496},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/SLAM视觉里程计.png","hash":"75a24ac2619b9795d404b95e9a82c13b28b85427","modified":1565916708496},{"_id":"public/2018/09/08/Caffe的GPU模式安装/CUDA和驱动版本对应.png","hash":"758c48aad359c7c1700b9d997efd44371a585ea0","modified":1565916708496},{"_id":"public/2018/09/08/Caffe的GPU模式安装/CUDA测试.png","hash":"a8857a5159cb9d53931958566e72341cd33a55c7","modified":1565916708497},{"_id":"public/2018/09/08/Caffe的GPU模式安装/CUDA.png","hash":"80ff063007c469a4e6fd72df2fc685083c8c0b12","modified":1565916708497},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/网格点和相关像素.png","hash":"8c482cc94e5befe6bc51dec50b86067449770511","modified":1565916708497},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/系统图.png","hash":"deaf09581d5e9af412d7a4e571dbdf0d4ab2abb9","modified":1565916708497},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/submap.png","hash":"cf85d9450d7c2ad066b5b67aefb3f6021b9ba2c8","modified":1565916708497},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1565916709518},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1565916709521},{"_id":"public/images/zhifubao.jpg","hash":"e9c2c9611fd3fd19d38cc49148690a6072cc2f0d","modified":1565916709524},{"_id":"public/images/weixin.jpg","hash":"a8883595c472d9588f2e6a7a15ed247d4ed5aa6d","modified":1565916709524},{"_id":"public/images/hexo.jpg","hash":"238b746202196a285f4ecac50dda0490e5ce8de9","modified":1565916709524},{"_id":"public/uploads/hexo.jpg","hash":"238b746202196a285f4ecac50dda0490e5ce8de9","modified":1565916709524},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1565916709524},{"_id":"public/2018/08/23/ORB-SLAM2学习之源码分析七-LocalClosing/LocalClosing.png","hash":"8e9cc79212fcad41b5c4236db67ad3d2b75bfa8a","modified":1565916709524},{"_id":"public/2019/05/27/视觉SLAM基础学习之非线性最小二乘问题求解方法/newton.png","hash":"b0e56bd9e9509c17a446f191cbcaa073ff6b2119","modified":1565916709524},{"_id":"public/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/slam框架.png","hash":"59ce8d2a245def44e30c6c2aa13abba5c71d641e","modified":1565916709524},{"_id":"public/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/LocalMapping.png","hash":"4f7178afd52a46883cade54e945585a521288210","modified":1565916709524},{"_id":"public/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/图像坐标示意图.png","hash":"bf9b5a6fc4ad928d8b4cff93169775812573ea41","modified":1565916709525},{"_id":"public/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/删除前.png","hash":"1761ef86648e3a44201ac5bfe0feed9f11657175","modified":1565916709525},{"_id":"public/2018/05/13/Docker学习之基础知识/bootfs.jpg","hash":"01142f86f5635ec2c041a775ded3f9d1b666fdb0","modified":1565916709525},{"_id":"public/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/磁盘分析.png","hash":"f25f0d500463b082cb288a8947ecaad97ed39163","modified":1565916709525},{"_id":"public/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/单目初始化.png","hash":"315344ff87fc3ca7458ea8e5f5bb3e0b312ebab3","modified":1565916709525},{"_id":"public/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/SVO追踪与建图.png","hash":"c0e92061a63b90473f14003dae9949163c61522b","modified":1565916709525},{"_id":"public/2018/08/18/ORB_SLAM2学习之源码分析三-优化/闭环处优化.png","hash":"dd009e6a51c7cc378153e0caa6166ee0bb9a974d","modified":1565916709525},{"_id":"public/2018/08/18/ORB_SLAM2学习之源码分析三-优化/局部优化.png","hash":"3da34210ca1fa3a88acf10a773c98268c3b39154","modified":1565916709525},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Tracking跟踪模型.png","hash":"b45e6d9dbec829c37e982d010f2279fbe08a96ce","modified":1565916709525},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Track.png","hash":"837abc3519effb6f2335367003cbd6708737ead4","modified":1565916709525},{"_id":"public/2018/08/18/ORB_SLAM2学习之源码分析三-优化/全局优化.png","hash":"2f9d5e0abfce80908f0abd5146af4ea468d4d12b","modified":1565916709525},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Tracking重点环节.png","hash":"fb1f769d0d4119019f55d271cfa707e00d5a35ad","modified":1565916709525},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/局部地图示意图.png","hash":"3da34210ca1fa3a88acf10a773c98268c3b39154","modified":1565916709525},{"_id":"public/2018/09/08/Caffe的GPU模式安装/cuDNN.png","hash":"a933b853174b7bd61c60c7c6c24c58e77ef085e7","modified":1565916709525},{"_id":"public/2018/09/08/Caffe的GPU模式安装/nvidia安装成功.png","hash":"21ca1a24d0e9393856d37b001d671558daa8b0e8","modified":1565916709525},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/算法2.png","hash":"6afd71b309bfc73a78d9d75c4d5cb790e6ca77ca","modified":1565916709525},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/算法3.png","hash":"87e71d16138969160f8b591adb41fd19755ec0e7","modified":1565916709525},{"_id":"public/2018/09/12/Cartographer学习一论文阅读/暴力搜索.png","hash":"e4074a3f7a5fd088104bdabc61aadaadfb41948c","modified":1565916709525},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1565916709530},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1565916709530},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1565916709531},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1565916709531},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1565916709531},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1565916709531},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1565916709531},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1565916709531},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1565916709531},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1565916709531},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1565916709531},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1565916709531},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1565916709531},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1565916709531},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1565916709531},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1565916709531},{"_id":"public/js/src/post-details.js","hash":"8bb973f5f74070c31f3338a744df33469bf008ff","modified":1565916709531},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1565916709531},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1565916709532},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1565916709532},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1565916709532},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1565916709532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1565916709532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1565916709532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1565916709532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1565916709532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1565916709532},{"_id":"public/lib/fastclick/README.html","hash":"c07b353b4efa132290ec4479102a55d80ac6d300","modified":1565916709532},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1565916709532},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1565916709532},{"_id":"public/css/main.css","hash":"ce6369029c8fd0214779d3af7e8f0547f0213f67","modified":1565916709532},{"_id":"public/images/1703706832.jpg","hash":"e010f5adee6c55ad1b9d5ff6c6b6ebf56e1d59de","modified":1565916709532},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1565916709532},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1565916709532},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1565916709532},{"_id":"public/2018/03/29/ROS学习之actionlib库（１）-actionlib库的介绍/节点图.png","hash":"094caf5c063a30b0996a7d17ebf790f81cc1d13e","modified":1565916709532},{"_id":"public/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/针孔相机模型.png","hash":"65d35e5e6450c51f2a4493994eb90d75e8bdba46","modified":1565916709532},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1565916709539},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1565916709539},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1565916709539},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1565916709539},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1565916709539},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1565916709539},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1565916709539},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1565916709539},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1565916709539},{"_id":"public/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/SLAM视觉里程计特征点法.png","hash":"fd627ac5267142ea3ccf20b1d97efb19ddb76abc","modified":1565916709539},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1565916709550},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1565916709550},{"_id":"public/2018/09/16/Cartographer学习二源码分析之核心代码/Cartographer系统框架图.png","hash":"cdb5b65ea332f81e9d68cf06fa7fddb2ecd54997","modified":1565916709550},{"_id":"public/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/节点图.png","hash":"816c18ac3d7833e9024d128037622fd564dc2552","modified":1565916709550},{"_id":"public/2018/04/03/ROS学习之pluginlib/pluginlib.png","hash":"e4295d05b85a22610ec2f33095bc123e50959d15","modified":1565916709550},{"_id":"public/2018/03/30/ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器/节点图.png","hash":"b9ecd6a8731cc674f049c22d4350adc2307a3d5e","modified":1565916709550},{"_id":"public/2018/09/08/Caffe的GPU模式安装/CUDA9安装.png","hash":"dfcb681be29d2d9b21936a31043cda65e989d8ce","modified":1565916709550},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1565916709553},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1565916709553},{"_id":"public/2018/10/14/ORB-SLAM2系统Rviz可视化方案/运行结果.png","hash":"915a2f5d0fd76845beb09e5652a162dfe724c85e","modified":1565916709554},{"_id":"public/2018/10/14/ORB-SLAM2系统Rviz可视化方案/pcl点云显示.png","hash":"b31752180dee6ebd9c6d275a2daa4645f0fff1a8","modified":1565916709554},{"_id":"public/2018/03/30/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器/节点图.png","hash":"a742d72ab6900d8993742be069efdd8a769587f3","modified":1565916709554},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1565916709558},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1565916709558},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1565916709559},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1565916709559},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1565916709559},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1565916709559},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1565916709559},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1565916709559},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1565916709559},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1565916709559},{"_id":"public/2018/09/19/Cartographer学习三源码分析之ROS应用/cartographer_old.png","hash":"e58d70b8482ffaee0c66e8fb0c658a8c2d3a501c","modified":1565916709600},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1565916709601},{"_id":"public/2018/09/08/Caffe的GPU模式安装/samples.png","hash":"ffff9be0c2d2583118bee582841a29b3b0419c0f","modified":1565916709601},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1565916709604},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1565916709605},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1565916709605},{"_id":"public/2018/09/16/Cartographer学习二源码分析之核心代码/整体流程.png","hash":"027095fcba9e8469340c2efbee24be29bb290363","modified":1565916709606},{"_id":"public/images/wo.png","hash":"4e42daf0173bbd7a3d4c8587c37d965de7a7c657","modified":1565916709606},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1565916709607},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1565916709612},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1565916709613}],"Category":[{"name":"语言","_id":"cjzdedbtn0003qlcr9emda53j"},{"name":"C++","parent":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbua000kqlcrdjze054a"},{"name":"工具","_id":"cjzdedbuk0011qlcruwsbwpup"},{"name":"深度学习","_id":"cjzdedbuu001jqlcr39a18ir4"},{"name":"机器人","_id":"cjzdedbv0001wqlcrinnwfi82"},{"name":"Docker","_id":"cjzdedbv40022qlcrp3cih2wk"},{"name":"系统","_id":"cjzdedbva002eqlcr4sn1wbtm"},{"name":"CMake","parent":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbvs0038qlcr1qy5o07l"},{"name":"Caffe","parent":"cjzdedbuu001jqlcr39a18ir4","_id":"cjzdedbw70046qlcrtqwsuf9e"},{"name":"VSCode","parent":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbwc004lqlcrfxhiqt5q"},{"name":"SLAM","parent":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbwc004nqlcrl67k1642"},{"name":"ROS","parent":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbwe004tqlcrq7hugm7w"},{"name":"Python","parent":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbwi0051qlcrlgazyy3r"},{"name":"ubuntu","parent":"cjzdedbva002eqlcr4sn1wbtm","_id":"cjzdedbwl005aqlcrlvldn9v4"},{"name":"Tensorflow","parent":"cjzdedbuu001jqlcr39a18ir4","_id":"cjzdedbwm005hqlcrywr8sk04"},{"name":"图像处理","_id":"cjzdedbwq005uqlcrxxh7yker"},{"name":"Cartographer","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxi0088qlcrd47mc7ne"},{"name":"navigation","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxj008dqlcrx7sdjli5"},{"name":"Event Camera","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxk008nqlcrb6kk2icj"},{"name":"ORB_SLAM2","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxk008sqlcryb6r7c0r"},{"name":"读书笔记","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxl008wqlcrhcjwq2xo"},{"name":"论文阅读","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxq009oqlcrdhmiv6xe"},{"name":"基础学习","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxr009sqlcrtorvnqze"},{"name":"可视化库","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxr009vqlcr67ei99om"},{"name":"YAML","parent":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbyn00b2qlcrjr90plxj"},{"name":"其他","parent":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0a00coqlcr2rtyklys"}],"Data":[],"Page":[{"_content":"aia7zPmTuu","source":"baidu_verify_aia7zPmTuu.html","raw":"aia7zPmTuu","date":"2019-05-30T12:29:26.307Z","updated":"2019-05-30T12:29:26.307Z","path":"baidu_verify_aia7zPmTuu.html","title":"","comments":1,"layout":"page","_id":"cjzdedbml0000qlcrv1w0vx2p","content":"aia7zPmTuu","site":{"data":{}},"excerpt":"","more":"aia7zPmTuu"},{"title":"关于我","date":"2018-03-22T03:25:56.000Z","_content":"\n### 基本情况\n\n本人目前就读于湖南长沙国防科技大学，研究生一年级，学习方向为视觉SLAM，菜鸟一枚，还请大神不吝赐教。其实我是一个计算机专业比较菜的学生党，偶然的机会看到师兄（童博士，他本人目前还不是博士，但大家都这么叫他～哈哈）在写东西，就了解了下，这才开始我的Hexo+Github的博客之旅。今后学习、生活、工作中的积累、总结都会发布到这里，作为自己成长的印记，希望今后回头看时能有所收获、得到启发。\n\n### 兴趣\n\n- 喜欢足球，主队巴萨、鲁能、曼城，喜欢的球员梅西、阿奎罗（一对好cp）、库蒂尼奥、蒿俊闵、武磊。\n\n- 喜欢音乐，网易云“九尾冲爱上四方坪”（这是学校旁边的俩公交车站名，我觉得很有意思哈哈），有学过吉他，嗯...和大多数人一样，吉他现在在床底下。\n\n- 喜欢读书，最爱《百年孤独》《大卫.科波菲尔》（分别在本科和不久前读完，前者的魔幻现实色彩让我身临其境，读起来爽的很），嗯，你没猜错，最喜欢的作家就是马尔克斯和狄更斯，还读过好多马尔克斯《爱情和其他魔鬼》，下一本打算读《霍乱时期的爱情》。\n\n- 喜欢健身和跑步，身体是革命的本钱一点也没错啊，不想因为各种忙耽误了运动和健康，得不偿失。大三就开始接触健身，大四跟着师兄（对，还是那个童博士）学习，算是掌握了基本的健身技能，现在在健身房能找到自己的存在感（虽然我很瘦，但是我有肌肉），继续努力！参加过校运动会的5公里、参加过长沙国际马拉松的迷你跑（也是5公里，说来惭愧），喜欢跑步时让自己放空的柑橘。\n\n- 喜欢骑行，喜欢骑车的感觉，尤其是晚上带着耳机在城市的大街少骑行，周围灯红酒绿、车水马龙，吹着凉风很舒服。嗯，大三前的暑假我从沈阳出发至山东济宁骑行1200多公里，这段经历应该算是比较强的了叭～哈哈。现在在学校骑着一辆师兄（这个就不是童博士了哈哈）留下来的车，我很满意～\n\n### 学习\n\n天道酬勤，希望毕业能去北京工作和女友在一个城市。\n\n### 健身mark\n\n|   时间   |      项目       | 重量\\kg |\n| :------: | :-------------: | :-----: |\n| 20180322 |  杠铃平板卧推   |  12.5   |\n| 20180520 |  杠铃平板卧推   |   20    |\n|    -     |      硬拉       |   20    |\n| 20180911 | 哑铃平/上斜卧推 |   15    |\n|    -     |      硬拉       |   25    |\n|    -     |  罗马尼亚深蹲   |   10    |\n\n","source":"about/index.md","raw":"---\ntitle: 关于我\ndate: 2018-03-22 11:25:56\n---\n\n### 基本情况\n\n本人目前就读于湖南长沙国防科技大学，研究生一年级，学习方向为视觉SLAM，菜鸟一枚，还请大神不吝赐教。其实我是一个计算机专业比较菜的学生党，偶然的机会看到师兄（童博士，他本人目前还不是博士，但大家都这么叫他～哈哈）在写东西，就了解了下，这才开始我的Hexo+Github的博客之旅。今后学习、生活、工作中的积累、总结都会发布到这里，作为自己成长的印记，希望今后回头看时能有所收获、得到启发。\n\n### 兴趣\n\n- 喜欢足球，主队巴萨、鲁能、曼城，喜欢的球员梅西、阿奎罗（一对好cp）、库蒂尼奥、蒿俊闵、武磊。\n\n- 喜欢音乐，网易云“九尾冲爱上四方坪”（这是学校旁边的俩公交车站名，我觉得很有意思哈哈），有学过吉他，嗯...和大多数人一样，吉他现在在床底下。\n\n- 喜欢读书，最爱《百年孤独》《大卫.科波菲尔》（分别在本科和不久前读完，前者的魔幻现实色彩让我身临其境，读起来爽的很），嗯，你没猜错，最喜欢的作家就是马尔克斯和狄更斯，还读过好多马尔克斯《爱情和其他魔鬼》，下一本打算读《霍乱时期的爱情》。\n\n- 喜欢健身和跑步，身体是革命的本钱一点也没错啊，不想因为各种忙耽误了运动和健康，得不偿失。大三就开始接触健身，大四跟着师兄（对，还是那个童博士）学习，算是掌握了基本的健身技能，现在在健身房能找到自己的存在感（虽然我很瘦，但是我有肌肉），继续努力！参加过校运动会的5公里、参加过长沙国际马拉松的迷你跑（也是5公里，说来惭愧），喜欢跑步时让自己放空的柑橘。\n\n- 喜欢骑行，喜欢骑车的感觉，尤其是晚上带着耳机在城市的大街少骑行，周围灯红酒绿、车水马龙，吹着凉风很舒服。嗯，大三前的暑假我从沈阳出发至山东济宁骑行1200多公里，这段经历应该算是比较强的了叭～哈哈。现在在学校骑着一辆师兄（这个就不是童博士了哈哈）留下来的车，我很满意～\n\n### 学习\n\n天道酬勤，希望毕业能去北京工作和女友在一个城市。\n\n### 健身mark\n\n|   时间   |      项目       | 重量\\kg |\n| :------: | :-------------: | :-----: |\n| 20180322 |  杠铃平板卧推   |  12.5   |\n| 20180520 |  杠铃平板卧推   |   20    |\n|    -     |      硬拉       |   20    |\n| 20180911 | 哑铃平/上斜卧推 |   15    |\n|    -     |      硬拉       |   25    |\n|    -     |  罗马尼亚深蹲   |   10    |\n\n","updated":"2019-05-30T12:29:26.307Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjzdedbyi00aqqlcrhk0va7yf","content":"<h3 id=\"基本情况\"><a href=\"#基本情况\" class=\"headerlink\" title=\"基本情况\"></a>基本情况</h3><p>本人目前就读于湖南长沙国防科技大学，研究生一年级，学习方向为视觉SLAM，菜鸟一枚，还请大神不吝赐教。其实我是一个计算机专业比较菜的学生党，偶然的机会看到师兄（童博士，他本人目前还不是博士，但大家都这么叫他～哈哈）在写东西，就了解了下，这才开始我的Hexo+Github的博客之旅。今后学习、生活、工作中的积累、总结都会发布到这里，作为自己成长的印记，希望今后回头看时能有所收获、得到启发。</p>\n<h3 id=\"兴趣\"><a href=\"#兴趣\" class=\"headerlink\" title=\"兴趣\"></a>兴趣</h3><ul>\n<li><p>喜欢足球，主队巴萨、鲁能、曼城，喜欢的球员梅西、阿奎罗（一对好cp）、库蒂尼奥、蒿俊闵、武磊。</p>\n</li>\n<li><p>喜欢音乐，网易云“九尾冲爱上四方坪”（这是学校旁边的俩公交车站名，我觉得很有意思哈哈），有学过吉他，嗯…和大多数人一样，吉他现在在床底下。</p>\n</li>\n<li><p>喜欢读书，最爱《百年孤独》《大卫.科波菲尔》（分别在本科和不久前读完，前者的魔幻现实色彩让我身临其境，读起来爽的很），嗯，你没猜错，最喜欢的作家就是马尔克斯和狄更斯，还读过好多马尔克斯《爱情和其他魔鬼》，下一本打算读《霍乱时期的爱情》。</p>\n</li>\n<li><p>喜欢健身和跑步，身体是革命的本钱一点也没错啊，不想因为各种忙耽误了运动和健康，得不偿失。大三就开始接触健身，大四跟着师兄（对，还是那个童博士）学习，算是掌握了基本的健身技能，现在在健身房能找到自己的存在感（虽然我很瘦，但是我有肌肉），继续努力！参加过校运动会的5公里、参加过长沙国际马拉松的迷你跑（也是5公里，说来惭愧），喜欢跑步时让自己放空的柑橘。</p>\n</li>\n<li><p>喜欢骑行，喜欢骑车的感觉，尤其是晚上带着耳机在城市的大街少骑行，周围灯红酒绿、车水马龙，吹着凉风很舒服。嗯，大三前的暑假我从沈阳出发至山东济宁骑行1200多公里，这段经历应该算是比较强的了叭～哈哈。现在在学校骑着一辆师兄（这个就不是童博士了哈哈）留下来的车，我很满意～</p>\n</li>\n</ul>\n<h3 id=\"学习\"><a href=\"#学习\" class=\"headerlink\" title=\"学习\"></a>学习</h3><p>天道酬勤，希望毕业能去北京工作和女友在一个城市。</p>\n<h3 id=\"健身mark\"><a href=\"#健身mark\" class=\"headerlink\" title=\"健身mark\"></a>健身mark</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">时间</th>\n<th style=\"text-align:center\">项目</th>\n<th style=\"text-align:center\">重量\\kg</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">20180322</td>\n<td style=\"text-align:center\">杠铃平板卧推</td>\n<td style=\"text-align:center\">12.5</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">20180520</td>\n<td style=\"text-align:center\">杠铃平板卧推</td>\n<td style=\"text-align:center\">20</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">硬拉</td>\n<td style=\"text-align:center\">20</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">20180911</td>\n<td style=\"text-align:center\">哑铃平/上斜卧推</td>\n<td style=\"text-align:center\">15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">硬拉</td>\n<td style=\"text-align:center\">25</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">罗马尼亚深蹲</td>\n<td style=\"text-align:center\">10</td>\n</tr>\n</tbody>\n</table>\n</div>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"基本情况\"><a href=\"#基本情况\" class=\"headerlink\" title=\"基本情况\"></a>基本情况</h3><p>本人目前就读于湖南长沙国防科技大学，研究生一年级，学习方向为视觉SLAM，菜鸟一枚，还请大神不吝赐教。其实我是一个计算机专业比较菜的学生党，偶然的机会看到师兄（童博士，他本人目前还不是博士，但大家都这么叫他～哈哈）在写东西，就了解了下，这才开始我的Hexo+Github的博客之旅。今后学习、生活、工作中的积累、总结都会发布到这里，作为自己成长的印记，希望今后回头看时能有所收获、得到启发。</p>\n<h3 id=\"兴趣\"><a href=\"#兴趣\" class=\"headerlink\" title=\"兴趣\"></a>兴趣</h3><ul>\n<li><p>喜欢足球，主队巴萨、鲁能、曼城，喜欢的球员梅西、阿奎罗（一对好cp）、库蒂尼奥、蒿俊闵、武磊。</p>\n</li>\n<li><p>喜欢音乐，网易云“九尾冲爱上四方坪”（这是学校旁边的俩公交车站名，我觉得很有意思哈哈），有学过吉他，嗯…和大多数人一样，吉他现在在床底下。</p>\n</li>\n<li><p>喜欢读书，最爱《百年孤独》《大卫.科波菲尔》（分别在本科和不久前读完，前者的魔幻现实色彩让我身临其境，读起来爽的很），嗯，你没猜错，最喜欢的作家就是马尔克斯和狄更斯，还读过好多马尔克斯《爱情和其他魔鬼》，下一本打算读《霍乱时期的爱情》。</p>\n</li>\n<li><p>喜欢健身和跑步，身体是革命的本钱一点也没错啊，不想因为各种忙耽误了运动和健康，得不偿失。大三就开始接触健身，大四跟着师兄（对，还是那个童博士）学习，算是掌握了基本的健身技能，现在在健身房能找到自己的存在感（虽然我很瘦，但是我有肌肉），继续努力！参加过校运动会的5公里、参加过长沙国际马拉松的迷你跑（也是5公里，说来惭愧），喜欢跑步时让自己放空的柑橘。</p>\n</li>\n<li><p>喜欢骑行，喜欢骑车的感觉，尤其是晚上带着耳机在城市的大街少骑行，周围灯红酒绿、车水马龙，吹着凉风很舒服。嗯，大三前的暑假我从沈阳出发至山东济宁骑行1200多公里，这段经历应该算是比较强的了叭～哈哈。现在在学校骑着一辆师兄（这个就不是童博士了哈哈）留下来的车，我很满意～</p>\n</li>\n</ul>\n<h3 id=\"学习\"><a href=\"#学习\" class=\"headerlink\" title=\"学习\"></a>学习</h3><p>天道酬勤，希望毕业能去北京工作和女友在一个城市。</p>\n<h3 id=\"健身mark\"><a href=\"#健身mark\" class=\"headerlink\" title=\"健身mark\"></a>健身mark</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">时间</th>\n<th style=\"text-align:center\">项目</th>\n<th style=\"text-align:center\">重量\\kg</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">20180322</td>\n<td style=\"text-align:center\">杠铃平板卧推</td>\n<td style=\"text-align:center\">12.5</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">20180520</td>\n<td style=\"text-align:center\">杠铃平板卧推</td>\n<td style=\"text-align:center\">20</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">硬拉</td>\n<td style=\"text-align:center\">20</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">20180911</td>\n<td style=\"text-align:center\">哑铃平/上斜卧推</td>\n<td style=\"text-align:center\">15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">硬拉</td>\n<td style=\"text-align:center\">25</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">罗马尼亚深蹲</td>\n<td style=\"text-align:center\">10</td>\n</tr>\n</tbody>\n</table>\n</div>\n"},{"title":"所有分类","date":"2018-03-22T02:00:34.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 所有分类\ndate: 2018-03-22 10:00:34\ntype: \"categories\"\n---\n","updated":"2019-05-30T12:29:26.307Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjzdedbyj00asqlcru8dd6u8e","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","date":"2018-03-22T02:08:22.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2018-03-22 10:08:22\ntype: \"tags\"\n---\n","updated":"2019-05-30T12:29:26.307Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjzdedbyk00avqlcrtsaf073z","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"C++学习之不常用的重要关键字","date":"2018-03-29T03:02:39.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++一些不常用关键字的学习内容。\n\n<!---more-->\n\n### `explicit`关键字\n\n`explicit`关键字只能用于修饰只有一个参数的类构造函数, 它的作用是表明该构造函数是显式的，声明为`explicit`的构造函数不能在隐式转换中使用。参见博客另一篇[文章](http://ttshun.com/2018/05/09/C++%E5%AD%A6%E4%B9%A0%E4%B9%8Bexplicit%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/)。\n\n","source":"_posts/C++学习之不常用的重要关键字.md","raw":"---\ntitle: C++学习之不常用的重要关键字\ndate: 2018-03-29 11:02:39\ntags:\n  - C++\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++一些不常用关键字的学习内容。\n\n<!---more-->\n\n### `explicit`关键字\n\n`explicit`关键字只能用于修饰只有一个参数的类构造函数, 它的作用是表明该构造函数是显式的，声明为`explicit`的构造函数不能在隐式转换中使用。参见博客另一篇[文章](http://ttshun.com/2018/05/09/C++%E5%AD%A6%E4%B9%A0%E4%B9%8Bexplicit%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/)。\n\n","slug":"C++学习之不常用的重要关键字","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbtf0001qlcrvbcmemo0","content":"<hr>\n<p>这篇文章是有关C++一些不常用关键字的学习内容。</p>\n<a id=\"more\"></a>\n<h3 id=\"explicit关键字\"><a href=\"#explicit关键字\" class=\"headerlink\" title=\"explicit关键字\"></a><code>explicit</code>关键字</h3><p><code>explicit</code>关键字只能用于修饰只有一个参数的类构造函数, 它的作用是表明该构造函数是显式的，声明为<code>explicit</code>的构造函数不能在隐式转换中使用。参见博客另一篇<a href=\"http://ttshun.com/2018/05/09/C++%E5%AD%A6%E4%B9%A0%E4%B9%8Bexplicit%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/\">文章</a>。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++一些不常用关键字的学习内容。</p>","more":"<h3 id=\"explicit关键字\"><a href=\"#explicit关键字\" class=\"headerlink\" title=\"explicit关键字\"></a><code>explicit</code>关键字</h3><p><code>explicit</code>关键字只能用于修饰只有一个参数的类构造函数, 它的作用是表明该构造函数是显式的，声明为<code>explicit</code>的构造函数不能在隐式转换中使用。参见博客另一篇<a href=\"http://ttshun.com/2018/05/09/C++%E5%AD%A6%E4%B9%A0%E4%B9%8Bexplicit%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/\">文章</a>。</p>"},{"title":"C++学习之基础概念","date":"2018-04-11T14:44:30.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++基础概念的记录内容。\n\n<!---more-->\n\n重写　子类重写父类的方法，覆盖原有方法\n\n重载　分为方法重载和运算符重载\n\n重用　代码服用/软件复用\n\n重构　调整程序代码改善软件质量和性能\n\n继承\n\n抽象/接口类（具体类）　虚函数　纯虚函数\n\n多态性　动态绑定\n\n模板　函数模板　类模板","source":"_posts/C++学习之基础概念.md","raw":"---\ntitle: C++学习之基础概念\ndate: 2018-04-11 22:44:30\ntags:\n  - C++\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++基础概念的记录内容。\n\n<!---more-->\n\n重写　子类重写父类的方法，覆盖原有方法\n\n重载　分为方法重载和运算符重载\n\n重用　代码服用/软件复用\n\n重构　调整程序代码改善软件质量和性能\n\n继承\n\n抽象/接口类（具体类）　虚函数　纯虚函数\n\n多态性　动态绑定\n\n模板　函数模板　类模板","slug":"C++学习之基础概念","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbtk0002qlcrmvqn5s5o","content":"<hr>\n<p>这篇文章是有关C++基础概念的记录内容。</p>\n<a id=\"more\"></a>\n<p>重写　子类重写父类的方法，覆盖原有方法</p>\n<p>重载　分为方法重载和运算符重载</p>\n<p>重用　代码服用/软件复用</p>\n<p>重构　调整程序代码改善软件质量和性能</p>\n<p>继承</p>\n<p>抽象/接口类（具体类）　虚函数　纯虚函数</p>\n<p>多态性　动态绑定</p>\n<p>模板　函数模板　类模板</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++基础概念的记录内容。</p>","more":"<p>重写　子类重写父类的方法，覆盖原有方法</p>\n<p>重载　分为方法重载和运算符重载</p>\n<p>重用　代码服用/软件复用</p>\n<p>重构　调整程序代码改善软件质量和性能</p>\n<p>继承</p>\n<p>抽象/接口类（具体类）　虚函数　纯虚函数</p>\n<p>多态性　动态绑定</p>\n<p>模板　函数模板　类模板</p>"},{"title":"C++学习之成员变量的初始化顺序","date":"2018-03-28T03:26:29.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++成员变量初始化顺序的学习内容。\n\n<!---more-->\n\n我现在是研一，最近研二的学长学姐们都在准备找实习，各种面试笔试，工作不好找，形势好严峻。所以听从学长的建议从现在开始积累编程语言（C++、Python）、算法、数据结构方面的基础知识，为今后面试找工作做好准备。在读*剑指offer*书时遇到*成员变量初始化顺序*这种问题，打算查资料深入学习下。\n\n首先是下面的测试代码：\n\n~~~c++\n#include <iostream>\nusing namespace std;\n\nclass A\n{\nprivate:\n\tint n1;\n\tint n2;\n\npublic:\n    //成员变量初始化方式一：构造函数初始化列表初始化\n\tA():n2(0),n1(n2+2){}\n    \n    //成员变量初始化方式二：构造函数内初始化\n    //A(){\n    //    n2　=　0;\n    //    n1 = n2 + 2;\n    //}\n\tvoid Print(){\n\t\tcout << \"n1:\" << n1 << \", n2: \" << n2 <<endl;  \n\t}\n};\n\nint main(int argc, char **argv) {\n\tA a;\n\ta.Print();\n\treturn 1;\n}\n~~~\n\n方式一：类的成员变量通过构造函数初始化列表初始化时，这段代码的输出结果：`n1:32766, n2:0`，当然多次执行时，`n1`的值并不相同。\n\n方式二：在构造函数内部初始化成员变量时，输出结果：`n1:2, n2:0`。\n\n### 分析\n\n1、成员变量在使用初始化列表初始化时，与构造函数中初始化成员列表的顺序无关，只与定义成员变量的顺序有关。因为成员变量的初始化次序是由变量在内存中的次序决定的，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。这点在EffectiveC++中有详细介绍。\n\n2、如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。\n\n3、注意：类的成员变量在定义时，不能初始化。因为此时类并没有进行实例化（创建对象），因此并没有分配内存。\n\n4、注意：类中const成员常量必须在构造函数初始化列表中初始化。\n\n5、注意：类中static成员变量，必须在类外初始化。\n\n6、静态变量进行初始化顺序是基类的静态变量先初始化，然后是其派生类，直到所有的静态变量都被初始化。这里需要注意全局变量和静态变量的初始化是不分次序的。这也不难理解，其实静态变量和全局变量都被放在公共内存区。可以把静态变量理解为带有”作用域“的全局变量。在一切初始化工作结束后，main函数会被调用，如果某个类的构造函数被执行，那么首先基类的成员变量会被初始化。 \n\n### 总结\n\n1. 类的成员变量的初始化\n   - 非static非const成员变量，一般在构造函数中进行初始化\n   - static成员变量，必须在类的外面进行初始化（在类的实现时，在类的外部进行初始化）\n   - const成员变量，必须在类的构造函数的初始化列表中初始化\n   - static const成员变量，可以在类的内部声明时初始化\n\n2. 类的成员变量初始化顺序\n   - 基类的静态变量或全局变量\n   - 派生类的静态变量或全局变量\n   - 基类的成员变量\n   - 派生类的成员变量\n\n3. 必须在构造函数的初始化列表中的情况\n\n   - 类的const常量\n   - 类的引用类型成员\n   - 没有默认构造函数的类类型成员\n   - 如果类存在继承关系，派生类必须在其初始化列表中调用基类的构造函数","source":"_posts/C++学习之成员变量的初始化顺序.md","raw":"---\ntitle: C++学习之成员变量的初始化顺序\ndate: 2018-03-28 11:26:29\ntags:\n  - C++\n  - 面试\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++成员变量初始化顺序的学习内容。\n\n<!---more-->\n\n我现在是研一，最近研二的学长学姐们都在准备找实习，各种面试笔试，工作不好找，形势好严峻。所以听从学长的建议从现在开始积累编程语言（C++、Python）、算法、数据结构方面的基础知识，为今后面试找工作做好准备。在读*剑指offer*书时遇到*成员变量初始化顺序*这种问题，打算查资料深入学习下。\n\n首先是下面的测试代码：\n\n~~~c++\n#include <iostream>\nusing namespace std;\n\nclass A\n{\nprivate:\n\tint n1;\n\tint n2;\n\npublic:\n    //成员变量初始化方式一：构造函数初始化列表初始化\n\tA():n2(0),n1(n2+2){}\n    \n    //成员变量初始化方式二：构造函数内初始化\n    //A(){\n    //    n2　=　0;\n    //    n1 = n2 + 2;\n    //}\n\tvoid Print(){\n\t\tcout << \"n1:\" << n1 << \", n2: \" << n2 <<endl;  \n\t}\n};\n\nint main(int argc, char **argv) {\n\tA a;\n\ta.Print();\n\treturn 1;\n}\n~~~\n\n方式一：类的成员变量通过构造函数初始化列表初始化时，这段代码的输出结果：`n1:32766, n2:0`，当然多次执行时，`n1`的值并不相同。\n\n方式二：在构造函数内部初始化成员变量时，输出结果：`n1:2, n2:0`。\n\n### 分析\n\n1、成员变量在使用初始化列表初始化时，与构造函数中初始化成员列表的顺序无关，只与定义成员变量的顺序有关。因为成员变量的初始化次序是由变量在内存中的次序决定的，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。这点在EffectiveC++中有详细介绍。\n\n2、如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。\n\n3、注意：类的成员变量在定义时，不能初始化。因为此时类并没有进行实例化（创建对象），因此并没有分配内存。\n\n4、注意：类中const成员常量必须在构造函数初始化列表中初始化。\n\n5、注意：类中static成员变量，必须在类外初始化。\n\n6、静态变量进行初始化顺序是基类的静态变量先初始化，然后是其派生类，直到所有的静态变量都被初始化。这里需要注意全局变量和静态变量的初始化是不分次序的。这也不难理解，其实静态变量和全局变量都被放在公共内存区。可以把静态变量理解为带有”作用域“的全局变量。在一切初始化工作结束后，main函数会被调用，如果某个类的构造函数被执行，那么首先基类的成员变量会被初始化。 \n\n### 总结\n\n1. 类的成员变量的初始化\n   - 非static非const成员变量，一般在构造函数中进行初始化\n   - static成员变量，必须在类的外面进行初始化（在类的实现时，在类的外部进行初始化）\n   - const成员变量，必须在类的构造函数的初始化列表中初始化\n   - static const成员变量，可以在类的内部声明时初始化\n\n2. 类的成员变量初始化顺序\n   - 基类的静态变量或全局变量\n   - 派生类的静态变量或全局变量\n   - 基类的成员变量\n   - 派生类的成员变量\n\n3. 必须在构造函数的初始化列表中的情况\n\n   - 类的const常量\n   - 类的引用类型成员\n   - 没有默认构造函数的类类型成员\n   - 如果类存在继承关系，派生类必须在其初始化列表中调用基类的构造函数","slug":"C++学习之成员变量的初始化顺序","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbtp0005qlcrcrkpoifm","content":"<hr>\n<p>这篇文章是有关C++成员变量初始化顺序的学习内容。</p>\n<a id=\"more\"></a>\n<p>我现在是研一，最近研二的学长学姐们都在准备找实习，各种面试笔试，工作不好找，形势好严峻。所以听从学长的建议从现在开始积累编程语言（C++、Python）、算法、数据结构方面的基础知识，为今后面试找工作做好准备。在读<em>剑指offer</em>书时遇到<em>成员变量初始化顺序</em>这种问题，打算查资料深入学习下。</p>\n<p>首先是下面的测试代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> n1;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> n2;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//成员变量初始化方式一：构造函数初始化列表初始化</span></span><br><span class=\"line\">\tA():n2(<span class=\"number\">0</span>),n1(n2+<span class=\"number\">2</span>)&#123;&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//成员变量初始化方式二：构造函数内初始化</span></span><br><span class=\"line\">    <span class=\"comment\">//A()&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">//    n2　=　0;</span></span><br><span class=\"line\">    <span class=\"comment\">//    n1 = n2 + 2;</span></span><br><span class=\"line\">    <span class=\"comment\">//&#125;</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Print</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"n1:\"</span> &lt;&lt; n1 &lt;&lt; <span class=\"string\">\", n2: \"</span> &lt;&lt; n2 &lt;&lt;<span class=\"built_in\">endl</span>;  </span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span> </span>&#123;</span><br><span class=\"line\">\tA a;</span><br><span class=\"line\">\ta.Print();</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>方式一：类的成员变量通过构造函数初始化列表初始化时，这段代码的输出结果：<code>n1:32766, n2:0</code>，当然多次执行时，<code>n1</code>的值并不相同。</p>\n<p>方式二：在构造函数内部初始化成员变量时，输出结果：<code>n1:2, n2:0</code>。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>1、成员变量在使用初始化列表初始化时，与构造函数中初始化成员列表的顺序无关，只与定义成员变量的顺序有关。因为成员变量的初始化次序是由变量在内存中的次序决定的，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。这点在EffectiveC++中有详细介绍。</p>\n<p>2、如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。</p>\n<p>3、注意：类的成员变量在定义时，不能初始化。因为此时类并没有进行实例化（创建对象），因此并没有分配内存。</p>\n<p>4、注意：类中const成员常量必须在构造函数初始化列表中初始化。</p>\n<p>5、注意：类中static成员变量，必须在类外初始化。</p>\n<p>6、静态变量进行初始化顺序是基类的静态变量先初始化，然后是其派生类，直到所有的静态变量都被初始化。这里需要注意全局变量和静态变量的初始化是不分次序的。这也不难理解，其实静态变量和全局变量都被放在公共内存区。可以把静态变量理解为带有”作用域“的全局变量。在一切初始化工作结束后，main函数会被调用，如果某个类的构造函数被执行，那么首先基类的成员变量会被初始化。 </p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li><p>类的成员变量的初始化</p>\n<ul>\n<li>非static非const成员变量，一般在构造函数中进行初始化</li>\n<li>static成员变量，必须在类的外面进行初始化（在类的实现时，在类的外部进行初始化）</li>\n<li>const成员变量，必须在类的构造函数的初始化列表中初始化</li>\n<li>static const成员变量，可以在类的内部声明时初始化</li>\n</ul>\n</li>\n<li><p>类的成员变量初始化顺序</p>\n<ul>\n<li>基类的静态变量或全局变量</li>\n<li>派生类的静态变量或全局变量</li>\n<li>基类的成员变量</li>\n<li>派生类的成员变量</li>\n</ul>\n</li>\n<li><p>必须在构造函数的初始化列表中的情况</p>\n<ul>\n<li>类的const常量</li>\n<li>类的引用类型成员</li>\n<li>没有默认构造函数的类类型成员</li>\n<li>如果类存在继承关系，派生类必须在其初始化列表中调用基类的构造函数</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++成员变量初始化顺序的学习内容。</p>","more":"<p>我现在是研一，最近研二的学长学姐们都在准备找实习，各种面试笔试，工作不好找，形势好严峻。所以听从学长的建议从现在开始积累编程语言（C++、Python）、算法、数据结构方面的基础知识，为今后面试找工作做好准备。在读<em>剑指offer</em>书时遇到<em>成员变量初始化顺序</em>这种问题，打算查资料深入学习下。</p>\n<p>首先是下面的测试代码：</p>\n<!--�0-->\n<p>方式一：类的成员变量通过构造函数初始化列表初始化时，这段代码的输出结果：<code>n1:32766, n2:0</code>，当然多次执行时，<code>n1</code>的值并不相同。</p>\n<p>方式二：在构造函数内部初始化成员变量时，输出结果：<code>n1:2, n2:0</code>。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>1、成员变量在使用初始化列表初始化时，与构造函数中初始化成员列表的顺序无关，只与定义成员变量的顺序有关。因为成员变量的初始化次序是由变量在内存中的次序决定的，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。这点在EffectiveC++中有详细介绍。</p>\n<p>2、如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。</p>\n<p>3、注意：类的成员变量在定义时，不能初始化。因为此时类并没有进行实例化（创建对象），因此并没有分配内存。</p>\n<p>4、注意：类中const成员常量必须在构造函数初始化列表中初始化。</p>\n<p>5、注意：类中static成员变量，必须在类外初始化。</p>\n<p>6、静态变量进行初始化顺序是基类的静态变量先初始化，然后是其派生类，直到所有的静态变量都被初始化。这里需要注意全局变量和静态变量的初始化是不分次序的。这也不难理解，其实静态变量和全局变量都被放在公共内存区。可以把静态变量理解为带有”作用域“的全局变量。在一切初始化工作结束后，main函数会被调用，如果某个类的构造函数被执行，那么首先基类的成员变量会被初始化。 </p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li><p>类的成员变量的初始化</p>\n<ul>\n<li>非static非const成员变量，一般在构造函数中进行初始化</li>\n<li>static成员变量，必须在类的外面进行初始化（在类的实现时，在类的外部进行初始化）</li>\n<li>const成员变量，必须在类的构造函数的初始化列表中初始化</li>\n<li>static const成员变量，可以在类的内部声明时初始化</li>\n</ul>\n</li>\n<li><p>类的成员变量初始化顺序</p>\n<ul>\n<li>基类的静态变量或全局变量</li>\n<li>派生类的静态变量或全局变量</li>\n<li>基类的成员变量</li>\n<li>派生类的成员变量</li>\n</ul>\n</li>\n<li><p>必须在构造函数的初始化列表中的情况</p>\n<ul>\n<li>类的const常量</li>\n<li>类的引用类型成员</li>\n<li>没有默认构造函数的类类型成员</li>\n<li>如果类存在继承关系，派生类必须在其初始化列表中调用基类的构造函数</li>\n</ul>\n</li>\n</ol>"},{"title":"C++学习之复制构造函数","date":"2018-04-16T10:05:21.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++复制构造函数的学习内容。\n\n<!---more-->\n\n## 构造函数\n\n类的每个对象之间的区别有：外在区别为对象的名称，内在区别是对象自身的属性值，即数据成员的值。在定义对象的同时进行的数据成员设置，称为对象的初始化。\n\n构造函数的作用就是在对象被创建时利用特定的值构造对象，将对象初始化为一个特定的状态。构造函数也是一类成员函数，**在对象被创建时将被自动调用**。调用时无须提供参数的构造函数称为默认构造函数，类中没有写构造函数，编译器会自动生成一个隐含的默认构造函数，其参数列表和函数体皆为空。\n\n构造函数可以直接访问类的所有数据成员，可以是内联函数（`inline`声明的函数），可以带有参数列表，可以带默认的形参值，可以重载。\n\n例子：\n\n~~~c++\nclass Clock{\n    public:\n    Clock(int newH, int newM, int newS);//构造函数\n    Clock(){\t\t\t\t\t\t\t//重载构造函数\n        hour = 0;\n        minute = 0;\n        second = 0;\n    }\n    void setTime(int newH, int newM, int newS);\n    void showTime();\n}\n//其他函数实现略\nint main(){\n    Clock c1(0, 0, 0);//调用有参数的构造函数\n    Clock c2;\t\t  //调用无参数的构造函数\n    ...\n}\n~~~\n\n## 复制构造函数\n\n复制构造函数是一种特殊的构造函数，具有一般构造函数的所有特性，其形参是本类对象的引用。其作用是使用一个已经存在的对象（由复制构造函数的参数指定），去初始化同类的一个新对象。\n\n可以根据实际需要定义复制构造函数，以实现同类对象之间的数据成员的传递，如果不定义类的复制构造函数，系统会在必要时（需要使用复制构造函数时，如下三种情况）自动生成一个隐含的复制构造函数，其功能是将初始值对象的每个数据成员的值都复制到新建立的对象中。\n\n复制构造函数被调用的情况：\n\n- 1. 当用类的一个对象去初始化该类的另一个对象时\n\n- 2. 当函数的形参是类的对象，调用函数时，进行形参和实参的结合时\n\n  **注意：**只有把对象用值传递时，才会调用复制构造函数，如果传递引用，则不会调用复制构造函数，所以传递比较大的对象时，传递引用会比传递值的效率高很多。\n\n  但是如果是值传递，在形参复制到实参会调用复制构造函数，如果允许复制构造函数传值，就会在复制构造函数内调用复制构造函数，形成永无休止的递归调用从而导致栈溢出。因此，**C++的标准不允许复制构造函数传值参数**，也就是只能传递引用（这样还可以避免无谓的消耗，提高代码的效率），在复制构造函数内部不会改变传入的对象的状态，所以可以使用**常量引用**。即`ClassA(const ClassA& other)`。\n\n\n- 3. 当函数的返回值是类的对象，函数执行完成返回调用者时\n\n  **注意：**由于在被调用函数内部定义的变量只在被调用函数作用域起作用，所以调用函数完成后，要返回的对象就会消亡。所以，这种情况系统会在主函数中创建一个无名临时对象，其生存期只在函数调用所处的表达式中。函数返回时会自动调用复制构造函数将返回值的值传给临时对象，使用临时对象完成赋值或输出等操作。\n\n例子：\n\n~~~c++\nclass Point{\n    public:\n        Point(int xx=0,int yy=0){\t//构造函数\n            x=xx;\n            y=yy;\n        }\n        Point(const Point &p){\t\t//复制构造函数，最好使用常量引用，不允许使用值传递的形式Point(Point p)\n            x=p.x;\n            y=p.y;\n        }\n        int getX(){return x;}\n        int getY(){return y;}\n    private:\n   \t \tint x,y;    \n}\nvoid fun(Point p){\n    cout << p.getX()<<<endl;\n}\nPoint g(){\n    Point a(1,2);\n    return a;\n}\nint main(){\n    Point a(1,2);\n    Point b(a);   //1\n    Point c = a;  //1\n    f(a);\t\t  //2\n    Point x = g();//3\n}\n~~~\n\n如果只是直接将原对象的数据成员值一一赋值给新对象的相应数据成员，其实没有必要再编写复制构造函数，只需使用隐含的默认构造函数足以。\n\n但是，编写复制构造函数可以实现这样的操作，即在进行对象的复制时，只是有选择、有变化地进行复制。\n\n另外，**当类的数据成员中有指针类型时，默认复制构造函数实现的只能是浅复制**，这会带来数据安全方面的隐患。要实现正确的复制，即深复制，必须编写复制构造函数。\n\n- 浅复制：用一个对象初始化另一个对象时，只复制了成员，并没有复制资源，使两个对象同时指向了同一资源的复制方式称为浅复制。但是析构函数又在对象生命周期结束后释放资源，势必会两次返还资源，就会导致编译器报错。\n- 深复制：即当一个对象创建时，分配了资源，这时必须显示定义复制构造函数，这种在用一个对象初始化另一个对象时，不仅复制了成员，也复制了资源的复制方式称为深复制。\n\n> 复制构造函数又被叫做拷贝构造函数（copy constructor），复制初始化也叫做拷贝初始化。\n>\n> 拷贝构造函数和拷贝初始化不要混淆。拷贝初始化过程要调用拷贝构造函数，但拷贝构造函数也可以用在直接初始化过程。\n>\n> 详情参见：[explicit关键字、构造函数与对象初始化](https://blog.csdn.net/tianmingdyx/article/details/79823470)\n\n\n\n","source":"_posts/C++学习之复制构造函数.md","raw":"---\ntitle: C++学习之复制构造函数\ndate: 2018-04-16 18:05:21\ntags:\n  - C++\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++复制构造函数的学习内容。\n\n<!---more-->\n\n## 构造函数\n\n类的每个对象之间的区别有：外在区别为对象的名称，内在区别是对象自身的属性值，即数据成员的值。在定义对象的同时进行的数据成员设置，称为对象的初始化。\n\n构造函数的作用就是在对象被创建时利用特定的值构造对象，将对象初始化为一个特定的状态。构造函数也是一类成员函数，**在对象被创建时将被自动调用**。调用时无须提供参数的构造函数称为默认构造函数，类中没有写构造函数，编译器会自动生成一个隐含的默认构造函数，其参数列表和函数体皆为空。\n\n构造函数可以直接访问类的所有数据成员，可以是内联函数（`inline`声明的函数），可以带有参数列表，可以带默认的形参值，可以重载。\n\n例子：\n\n~~~c++\nclass Clock{\n    public:\n    Clock(int newH, int newM, int newS);//构造函数\n    Clock(){\t\t\t\t\t\t\t//重载构造函数\n        hour = 0;\n        minute = 0;\n        second = 0;\n    }\n    void setTime(int newH, int newM, int newS);\n    void showTime();\n}\n//其他函数实现略\nint main(){\n    Clock c1(0, 0, 0);//调用有参数的构造函数\n    Clock c2;\t\t  //调用无参数的构造函数\n    ...\n}\n~~~\n\n## 复制构造函数\n\n复制构造函数是一种特殊的构造函数，具有一般构造函数的所有特性，其形参是本类对象的引用。其作用是使用一个已经存在的对象（由复制构造函数的参数指定），去初始化同类的一个新对象。\n\n可以根据实际需要定义复制构造函数，以实现同类对象之间的数据成员的传递，如果不定义类的复制构造函数，系统会在必要时（需要使用复制构造函数时，如下三种情况）自动生成一个隐含的复制构造函数，其功能是将初始值对象的每个数据成员的值都复制到新建立的对象中。\n\n复制构造函数被调用的情况：\n\n- 1. 当用类的一个对象去初始化该类的另一个对象时\n\n- 2. 当函数的形参是类的对象，调用函数时，进行形参和实参的结合时\n\n  **注意：**只有把对象用值传递时，才会调用复制构造函数，如果传递引用，则不会调用复制构造函数，所以传递比较大的对象时，传递引用会比传递值的效率高很多。\n\n  但是如果是值传递，在形参复制到实参会调用复制构造函数，如果允许复制构造函数传值，就会在复制构造函数内调用复制构造函数，形成永无休止的递归调用从而导致栈溢出。因此，**C++的标准不允许复制构造函数传值参数**，也就是只能传递引用（这样还可以避免无谓的消耗，提高代码的效率），在复制构造函数内部不会改变传入的对象的状态，所以可以使用**常量引用**。即`ClassA(const ClassA& other)`。\n\n\n- 3. 当函数的返回值是类的对象，函数执行完成返回调用者时\n\n  **注意：**由于在被调用函数内部定义的变量只在被调用函数作用域起作用，所以调用函数完成后，要返回的对象就会消亡。所以，这种情况系统会在主函数中创建一个无名临时对象，其生存期只在函数调用所处的表达式中。函数返回时会自动调用复制构造函数将返回值的值传给临时对象，使用临时对象完成赋值或输出等操作。\n\n例子：\n\n~~~c++\nclass Point{\n    public:\n        Point(int xx=0,int yy=0){\t//构造函数\n            x=xx;\n            y=yy;\n        }\n        Point(const Point &p){\t\t//复制构造函数，最好使用常量引用，不允许使用值传递的形式Point(Point p)\n            x=p.x;\n            y=p.y;\n        }\n        int getX(){return x;}\n        int getY(){return y;}\n    private:\n   \t \tint x,y;    \n}\nvoid fun(Point p){\n    cout << p.getX()<<<endl;\n}\nPoint g(){\n    Point a(1,2);\n    return a;\n}\nint main(){\n    Point a(1,2);\n    Point b(a);   //1\n    Point c = a;  //1\n    f(a);\t\t  //2\n    Point x = g();//3\n}\n~~~\n\n如果只是直接将原对象的数据成员值一一赋值给新对象的相应数据成员，其实没有必要再编写复制构造函数，只需使用隐含的默认构造函数足以。\n\n但是，编写复制构造函数可以实现这样的操作，即在进行对象的复制时，只是有选择、有变化地进行复制。\n\n另外，**当类的数据成员中有指针类型时，默认复制构造函数实现的只能是浅复制**，这会带来数据安全方面的隐患。要实现正确的复制，即深复制，必须编写复制构造函数。\n\n- 浅复制：用一个对象初始化另一个对象时，只复制了成员，并没有复制资源，使两个对象同时指向了同一资源的复制方式称为浅复制。但是析构函数又在对象生命周期结束后释放资源，势必会两次返还资源，就会导致编译器报错。\n- 深复制：即当一个对象创建时，分配了资源，这时必须显示定义复制构造函数，这种在用一个对象初始化另一个对象时，不仅复制了成员，也复制了资源的复制方式称为深复制。\n\n> 复制构造函数又被叫做拷贝构造函数（copy constructor），复制初始化也叫做拷贝初始化。\n>\n> 拷贝构造函数和拷贝初始化不要混淆。拷贝初始化过程要调用拷贝构造函数，但拷贝构造函数也可以用在直接初始化过程。\n>\n> 详情参见：[explicit关键字、构造函数与对象初始化](https://blog.csdn.net/tianmingdyx/article/details/79823470)\n\n\n\n","slug":"C++学习之复制构造函数","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbtr0006qlcrkdi91pkk","content":"<hr>\n<p>这篇文章是有关C++复制构造函数的学习内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"构造函数\"><a href=\"#构造函数\" class=\"headerlink\" title=\"构造函数\"></a>构造函数</h2><p>类的每个对象之间的区别有：外在区别为对象的名称，内在区别是对象自身的属性值，即数据成员的值。在定义对象的同时进行的数据成员设置，称为对象的初始化。</p>\n<p>构造函数的作用就是在对象被创建时利用特定的值构造对象，将对象初始化为一个特定的状态。构造函数也是一类成员函数，<strong>在对象被创建时将被自动调用</strong>。调用时无须提供参数的构造函数称为默认构造函数，类中没有写构造函数，编译器会自动生成一个隐含的默认构造函数，其参数列表和函数体皆为空。</p>\n<p>构造函数可以直接访问类的所有数据成员，可以是内联函数（<code>inline</code>声明的函数），可以带有参数列表，可以带默认的形参值，可以重载。</p>\n<p>例子：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Clock</span>&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">    Clock(<span class=\"keyword\">int</span> newH, <span class=\"keyword\">int</span> newM, <span class=\"keyword\">int</span> newS);<span class=\"comment\">//构造函数</span></span><br><span class=\"line\">    Clock()&#123;\t\t\t\t\t\t\t<span class=\"comment\">//重载构造函数</span></span><br><span class=\"line\">        hour = <span class=\"number\">0</span>;</span><br><span class=\"line\">        minute = <span class=\"number\">0</span>;</span><br><span class=\"line\">        second = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setTime</span><span class=\"params\">(<span class=\"keyword\">int</span> newH, <span class=\"keyword\">int</span> newM, <span class=\"keyword\">int</span> newS)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">showTime</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//其他函数实现略</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Clock <span class=\"title\">c1</span><span class=\"params\">(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>)</span></span>;<span class=\"comment\">//调用有参数的构造函数</span></span><br><span class=\"line\">    Clock c2;\t\t  <span class=\"comment\">//调用无参数的构造函数</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"复制构造函数\"><a href=\"#复制构造函数\" class=\"headerlink\" title=\"复制构造函数\"></a>复制构造函数</h2><p>复制构造函数是一种特殊的构造函数，具有一般构造函数的所有特性，其形参是本类对象的引用。其作用是使用一个已经存在的对象（由复制构造函数的参数指定），去初始化同类的一个新对象。</p>\n<p>可以根据实际需要定义复制构造函数，以实现同类对象之间的数据成员的传递，如果不定义类的复制构造函数，系统会在必要时（需要使用复制构造函数时，如下三种情况）自动生成一个隐含的复制构造函数，其功能是将初始值对象的每个数据成员的值都复制到新建立的对象中。</p>\n<p>复制构造函数被调用的情况：</p>\n<ul>\n<li><ol>\n<li>当用类的一个对象去初始化该类的另一个对象时</li>\n</ol>\n</li>\n<li><ol>\n<li>当函数的形参是类的对象，调用函数时，进行形参和实参的结合时</li>\n</ol>\n<p><strong>注意：</strong>只有把对象用值传递时，才会调用复制构造函数，如果传递引用，则不会调用复制构造函数，所以传递比较大的对象时，传递引用会比传递值的效率高很多。</p>\n<p>但是如果是值传递，在形参复制到实参会调用复制构造函数，如果允许复制构造函数传值，就会在复制构造函数内调用复制构造函数，形成永无休止的递归调用从而导致栈溢出。因此，<strong>C++的标准不允许复制构造函数传值参数</strong>，也就是只能传递引用（这样还可以避免无谓的消耗，提高代码的效率），在复制构造函数内部不会改变传入的对象的状态，所以可以使用<strong>常量引用</strong>。即<code>ClassA(const ClassA&amp; other)</code>。</p>\n</li>\n</ul>\n<ul>\n<li><ol>\n<li>当函数的返回值是类的对象，函数执行完成返回调用者时</li>\n</ol>\n<p><strong>注意：</strong>由于在被调用函数内部定义的变量只在被调用函数作用域起作用，所以调用函数完成后，要返回的对象就会消亡。所以，这种情况系统会在主函数中创建一个无名临时对象，其生存期只在函数调用所处的表达式中。函数返回时会自动调用复制构造函数将返回值的值传给临时对象，使用临时对象完成赋值或输出等操作。</p>\n</li>\n</ul>\n<p>例子：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Point</span>&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">        Point(<span class=\"keyword\">int</span> xx=<span class=\"number\">0</span>,<span class=\"keyword\">int</span> yy=<span class=\"number\">0</span>)&#123;\t<span class=\"comment\">//构造函数</span></span><br><span class=\"line\">            x=xx;</span><br><span class=\"line\">            y=yy;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Point(<span class=\"keyword\">const</span> Point &amp;p)&#123;\t\t<span class=\"comment\">//复制构造函数，最好使用常量引用，不允许使用值传递的形式Point(Point p)</span></span><br><span class=\"line\">            x=p.x;</span><br><span class=\"line\">            y=p.y;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getX</span><span class=\"params\">()</span></span>&#123;<span class=\"keyword\">return</span> x;&#125;</span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getY</span><span class=\"params\">()</span></span>&#123;<span class=\"keyword\">return</span> y;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">private</span>:</span><br><span class=\"line\">   \t \t<span class=\"keyword\">int</span> x,y;    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">(Point p)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; p.getX()&lt;&lt;&lt;<span class=\"built_in\">endl</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\">Point <span class=\"title\">g</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">a</span><span class=\"params\">(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">a</span><span class=\"params\">(<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">b</span><span class=\"params\">(a)</span></span>;   <span class=\"comment\">//1</span></span><br><span class=\"line\">    Point c = a;  <span class=\"comment\">//1</span></span><br><span class=\"line\">    f(a);\t\t  <span class=\"comment\">//2</span></span><br><span class=\"line\">    Point x = g();<span class=\"comment\">//3</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果只是直接将原对象的数据成员值一一赋值给新对象的相应数据成员，其实没有必要再编写复制构造函数，只需使用隐含的默认构造函数足以。</p>\n<p>但是，编写复制构造函数可以实现这样的操作，即在进行对象的复制时，只是有选择、有变化地进行复制。</p>\n<p>另外，<strong>当类的数据成员中有指针类型时，默认复制构造函数实现的只能是浅复制</strong>，这会带来数据安全方面的隐患。要实现正确的复制，即深复制，必须编写复制构造函数。</p>\n<ul>\n<li>浅复制：用一个对象初始化另一个对象时，只复制了成员，并没有复制资源，使两个对象同时指向了同一资源的复制方式称为浅复制。但是析构函数又在对象生命周期结束后释放资源，势必会两次返还资源，就会导致编译器报错。</li>\n<li>深复制：即当一个对象创建时，分配了资源，这时必须显示定义复制构造函数，这种在用一个对象初始化另一个对象时，不仅复制了成员，也复制了资源的复制方式称为深复制。</li>\n</ul>\n<blockquote>\n<p>复制构造函数又被叫做拷贝构造函数（copy constructor），复制初始化也叫做拷贝初始化。</p>\n<p>拷贝构造函数和拷贝初始化不要混淆。拷贝初始化过程要调用拷贝构造函数，但拷贝构造函数也可以用在直接初始化过程。</p>\n<p>详情参见：<a href=\"https://blog.csdn.net/tianmingdyx/article/details/79823470\" target=\"_blank\" rel=\"noopener\">explicit关键字、构造函数与对象初始化</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++复制构造函数的学习内容。</p>","more":"<h2 id=\"构造函数\"><a href=\"#构造函数\" class=\"headerlink\" title=\"构造函数\"></a>构造函数</h2><p>类的每个对象之间的区别有：外在区别为对象的名称，内在区别是对象自身的属性值，即数据成员的值。在定义对象的同时进行的数据成员设置，称为对象的初始化。</p>\n<p>构造函数的作用就是在对象被创建时利用特定的值构造对象，将对象初始化为一个特定的状态。构造函数也是一类成员函数，<strong>在对象被创建时将被自动调用</strong>。调用时无须提供参数的构造函数称为默认构造函数，类中没有写构造函数，编译器会自动生成一个隐含的默认构造函数，其参数列表和函数体皆为空。</p>\n<p>构造函数可以直接访问类的所有数据成员，可以是内联函数（<code>inline</code>声明的函数），可以带有参数列表，可以带默认的形参值，可以重载。</p>\n<p>例子：</p>\n<!--�1-->\n<h2 id=\"复制构造函数\"><a href=\"#复制构造函数\" class=\"headerlink\" title=\"复制构造函数\"></a>复制构造函数</h2><p>复制构造函数是一种特殊的构造函数，具有一般构造函数的所有特性，其形参是本类对象的引用。其作用是使用一个已经存在的对象（由复制构造函数的参数指定），去初始化同类的一个新对象。</p>\n<p>可以根据实际需要定义复制构造函数，以实现同类对象之间的数据成员的传递，如果不定义类的复制构造函数，系统会在必要时（需要使用复制构造函数时，如下三种情况）自动生成一个隐含的复制构造函数，其功能是将初始值对象的每个数据成员的值都复制到新建立的对象中。</p>\n<p>复制构造函数被调用的情况：</p>\n<ul>\n<li><ol>\n<li>当用类的一个对象去初始化该类的另一个对象时</li>\n</ol>\n</li>\n<li><ol>\n<li>当函数的形参是类的对象，调用函数时，进行形参和实参的结合时</li>\n</ol>\n<p><strong>注意：</strong>只有把对象用值传递时，才会调用复制构造函数，如果传递引用，则不会调用复制构造函数，所以传递比较大的对象时，传递引用会比传递值的效率高很多。</p>\n<p>但是如果是值传递，在形参复制到实参会调用复制构造函数，如果允许复制构造函数传值，就会在复制构造函数内调用复制构造函数，形成永无休止的递归调用从而导致栈溢出。因此，<strong>C++的标准不允许复制构造函数传值参数</strong>，也就是只能传递引用（这样还可以避免无谓的消耗，提高代码的效率），在复制构造函数内部不会改变传入的对象的状态，所以可以使用<strong>常量引用</strong>。即<code>ClassA(const ClassA&amp; other)</code>。</p>\n</li>\n</ul>\n<ul>\n<li><ol>\n<li>当函数的返回值是类的对象，函数执行完成返回调用者时</li>\n</ol>\n<p><strong>注意：</strong>由于在被调用函数内部定义的变量只在被调用函数作用域起作用，所以调用函数完成后，要返回的对象就会消亡。所以，这种情况系统会在主函数中创建一个无名临时对象，其生存期只在函数调用所处的表达式中。函数返回时会自动调用复制构造函数将返回值的值传给临时对象，使用临时对象完成赋值或输出等操作。</p>\n</li>\n</ul>\n<p>例子：</p>\n<!--�2-->\n<p>如果只是直接将原对象的数据成员值一一赋值给新对象的相应数据成员，其实没有必要再编写复制构造函数，只需使用隐含的默认构造函数足以。</p>\n<p>但是，编写复制构造函数可以实现这样的操作，即在进行对象的复制时，只是有选择、有变化地进行复制。</p>\n<p>另外，<strong>当类的数据成员中有指针类型时，默认复制构造函数实现的只能是浅复制</strong>，这会带来数据安全方面的隐患。要实现正确的复制，即深复制，必须编写复制构造函数。</p>\n<ul>\n<li>浅复制：用一个对象初始化另一个对象时，只复制了成员，并没有复制资源，使两个对象同时指向了同一资源的复制方式称为浅复制。但是析构函数又在对象生命周期结束后释放资源，势必会两次返还资源，就会导致编译器报错。</li>\n<li>深复制：即当一个对象创建时，分配了资源，这时必须显示定义复制构造函数，这种在用一个对象初始化另一个对象时，不仅复制了成员，也复制了资源的复制方式称为深复制。</li>\n</ul>\n<blockquote>\n<p>复制构造函数又被叫做拷贝构造函数（copy constructor），复制初始化也叫做拷贝初始化。</p>\n<p>拷贝构造函数和拷贝初始化不要混淆。拷贝初始化过程要调用拷贝构造函数，但拷贝构造函数也可以用在直接初始化过程。</p>\n<p>详情参见：<a href=\"https://blog.csdn.net/tianmingdyx/article/details/79823470\" target=\"_blank\" rel=\"noopener\">explicit关键字、构造函数与对象初始化</a></p>\n</blockquote>"},{"title":"C++学习之智能指针","date":"2018-05-09T03:01:03.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++智能指针的学习内容。\n\n<!---more-->\n\nC++11之前\nauto_ptr\n\nC++11\nshared_ptr\nunique_ptr\nweak_ptr\n\n\nC++14\nmake_shared\nmake_unique","source":"_posts/C++学习之智能指针.md","raw":"---\ntitle: C++学习之智能指针\ndate: 2018-05-09 11:01:03\ntags:\n  - C++\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++智能指针的学习内容。\n\n<!---more-->\n\nC++11之前\nauto_ptr\n\nC++11\nshared_ptr\nunique_ptr\nweak_ptr\n\n\nC++14\nmake_shared\nmake_unique","slug":"C++学习之智能指针","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbtt0007qlcr1bmpyzvf","content":"<hr>\n<p>这篇文章是有关C++智能指针的学习内容。</p>\n<a id=\"more\"></a>\n<p>C++11之前<br>auto_ptr</p>\n<p>C++11<br>shared_ptr<br>unique_ptr<br>weak_ptr</p>\n<p>C++14<br>make_shared<br>make_unique</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++智能指针的学习内容。</p>","more":"<p>C++11之前<br>auto_ptr</p>\n<p>C++11<br>shared_ptr<br>unique_ptr<br>weak_ptr</p>\n<p>C++14<br>make_shared<br>make_unique</p>"},{"title":"CMake编译调试","date":"2018-04-29T06:50:40.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关CMake编译调试相关指令的内容。\n\n<!--more--->\n\nCMake编译时如果需要选择c++编译器版本，需要添加：`add_compile_options(-std=c++11)`。\n\n如果需要编译出共享库而不是静态库，执行`cmake`命令时使用`cmake .. -DBUILD_SHARED_LIBS=ON`。\n\n\n\n使用CMake编译的程序，也可以使用gdb进行调试。方法如下。\n\n### CMakeList.txt文件前面添加内容：\n\n~~~cmake\nSET(CMAKE_BUILD_TYPE \"Debug\") \nSET(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -Wall -g -ggdb\")\nSET(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O3 -Wall\")\n~~~\n\n### 重新编译\n\n在build目录下执行编译命令：\n\n~~~shell\ncmake .. -DCMAKE_BUILD_TYPE=Debug\nmake\n~~~\n\n### 启动调试\n\n~~~shell\ngdb exe #exe为可执行文件\n~~~\n\n### 调试程序\n\n具体的调试方法，参考https://blog.csdn.net/haoel/article/details/2879/\n\n","source":"_posts/CMake编译调试.md","raw":"---\ntitle: CMake编译调试\ndate: 2018-04-29 14:50:40\ntags:\n   - CMake\ncategories: \n  - 工具\n  - CMake\ncopyright: true\n---\n\n-----\n\n这篇文章是有关CMake编译调试相关指令的内容。\n\n<!--more--->\n\nCMake编译时如果需要选择c++编译器版本，需要添加：`add_compile_options(-std=c++11)`。\n\n如果需要编译出共享库而不是静态库，执行`cmake`命令时使用`cmake .. -DBUILD_SHARED_LIBS=ON`。\n\n\n\n使用CMake编译的程序，也可以使用gdb进行调试。方法如下。\n\n### CMakeList.txt文件前面添加内容：\n\n~~~cmake\nSET(CMAKE_BUILD_TYPE \"Debug\") \nSET(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -Wall -g -ggdb\")\nSET(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O3 -Wall\")\n~~~\n\n### 重新编译\n\n在build目录下执行编译命令：\n\n~~~shell\ncmake .. -DCMAKE_BUILD_TYPE=Debug\nmake\n~~~\n\n### 启动调试\n\n~~~shell\ngdb exe #exe为可执行文件\n~~~\n\n### 调试程序\n\n具体的调试方法，参考https://blog.csdn.net/haoel/article/details/2879/\n\n","slug":"CMake编译调试","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbtz000bqlcr5cdoa4ez","content":"<hr>\n<p>这篇文章是有关CMake编译调试相关指令的内容。</p>\n<a id=\"more\"></a>\n<p>CMake编译时如果需要选择c++编译器版本，需要添加：<code>add_compile_options(-std=c++11)</code>。</p>\n<p>如果需要编译出共享库而不是静态库，执行<code>cmake</code>命令时使用<code>cmake .. -DBUILD_SHARED_LIBS=ON</code>。</p>\n<p>使用CMake编译的程序，也可以使用gdb进行调试。方法如下。</p>\n<h3 id=\"CMakeList-txt文件前面添加内容：\"><a href=\"#CMakeList-txt文件前面添加内容：\" class=\"headerlink\" title=\"CMakeList.txt文件前面添加内容：\"></a>CMakeList.txt文件前面添加内容：</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_BUILD_TYPE <span class=\"string\">\"Debug\"</span>) </span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_CXX_FLAGS_DEBUG <span class=\"string\">\"$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_CXX_FLAGS_RELEASE <span class=\"string\">\"$ENV&#123;CXXFLAGS&#125; -O3 -Wall\"</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"重新编译\"><a href=\"#重新编译\" class=\"headerlink\" title=\"重新编译\"></a>重新编译</h3><p>在build目录下执行编译命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cmake .. -DCMAKE_BUILD_TYPE=Debug</span><br><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动调试\"><a href=\"#启动调试\" class=\"headerlink\" title=\"启动调试\"></a>启动调试</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gdb exe #exe为可执行文件</span><br></pre></td></tr></table></figure>\n<h3 id=\"调试程序\"><a href=\"#调试程序\" class=\"headerlink\" title=\"调试程序\"></a>调试程序</h3><p>具体的调试方法，参考<a href=\"https://blog.csdn.net/haoel/article/details/2879/\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/haoel/article/details/2879/</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关CMake编译调试相关指令的内容。</p>","more":"<p>CMake编译时如果需要选择c++编译器版本，需要添加：<code>add_compile_options(-std=c++11)</code>。</p>\n<p>如果需要编译出共享库而不是静态库，执行<code>cmake</code>命令时使用<code>cmake .. -DBUILD_SHARED_LIBS=ON</code>。</p>\n<p>使用CMake编译的程序，也可以使用gdb进行调试。方法如下。</p>\n<h3 id=\"CMakeList-txt文件前面添加内容：\"><a href=\"#CMakeList-txt文件前面添加内容：\" class=\"headerlink\" title=\"CMakeList.txt文件前面添加内容：\"></a>CMakeList.txt文件前面添加内容：</h3><!--�3-->\n<h3 id=\"重新编译\"><a href=\"#重新编译\" class=\"headerlink\" title=\"重新编译\"></a>重新编译</h3><p>在build目录下执行编译命令：</p>\n<!--�4-->\n<h3 id=\"启动调试\"><a href=\"#启动调试\" class=\"headerlink\" title=\"启动调试\"></a>启动调试</h3><!--�5-->\n<h3 id=\"调试程序\"><a href=\"#调试程序\" class=\"headerlink\" title=\"调试程序\"></a>调试程序</h3><p>具体的调试方法，参考<a href=\"https://blog.csdn.net/haoel/article/details/2879/\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/haoel/article/details/2879/</a></p>"},{"title":"CMake学习之查找链接库--find_package使用方法","date":"2018-08-03T13:38:19.000Z","copyright":true,"_content":"\n------\n\n这篇文章是有关CMake中使用find_package指令的内容。\n\n<!--more--->\n\n**如果编译软件使用了外部库，事先并不知道它的头文件和链接库的位置。得在编译命令中加上包含它们的查找路径。CMake使用`find_package`命令来解决这个问题。本文讨论了如何在CMake项目中使用外部库，即`find_package()`的工作原理。**\n\n## FIND_PACKAGE\n\n`FIND_PACKAGE( <name> [version][EXACT] [QUIET][NO_MODULE] [ [ REQUIRED | COMPONENTS ][ componets... ] ] )`\n\n用来调用预定义在 CMAKE_MODULE_PATH 下的 `Find<name>.cmake `模块。也可以自己定义` Find<name>`模块，将其放入工程的某个目录中，通过` SET(CMAKE_MODULE_PATH dir)`设置查找路径，供工程`FIND_PACKAGE`使用。\n\n这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 `Find<name>.cmake `并执行。\n\n- version参数：需要一个版本号，它是正在查找的包应该兼容的版本号。\n- EXACT选项：要求版本号必须精确匹配。如果在find-module内部对该命令的递归调用没有给定[version]参数，那么[version]和EXACT选项会自动地从外部调用前向继承。对版本的支持目前只存在于包和包之间（详见下文）。\n\n- QUIET 参数：会禁掉包没有被发现时的警告信息。对应于`Find<name>.cmake`模块中的 NAME_FIND_QUIETLY。\n- REQUIRED 参数：其含义是指是否是工程必须的，表示如果报没有找到的话，cmake的过程会终止，并输出警告信息。对应于`Find<name>.cmake`模块中的 NAME_FIND_REQUIRED 变量。\n- COMPONENTS参数：在REQUIRED选项之后，或者如果没有指定REQUIRED选项但是指定了COMPONENTS选项，在它们的后面可以列出一些与包相关（依赖）的部件清单（components list）\n\n示例：\n\nFIND_PACKAGE( libdb_cxx REQUIRED)\n\n这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 Findlibdb_cxx.cmake 并执行。\n\n## 包查找是如何工作的\n\n1. `find_package()` 命令会在模块路径中寻找`Find<name>.cmake` ，这是查找库的一个典型方式。首先CMake查看`${CMAKE_MODULE_PATH}`中的所有目录，然后再查看它自己的模块目录`<CMAKE_ROOT>/share/cmake-x.y/Modules/`（`$CMAKE_ROOT`的具体值可以通过CMake中`message`命令输出）。**这称为模块模式。**\n2. 如果没找到这样的文件，在`~/.cmake/packages/`或`/usr/local/share/`中的各个包目录中查找，寻找`<库名字的大写>Config.cmake`或者`<库名字的小写>-config.cmake`(比如库Opencv，它会查找`/usr/local/share/OpenCV`中的`OpenCVConfig.cmake`或`opencv-config.cmake`)。**这称为配置模式。**配置模式的文件的编写见 [这里的文档](http://vtk.org/Wiki/CMake/Tutorials/How_to_create_a_ProjectConfig.cmake_file) 。可能还会用到 [importing and exporting targets](http://vtk.org/Wiki/CMake/Tutorials/Exporting_and_Importing_Targets) 这篇文档。\n\n\n不管使用哪一种模式，只要找到包，就会定义下面这些变量：\n\n~~~\n<NAME>_FOUND\n<NAME>_INCLUDE_DIRS or <NAME>_INCLUDES\n<NAME>_LIBRARIES or <NAME>_LIBRARIES or <NAME>_LIBS\n<NAME>_DEFINITIONS\n~~~\n\n这些都在 `Find<name>.cmake`文件中。\n\n找到NAME包后，变量NAME_INCLUDE_DIRS中将包括指定NAME库头文件的查找路径。\n变量NAME_LIBRARY_DIRS中将包含指定NAME库的.a或.so文件的所在目录的路径。\n\n参考链接：\n\nhttp://blog.csdn.net/bytxl/article/details/50637277\n\nhttps://blog.csdn.net/u011092188/article/details/61425924","source":"_posts/CMake学习之查找链接库-find-package使用方法.md","raw":"---\ntitle: CMake学习之查找链接库--find_package使用方法\ndate: 2018-08-03 21:38:19\ntags:\n   - CMake\ncategories: \n  - 工具\n  - CMake\ncopyright: true\n---\n\n------\n\n这篇文章是有关CMake中使用find_package指令的内容。\n\n<!--more--->\n\n**如果编译软件使用了外部库，事先并不知道它的头文件和链接库的位置。得在编译命令中加上包含它们的查找路径。CMake使用`find_package`命令来解决这个问题。本文讨论了如何在CMake项目中使用外部库，即`find_package()`的工作原理。**\n\n## FIND_PACKAGE\n\n`FIND_PACKAGE( <name> [version][EXACT] [QUIET][NO_MODULE] [ [ REQUIRED | COMPONENTS ][ componets... ] ] )`\n\n用来调用预定义在 CMAKE_MODULE_PATH 下的 `Find<name>.cmake `模块。也可以自己定义` Find<name>`模块，将其放入工程的某个目录中，通过` SET(CMAKE_MODULE_PATH dir)`设置查找路径，供工程`FIND_PACKAGE`使用。\n\n这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 `Find<name>.cmake `并执行。\n\n- version参数：需要一个版本号，它是正在查找的包应该兼容的版本号。\n- EXACT选项：要求版本号必须精确匹配。如果在find-module内部对该命令的递归调用没有给定[version]参数，那么[version]和EXACT选项会自动地从外部调用前向继承。对版本的支持目前只存在于包和包之间（详见下文）。\n\n- QUIET 参数：会禁掉包没有被发现时的警告信息。对应于`Find<name>.cmake`模块中的 NAME_FIND_QUIETLY。\n- REQUIRED 参数：其含义是指是否是工程必须的，表示如果报没有找到的话，cmake的过程会终止，并输出警告信息。对应于`Find<name>.cmake`模块中的 NAME_FIND_REQUIRED 变量。\n- COMPONENTS参数：在REQUIRED选项之后，或者如果没有指定REQUIRED选项但是指定了COMPONENTS选项，在它们的后面可以列出一些与包相关（依赖）的部件清单（components list）\n\n示例：\n\nFIND_PACKAGE( libdb_cxx REQUIRED)\n\n这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 Findlibdb_cxx.cmake 并执行。\n\n## 包查找是如何工作的\n\n1. `find_package()` 命令会在模块路径中寻找`Find<name>.cmake` ，这是查找库的一个典型方式。首先CMake查看`${CMAKE_MODULE_PATH}`中的所有目录，然后再查看它自己的模块目录`<CMAKE_ROOT>/share/cmake-x.y/Modules/`（`$CMAKE_ROOT`的具体值可以通过CMake中`message`命令输出）。**这称为模块模式。**\n2. 如果没找到这样的文件，在`~/.cmake/packages/`或`/usr/local/share/`中的各个包目录中查找，寻找`<库名字的大写>Config.cmake`或者`<库名字的小写>-config.cmake`(比如库Opencv，它会查找`/usr/local/share/OpenCV`中的`OpenCVConfig.cmake`或`opencv-config.cmake`)。**这称为配置模式。**配置模式的文件的编写见 [这里的文档](http://vtk.org/Wiki/CMake/Tutorials/How_to_create_a_ProjectConfig.cmake_file) 。可能还会用到 [importing and exporting targets](http://vtk.org/Wiki/CMake/Tutorials/Exporting_and_Importing_Targets) 这篇文档。\n\n\n不管使用哪一种模式，只要找到包，就会定义下面这些变量：\n\n~~~\n<NAME>_FOUND\n<NAME>_INCLUDE_DIRS or <NAME>_INCLUDES\n<NAME>_LIBRARIES or <NAME>_LIBRARIES or <NAME>_LIBS\n<NAME>_DEFINITIONS\n~~~\n\n这些都在 `Find<name>.cmake`文件中。\n\n找到NAME包后，变量NAME_INCLUDE_DIRS中将包括指定NAME库头文件的查找路径。\n变量NAME_LIBRARY_DIRS中将包含指定NAME库的.a或.so文件的所在目录的路径。\n\n参考链接：\n\nhttp://blog.csdn.net/bytxl/article/details/50637277\n\nhttps://blog.csdn.net/u011092188/article/details/61425924","slug":"CMake学习之查找链接库-find-package使用方法","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbu4000dqlcr2dgsgpbu","content":"<hr>\n<p>这篇文章是有关CMake中使用find_package指令的内容。</p>\n<a id=\"more\"></a>\n<p><strong>如果编译软件使用了外部库，事先并不知道它的头文件和链接库的位置。得在编译命令中加上包含它们的查找路径。CMake使用<code>find_package</code>命令来解决这个问题。本文讨论了如何在CMake项目中使用外部库，即<code>find_package()</code>的工作原理。</strong></p>\n<h2 id=\"FIND-PACKAGE\"><a href=\"#FIND-PACKAGE\" class=\"headerlink\" title=\"FIND_PACKAGE\"></a>FIND_PACKAGE</h2><p><code>FIND_PACKAGE( &lt;name&gt; [version][EXACT] [QUIET][NO_MODULE] [ [ REQUIRED | COMPONENTS ][ componets... ] ] )</code></p>\n<p>用来调用预定义在 CMAKE_MODULE_PATH 下的 <code>Find&lt;name&gt;.cmake</code>模块。也可以自己定义<code>Find&lt;name&gt;</code>模块，将其放入工程的某个目录中，通过<code>SET(CMAKE_MODULE_PATH dir)</code>设置查找路径，供工程<code>FIND_PACKAGE</code>使用。</p>\n<p>这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 <code>Find&lt;name&gt;.cmake</code>并执行。</p>\n<ul>\n<li>version参数：需要一个版本号，它是正在查找的包应该兼容的版本号。</li>\n<li><p>EXACT选项：要求版本号必须精确匹配。如果在find-module内部对该命令的递归调用没有给定[version]参数，那么[version]和EXACT选项会自动地从外部调用前向继承。对版本的支持目前只存在于包和包之间（详见下文）。</p>\n</li>\n<li><p>QUIET 参数：会禁掉包没有被发现时的警告信息。对应于<code>Find&lt;name&gt;.cmake</code>模块中的 NAME_FIND_QUIETLY。</p>\n</li>\n<li>REQUIRED 参数：其含义是指是否是工程必须的，表示如果报没有找到的话，cmake的过程会终止，并输出警告信息。对应于<code>Find&lt;name&gt;.cmake</code>模块中的 NAME_FIND_REQUIRED 变量。</li>\n<li>COMPONENTS参数：在REQUIRED选项之后，或者如果没有指定REQUIRED选项但是指定了COMPONENTS选项，在它们的后面可以列出一些与包相关（依赖）的部件清单（components list）</li>\n</ul>\n<p>示例：</p>\n<p>FIND_PACKAGE( libdb_cxx REQUIRED)</p>\n<p>这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 Findlibdb_cxx.cmake 并执行。</p>\n<h2 id=\"包查找是如何工作的\"><a href=\"#包查找是如何工作的\" class=\"headerlink\" title=\"包查找是如何工作的\"></a>包查找是如何工作的</h2><ol>\n<li><code>find_package()</code> 命令会在模块路径中寻找<code>Find&lt;name&gt;.cmake</code> ，这是查找库的一个典型方式。首先CMake查看<code>${CMAKE_MODULE_PATH}</code>中的所有目录，然后再查看它自己的模块目录<code>&lt;CMAKE_ROOT&gt;/share/cmake-x.y/Modules/</code>（<code>$CMAKE_ROOT</code>的具体值可以通过CMake中<code>message</code>命令输出）。<strong>这称为模块模式。</strong></li>\n<li>如果没找到这样的文件，在<code>~/.cmake/packages/</code>或<code>/usr/local/share/</code>中的各个包目录中查找，寻找<code>&lt;库名字的大写&gt;Config.cmake</code>或者<code>&lt;库名字的小写&gt;-config.cmake</code>(比如库Opencv，它会查找<code>/usr/local/share/OpenCV</code>中的<code>OpenCVConfig.cmake</code>或<code>opencv-config.cmake</code>)。<strong>这称为配置模式。</strong>配置模式的文件的编写见 <a href=\"http://vtk.org/Wiki/CMake/Tutorials/How_to_create_a_ProjectConfig.cmake_file\" target=\"_blank\" rel=\"noopener\">这里的文档</a> 。可能还会用到 <a href=\"http://vtk.org/Wiki/CMake/Tutorials/Exporting_and_Importing_Targets\" target=\"_blank\" rel=\"noopener\">importing and exporting targets</a> 这篇文档。</li>\n</ol>\n<p>不管使用哪一种模式，只要找到包，就会定义下面这些变量：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;NAME&gt;_FOUND</span><br><span class=\"line\">&lt;NAME&gt;_INCLUDE_DIRS or &lt;NAME&gt;_INCLUDES</span><br><span class=\"line\">&lt;NAME&gt;_LIBRARIES or &lt;NAME&gt;_LIBRARIES or &lt;NAME&gt;_LIBS</span><br><span class=\"line\">&lt;NAME&gt;_DEFINITIONS</span><br></pre></td></tr></table></figure>\n<p>这些都在 <code>Find&lt;name&gt;.cmake</code>文件中。</p>\n<p>找到NAME包后，变量NAME_INCLUDE_DIRS中将包括指定NAME库头文件的查找路径。<br>变量NAME_LIBRARY_DIRS中将包含指定NAME库的.a或.so文件的所在目录的路径。</p>\n<p>参考链接：</p>\n<p><a href=\"http://blog.csdn.net/bytxl/article/details/50637277\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/bytxl/article/details/50637277</a></p>\n<p><a href=\"https://blog.csdn.net/u011092188/article/details/61425924\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011092188/article/details/61425924</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关CMake中使用find_package指令的内容。</p>","more":"<p><strong>如果编译软件使用了外部库，事先并不知道它的头文件和链接库的位置。得在编译命令中加上包含它们的查找路径。CMake使用<code>find_package</code>命令来解决这个问题。本文讨论了如何在CMake项目中使用外部库，即<code>find_package()</code>的工作原理。</strong></p>\n<h2 id=\"FIND-PACKAGE\"><a href=\"#FIND-PACKAGE\" class=\"headerlink\" title=\"FIND_PACKAGE\"></a>FIND_PACKAGE</h2><p><code>FIND_PACKAGE( &lt;name&gt; [version][EXACT] [QUIET][NO_MODULE] [ [ REQUIRED | COMPONENTS ][ componets... ] ] )</code></p>\n<p>用来调用预定义在 CMAKE_MODULE_PATH 下的 <code>Find&lt;name&gt;.cmake</code>模块。也可以自己定义<code>Find&lt;name&gt;</code>模块，将其放入工程的某个目录中，通过<code>SET(CMAKE_MODULE_PATH dir)</code>设置查找路径，供工程<code>FIND_PACKAGE</code>使用。</p>\n<p>这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 <code>Find&lt;name&gt;.cmake</code>并执行。</p>\n<ul>\n<li>version参数：需要一个版本号，它是正在查找的包应该兼容的版本号。</li>\n<li><p>EXACT选项：要求版本号必须精确匹配。如果在find-module内部对该命令的递归调用没有给定[version]参数，那么[version]和EXACT选项会自动地从外部调用前向继承。对版本的支持目前只存在于包和包之间（详见下文）。</p>\n</li>\n<li><p>QUIET 参数：会禁掉包没有被发现时的警告信息。对应于<code>Find&lt;name&gt;.cmake</code>模块中的 NAME_FIND_QUIETLY。</p>\n</li>\n<li>REQUIRED 参数：其含义是指是否是工程必须的，表示如果报没有找到的话，cmake的过程会终止，并输出警告信息。对应于<code>Find&lt;name&gt;.cmake</code>模块中的 NAME_FIND_REQUIRED 变量。</li>\n<li>COMPONENTS参数：在REQUIRED选项之后，或者如果没有指定REQUIRED选项但是指定了COMPONENTS选项，在它们的后面可以列出一些与包相关（依赖）的部件清单（components list）</li>\n</ul>\n<p>示例：</p>\n<p>FIND_PACKAGE( libdb_cxx REQUIRED)</p>\n<p>这条命令执行后，CMake 会到变量 CMAKE_MODULE_PATH 指示的目录中查找文件 Findlibdb_cxx.cmake 并执行。</p>\n<h2 id=\"包查找是如何工作的\"><a href=\"#包查找是如何工作的\" class=\"headerlink\" title=\"包查找是如何工作的\"></a>包查找是如何工作的</h2><ol>\n<li><code>find_package()</code> 命令会在模块路径中寻找<code>Find&lt;name&gt;.cmake</code> ，这是查找库的一个典型方式。首先CMake查看<code>${CMAKE_MODULE_PATH}</code>中的所有目录，然后再查看它自己的模块目录<code>&lt;CMAKE_ROOT&gt;/share/cmake-x.y/Modules/</code>（<code>$CMAKE_ROOT</code>的具体值可以通过CMake中<code>message</code>命令输出）。<strong>这称为模块模式。</strong></li>\n<li>如果没找到这样的文件，在<code>~/.cmake/packages/</code>或<code>/usr/local/share/</code>中的各个包目录中查找，寻找<code>&lt;库名字的大写&gt;Config.cmake</code>或者<code>&lt;库名字的小写&gt;-config.cmake</code>(比如库Opencv，它会查找<code>/usr/local/share/OpenCV</code>中的<code>OpenCVConfig.cmake</code>或<code>opencv-config.cmake</code>)。<strong>这称为配置模式。</strong>配置模式的文件的编写见 <a href=\"http://vtk.org/Wiki/CMake/Tutorials/How_to_create_a_ProjectConfig.cmake_file\" target=\"_blank\" rel=\"noopener\">这里的文档</a> 。可能还会用到 <a href=\"http://vtk.org/Wiki/CMake/Tutorials/Exporting_and_Importing_Targets\" target=\"_blank\" rel=\"noopener\">importing and exporting targets</a> 这篇文档。</li>\n</ol>\n<p>不管使用哪一种模式，只要找到包，就会定义下面这些变量：</p>\n<!--�6-->\n<p>这些都在 <code>Find&lt;name&gt;.cmake</code>文件中。</p>\n<p>找到NAME包后，变量NAME_INCLUDE_DIRS中将包括指定NAME库头文件的查找路径。<br>变量NAME_LIBRARY_DIRS中将包含指定NAME库的.a或.so文件的所在目录的路径。</p>\n<p>参考链接：</p>\n<p><a href=\"http://blog.csdn.net/bytxl/article/details/50637277\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/bytxl/article/details/50637277</a></p>\n<p><a href=\"https://blog.csdn.net/u011092188/article/details/61425924\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011092188/article/details/61425924</a></p>"},{"title":"Caffe的CPU模式安装","date":"2018-04-21T07:20:24.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关Caffe CPU模式安装的内容。\n\n<!--more--->\n\n在跑师兄的程序时，有一个场景检测模块用到Caffe深度学习框架库，可惜自己的台式机显卡太菜，装不了CUDA。只能尝试使用Caffe的CPU模式。Caffe在计算时有两种模式可以选择，CPU或GPU，使用GPU处理图像速度会更快。\n\n## 检查是否有NVIDIA显卡\n\n~~~shell\nlspci | grep -i nvidia\n~~~\n\n如果没有显示内容，说明电脑没有nvidia显卡。如果输出相关显卡及版本信息，说明可以使用GPU模式。\n\n## 安装依赖包\n\n~~~shell\nsudo apt-get install libprotobuf-dev \nsudo apt-get install libleveldb-dev\nsudo apt-get install libsnappy-dev \nsudo apt-get install libopencv-dev\nsudo apt-get install libhdf5-serial-dev\nsudo apt-get install protobuf-compiler\nsudo apt-get install libgflags-dev\nsudo apt-get install libgoogle-glog-dev\nsudo apt-get install liblmdb-dev\nsudo apt-get install libatlas-base-dev\n~~~\n\n## 下载Caffe\n\n安装git\n\n~~~shell\nsudo apt-get install git\n~~~\n\n克隆Caffe\n\n~~~shell\ngit clone git://github.com/BVLC/caffe.git\n~~~\n\n## 编译Caffe\n\n### 进入Caffe目录\n\n~~~shell\ncd caffe/\n~~~\n\n### 生成Makefile.config文件\n\n将caffe目录下自带的Makefile.config.example文件复制一份并更名为Makefile.config，命令如下：\n\n~~~shell\ncp Makefile.config.example Makefile.config\n~~~\n\n### 修改Makefile.config文件\n\n- 取消`CPU_ONLY := 1`行的注释，设置为CPU模式\n- 配置引用文件路径\n  - `INCLUDE_DIRS`新增内容：`/usr/include/hdf5/serial`\n  - `LIBRARY_DIRS`新增内容：`/usr/lib/x86_64-linux-gnu/hdf5/serial`\n\n### 编译\n\n需要在caffe目录下新建`build`目录，命令如下：\n\n~~~shell\nmkdir build\ncd build\ncamke ..\nsudo make all\nsudo make test\nsudo make runtest\n~~~\n\n编译成功的话，就会显示若干个用例执行成功。\n\n可以执行`sudo make clean`撤销执行。\n\n本人开始并没有新建build目录，直接开始`make`的。但是出现了类似如下的错误：\n\n~~~shell\nError: 'make all' 'make test'\n.build_release/lib/libcaffe.so: undefined reference to cv::imread(cv::String const&, int)' \n.build_release/lib/libcaffe.so: undefined reference tocv::imencode(cv::String const&, cv::_InputArray const&, std::vector >&, std::vector > const&)'\n~~~\n\n网上有很多解决方式，本人试过都没有效果，最后按照上述过程编译就不会有这个错误。\n\n\n\n参考文章：\n\nhttps://blog.csdn.net/u010193446/article/details/53259294\n\nhttps://www.cnblogs.com/empty16/p/4828476.html?utm_source=tuicool&utm_medium=referral","source":"_posts/Caffe的CPU模式安装.md","raw":"---\ntitle: Caffe的CPU模式安装\ndate: 2018-04-21 15:20:24\ntags:\n  - Caffe\ncategories: \n  - 深度学习\n  - Caffe\ncopyright: true\n---\n\n-----\n\n这篇文章是有关Caffe CPU模式安装的内容。\n\n<!--more--->\n\n在跑师兄的程序时，有一个场景检测模块用到Caffe深度学习框架库，可惜自己的台式机显卡太菜，装不了CUDA。只能尝试使用Caffe的CPU模式。Caffe在计算时有两种模式可以选择，CPU或GPU，使用GPU处理图像速度会更快。\n\n## 检查是否有NVIDIA显卡\n\n~~~shell\nlspci | grep -i nvidia\n~~~\n\n如果没有显示内容，说明电脑没有nvidia显卡。如果输出相关显卡及版本信息，说明可以使用GPU模式。\n\n## 安装依赖包\n\n~~~shell\nsudo apt-get install libprotobuf-dev \nsudo apt-get install libleveldb-dev\nsudo apt-get install libsnappy-dev \nsudo apt-get install libopencv-dev\nsudo apt-get install libhdf5-serial-dev\nsudo apt-get install protobuf-compiler\nsudo apt-get install libgflags-dev\nsudo apt-get install libgoogle-glog-dev\nsudo apt-get install liblmdb-dev\nsudo apt-get install libatlas-base-dev\n~~~\n\n## 下载Caffe\n\n安装git\n\n~~~shell\nsudo apt-get install git\n~~~\n\n克隆Caffe\n\n~~~shell\ngit clone git://github.com/BVLC/caffe.git\n~~~\n\n## 编译Caffe\n\n### 进入Caffe目录\n\n~~~shell\ncd caffe/\n~~~\n\n### 生成Makefile.config文件\n\n将caffe目录下自带的Makefile.config.example文件复制一份并更名为Makefile.config，命令如下：\n\n~~~shell\ncp Makefile.config.example Makefile.config\n~~~\n\n### 修改Makefile.config文件\n\n- 取消`CPU_ONLY := 1`行的注释，设置为CPU模式\n- 配置引用文件路径\n  - `INCLUDE_DIRS`新增内容：`/usr/include/hdf5/serial`\n  - `LIBRARY_DIRS`新增内容：`/usr/lib/x86_64-linux-gnu/hdf5/serial`\n\n### 编译\n\n需要在caffe目录下新建`build`目录，命令如下：\n\n~~~shell\nmkdir build\ncd build\ncamke ..\nsudo make all\nsudo make test\nsudo make runtest\n~~~\n\n编译成功的话，就会显示若干个用例执行成功。\n\n可以执行`sudo make clean`撤销执行。\n\n本人开始并没有新建build目录，直接开始`make`的。但是出现了类似如下的错误：\n\n~~~shell\nError: 'make all' 'make test'\n.build_release/lib/libcaffe.so: undefined reference to cv::imread(cv::String const&, int)' \n.build_release/lib/libcaffe.so: undefined reference tocv::imencode(cv::String const&, cv::_InputArray const&, std::vector >&, std::vector > const&)'\n~~~\n\n网上有很多解决方式，本人试过都没有效果，最后按照上述过程编译就不会有这个错误。\n\n\n\n参考文章：\n\nhttps://blog.csdn.net/u010193446/article/details/53259294\n\nhttps://www.cnblogs.com/empty16/p/4828476.html?utm_source=tuicool&utm_medium=referral","slug":"Caffe的CPU模式安装","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbu7000hqlcrvn8x0yi2","content":"<hr>\n<p>这篇文章是有关Caffe CPU模式安装的内容。</p>\n<a id=\"more\"></a>\n<p>在跑师兄的程序时，有一个场景检测模块用到Caffe深度学习框架库，可惜自己的台式机显卡太菜，装不了CUDA。只能尝试使用Caffe的CPU模式。Caffe在计算时有两种模式可以选择，CPU或GPU，使用GPU处理图像速度会更快。</p>\n<h2 id=\"检查是否有NVIDIA显卡\"><a href=\"#检查是否有NVIDIA显卡\" class=\"headerlink\" title=\"检查是否有NVIDIA显卡\"></a>检查是否有NVIDIA显卡</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lspci | grep -i nvidia</span><br></pre></td></tr></table></figure>\n<p>如果没有显示内容，说明电脑没有nvidia显卡。如果输出相关显卡及版本信息，说明可以使用GPU模式。</p>\n<h2 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install libprotobuf-dev </span><br><span class=\"line\">sudo apt-get install libleveldb-dev</span><br><span class=\"line\">sudo apt-get install libsnappy-dev </span><br><span class=\"line\">sudo apt-get install libopencv-dev</span><br><span class=\"line\">sudo apt-get install libhdf5-serial-dev</span><br><span class=\"line\">sudo apt-get install protobuf-compiler</span><br><span class=\"line\">sudo apt-get install libgflags-dev</span><br><span class=\"line\">sudo apt-get install libgoogle-glog-dev</span><br><span class=\"line\">sudo apt-get install liblmdb-dev</span><br><span class=\"line\">sudo apt-get install libatlas-base-dev</span><br></pre></td></tr></table></figure>\n<h2 id=\"下载Caffe\"><a href=\"#下载Caffe\" class=\"headerlink\" title=\"下载Caffe\"></a>下载Caffe</h2><p>安装git</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install git</span><br></pre></td></tr></table></figure>\n<p>克隆Caffe</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone git://github.com/BVLC/caffe.git</span><br></pre></td></tr></table></figure>\n<h2 id=\"编译Caffe\"><a href=\"#编译Caffe\" class=\"headerlink\" title=\"编译Caffe\"></a>编译Caffe</h2><h3 id=\"进入Caffe目录\"><a href=\"#进入Caffe目录\" class=\"headerlink\" title=\"进入Caffe目录\"></a>进入Caffe目录</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd caffe/</span><br></pre></td></tr></table></figure>\n<h3 id=\"生成Makefile-config文件\"><a href=\"#生成Makefile-config文件\" class=\"headerlink\" title=\"生成Makefile.config文件\"></a>生成Makefile.config文件</h3><p>将caffe目录下自带的Makefile.config.example文件复制一份并更名为Makefile.config，命令如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp Makefile.config.example Makefile.config</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改Makefile-config文件\"><a href=\"#修改Makefile-config文件\" class=\"headerlink\" title=\"修改Makefile.config文件\"></a>修改Makefile.config文件</h3><ul>\n<li>取消<code>CPU_ONLY := 1</code>行的注释，设置为CPU模式</li>\n<li>配置引用文件路径<ul>\n<li><code>INCLUDE_DIRS</code>新增内容：<code>/usr/include/hdf5/serial</code></li>\n<li><code>LIBRARY_DIRS</code>新增内容：<code>/usr/lib/x86_64-linux-gnu/hdf5/serial</code></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h3><p>需要在caffe目录下新建<code>build</code>目录，命令如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir build</span><br><span class=\"line\">cd build</span><br><span class=\"line\">camke ..</span><br><span class=\"line\">sudo make all</span><br><span class=\"line\">sudo make test</span><br><span class=\"line\">sudo make runtest</span><br></pre></td></tr></table></figure>\n<p>编译成功的话，就会显示若干个用例执行成功。</p>\n<p>可以执行<code>sudo make clean</code>撤销执行。</p>\n<p>本人开始并没有新建build目录，直接开始<code>make</code>的。但是出现了类似如下的错误：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Error: 'make all' 'make test'</span><br><span class=\"line\">.build_release/lib/libcaffe.so: undefined reference to cv::imread(cv::String const&amp;, int)' </span><br><span class=\"line\">.build_release/lib/libcaffe.so: undefined reference tocv::imencode(cv::String const&amp;, cv::_InputArray const&amp;, std::vector &gt;&amp;, std::vector &gt; const&amp;)'</span><br></pre></td></tr></table></figure>\n<p>网上有很多解决方式，本人试过都没有效果，最后按照上述过程编译就不会有这个错误。</p>\n<p>参考文章：</p>\n<p><a href=\"https://blog.csdn.net/u010193446/article/details/53259294\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010193446/article/details/53259294</a></p>\n<p><a href=\"https://www.cnblogs.com/empty16/p/4828476.html?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/empty16/p/4828476.html?utm_source=tuicool&amp;utm_medium=referral</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关Caffe CPU模式安装的内容。</p>","more":"<p>在跑师兄的程序时，有一个场景检测模块用到Caffe深度学习框架库，可惜自己的台式机显卡太菜，装不了CUDA。只能尝试使用Caffe的CPU模式。Caffe在计算时有两种模式可以选择，CPU或GPU，使用GPU处理图像速度会更快。</p>\n<h2 id=\"检查是否有NVIDIA显卡\"><a href=\"#检查是否有NVIDIA显卡\" class=\"headerlink\" title=\"检查是否有NVIDIA显卡\"></a>检查是否有NVIDIA显卡</h2><!--�7-->\n<p>如果没有显示内容，说明电脑没有nvidia显卡。如果输出相关显卡及版本信息，说明可以使用GPU模式。</p>\n<h2 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a>安装依赖包</h2><!--�8-->\n<h2 id=\"下载Caffe\"><a href=\"#下载Caffe\" class=\"headerlink\" title=\"下载Caffe\"></a>下载Caffe</h2><p>安装git</p>\n<!--�9-->\n<p>克隆Caffe</p>\n<!--�10-->\n<h2 id=\"编译Caffe\"><a href=\"#编译Caffe\" class=\"headerlink\" title=\"编译Caffe\"></a>编译Caffe</h2><h3 id=\"进入Caffe目录\"><a href=\"#进入Caffe目录\" class=\"headerlink\" title=\"进入Caffe目录\"></a>进入Caffe目录</h3><!--�11-->\n<h3 id=\"生成Makefile-config文件\"><a href=\"#生成Makefile-config文件\" class=\"headerlink\" title=\"生成Makefile.config文件\"></a>生成Makefile.config文件</h3><p>将caffe目录下自带的Makefile.config.example文件复制一份并更名为Makefile.config，命令如下：</p>\n<!--�12-->\n<h3 id=\"修改Makefile-config文件\"><a href=\"#修改Makefile-config文件\" class=\"headerlink\" title=\"修改Makefile.config文件\"></a>修改Makefile.config文件</h3><ul>\n<li>取消<code>CPU_ONLY := 1</code>行的注释，设置为CPU模式</li>\n<li>配置引用文件路径<ul>\n<li><code>INCLUDE_DIRS</code>新增内容：<code>/usr/include/hdf5/serial</code></li>\n<li><code>LIBRARY_DIRS</code>新增内容：<code>/usr/lib/x86_64-linux-gnu/hdf5/serial</code></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h3><p>需要在caffe目录下新建<code>build</code>目录，命令如下：</p>\n<!--�13-->\n<p>编译成功的话，就会显示若干个用例执行成功。</p>\n<p>可以执行<code>sudo make clean</code>撤销执行。</p>\n<p>本人开始并没有新建build目录，直接开始<code>make</code>的。但是出现了类似如下的错误：</p>\n<!--�14-->\n<p>网上有很多解决方式，本人试过都没有效果，最后按照上述过程编译就不会有这个错误。</p>\n<p>参考文章：</p>\n<p><a href=\"https://blog.csdn.net/u010193446/article/details/53259294\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010193446/article/details/53259294</a></p>\n<p><a href=\"https://www.cnblogs.com/empty16/p/4828476.html?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/empty16/p/4828476.html?utm_source=tuicool&amp;utm_medium=referral</a></p>"},{"title":"Cartographer学习二源码分析之核心代码","date":"2018-09-16T05:52:13.000Z","mathjax":true,"copyright":true,"_content":"\n----\n\n本篇文章是记录激光开源SLAM系统Cartographer源码学习有关的内容。现在做的项目是基于师兄的毕业设计，使用的cartographer版本是20170320，和最新的系统已经有了挺大的差别，但大部分网上资料介绍的系统源码版本都比较旧，所以还是先学习旧版本的系统，搞明白核心内容后再了解更新的功能。\n\n<!--more--->\n\n## 概述\n\nGoogle开源的代码包含两个部分：cartographer[1]和cartographer_ros[2]。cartographer主要负责处理来自雷达、IMU和里程计的数据并基于这些数据进行地图的构建，是cartographer理论的底层实现。cartographer_ros则基于ros的通信机制获取传感器的数据并将它们转换成cartographer中定义的格式传递给cartographer处理，与此同时也将cartographer的处理结果发布用于显示或保存，是基于cartographer的上层应用。ROS应用放在下篇文章分析。\n\n先借用[知乎问题中mfxox](https://www.zhihu.com/question/51348391)的图：\n\n{% asset_img 整体流程.png %}\n\n## Cartographer代码框架\n\n如下图所示，是google官方说明文档中的框架图：\n\n{% asset_img Cartographer系统框架图.png %}\n\nCartographer系统可以分为两个互相有联系的独立系统：local SLAM（frontend）和global SLAM（backend）。\n\n- 前端检测：local SLAM负责构建局部一致的submaps集合并进行融合，这个过程会产生漂移误差。\n\n- 后端闭环优化：global SLAM运行在后端线程，负责在scans和submaps之间使用scan-matching找到回环约束，同时融合其他传感器数据（包括检测重力的方向），完成全局一致性任务。\n\n  > 关于GraphSLAM原理，可以[参考文章](https://blog.csdn.net/heyijia0327/article/details/47686523)，有例子介绍很清晰。\n\n总得来说，前端负责生成高质量的submaps，后端则负责完成地图的全局一致性任务。\n\n输入的传感器数据有四个：\n\n- Range Data（激光雷达，摄像头等）\n- Odometry Pose(里程计数据)\n- IMU Data\n- FixedFramePose（是指确定的位置？？）\n\n里程计数据与IMU数据共同进入PoseExtraPolator，做航迹推算。给定一个里程计与IMU得到的位置估计，用两次以上里程计计算平均速度，用两次以上IMU数据计算平均角速度，然后推算出下一时刻的位置姿态，给到Scan Matching中作为扫描匹配的初值。\n\nRange Data数据经过体素滤波（一种滤波方法）和自适应体素滤波，进入scanMatching，作为观测值。scanMatching用论文中介绍的基于ceres优化的scanMatching方法获得观测最优位置估计，经过Motion Filter滤波，作为位置最优估计构建submap。\n\n## Cartographer代码结构\n\n### 各模块功能\n\n- common：定义基本数据结构以及一些工具的使用接口，包括对数据的处理、时间转换、采样器、脉冲率计算、直方图类、数据计算类、对线程和线程锁的封装等\n- io：文件流写、点云batch类、\n- sensor：定义雷达数据及点云等相关的数据结构\n- transform：定义位姿的数据结构及其相关的转换\n- mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口\n- kalman_filter：（基于UKF的多传感器数据融合）主要通过kalman滤波器完成对IMU、里程计及基于雷达数据的估计位姿的融合，进而估计新进的laser  scan的位姿\n- mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口\n- mapping_2d和mapping_3d：对mapping接口的不同实现（scan match策略对应的文件在这俩目录下的scan_matching目录中）\n\n### mapping_2d\n\n#### GlobalTrajectoryBuilder\n\n实现接收处理上层应用传递的传感器数据的主要接口。有几个重要的成员函数：\n\n- `AddRangefinderData`：用于接收处理上层应用传递的雷达数据\n- `AddImuData`：用于接收处理上层应用传递的IMU数据\n- `AddOdometerPose`：用于接收处理上层应用传递的里程计数据\n\n#### LocalTrajectoryBuilder\n\nlocal SLAM，主要完成完成UKF（扩展卡尔曼滤波器）、scan matching、局部submap的构建，提供了接收处理传感器数据的public函数：\n\n- `AddImuData`：用于处理IMU数据\n\n- `AddOdometerPose`：用于处理里程计数据\n\n- `AddHorizontalLaserFan`：用于处理雷达数据\n\n#### SparsePoseGraph\n\n主要完成基于闭环检测的全局位姿优化。\n\n## 参考资料\n\n1. [cartographer文档](https://google-cartographer.readthedocs.io/en/latest/index.html#)\n2. [cartographer ROS文档](https://google-cartographer-ros.readthedocs.io/en/latest/#)\n3. [cartographer源码阅读（1）——算法整体结构](https://blog.csdn.net/u013721521/article/details/81477005)\n4. [【SLAM】（一）Google Cartographer的初步尝试](https://blog.csdn.net/jsgaobiao/article/details/53116042)\n5. [Cartographer理论及实现浅析](https://blog.csdn.net/u012700322/article/details/53513527)\n6. **[Cartographer 代码阅读分析](https://blog.csdn.net/roadseek_zw/article/details/66968762)**\n7. **[Cartographer 代码阅读分析-2](https://blog.csdn.net/roadseek_zw/article/details/72886079)**\n8. [Cartographer源码分析58系列](https://blog.csdn.net/learnmoreonce/article/category/6989560/3)","source":"_posts/Cartographer学习二源码分析之核心代码.md","raw":"---\ntitle: Cartographer学习二源码分析之核心代码\ndate: 2018-09-16 13:52:13\ntags: \n  - Lidar SLAM\n  - Cartographer\nmathjax: true\ncategories:\n  - 机器人 \n  - SLAM\n  - Cartographer\ncopyright: true\n---\n\n----\n\n本篇文章是记录激光开源SLAM系统Cartographer源码学习有关的内容。现在做的项目是基于师兄的毕业设计，使用的cartographer版本是20170320，和最新的系统已经有了挺大的差别，但大部分网上资料介绍的系统源码版本都比较旧，所以还是先学习旧版本的系统，搞明白核心内容后再了解更新的功能。\n\n<!--more--->\n\n## 概述\n\nGoogle开源的代码包含两个部分：cartographer[1]和cartographer_ros[2]。cartographer主要负责处理来自雷达、IMU和里程计的数据并基于这些数据进行地图的构建，是cartographer理论的底层实现。cartographer_ros则基于ros的通信机制获取传感器的数据并将它们转换成cartographer中定义的格式传递给cartographer处理，与此同时也将cartographer的处理结果发布用于显示或保存，是基于cartographer的上层应用。ROS应用放在下篇文章分析。\n\n先借用[知乎问题中mfxox](https://www.zhihu.com/question/51348391)的图：\n\n{% asset_img 整体流程.png %}\n\n## Cartographer代码框架\n\n如下图所示，是google官方说明文档中的框架图：\n\n{% asset_img Cartographer系统框架图.png %}\n\nCartographer系统可以分为两个互相有联系的独立系统：local SLAM（frontend）和global SLAM（backend）。\n\n- 前端检测：local SLAM负责构建局部一致的submaps集合并进行融合，这个过程会产生漂移误差。\n\n- 后端闭环优化：global SLAM运行在后端线程，负责在scans和submaps之间使用scan-matching找到回环约束，同时融合其他传感器数据（包括检测重力的方向），完成全局一致性任务。\n\n  > 关于GraphSLAM原理，可以[参考文章](https://blog.csdn.net/heyijia0327/article/details/47686523)，有例子介绍很清晰。\n\n总得来说，前端负责生成高质量的submaps，后端则负责完成地图的全局一致性任务。\n\n输入的传感器数据有四个：\n\n- Range Data（激光雷达，摄像头等）\n- Odometry Pose(里程计数据)\n- IMU Data\n- FixedFramePose（是指确定的位置？？）\n\n里程计数据与IMU数据共同进入PoseExtraPolator，做航迹推算。给定一个里程计与IMU得到的位置估计，用两次以上里程计计算平均速度，用两次以上IMU数据计算平均角速度，然后推算出下一时刻的位置姿态，给到Scan Matching中作为扫描匹配的初值。\n\nRange Data数据经过体素滤波（一种滤波方法）和自适应体素滤波，进入scanMatching，作为观测值。scanMatching用论文中介绍的基于ceres优化的scanMatching方法获得观测最优位置估计，经过Motion Filter滤波，作为位置最优估计构建submap。\n\n## Cartographer代码结构\n\n### 各模块功能\n\n- common：定义基本数据结构以及一些工具的使用接口，包括对数据的处理、时间转换、采样器、脉冲率计算、直方图类、数据计算类、对线程和线程锁的封装等\n- io：文件流写、点云batch类、\n- sensor：定义雷达数据及点云等相关的数据结构\n- transform：定义位姿的数据结构及其相关的转换\n- mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口\n- kalman_filter：（基于UKF的多传感器数据融合）主要通过kalman滤波器完成对IMU、里程计及基于雷达数据的估计位姿的融合，进而估计新进的laser  scan的位姿\n- mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口\n- mapping_2d和mapping_3d：对mapping接口的不同实现（scan match策略对应的文件在这俩目录下的scan_matching目录中）\n\n### mapping_2d\n\n#### GlobalTrajectoryBuilder\n\n实现接收处理上层应用传递的传感器数据的主要接口。有几个重要的成员函数：\n\n- `AddRangefinderData`：用于接收处理上层应用传递的雷达数据\n- `AddImuData`：用于接收处理上层应用传递的IMU数据\n- `AddOdometerPose`：用于接收处理上层应用传递的里程计数据\n\n#### LocalTrajectoryBuilder\n\nlocal SLAM，主要完成完成UKF（扩展卡尔曼滤波器）、scan matching、局部submap的构建，提供了接收处理传感器数据的public函数：\n\n- `AddImuData`：用于处理IMU数据\n\n- `AddOdometerPose`：用于处理里程计数据\n\n- `AddHorizontalLaserFan`：用于处理雷达数据\n\n#### SparsePoseGraph\n\n主要完成基于闭环检测的全局位姿优化。\n\n## 参考资料\n\n1. [cartographer文档](https://google-cartographer.readthedocs.io/en/latest/index.html#)\n2. [cartographer ROS文档](https://google-cartographer-ros.readthedocs.io/en/latest/#)\n3. [cartographer源码阅读（1）——算法整体结构](https://blog.csdn.net/u013721521/article/details/81477005)\n4. [【SLAM】（一）Google Cartographer的初步尝试](https://blog.csdn.net/jsgaobiao/article/details/53116042)\n5. [Cartographer理论及实现浅析](https://blog.csdn.net/u012700322/article/details/53513527)\n6. **[Cartographer 代码阅读分析](https://blog.csdn.net/roadseek_zw/article/details/66968762)**\n7. **[Cartographer 代码阅读分析-2](https://blog.csdn.net/roadseek_zw/article/details/72886079)**\n8. [Cartographer源码分析58系列](https://blog.csdn.net/learnmoreonce/article/category/6989560/3)","slug":"Cartographer学习二源码分析之核心代码","published":1,"updated":"2019-05-30T12:29:26.275Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbu9000jqlcr3ez65lsa","content":"<hr>\n<p>本篇文章是记录激光开源SLAM系统Cartographer源码学习有关的内容。现在做的项目是基于师兄的毕业设计，使用的cartographer版本是20170320，和最新的系统已经有了挺大的差别，但大部分网上资料介绍的系统源码版本都比较旧，所以还是先学习旧版本的系统，搞明白核心内容后再了解更新的功能。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Google开源的代码包含两个部分：cartographer[1]和cartographer_ros[2]。cartographer主要负责处理来自雷达、IMU和里程计的数据并基于这些数据进行地图的构建，是cartographer理论的底层实现。cartographer_ros则基于ros的通信机制获取传感器的数据并将它们转换成cartographer中定义的格式传递给cartographer处理，与此同时也将cartographer的处理结果发布用于显示或保存，是基于cartographer的上层应用。ROS应用放在下篇文章分析。</p>\n<p>先借用<a href=\"https://www.zhihu.com/question/51348391\" target=\"_blank\" rel=\"noopener\">知乎问题中mfxox</a>的图：</p>\n<img src=\"/2018/09/16/Cartographer学习二源码分析之核心代码/整体流程.png\">\n<h2 id=\"Cartographer代码框架\"><a href=\"#Cartographer代码框架\" class=\"headerlink\" title=\"Cartographer代码框架\"></a>Cartographer代码框架</h2><p>如下图所示，是google官方说明文档中的框架图：</p>\n<img src=\"/2018/09/16/Cartographer学习二源码分析之核心代码/Cartographer系统框架图.png\">\n<p>Cartographer系统可以分为两个互相有联系的独立系统：local SLAM（frontend）和global SLAM（backend）。</p>\n<ul>\n<li><p>前端检测：local SLAM负责构建局部一致的submaps集合并进行融合，这个过程会产生漂移误差。</p>\n</li>\n<li><p>后端闭环优化：global SLAM运行在后端线程，负责在scans和submaps之间使用scan-matching找到回环约束，同时融合其他传感器数据（包括检测重力的方向），完成全局一致性任务。</p>\n<blockquote>\n<p>关于GraphSLAM原理，可以<a href=\"https://blog.csdn.net/heyijia0327/article/details/47686523\" target=\"_blank\" rel=\"noopener\">参考文章</a>，有例子介绍很清晰。</p>\n</blockquote>\n</li>\n</ul>\n<p>总得来说，前端负责生成高质量的submaps，后端则负责完成地图的全局一致性任务。</p>\n<p>输入的传感器数据有四个：</p>\n<ul>\n<li>Range Data（激光雷达，摄像头等）</li>\n<li>Odometry Pose(里程计数据)</li>\n<li>IMU Data</li>\n<li>FixedFramePose（是指确定的位置？？）</li>\n</ul>\n<p>里程计数据与IMU数据共同进入PoseExtraPolator，做航迹推算。给定一个里程计与IMU得到的位置估计，用两次以上里程计计算平均速度，用两次以上IMU数据计算平均角速度，然后推算出下一时刻的位置姿态，给到Scan Matching中作为扫描匹配的初值。</p>\n<p>Range Data数据经过体素滤波（一种滤波方法）和自适应体素滤波，进入scanMatching，作为观测值。scanMatching用论文中介绍的基于ceres优化的scanMatching方法获得观测最优位置估计，经过Motion Filter滤波，作为位置最优估计构建submap。</p>\n<h2 id=\"Cartographer代码结构\"><a href=\"#Cartographer代码结构\" class=\"headerlink\" title=\"Cartographer代码结构\"></a>Cartographer代码结构</h2><h3 id=\"各模块功能\"><a href=\"#各模块功能\" class=\"headerlink\" title=\"各模块功能\"></a>各模块功能</h3><ul>\n<li>common：定义基本数据结构以及一些工具的使用接口，包括对数据的处理、时间转换、采样器、脉冲率计算、直方图类、数据计算类、对线程和线程锁的封装等</li>\n<li>io：文件流写、点云batch类、</li>\n<li>sensor：定义雷达数据及点云等相关的数据结构</li>\n<li>transform：定义位姿的数据结构及其相关的转换</li>\n<li>mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口</li>\n<li>kalman_filter：（基于UKF的多传感器数据融合）主要通过kalman滤波器完成对IMU、里程计及基于雷达数据的估计位姿的融合，进而估计新进的laser  scan的位姿</li>\n<li>mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口</li>\n<li>mapping_2d和mapping_3d：对mapping接口的不同实现（scan match策略对应的文件在这俩目录下的scan_matching目录中）</li>\n</ul>\n<h3 id=\"mapping-2d\"><a href=\"#mapping-2d\" class=\"headerlink\" title=\"mapping_2d\"></a>mapping_2d</h3><h4 id=\"GlobalTrajectoryBuilder\"><a href=\"#GlobalTrajectoryBuilder\" class=\"headerlink\" title=\"GlobalTrajectoryBuilder\"></a>GlobalTrajectoryBuilder</h4><p>实现接收处理上层应用传递的传感器数据的主要接口。有几个重要的成员函数：</p>\n<ul>\n<li><code>AddRangefinderData</code>：用于接收处理上层应用传递的雷达数据</li>\n<li><code>AddImuData</code>：用于接收处理上层应用传递的IMU数据</li>\n<li><code>AddOdometerPose</code>：用于接收处理上层应用传递的里程计数据</li>\n</ul>\n<h4 id=\"LocalTrajectoryBuilder\"><a href=\"#LocalTrajectoryBuilder\" class=\"headerlink\" title=\"LocalTrajectoryBuilder\"></a>LocalTrajectoryBuilder</h4><p>local SLAM，主要完成完成UKF（扩展卡尔曼滤波器）、scan matching、局部submap的构建，提供了接收处理传感器数据的public函数：</p>\n<ul>\n<li><p><code>AddImuData</code>：用于处理IMU数据</p>\n</li>\n<li><p><code>AddOdometerPose</code>：用于处理里程计数据</p>\n</li>\n<li><p><code>AddHorizontalLaserFan</code>：用于处理雷达数据</p>\n</li>\n</ul>\n<h4 id=\"SparsePoseGraph\"><a href=\"#SparsePoseGraph\" class=\"headerlink\" title=\"SparsePoseGraph\"></a>SparsePoseGraph</h4><p>主要完成基于闭环检测的全局位姿优化。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://google-cartographer.readthedocs.io/en/latest/index.html#\" target=\"_blank\" rel=\"noopener\">cartographer文档</a></li>\n<li><a href=\"https://google-cartographer-ros.readthedocs.io/en/latest/#\" target=\"_blank\" rel=\"noopener\">cartographer ROS文档</a></li>\n<li><a href=\"https://blog.csdn.net/u013721521/article/details/81477005\" target=\"_blank\" rel=\"noopener\">cartographer源码阅读（1）——算法整体结构</a></li>\n<li><a href=\"https://blog.csdn.net/jsgaobiao/article/details/53116042\" target=\"_blank\" rel=\"noopener\">【SLAM】（一）Google Cartographer的初步尝试</a></li>\n<li><a href=\"https://blog.csdn.net/u012700322/article/details/53513527\" target=\"_blank\" rel=\"noopener\">Cartographer理论及实现浅析</a></li>\n<li><strong><a href=\"https://blog.csdn.net/roadseek_zw/article/details/66968762\" target=\"_blank\" rel=\"noopener\">Cartographer 代码阅读分析</a></strong></li>\n<li><strong><a href=\"https://blog.csdn.net/roadseek_zw/article/details/72886079\" target=\"_blank\" rel=\"noopener\">Cartographer 代码阅读分析-2</a></strong></li>\n<li><a href=\"https://blog.csdn.net/learnmoreonce/article/category/6989560/3\" target=\"_blank\" rel=\"noopener\">Cartographer源码分析58系列</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本篇文章是记录激光开源SLAM系统Cartographer源码学习有关的内容。现在做的项目是基于师兄的毕业设计，使用的cartographer版本是20170320，和最新的系统已经有了挺大的差别，但大部分网上资料介绍的系统源码版本都比较旧，所以还是先学习旧版本的系统，搞明白核心内容后再了解更新的功能。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Google开源的代码包含两个部分：cartographer[1]和cartographer_ros[2]。cartographer主要负责处理来自雷达、IMU和里程计的数据并基于这些数据进行地图的构建，是cartographer理论的底层实现。cartographer_ros则基于ros的通信机制获取传感器的数据并将它们转换成cartographer中定义的格式传递给cartographer处理，与此同时也将cartographer的处理结果发布用于显示或保存，是基于cartographer的上层应用。ROS应用放在下篇文章分析。</p>\n<p>先借用<a href=\"https://www.zhihu.com/question/51348391\" target=\"_blank\" rel=\"noopener\">知乎问题中mfxox</a>的图：</p>\n<img src=\"/2018/09/16/Cartographer学习二源码分析之核心代码/整体流程.png\">\n<h2 id=\"Cartographer代码框架\"><a href=\"#Cartographer代码框架\" class=\"headerlink\" title=\"Cartographer代码框架\"></a>Cartographer代码框架</h2><p>如下图所示，是google官方说明文档中的框架图：</p>\n<img src=\"/2018/09/16/Cartographer学习二源码分析之核心代码/Cartographer系统框架图.png\">\n<p>Cartographer系统可以分为两个互相有联系的独立系统：local SLAM（frontend）和global SLAM（backend）。</p>\n<ul>\n<li><p>前端检测：local SLAM负责构建局部一致的submaps集合并进行融合，这个过程会产生漂移误差。</p>\n</li>\n<li><p>后端闭环优化：global SLAM运行在后端线程，负责在scans和submaps之间使用scan-matching找到回环约束，同时融合其他传感器数据（包括检测重力的方向），完成全局一致性任务。</p>\n<blockquote>\n<p>关于GraphSLAM原理，可以<a href=\"https://blog.csdn.net/heyijia0327/article/details/47686523\" target=\"_blank\" rel=\"noopener\">参考文章</a>，有例子介绍很清晰。</p>\n</blockquote>\n</li>\n</ul>\n<p>总得来说，前端负责生成高质量的submaps，后端则负责完成地图的全局一致性任务。</p>\n<p>输入的传感器数据有四个：</p>\n<ul>\n<li>Range Data（激光雷达，摄像头等）</li>\n<li>Odometry Pose(里程计数据)</li>\n<li>IMU Data</li>\n<li>FixedFramePose（是指确定的位置？？）</li>\n</ul>\n<p>里程计数据与IMU数据共同进入PoseExtraPolator，做航迹推算。给定一个里程计与IMU得到的位置估计，用两次以上里程计计算平均速度，用两次以上IMU数据计算平均角速度，然后推算出下一时刻的位置姿态，给到Scan Matching中作为扫描匹配的初值。</p>\n<p>Range Data数据经过体素滤波（一种滤波方法）和自适应体素滤波，进入scanMatching，作为观测值。scanMatching用论文中介绍的基于ceres优化的scanMatching方法获得观测最优位置估计，经过Motion Filter滤波，作为位置最优估计构建submap。</p>\n<h2 id=\"Cartographer代码结构\"><a href=\"#Cartographer代码结构\" class=\"headerlink\" title=\"Cartographer代码结构\"></a>Cartographer代码结构</h2><h3 id=\"各模块功能\"><a href=\"#各模块功能\" class=\"headerlink\" title=\"各模块功能\"></a>各模块功能</h3><ul>\n<li>common：定义基本数据结构以及一些工具的使用接口，包括对数据的处理、时间转换、采样器、脉冲率计算、直方图类、数据计算类、对线程和线程锁的封装等</li>\n<li>io：文件流写、点云batch类、</li>\n<li>sensor：定义雷达数据及点云等相关的数据结构</li>\n<li>transform：定义位姿的数据结构及其相关的转换</li>\n<li>mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口</li>\n<li>kalman_filter：（基于UKF的多传感器数据融合）主要通过kalman滤波器完成对IMU、里程计及基于雷达数据的估计位姿的融合，进而估计新进的laser  scan的位姿</li>\n<li>mapping：定义上层应用的调用接口以及局部submap构建和基于闭环检测的位姿优化等的接口</li>\n<li>mapping_2d和mapping_3d：对mapping接口的不同实现（scan match策略对应的文件在这俩目录下的scan_matching目录中）</li>\n</ul>\n<h3 id=\"mapping-2d\"><a href=\"#mapping-2d\" class=\"headerlink\" title=\"mapping_2d\"></a>mapping_2d</h3><h4 id=\"GlobalTrajectoryBuilder\"><a href=\"#GlobalTrajectoryBuilder\" class=\"headerlink\" title=\"GlobalTrajectoryBuilder\"></a>GlobalTrajectoryBuilder</h4><p>实现接收处理上层应用传递的传感器数据的主要接口。有几个重要的成员函数：</p>\n<ul>\n<li><code>AddRangefinderData</code>：用于接收处理上层应用传递的雷达数据</li>\n<li><code>AddImuData</code>：用于接收处理上层应用传递的IMU数据</li>\n<li><code>AddOdometerPose</code>：用于接收处理上层应用传递的里程计数据</li>\n</ul>\n<h4 id=\"LocalTrajectoryBuilder\"><a href=\"#LocalTrajectoryBuilder\" class=\"headerlink\" title=\"LocalTrajectoryBuilder\"></a>LocalTrajectoryBuilder</h4><p>local SLAM，主要完成完成UKF（扩展卡尔曼滤波器）、scan matching、局部submap的构建，提供了接收处理传感器数据的public函数：</p>\n<ul>\n<li><p><code>AddImuData</code>：用于处理IMU数据</p>\n</li>\n<li><p><code>AddOdometerPose</code>：用于处理里程计数据</p>\n</li>\n<li><p><code>AddHorizontalLaserFan</code>：用于处理雷达数据</p>\n</li>\n</ul>\n<h4 id=\"SparsePoseGraph\"><a href=\"#SparsePoseGraph\" class=\"headerlink\" title=\"SparsePoseGraph\"></a>SparsePoseGraph</h4><p>主要完成基于闭环检测的全局位姿优化。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://google-cartographer.readthedocs.io/en/latest/index.html#\" target=\"_blank\" rel=\"noopener\">cartographer文档</a></li>\n<li><a href=\"https://google-cartographer-ros.readthedocs.io/en/latest/#\" target=\"_blank\" rel=\"noopener\">cartographer ROS文档</a></li>\n<li><a href=\"https://blog.csdn.net/u013721521/article/details/81477005\" target=\"_blank\" rel=\"noopener\">cartographer源码阅读（1）——算法整体结构</a></li>\n<li><a href=\"https://blog.csdn.net/jsgaobiao/article/details/53116042\" target=\"_blank\" rel=\"noopener\">【SLAM】（一）Google Cartographer的初步尝试</a></li>\n<li><a href=\"https://blog.csdn.net/u012700322/article/details/53513527\" target=\"_blank\" rel=\"noopener\">Cartographer理论及实现浅析</a></li>\n<li><strong><a href=\"https://blog.csdn.net/roadseek_zw/article/details/66968762\" target=\"_blank\" rel=\"noopener\">Cartographer 代码阅读分析</a></strong></li>\n<li><strong><a href=\"https://blog.csdn.net/roadseek_zw/article/details/72886079\" target=\"_blank\" rel=\"noopener\">Cartographer 代码阅读分析-2</a></strong></li>\n<li><a href=\"https://blog.csdn.net/learnmoreonce/article/category/6989560/3\" target=\"_blank\" rel=\"noopener\">Cartographer源码分析58系列</a></li>\n</ol>"},{"title":"Docker学习之基础知识","date":"2018-05-13T13:31:07.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关Docker基础知识的内容。\n\n<!--more--->\n\n官方文档：https://docs.docker.com/install/linux/docker-ce/ubuntu/\n\n学习到这啦：Containers share your image：https://docs.docker.com/get-started/part2/#share-your-image\n\nDockerfile：https://docs.docker.com/engine/reference/builder/#usage\n\nDocker在乌班图系统上支持overlay2和aufs两种存储驱动。并且默认使用overlay2，如果需要使用aufs，需要手动配置。\n\nDocker是一个为开发者和系统管理员提供的平台，允许使用容器来开发、部署、运行应用。\n\nDocker的文件系统分为两层：bootfs和rootfs。\n\n{% asset_img bootfs.jpg %}\n\nDocker采用AUFS分层文件系统时，文件系统的改动都是发生在最上面的容器层。在容器的生命周期内，它是持续的，包括容器在被停止后。但容器被删除后，该数据层也随之被删除了。因此Docker使用volume（卷）的形式来向容器提供持久化存储。Docker使用UnionFS搭建的分层镜像：\n\n{% asset_img docker-filesystems-multilayer.png %}\n\n## 概念\n\n- 容器（container）：是一个镜像的实例，通过运行一个镜像启动。它是一个镜像的运行时实例，这时，执行的镜像位于内存中。可以使用docker ps命令查看运行中的容器清单。运行着的容器有一个可写层（writable或称为容器层container layer），位于底下的若干只读层之上，运行时的所有变化，包括对数据和文件的写和更新，都会保存在这个层中。因此，从同一个镜像运行的多个容器包含了不同的容器层。\n- 镜像（image）：是一个可执行包，包括执行一个应用程序的所有代码、运行时、库、环境变量以及配置文件。镜像是轻便的，它由Dockerfile定义。镜像是文件系统数据的复制，只允许读，它包括一个或多个只读层（read-only layers），一旦被创建就无法修改。\n- 仓库（repository）：镜像的集合，其中的代码已经编译完成。\n- registry：仓库的集合。默认使用Docker的公共registry，也可以自己设置私人registry。\n- Swarm：一些运行Docker并且加入到cluster中的机器的集合。\n\n## Docker命令\n\n~~~shell\ndocker --version \t\t\t#查看Docker版本\ndocker info \t\t\t\t#查看Docker安装有关的所有细节信息\ndocker version\t\t\t\t#查看Docker安装有关的所有细节信息\ndocker image ls\t\t\t\t#列出镜像清单\ndocker container ls \t \t#列出容器清单（列出运行中的容器）\ndocker container ls --all \t#列出容器清单（列出所有容器）\ndocker container ls --aq \t#列出容器清单（列出所有容器，简单模式，只有容器ID）\ndocker run hello-world\t\t#执行Docker镜像，镜像名字为hello-world\n\n~~~\n\n## 分层结构\n\n- Stack：一组有关联的服务的组合，可以编排在一起，一起管理。\n- Services：一个应用的不同部分。伸缩一个服务就是改变这一个服务的运行的容器的数量。\n- Container\n\n## Flocker：容器的分布式存储平台\n\n原生的 Docker volume 不具备可移植性。于是，出现了Docker 的分布式卷解决方案 [Flocker](https://github.com/ClusterHQ/flocker)。Flocker的结构：\n\n{% asset_img flocker.jpg %}\n\n参考文章：http://www.cnblogs.com/sammyliu/p/5932996.html","source":"_posts/Docker学习之基础知识.md","raw":"---\ntitle: Docker学习之基础知识\ndate: 2018-05-13 21:31:07\ntags:\n   - Docker\ncategories: Docker\ncopyright: true\n---\n\n-----\n\n这篇文章是有关Docker基础知识的内容。\n\n<!--more--->\n\n官方文档：https://docs.docker.com/install/linux/docker-ce/ubuntu/\n\n学习到这啦：Containers share your image：https://docs.docker.com/get-started/part2/#share-your-image\n\nDockerfile：https://docs.docker.com/engine/reference/builder/#usage\n\nDocker在乌班图系统上支持overlay2和aufs两种存储驱动。并且默认使用overlay2，如果需要使用aufs，需要手动配置。\n\nDocker是一个为开发者和系统管理员提供的平台，允许使用容器来开发、部署、运行应用。\n\nDocker的文件系统分为两层：bootfs和rootfs。\n\n{% asset_img bootfs.jpg %}\n\nDocker采用AUFS分层文件系统时，文件系统的改动都是发生在最上面的容器层。在容器的生命周期内，它是持续的，包括容器在被停止后。但容器被删除后，该数据层也随之被删除了。因此Docker使用volume（卷）的形式来向容器提供持久化存储。Docker使用UnionFS搭建的分层镜像：\n\n{% asset_img docker-filesystems-multilayer.png %}\n\n## 概念\n\n- 容器（container）：是一个镜像的实例，通过运行一个镜像启动。它是一个镜像的运行时实例，这时，执行的镜像位于内存中。可以使用docker ps命令查看运行中的容器清单。运行着的容器有一个可写层（writable或称为容器层container layer），位于底下的若干只读层之上，运行时的所有变化，包括对数据和文件的写和更新，都会保存在这个层中。因此，从同一个镜像运行的多个容器包含了不同的容器层。\n- 镜像（image）：是一个可执行包，包括执行一个应用程序的所有代码、运行时、库、环境变量以及配置文件。镜像是轻便的，它由Dockerfile定义。镜像是文件系统数据的复制，只允许读，它包括一个或多个只读层（read-only layers），一旦被创建就无法修改。\n- 仓库（repository）：镜像的集合，其中的代码已经编译完成。\n- registry：仓库的集合。默认使用Docker的公共registry，也可以自己设置私人registry。\n- Swarm：一些运行Docker并且加入到cluster中的机器的集合。\n\n## Docker命令\n\n~~~shell\ndocker --version \t\t\t#查看Docker版本\ndocker info \t\t\t\t#查看Docker安装有关的所有细节信息\ndocker version\t\t\t\t#查看Docker安装有关的所有细节信息\ndocker image ls\t\t\t\t#列出镜像清单\ndocker container ls \t \t#列出容器清单（列出运行中的容器）\ndocker container ls --all \t#列出容器清单（列出所有容器）\ndocker container ls --aq \t#列出容器清单（列出所有容器，简单模式，只有容器ID）\ndocker run hello-world\t\t#执行Docker镜像，镜像名字为hello-world\n\n~~~\n\n## 分层结构\n\n- Stack：一组有关联的服务的组合，可以编排在一起，一起管理。\n- Services：一个应用的不同部分。伸缩一个服务就是改变这一个服务的运行的容器的数量。\n- Container\n\n## Flocker：容器的分布式存储平台\n\n原生的 Docker volume 不具备可移植性。于是，出现了Docker 的分布式卷解决方案 [Flocker](https://github.com/ClusterHQ/flocker)。Flocker的结构：\n\n{% asset_img flocker.jpg %}\n\n参考文章：http://www.cnblogs.com/sammyliu/p/5932996.html","slug":"Docker学习之基础知识","published":1,"updated":"2019-05-30T12:29:26.279Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbub000mqlcrc4a7wkqs","content":"<hr>\n<p>这篇文章是有关Docker基础知识的内容。</p>\n<a id=\"more\"></a>\n<p>官方文档：<a href=\"https://docs.docker.com/install/linux/docker-ce/ubuntu/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/install/linux/docker-ce/ubuntu/</a></p>\n<p>学习到这啦：Containers share your image：<a href=\"https://docs.docker.com/get-started/part2/#share-your-image\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/get-started/part2/#share-your-image</a></p>\n<p>Dockerfile：<a href=\"https://docs.docker.com/engine/reference/builder/#usage\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/builder/#usage</a></p>\n<p>Docker在乌班图系统上支持overlay2和aufs两种存储驱动。并且默认使用overlay2，如果需要使用aufs，需要手动配置。</p>\n<p>Docker是一个为开发者和系统管理员提供的平台，允许使用容器来开发、部署、运行应用。</p>\n<p>Docker的文件系统分为两层：bootfs和rootfs。</p>\n<img src=\"/2018/05/13/Docker学习之基础知识/bootfs.jpg\">\n<p>Docker采用AUFS分层文件系统时，文件系统的改动都是发生在最上面的容器层。在容器的生命周期内，它是持续的，包括容器在被停止后。但容器被删除后，该数据层也随之被删除了。因此Docker使用volume（卷）的形式来向容器提供持久化存储。Docker使用UnionFS搭建的分层镜像：</p>\n<img src=\"/2018/05/13/Docker学习之基础知识/docker-filesystems-multilayer.png\">\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><ul>\n<li>容器（container）：是一个镜像的实例，通过运行一个镜像启动。它是一个镜像的运行时实例，这时，执行的镜像位于内存中。可以使用docker ps命令查看运行中的容器清单。运行着的容器有一个可写层（writable或称为容器层container layer），位于底下的若干只读层之上，运行时的所有变化，包括对数据和文件的写和更新，都会保存在这个层中。因此，从同一个镜像运行的多个容器包含了不同的容器层。</li>\n<li>镜像（image）：是一个可执行包，包括执行一个应用程序的所有代码、运行时、库、环境变量以及配置文件。镜像是轻便的，它由Dockerfile定义。镜像是文件系统数据的复制，只允许读，它包括一个或多个只读层（read-only layers），一旦被创建就无法修改。</li>\n<li>仓库（repository）：镜像的集合，其中的代码已经编译完成。</li>\n<li>registry：仓库的集合。默认使用Docker的公共registry，也可以自己设置私人registry。</li>\n<li>Swarm：一些运行Docker并且加入到cluster中的机器的集合。</li>\n</ul>\n<h2 id=\"Docker命令\"><a href=\"#Docker命令\" class=\"headerlink\" title=\"Docker命令\"></a>Docker命令</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker --version \t\t\t#查看Docker版本</span><br><span class=\"line\">docker info \t\t\t\t#查看Docker安装有关的所有细节信息</span><br><span class=\"line\">docker version\t\t\t\t#查看Docker安装有关的所有细节信息</span><br><span class=\"line\">docker image ls\t\t\t\t#列出镜像清单</span><br><span class=\"line\">docker container ls \t \t#列出容器清单（列出运行中的容器）</span><br><span class=\"line\">docker container ls --all \t#列出容器清单（列出所有容器）</span><br><span class=\"line\">docker container ls --aq \t#列出容器清单（列出所有容器，简单模式，只有容器ID）</span><br><span class=\"line\">docker run hello-world\t\t#执行Docker镜像，镜像名字为hello-world</span><br></pre></td></tr></table></figure>\n<h2 id=\"分层结构\"><a href=\"#分层结构\" class=\"headerlink\" title=\"分层结构\"></a>分层结构</h2><ul>\n<li>Stack：一组有关联的服务的组合，可以编排在一起，一起管理。</li>\n<li>Services：一个应用的不同部分。伸缩一个服务就是改变这一个服务的运行的容器的数量。</li>\n<li>Container</li>\n</ul>\n<h2 id=\"Flocker：容器的分布式存储平台\"><a href=\"#Flocker：容器的分布式存储平台\" class=\"headerlink\" title=\"Flocker：容器的分布式存储平台\"></a>Flocker：容器的分布式存储平台</h2><p>原生的 Docker volume 不具备可移植性。于是，出现了Docker 的分布式卷解决方案 <a href=\"https://github.com/ClusterHQ/flocker\" target=\"_blank\" rel=\"noopener\">Flocker</a>。Flocker的结构：</p>\n<img src=\"/2018/05/13/Docker学习之基础知识/flocker.jpg\">\n<p>参考文章：<a href=\"http://www.cnblogs.com/sammyliu/p/5932996.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/sammyliu/p/5932996.html</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关Docker基础知识的内容。</p>","more":"<p>官方文档：<a href=\"https://docs.docker.com/install/linux/docker-ce/ubuntu/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/install/linux/docker-ce/ubuntu/</a></p>\n<p>学习到这啦：Containers share your image：<a href=\"https://docs.docker.com/get-started/part2/#share-your-image\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/get-started/part2/#share-your-image</a></p>\n<p>Dockerfile：<a href=\"https://docs.docker.com/engine/reference/builder/#usage\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/builder/#usage</a></p>\n<p>Docker在乌班图系统上支持overlay2和aufs两种存储驱动。并且默认使用overlay2，如果需要使用aufs，需要手动配置。</p>\n<p>Docker是一个为开发者和系统管理员提供的平台，允许使用容器来开发、部署、运行应用。</p>\n<p>Docker的文件系统分为两层：bootfs和rootfs。</p>\n<img src=\"/2018/05/13/Docker学习之基础知识/bootfs.jpg\">\n<p>Docker采用AUFS分层文件系统时，文件系统的改动都是发生在最上面的容器层。在容器的生命周期内，它是持续的，包括容器在被停止后。但容器被删除后，该数据层也随之被删除了。因此Docker使用volume（卷）的形式来向容器提供持久化存储。Docker使用UnionFS搭建的分层镜像：</p>\n<img src=\"/2018/05/13/Docker学习之基础知识/docker-filesystems-multilayer.png\">\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><ul>\n<li>容器（container）：是一个镜像的实例，通过运行一个镜像启动。它是一个镜像的运行时实例，这时，执行的镜像位于内存中。可以使用docker ps命令查看运行中的容器清单。运行着的容器有一个可写层（writable或称为容器层container layer），位于底下的若干只读层之上，运行时的所有变化，包括对数据和文件的写和更新，都会保存在这个层中。因此，从同一个镜像运行的多个容器包含了不同的容器层。</li>\n<li>镜像（image）：是一个可执行包，包括执行一个应用程序的所有代码、运行时、库、环境变量以及配置文件。镜像是轻便的，它由Dockerfile定义。镜像是文件系统数据的复制，只允许读，它包括一个或多个只读层（read-only layers），一旦被创建就无法修改。</li>\n<li>仓库（repository）：镜像的集合，其中的代码已经编译完成。</li>\n<li>registry：仓库的集合。默认使用Docker的公共registry，也可以自己设置私人registry。</li>\n<li>Swarm：一些运行Docker并且加入到cluster中的机器的集合。</li>\n</ul>\n<h2 id=\"Docker命令\"><a href=\"#Docker命令\" class=\"headerlink\" title=\"Docker命令\"></a>Docker命令</h2><!--�15-->\n<h2 id=\"分层结构\"><a href=\"#分层结构\" class=\"headerlink\" title=\"分层结构\"></a>分层结构</h2><ul>\n<li>Stack：一组有关联的服务的组合，可以编排在一起，一起管理。</li>\n<li>Services：一个应用的不同部分。伸缩一个服务就是改变这一个服务的运行的容器的数量。</li>\n<li>Container</li>\n</ul>\n<h2 id=\"Flocker：容器的分布式存储平台\"><a href=\"#Flocker：容器的分布式存储平台\" class=\"headerlink\" title=\"Flocker：容器的分布式存储平台\"></a>Flocker：容器的分布式存储平台</h2><p>原生的 Docker volume 不具备可移植性。于是，出现了Docker 的分布式卷解决方案 <a href=\"https://github.com/ClusterHQ/flocker\" target=\"_blank\" rel=\"noopener\">Flocker</a>。Flocker的结构：</p>\n<img src=\"/2018/05/13/Docker学习之基础知识/flocker.jpg\">\n<p>参考文章：<a href=\"http://www.cnblogs.com/sammyliu/p/5932996.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/sammyliu/p/5932996.html</a></p>"},{"title":"Cartographer学习三源码分析之ROS应用","date":"2018-09-19T14:02:01.000Z","mathjax":true,"copyright":true,"_content":"\n---\n\n本篇文章是记录cartographer_ros源码学习有关的内容，使用的cartographer版本是20170320。\n\n<!--more--->\n\n## 概述\n\ncartographer_ros是基于cartographer的上层应用，它使用ROS作为通信机制，订阅各传感器数据节点发布到消息发布器的数据，然后打包封装成统一的数据格式，通过接口传入cartographer系统核心；通过接口获取系统核心处理后的数据，发布到相应的消息发布器，由rviz展示。下面是cartographer_ros系统运行时节点图：\n\n{% asset_img cartographer_old.png %}\n\n## ROS应用框架\n\n下图是一个更简洁的框架图：\n\n{% asset_img ROS框架.png %}\n\n其中，cartographer_node是ROS应用的主要节点，它订阅了很多话题，其中/scan是激光雷达的数据，/imu是IMU的数据，又发布了很多数据用于展示。\n\n## RVIZ配置文件\n\n如果是无参数启动rviz，会默认使用配置`~/.rviz/default.rviz`。如果是正常退出，这一次的配置就会被保存到`~/.rviz/default.rviz`，需要另外保存成配置文件的话，可以选择`File->Save Config As`。\n\n如果使用自己的配置文件，需要在`.launch`文件中添加内容：\n\n~~~xml\n<launch>\n<node pkg=\"rviz\" type=\"rviz\" name=\"rviz\"\n    args=\"-d $(find cartographer_ros)/configuration_files/demo_3d.rviz\"/>\n</launch>\n~~~\n\n## 运行bag文件\n\n如果需要使用`roslaunch`使用`rosbag`运行bag文件，在launch文件中添加内容：\n\n~~~xml\n<launch>\n  <node pkg=\"rosbag\" type=\"play\" name=\"playe\" output=\"screen\" args=\"--clock /home/path/to/bagfile/2017-10-18-21-30-41.bag\"/>\n  <!-- 注意bag文件的路径必须为绝对路径-->\n</launch>\n~~~\n\nbag文件的路径可以通过启动参数确定，使用`$(arg bag_filename)`替换上面的绝对路径。参数值可以通过命令行赋值，命令格式：\n\n~~~shell\nroslaunch cartographer_ros demo_backpack_3d.launch bag_filename:=${HOME}/slam/example_bags/b3-2016-04-05-14-14-00.bag\n~~~\n\n","source":"_posts/Cartographer学习三源码分析之ROS应用.md","raw":"---\ntitle: Cartographer学习三源码分析之ROS应用\ndate: 2018-09-19 22:02:01\ntags: \n  - Lidar SLAM\n  - Cartographer\n  - rviz\nmathjax: true\ncategories:\n  - 机器人 \n  - SLAM\n  - Cartographer\ncopyright: true\n---\n\n---\n\n本篇文章是记录cartographer_ros源码学习有关的内容，使用的cartographer版本是20170320。\n\n<!--more--->\n\n## 概述\n\ncartographer_ros是基于cartographer的上层应用，它使用ROS作为通信机制，订阅各传感器数据节点发布到消息发布器的数据，然后打包封装成统一的数据格式，通过接口传入cartographer系统核心；通过接口获取系统核心处理后的数据，发布到相应的消息发布器，由rviz展示。下面是cartographer_ros系统运行时节点图：\n\n{% asset_img cartographer_old.png %}\n\n## ROS应用框架\n\n下图是一个更简洁的框架图：\n\n{% asset_img ROS框架.png %}\n\n其中，cartographer_node是ROS应用的主要节点，它订阅了很多话题，其中/scan是激光雷达的数据，/imu是IMU的数据，又发布了很多数据用于展示。\n\n## RVIZ配置文件\n\n如果是无参数启动rviz，会默认使用配置`~/.rviz/default.rviz`。如果是正常退出，这一次的配置就会被保存到`~/.rviz/default.rviz`，需要另外保存成配置文件的话，可以选择`File->Save Config As`。\n\n如果使用自己的配置文件，需要在`.launch`文件中添加内容：\n\n~~~xml\n<launch>\n<node pkg=\"rviz\" type=\"rviz\" name=\"rviz\"\n    args=\"-d $(find cartographer_ros)/configuration_files/demo_3d.rviz\"/>\n</launch>\n~~~\n\n## 运行bag文件\n\n如果需要使用`roslaunch`使用`rosbag`运行bag文件，在launch文件中添加内容：\n\n~~~xml\n<launch>\n  <node pkg=\"rosbag\" type=\"play\" name=\"playe\" output=\"screen\" args=\"--clock /home/path/to/bagfile/2017-10-18-21-30-41.bag\"/>\n  <!-- 注意bag文件的路径必须为绝对路径-->\n</launch>\n~~~\n\nbag文件的路径可以通过启动参数确定，使用`$(arg bag_filename)`替换上面的绝对路径。参数值可以通过命令行赋值，命令格式：\n\n~~~shell\nroslaunch cartographer_ros demo_backpack_3d.launch bag_filename:=${HOME}/slam/example_bags/b3-2016-04-05-14-14-00.bag\n~~~\n\n","slug":"Cartographer学习三源码分析之ROS应用","published":1,"updated":"2019-05-30T12:29:26.271Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuc000nqlcr296gyn4f","content":"<hr>\n<p>本篇文章是记录cartographer_ros源码学习有关的内容，使用的cartographer版本是20170320。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>cartographer_ros是基于cartographer的上层应用，它使用ROS作为通信机制，订阅各传感器数据节点发布到消息发布器的数据，然后打包封装成统一的数据格式，通过接口传入cartographer系统核心；通过接口获取系统核心处理后的数据，发布到相应的消息发布器，由rviz展示。下面是cartographer_ros系统运行时节点图：</p>\n<img src=\"/2018/09/19/Cartographer学习三源码分析之ROS应用/cartographer_old.png\">\n<h2 id=\"ROS应用框架\"><a href=\"#ROS应用框架\" class=\"headerlink\" title=\"ROS应用框架\"></a>ROS应用框架</h2><p>下图是一个更简洁的框架图：</p>\n<img src=\"/2018/09/19/Cartographer学习三源码分析之ROS应用/ROS框架.png\">\n<p>其中，cartographer_node是ROS应用的主要节点，它订阅了很多话题，其中/scan是激光雷达的数据，/imu是IMU的数据，又发布了很多数据用于展示。</p>\n<h2 id=\"RVIZ配置文件\"><a href=\"#RVIZ配置文件\" class=\"headerlink\" title=\"RVIZ配置文件\"></a>RVIZ配置文件</h2><p>如果是无参数启动rviz，会默认使用配置<code>~/.rviz/default.rviz</code>。如果是正常退出，这一次的配置就会被保存到<code>~/.rviz/default.rviz</code>，需要另外保存成配置文件的话，可以选择<code>File-&gt;Save Config As</code>。</p>\n<p>如果使用自己的配置文件，需要在<code>.launch</code>文件中添加内容：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">launch</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"rviz\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"rviz\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"rviz\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">args</span>=<span class=\"string\">\"-d $(find cartographer_ros)/configuration_files/demo_3d.rviz\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">launch</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"运行bag文件\"><a href=\"#运行bag文件\" class=\"headerlink\" title=\"运行bag文件\"></a>运行bag文件</h2><p>如果需要使用<code>roslaunch</code>使用<code>rosbag</code>运行bag文件，在launch文件中添加内容：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">launch</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"rosbag\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"play\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"playe\"</span> <span class=\"attr\">output</span>=<span class=\"string\">\"screen\"</span> <span class=\"attr\">args</span>=<span class=\"string\">\"--clock /home/path/to/bagfile/2017-10-18-21-30-41.bag\"</span>/&gt;</span></span><br><span class=\"line\">  <span class=\"comment\">&lt;!-- 注意bag文件的路径必须为绝对路径--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">launch</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>bag文件的路径可以通过启动参数确定，使用<code>$(arg bag_filename)</code>替换上面的绝对路径。参数值可以通过命令行赋值，命令格式：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roslaunch cartographer_ros demo_backpack_3d.launch bag_filename:=$&#123;HOME&#125;/slam/example_bags/b3-2016-04-05-14-14-00.bag</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本篇文章是记录cartographer_ros源码学习有关的内容，使用的cartographer版本是20170320。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>cartographer_ros是基于cartographer的上层应用，它使用ROS作为通信机制，订阅各传感器数据节点发布到消息发布器的数据，然后打包封装成统一的数据格式，通过接口传入cartographer系统核心；通过接口获取系统核心处理后的数据，发布到相应的消息发布器，由rviz展示。下面是cartographer_ros系统运行时节点图：</p>\n<img src=\"/2018/09/19/Cartographer学习三源码分析之ROS应用/cartographer_old.png\">\n<h2 id=\"ROS应用框架\"><a href=\"#ROS应用框架\" class=\"headerlink\" title=\"ROS应用框架\"></a>ROS应用框架</h2><p>下图是一个更简洁的框架图：</p>\n<img src=\"/2018/09/19/Cartographer学习三源码分析之ROS应用/ROS框架.png\">\n<p>其中，cartographer_node是ROS应用的主要节点，它订阅了很多话题，其中/scan是激光雷达的数据，/imu是IMU的数据，又发布了很多数据用于展示。</p>\n<h2 id=\"RVIZ配置文件\"><a href=\"#RVIZ配置文件\" class=\"headerlink\" title=\"RVIZ配置文件\"></a>RVIZ配置文件</h2><p>如果是无参数启动rviz，会默认使用配置<code>~/.rviz/default.rviz</code>。如果是正常退出，这一次的配置就会被保存到<code>~/.rviz/default.rviz</code>，需要另外保存成配置文件的话，可以选择<code>File-&gt;Save Config As</code>。</p>\n<p>如果使用自己的配置文件，需要在<code>.launch</code>文件中添加内容：</p>\n<!--�16-->\n<h2 id=\"运行bag文件\"><a href=\"#运行bag文件\" class=\"headerlink\" title=\"运行bag文件\"></a>运行bag文件</h2><p>如果需要使用<code>roslaunch</code>使用<code>rosbag</code>运行bag文件，在launch文件中添加内容：</p>\n<!--�17-->\n<p>bag文件的路径可以通过启动参数确定，使用<code>$(arg bag_filename)</code>替换上面的绝对路径。参数值可以通过命令行赋值，命令格式：</p>\n<!--�18-->"},{"title":"Linux设置环境变量","date":"2018-08-07T08:03:24.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关Linux中环境变量设置的内容记录。\n\n<!--more--->\n\n### 当前终端有效\n\n`export PATH=$PATH:/home/..... `(路径目录)：此方法只在当前终端有效 \t\n\n使用`echo $PATH`命令查看环境变量的内容。\n\n> 命令`source /devel/setup.bash`将当前工作空间加入环境变量，也是只对当前终端有效。\n\n### 永久有效\n\n将路径永久添加到PATH，每次启动终端都会找到路径：\n\n`echo \"source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh\" >> ~/.bashrc`","source":"_posts/Linux设置环境变量.md","raw":"---\ntitle: Linux设置环境变量\ndate: 2018-08-07 16:03:24\ntags:\n  - ubuntu\ncategories: \n  - 系统\n  - ubuntu\ncopyright: true\n---\n\n---\n\n这篇文章是有关Linux中环境变量设置的内容记录。\n\n<!--more--->\n\n### 当前终端有效\n\n`export PATH=$PATH:/home/..... `(路径目录)：此方法只在当前终端有效 \t\n\n使用`echo $PATH`命令查看环境变量的内容。\n\n> 命令`source /devel/setup.bash`将当前工作空间加入环境变量，也是只对当前终端有效。\n\n### 永久有效\n\n将路径永久添加到PATH，每次启动终端都会找到路径：\n\n`echo \"source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh\" >> ~/.bashrc`","slug":"Linux设置环境变量","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbue000qqlcry10frh6h","content":"<hr>\n<p>这篇文章是有关Linux中环境变量设置的内容记录。</p>\n<a id=\"more\"></a>\n<h3 id=\"当前终端有效\"><a href=\"#当前终端有效\" class=\"headerlink\" title=\"当前终端有效\"></a>当前终端有效</h3><p><code>export PATH=$PATH:/home/.....</code>(路径目录)：此方法只在当前终端有效     </p>\n<p>使用<code>echo $PATH</code>命令查看环境变量的内容。</p>\n<blockquote>\n<p>命令<code>source /devel/setup.bash</code>将当前工作空间加入环境变量，也是只对当前终端有效。</p>\n</blockquote>\n<h3 id=\"永久有效\"><a href=\"#永久有效\" class=\"headerlink\" title=\"永久有效\"></a>永久有效</h3><p>将路径永久添加到PATH，每次启动终端都会找到路径：</p>\n<p><code>echo &quot;source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh&quot; &gt;&gt; ~/.bashrc</code></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关Linux中环境变量设置的内容记录。</p>","more":"<h3 id=\"当前终端有效\"><a href=\"#当前终端有效\" class=\"headerlink\" title=\"当前终端有效\"></a>当前终端有效</h3><p><code>export PATH=$PATH:/home/.....</code>(路径目录)：此方法只在当前终端有效     </p>\n<p>使用<code>echo $PATH</code>命令查看环境变量的内容。</p>\n<blockquote>\n<p>命令<code>source /devel/setup.bash</code>将当前工作空间加入环境变量，也是只对当前终端有效。</p>\n</blockquote>\n<h3 id=\"永久有效\"><a href=\"#永久有效\" class=\"headerlink\" title=\"永久有效\"></a>永久有效</h3><p>将路径永久添加到PATH，每次启动终端都会找到路径：</p>\n<p><code>echo &quot;source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh&quot; &gt;&gt; ~/.bashrc</code></p>"},{"title":"Event-based特征追踪评估方法","date":"2019-06-13T05:55:04.000Z","copyright":true,"_content":"---\n\n记录UZH机器感知实验室的一个Github项目学习过程，该项目目的是对Event-based特征追踪算法进行评估，包括轨迹的显示、误差、追踪时间的统计评测等。\n<!--more--->\n\nGithub项目地址：https://github.com/uzh-rpg/rpg_feature_tracking_analysis\n\n## 基于Event的特征追踪算法评估工作流程\n\n### 评估特征追踪轨迹Ground Truth的两个方法\n\n- 基于同步图像帧和event的KLT特征追踪\n- 基于路标点反投影的特征追踪\n\n### 算法功能\n\n- 使用上述方法之一评估用户的特征追踪方法\n- 生成随时间变化的特征追踪误差图（可用于论文插图）\n- 生成特征追踪的三维时空图\n- 生成特征追踪视频\n- 将用户的特征追踪方法与其他方法进行比较\n- 生成单个特征的跟踪误差图\n\n### 工作原理\n\n特征追踪评估两个步骤：\n\n- Ground Truth Tracker初始化\n- Tracking\n\n基于KLT追踪方法获取Ground Truth，该算法的输入为测试数据集图像帧序列（以rosbag文件的形式，rostopic为`/dvs/image_raw`），算法执行步骤：\n\n- 对于每个特征轨迹，确定其初始时间\n- 在初始化时，或者初始化之后找到第一帧灰度图像\n- 特征的x、y位置坐标插值到轨迹中，对应当前帧的时间戳\n- KLT方法追踪该特征，直到该特征丢失；对于每一帧图像都要更新模板\n\n在阅读代码后，总结算法执行流程如下：\n\n - 对于追踪算法得到的特征轨迹，提取每一个特征轨迹的第一个特征的时间戳\n - 根据图像帧时间戳，找到与初始特征时间戳距离最近的图像帧，时间差不超过1e-5，否则选择比初始特征时间戳大的最小时间戳对应的图像\n - 一维线性插值找到图像帧时间戳时刻对应的特征点的坐标，[id, t_image, x_interp, y_interp]组成元组，构成一个图像帧中的特征\n - 收集到所有的初始图像帧特征，保存留作备用\n - 找到初始图像帧特征中的时间戳最小值，选择该值1e-4范围内的所有特征作为初始活跃特征\n - 使用LK光流法在前两帧图像中追踪这些特征\n - 追踪到的特征作为新的特征与收集到的所有初始特征中的部分特征进行合并，参与合并的部分初始特征是第二帧图像周围的特征，然后在第三帧图像中追踪合并的特征\n - 重复上述过程，直到所有图像帧使用完毕\n\n基于Ground Truth的重投影，算法执行步骤：\n\n- 对于每个特征轨迹，确定初始时间和位置\n- 使用插值方法，确定每次初始化时的深度和位姿\n- 使用位姿、深度、相机标定参数，back-projected特征\n- 对于之后的每个位姿，将路标点重投影至图像帧中，生成特征轨迹\n- 超出图像帧平面范围的特征将被丢弃\n\n基于追踪的重投影过程不支持相机的畸变。\n\n## 数据输入\n\n需要使用`.txt`文件提供特征轨迹数据，内容包括特征ID（追踪到的属于同一个特征的event使用相同的ID）、特征位置坐标、特征时间戳。如下所示：\n\n```yaml\n# feature_id timestamp x y\n25 1.403636580013555527e+09 125.827 15.615 \n13 1.403636580015467890e+09 20.453 90.142 \n...\n```\n\n用于Ground Truth生成的图像、位姿、深度图、相机参数必须以rosbag的格式提供。各数据的信息格式如下：\n\n- images: `sensor_msgs/Image`\n- poses: `geometry_msgs/PoseStamped`\n- depth maps: `sensor_msgs/Image`-`CV_32F`\n\n有关ros话题和rosbag文件信息，使用`dataset.yaml`文件提供。\n\n```yaml\ntype: bag\nname: relative/path/to/ros.bag  # relative path of bag\n\n# For KLT based tracking \nimage_topic: /dvs/image_raw  \n\n# For reprojection based tracking\ndepth_map_topic: /dvs/depthmap\npose_topic: /dvs/pose\ncamera_info_topic: /dvs/camera_info\n```\n\n### 执行命令\n\n#### 测试特征追踪算法\n\n需要进行如下步骤：\n\n- `--file /path/to/tracks.txt`：给定用户自己的特征追踪算法生成的特征追踪结果\n\n- `--dataset /path/to/your_dataset.yaml`：给定测试数据集的配置文件，文件内容如下\n\n  ```yaml\n  type: \"bag\"\n  name: \"your_dataset.bag\"  \t\t# 测试数据集rosbag文件名\n  image_topic: \"/dvs/image_raw\"\t# rosbag文件图像相关话题（ETH数据集rosbag图像话题都是这个）\n  ```\n\n- `--root /path/to/bags`：测试数据所在路径（到测试数据集rosbag文件的父目录）\n\n测试执行命令举例：\n\n1. 测试1：`python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview`\n2. 测试2：`python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_kueng_iros_16/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview`\n\n执行命令解释：\n\n```shell\npython evaluate_tracks.py \t\t# 评估用户特征追踪算法\n\t\t--error_threshold 10 \t# 用在可视化和画图时的阈值，追踪误差超过该阈值的特征将被丢弃\n\t\t--tracker_type KLT \t\t# 特征ground truth追踪方法\n\t\t--file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt # 用户特征追踪算法得到的特征轨迹\n\t\t--dataset ./example/dataset_params/bicycles.yaml # 保存测试数据集的类型、名称、ros话题\n\t\t--root ./example/bags \t# 测试数据集保存路径\n\t\t--plot_3d \n\t\t--plot_errors \n\t\t--video_preview\n```\n\n#### 对比特征追踪方法\n\n测试执行命令：\n\n1. 测试1：`python compare_tracks.py --error_threshold 10 --root ./example/tracks/ --config ./example/comparison_params/bicycles.yaml --results_directory ./example/comparison_results/bicycles_gehrig_eccv_18_kueng_iros_16`\n\n执行命令解释：\n\n```shell\npython compare_tracks.py \n\t\t--error_threshold 10 \n\t\t--root ./example/tracks/ \n\t\t--config ./example/comparison_params/bicycles.yaml \n\t\t--results_directory ./example/comparison_results\n```\n","source":"_posts/Event-based特征追踪评估方法.md","raw":"---\ntitle: Event-based特征追踪评估方法\ndate: 2019-06-13 13:55:04\ntags:\n  - Event-based Feature\n  - Event Camera\ncategories: \n  - 机器人\n  - SLAM\n  - Event Camera\ncopyright: true\n---\n---\n\n记录UZH机器感知实验室的一个Github项目学习过程，该项目目的是对Event-based特征追踪算法进行评估，包括轨迹的显示、误差、追踪时间的统计评测等。\n<!--more--->\n\nGithub项目地址：https://github.com/uzh-rpg/rpg_feature_tracking_analysis\n\n## 基于Event的特征追踪算法评估工作流程\n\n### 评估特征追踪轨迹Ground Truth的两个方法\n\n- 基于同步图像帧和event的KLT特征追踪\n- 基于路标点反投影的特征追踪\n\n### 算法功能\n\n- 使用上述方法之一评估用户的特征追踪方法\n- 生成随时间变化的特征追踪误差图（可用于论文插图）\n- 生成特征追踪的三维时空图\n- 生成特征追踪视频\n- 将用户的特征追踪方法与其他方法进行比较\n- 生成单个特征的跟踪误差图\n\n### 工作原理\n\n特征追踪评估两个步骤：\n\n- Ground Truth Tracker初始化\n- Tracking\n\n基于KLT追踪方法获取Ground Truth，该算法的输入为测试数据集图像帧序列（以rosbag文件的形式，rostopic为`/dvs/image_raw`），算法执行步骤：\n\n- 对于每个特征轨迹，确定其初始时间\n- 在初始化时，或者初始化之后找到第一帧灰度图像\n- 特征的x、y位置坐标插值到轨迹中，对应当前帧的时间戳\n- KLT方法追踪该特征，直到该特征丢失；对于每一帧图像都要更新模板\n\n在阅读代码后，总结算法执行流程如下：\n\n - 对于追踪算法得到的特征轨迹，提取每一个特征轨迹的第一个特征的时间戳\n - 根据图像帧时间戳，找到与初始特征时间戳距离最近的图像帧，时间差不超过1e-5，否则选择比初始特征时间戳大的最小时间戳对应的图像\n - 一维线性插值找到图像帧时间戳时刻对应的特征点的坐标，[id, t_image, x_interp, y_interp]组成元组，构成一个图像帧中的特征\n - 收集到所有的初始图像帧特征，保存留作备用\n - 找到初始图像帧特征中的时间戳最小值，选择该值1e-4范围内的所有特征作为初始活跃特征\n - 使用LK光流法在前两帧图像中追踪这些特征\n - 追踪到的特征作为新的特征与收集到的所有初始特征中的部分特征进行合并，参与合并的部分初始特征是第二帧图像周围的特征，然后在第三帧图像中追踪合并的特征\n - 重复上述过程，直到所有图像帧使用完毕\n\n基于Ground Truth的重投影，算法执行步骤：\n\n- 对于每个特征轨迹，确定初始时间和位置\n- 使用插值方法，确定每次初始化时的深度和位姿\n- 使用位姿、深度、相机标定参数，back-projected特征\n- 对于之后的每个位姿，将路标点重投影至图像帧中，生成特征轨迹\n- 超出图像帧平面范围的特征将被丢弃\n\n基于追踪的重投影过程不支持相机的畸变。\n\n## 数据输入\n\n需要使用`.txt`文件提供特征轨迹数据，内容包括特征ID（追踪到的属于同一个特征的event使用相同的ID）、特征位置坐标、特征时间戳。如下所示：\n\n```yaml\n# feature_id timestamp x y\n25 1.403636580013555527e+09 125.827 15.615 \n13 1.403636580015467890e+09 20.453 90.142 \n...\n```\n\n用于Ground Truth生成的图像、位姿、深度图、相机参数必须以rosbag的格式提供。各数据的信息格式如下：\n\n- images: `sensor_msgs/Image`\n- poses: `geometry_msgs/PoseStamped`\n- depth maps: `sensor_msgs/Image`-`CV_32F`\n\n有关ros话题和rosbag文件信息，使用`dataset.yaml`文件提供。\n\n```yaml\ntype: bag\nname: relative/path/to/ros.bag  # relative path of bag\n\n# For KLT based tracking \nimage_topic: /dvs/image_raw  \n\n# For reprojection based tracking\ndepth_map_topic: /dvs/depthmap\npose_topic: /dvs/pose\ncamera_info_topic: /dvs/camera_info\n```\n\n### 执行命令\n\n#### 测试特征追踪算法\n\n需要进行如下步骤：\n\n- `--file /path/to/tracks.txt`：给定用户自己的特征追踪算法生成的特征追踪结果\n\n- `--dataset /path/to/your_dataset.yaml`：给定测试数据集的配置文件，文件内容如下\n\n  ```yaml\n  type: \"bag\"\n  name: \"your_dataset.bag\"  \t\t# 测试数据集rosbag文件名\n  image_topic: \"/dvs/image_raw\"\t# rosbag文件图像相关话题（ETH数据集rosbag图像话题都是这个）\n  ```\n\n- `--root /path/to/bags`：测试数据所在路径（到测试数据集rosbag文件的父目录）\n\n测试执行命令举例：\n\n1. 测试1：`python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview`\n2. 测试2：`python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_kueng_iros_16/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview`\n\n执行命令解释：\n\n```shell\npython evaluate_tracks.py \t\t# 评估用户特征追踪算法\n\t\t--error_threshold 10 \t# 用在可视化和画图时的阈值，追踪误差超过该阈值的特征将被丢弃\n\t\t--tracker_type KLT \t\t# 特征ground truth追踪方法\n\t\t--file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt # 用户特征追踪算法得到的特征轨迹\n\t\t--dataset ./example/dataset_params/bicycles.yaml # 保存测试数据集的类型、名称、ros话题\n\t\t--root ./example/bags \t# 测试数据集保存路径\n\t\t--plot_3d \n\t\t--plot_errors \n\t\t--video_preview\n```\n\n#### 对比特征追踪方法\n\n测试执行命令：\n\n1. 测试1：`python compare_tracks.py --error_threshold 10 --root ./example/tracks/ --config ./example/comparison_params/bicycles.yaml --results_directory ./example/comparison_results/bicycles_gehrig_eccv_18_kueng_iros_16`\n\n执行命令解释：\n\n```shell\npython compare_tracks.py \n\t\t--error_threshold 10 \n\t\t--root ./example/tracks/ \n\t\t--config ./example/comparison_params/bicycles.yaml \n\t\t--results_directory ./example/comparison_results\n```\n","slug":"Event-based特征追踪评估方法","published":1,"updated":"2019-08-14T01:52:50.472Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuf000sqlcrbgz0w9h5","content":"<hr>\n<p>记录UZH机器感知实验室的一个Github项目学习过程，该项目目的是对Event-based特征追踪算法进行评估，包括轨迹的显示、误差、追踪时间的统计评测等。<br><a id=\"more\"></a></p>\n<p>Github项目地址：<a href=\"https://github.com/uzh-rpg/rpg_feature_tracking_analysis\" target=\"_blank\" rel=\"noopener\">https://github.com/uzh-rpg/rpg_feature_tracking_analysis</a></p>\n<h2 id=\"基于Event的特征追踪算法评估工作流程\"><a href=\"#基于Event的特征追踪算法评估工作流程\" class=\"headerlink\" title=\"基于Event的特征追踪算法评估工作流程\"></a>基于Event的特征追踪算法评估工作流程</h2><h3 id=\"评估特征追踪轨迹Ground-Truth的两个方法\"><a href=\"#评估特征追踪轨迹Ground-Truth的两个方法\" class=\"headerlink\" title=\"评估特征追踪轨迹Ground Truth的两个方法\"></a>评估特征追踪轨迹Ground Truth的两个方法</h3><ul>\n<li>基于同步图像帧和event的KLT特征追踪</li>\n<li>基于路标点反投影的特征追踪</li>\n</ul>\n<h3 id=\"算法功能\"><a href=\"#算法功能\" class=\"headerlink\" title=\"算法功能\"></a>算法功能</h3><ul>\n<li>使用上述方法之一评估用户的特征追踪方法</li>\n<li>生成随时间变化的特征追踪误差图（可用于论文插图）</li>\n<li>生成特征追踪的三维时空图</li>\n<li>生成特征追踪视频</li>\n<li>将用户的特征追踪方法与其他方法进行比较</li>\n<li>生成单个特征的跟踪误差图</li>\n</ul>\n<h3 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h3><p>特征追踪评估两个步骤：</p>\n<ul>\n<li>Ground Truth Tracker初始化</li>\n<li>Tracking</li>\n</ul>\n<p>基于KLT追踪方法获取Ground Truth，该算法的输入为测试数据集图像帧序列（以rosbag文件的形式，rostopic为<code>/dvs/image_raw</code>），算法执行步骤：</p>\n<ul>\n<li>对于每个特征轨迹，确定其初始时间</li>\n<li>在初始化时，或者初始化之后找到第一帧灰度图像</li>\n<li>特征的x、y位置坐标插值到轨迹中，对应当前帧的时间戳</li>\n<li>KLT方法追踪该特征，直到该特征丢失；对于每一帧图像都要更新模板</li>\n</ul>\n<p>在阅读代码后，总结算法执行流程如下：</p>\n<ul>\n<li>对于追踪算法得到的特征轨迹，提取每一个特征轨迹的第一个特征的时间戳</li>\n<li>根据图像帧时间戳，找到与初始特征时间戳距离最近的图像帧，时间差不超过1e-5，否则选择比初始特征时间戳大的最小时间戳对应的图像</li>\n<li>一维线性插值找到图像帧时间戳时刻对应的特征点的坐标，[id, t_image, x_interp, y_interp]组成元组，构成一个图像帧中的特征</li>\n<li>收集到所有的初始图像帧特征，保存留作备用</li>\n<li>找到初始图像帧特征中的时间戳最小值，选择该值1e-4范围内的所有特征作为初始活跃特征</li>\n<li>使用LK光流法在前两帧图像中追踪这些特征</li>\n<li>追踪到的特征作为新的特征与收集到的所有初始特征中的部分特征进行合并，参与合并的部分初始特征是第二帧图像周围的特征，然后在第三帧图像中追踪合并的特征</li>\n<li>重复上述过程，直到所有图像帧使用完毕</li>\n</ul>\n<p>基于Ground Truth的重投影，算法执行步骤：</p>\n<ul>\n<li>对于每个特征轨迹，确定初始时间和位置</li>\n<li>使用插值方法，确定每次初始化时的深度和位姿</li>\n<li>使用位姿、深度、相机标定参数，back-projected特征</li>\n<li>对于之后的每个位姿，将路标点重投影至图像帧中，生成特征轨迹</li>\n<li>超出图像帧平面范围的特征将被丢弃</li>\n</ul>\n<p>基于追踪的重投影过程不支持相机的畸变。</p>\n<h2 id=\"数据输入\"><a href=\"#数据输入\" class=\"headerlink\" title=\"数据输入\"></a>数据输入</h2><p>需要使用<code>.txt</code>文件提供特征轨迹数据，内容包括特征ID（追踪到的属于同一个特征的event使用相同的ID）、特征位置坐标、特征时间戳。如下所示：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># feature_id timestamp x y</span></span><br><span class=\"line\"><span class=\"number\">25</span> <span class=\"number\">1.403636580013555527e+09</span> <span class=\"number\">125.827</span> <span class=\"number\">15.615</span> </span><br><span class=\"line\"><span class=\"number\">13</span> <span class=\"number\">1.403636580015467890e+09</span> <span class=\"number\">20.453</span> <span class=\"number\">90.142</span> </span><br><span class=\"line\"><span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>用于Ground Truth生成的图像、位姿、深度图、相机参数必须以rosbag的格式提供。各数据的信息格式如下：</p>\n<ul>\n<li>images: <code>sensor_msgs/Image</code></li>\n<li>poses: <code>geometry_msgs/PoseStamped</code></li>\n<li>depth maps: <code>sensor_msgs/Image</code>-<code>CV_32F</code></li>\n</ul>\n<p>有关ros话题和rosbag文件信息，使用<code>dataset.yaml</code>文件提供。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">type:</span> <span class=\"string\">bag</span></span><br><span class=\"line\"><span class=\"attr\">name:</span> <span class=\"string\">relative/path/to/ros.bag</span>  <span class=\"comment\"># relative path of bag</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># For KLT based tracking </span></span><br><span class=\"line\"><span class=\"attr\">image_topic:</span> <span class=\"string\">/dvs/image_raw</span>  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># For reprojection based tracking</span></span><br><span class=\"line\"><span class=\"attr\">depth_map_topic:</span> <span class=\"string\">/dvs/depthmap</span></span><br><span class=\"line\"><span class=\"attr\">pose_topic:</span> <span class=\"string\">/dvs/pose</span></span><br><span class=\"line\"><span class=\"attr\">camera_info_topic:</span> <span class=\"string\">/dvs/camera_info</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><h4 id=\"测试特征追踪算法\"><a href=\"#测试特征追踪算法\" class=\"headerlink\" title=\"测试特征追踪算法\"></a>测试特征追踪算法</h4><p>需要进行如下步骤：</p>\n<ul>\n<li><p><code>--file /path/to/tracks.txt</code>：给定用户自己的特征追踪算法生成的特征追踪结果</p>\n</li>\n<li><p><code>--dataset /path/to/your_dataset.yaml</code>：给定测试数据集的配置文件，文件内容如下</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">type:</span> <span class=\"string\">\"bag\"</span></span><br><span class=\"line\"><span class=\"attr\">name:</span> <span class=\"string\">\"your_dataset.bag\"</span>  \t\t<span class=\"comment\"># 测试数据集rosbag文件名</span></span><br><span class=\"line\"><span class=\"attr\">image_topic:</span> <span class=\"string\">\"/dvs/image_raw\"</span>\t<span class=\"comment\"># rosbag文件图像相关话题（ETH数据集rosbag图像话题都是这个）</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>--root /path/to/bags</code>：测试数据所在路径（到测试数据集rosbag文件的父目录）</p>\n</li>\n</ul>\n<p>测试执行命令举例：</p>\n<ol>\n<li>测试1：<code>python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview</code></li>\n<li>测试2：<code>python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_kueng_iros_16/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview</code></li>\n</ol>\n<p>执行命令解释：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python evaluate_tracks.py \t\t# 评估用户特征追踪算法</span><br><span class=\"line\">\t\t--error_threshold 10 \t# 用在可视化和画图时的阈值，追踪误差超过该阈值的特征将被丢弃</span><br><span class=\"line\">\t\t--tracker_type KLT \t\t# 特征ground truth追踪方法</span><br><span class=\"line\">\t\t--file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt # 用户特征追踪算法得到的特征轨迹</span><br><span class=\"line\">\t\t--dataset ./example/dataset_params/bicycles.yaml # 保存测试数据集的类型、名称、ros话题</span><br><span class=\"line\">\t\t--root ./example/bags \t# 测试数据集保存路径</span><br><span class=\"line\">\t\t--plot_3d </span><br><span class=\"line\">\t\t--plot_errors </span><br><span class=\"line\">\t\t--video_preview</span><br></pre></td></tr></table></figure>\n<h4 id=\"对比特征追踪方法\"><a href=\"#对比特征追踪方法\" class=\"headerlink\" title=\"对比特征追踪方法\"></a>对比特征追踪方法</h4><p>测试执行命令：</p>\n<ol>\n<li>测试1：<code>python compare_tracks.py --error_threshold 10 --root ./example/tracks/ --config ./example/comparison_params/bicycles.yaml --results_directory ./example/comparison_results/bicycles_gehrig_eccv_18_kueng_iros_16</code></li>\n</ol>\n<p>执行命令解释：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python compare_tracks.py </span><br><span class=\"line\">\t\t--error_threshold 10 </span><br><span class=\"line\">\t\t--root ./example/tracks/ </span><br><span class=\"line\">\t\t--config ./example/comparison_params/bicycles.yaml </span><br><span class=\"line\">\t\t--results_directory ./example/comparison_results</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<hr>\n<p>记录UZH机器感知实验室的一个Github项目学习过程，该项目目的是对Event-based特征追踪算法进行评估，包括轨迹的显示、误差、追踪时间的统计评测等。<br>","more":"</p>\n<p>Github项目地址：<a href=\"https://github.com/uzh-rpg/rpg_feature_tracking_analysis\" target=\"_blank\" rel=\"noopener\">https://github.com/uzh-rpg/rpg_feature_tracking_analysis</a></p>\n<h2 id=\"基于Event的特征追踪算法评估工作流程\"><a href=\"#基于Event的特征追踪算法评估工作流程\" class=\"headerlink\" title=\"基于Event的特征追踪算法评估工作流程\"></a>基于Event的特征追踪算法评估工作流程</h2><h3 id=\"评估特征追踪轨迹Ground-Truth的两个方法\"><a href=\"#评估特征追踪轨迹Ground-Truth的两个方法\" class=\"headerlink\" title=\"评估特征追踪轨迹Ground Truth的两个方法\"></a>评估特征追踪轨迹Ground Truth的两个方法</h3><ul>\n<li>基于同步图像帧和event的KLT特征追踪</li>\n<li>基于路标点反投影的特征追踪</li>\n</ul>\n<h3 id=\"算法功能\"><a href=\"#算法功能\" class=\"headerlink\" title=\"算法功能\"></a>算法功能</h3><ul>\n<li>使用上述方法之一评估用户的特征追踪方法</li>\n<li>生成随时间变化的特征追踪误差图（可用于论文插图）</li>\n<li>生成特征追踪的三维时空图</li>\n<li>生成特征追踪视频</li>\n<li>将用户的特征追踪方法与其他方法进行比较</li>\n<li>生成单个特征的跟踪误差图</li>\n</ul>\n<h3 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h3><p>特征追踪评估两个步骤：</p>\n<ul>\n<li>Ground Truth Tracker初始化</li>\n<li>Tracking</li>\n</ul>\n<p>基于KLT追踪方法获取Ground Truth，该算法的输入为测试数据集图像帧序列（以rosbag文件的形式，rostopic为<code>/dvs/image_raw</code>），算法执行步骤：</p>\n<ul>\n<li>对于每个特征轨迹，确定其初始时间</li>\n<li>在初始化时，或者初始化之后找到第一帧灰度图像</li>\n<li>特征的x、y位置坐标插值到轨迹中，对应当前帧的时间戳</li>\n<li>KLT方法追踪该特征，直到该特征丢失；对于每一帧图像都要更新模板</li>\n</ul>\n<p>在阅读代码后，总结算法执行流程如下：</p>\n<ul>\n<li>对于追踪算法得到的特征轨迹，提取每一个特征轨迹的第一个特征的时间戳</li>\n<li>根据图像帧时间戳，找到与初始特征时间戳距离最近的图像帧，时间差不超过1e-5，否则选择比初始特征时间戳大的最小时间戳对应的图像</li>\n<li>一维线性插值找到图像帧时间戳时刻对应的特征点的坐标，[id, t_image, x_interp, y_interp]组成元组，构成一个图像帧中的特征</li>\n<li>收集到所有的初始图像帧特征，保存留作备用</li>\n<li>找到初始图像帧特征中的时间戳最小值，选择该值1e-4范围内的所有特征作为初始活跃特征</li>\n<li>使用LK光流法在前两帧图像中追踪这些特征</li>\n<li>追踪到的特征作为新的特征与收集到的所有初始特征中的部分特征进行合并，参与合并的部分初始特征是第二帧图像周围的特征，然后在第三帧图像中追踪合并的特征</li>\n<li>重复上述过程，直到所有图像帧使用完毕</li>\n</ul>\n<p>基于Ground Truth的重投影，算法执行步骤：</p>\n<ul>\n<li>对于每个特征轨迹，确定初始时间和位置</li>\n<li>使用插值方法，确定每次初始化时的深度和位姿</li>\n<li>使用位姿、深度、相机标定参数，back-projected特征</li>\n<li>对于之后的每个位姿，将路标点重投影至图像帧中，生成特征轨迹</li>\n<li>超出图像帧平面范围的特征将被丢弃</li>\n</ul>\n<p>基于追踪的重投影过程不支持相机的畸变。</p>\n<h2 id=\"数据输入\"><a href=\"#数据输入\" class=\"headerlink\" title=\"数据输入\"></a>数据输入</h2><p>需要使用<code>.txt</code>文件提供特征轨迹数据，内容包括特征ID（追踪到的属于同一个特征的event使用相同的ID）、特征位置坐标、特征时间戳。如下所示：</p>\n<!--�19-->\n<p>用于Ground Truth生成的图像、位姿、深度图、相机参数必须以rosbag的格式提供。各数据的信息格式如下：</p>\n<ul>\n<li>images: <code>sensor_msgs/Image</code></li>\n<li>poses: <code>geometry_msgs/PoseStamped</code></li>\n<li>depth maps: <code>sensor_msgs/Image</code>-<code>CV_32F</code></li>\n</ul>\n<p>有关ros话题和rosbag文件信息，使用<code>dataset.yaml</code>文件提供。</p>\n<!--�20-->\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><h4 id=\"测试特征追踪算法\"><a href=\"#测试特征追踪算法\" class=\"headerlink\" title=\"测试特征追踪算法\"></a>测试特征追踪算法</h4><p>需要进行如下步骤：</p>\n<ul>\n<li><p><code>--file /path/to/tracks.txt</code>：给定用户自己的特征追踪算法生成的特征追踪结果</p>\n</li>\n<li><p><code>--dataset /path/to/your_dataset.yaml</code>：给定测试数据集的配置文件，文件内容如下</p>\n<!--�21-->\n</li>\n<li><p><code>--root /path/to/bags</code>：测试数据所在路径（到测试数据集rosbag文件的父目录）</p>\n</li>\n</ul>\n<p>测试执行命令举例：</p>\n<ol>\n<li>测试1：<code>python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_gehrig_eccv_18/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview</code></li>\n<li>测试2：<code>python evaluate_tracks.py --error_threshold 10 --tracker_type KLT --file ./example/tracks/bicycles_kueng_iros_16/tracks.txt --dataset ./example/dataset_params/bicycles.yaml --root ./example/bags --plot_3d --plot_errors --video_preview</code></li>\n</ol>\n<p>执行命令解释：</p>\n<!--�22-->\n<h4 id=\"对比特征追踪方法\"><a href=\"#对比特征追踪方法\" class=\"headerlink\" title=\"对比特征追踪方法\"></a>对比特征追踪方法</h4><p>测试执行命令：</p>\n<ol>\n<li>测试1：<code>python compare_tracks.py --error_threshold 10 --root ./example/tracks/ --config ./example/comparison_params/bicycles.yaml --results_directory ./example/comparison_results/bicycles_gehrig_eccv_18_kueng_iros_16</code></li>\n</ol>\n<p>执行命令解释：</p>\n<!--�23-->"},{"title":"ORB_SLAM2学习之源码分析七-LocalClosing","date":"2018-08-23T04:38:31.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalClosing模块部分。\n\n<!--more--->\n\n## 概述\n\nLocalClosing模块是SLAM系统非常重要的一部分，由于VO过程存在累计误差（漂移），LocalClosing模块主要任务是检测闭环，即确定是否曾到达过此处，并在找到闭环之后计算Sim3变换，进行关键帧位姿、地图点的优化（后端优化），可以将这个累计误差缩小到一个可接受的范围内。闭环检测模块使用LocalMapping模块传送过来的关键帧，插入关键帧的操作是在LocalMapping线程主循环剔除冗余关键帧之后进行的，执行语句`mpLoopCloser->InsertKeyFrame(mpCurrentKeyFrame)`。\n\n## 具体操作\n\n{% asset_img LocalClosing.png %}\n\n### 检测闭环\n\n对应`LoopClosing::DetectLoop()`函数。检测回环候选（在`KeyFrameDataBase`中找到与`mlpLoopKeyFrameQueue`相似的闭环候选帧）并检查共视关系（检查候选帧连续性），函数会将所有通过一致性检测的候选关键帧统一放到集合`mvpEnoughConsistentCandidates`中，由下一步最终确定闭环帧。主要过程如下：\n\n1. 计算当前帧`mpCurrentKF`和所有与当前帧有共视关系的关键帧的Bow得分，得到最小得分**`minScore`** ；\n\n2. 根据这个最小得分`minScore` 从`mpKeyFrameDB`（关键帧库）中找出候选的关键帧集合**`vpCandidateKFs`**；\n\n   > 使用`KeyFrameDatabase::DetectLoopCandidates`完成候选帧的筛选，具体过程：\n   >\n   > - Bow得分>minScore；\n   > - 统计满足1的关键帧中有共同单词最多的单词数maxcommonwords；\n   > - 筛选出共同单词数大于mincommons(=0.8*maxcommons)的关键帧；*\n   > - 相连的关键帧分为一组，计算组得分（总分），得到最大总分bestAccScore，筛选出总分大于minScoreToRetain(=0.75*bestAccScore)的组，用组中得分最高的候选帧lAccScoreAndMatch代表该组。计算组得分的目的是剔除单独一帧得分较高，但是没有共视关键帧，作为闭环来说不够鲁棒。\n\n   ​\n\n3. 对于**`vpCandidateKFs`**里面的每一个关键帧，作为当前关键帧。找出其有共视关系的关键帧组成一个当前集合**`spCandidateGroup`。如果当前关键帧是`vpCandidateKFs`中第一帧的话，直接把这个`spCandidateGroup`集合，以分数0直接放到`mvConsistentGroups`中。**如果不是第一帧的话，就从**`mvConsistentGroups`**中依次取出里面的元素`pair<set<KeyFrame*>,int>`的`first`，这些元素也是关键帧们组成**以前集合`sPreviousGroup`**。只要是当前集合中的任意一个关键帧能在以前集合里面找到，就要将当前集合的得分加1，并把当前集合放到`mvConsistentGroups`里面**。**如果当前集合的得分大于3（`mnCovisibilityConsistencyTh`）的话**，当前帧就通过了一致性检测**，把当前帧放到**`mvpEnoughConsistentCandidates`，最后会找到很多候选的关键帧。下一步用sim3找出闭环帧。**\n\n   > 注意该函数改变的就是**`mvpEnoughConsistentCandidates`**，`mvpEnoughConsistentCandidates`作为**该函数的输出**。\n\n### 计算Sim3\n\n对应`LoopClosing::ComputeSim3()`函数。该函数计算相似变换，从`mvpEnoughConsistentCandidates`中找出真正的闭环帧`mpMatchedKF`。主要过程如下：\n\n1. 通过`SearchByBow`，搜索当前关键帧中和候选帧匹配的地图点，当匹配的数目超过20，就为该候选帧和当前帧构造一个`sim3Solver`，即相似求解器；\n\n2. 用相似求解器`Sim3Solver`求解出候选帧与当前帧之间的相似变换`Scm`，这里使用RANSAC方法；\n\n3. 根据计算出的位姿，通过相似变换求找出更多的匹配地图点（`SearchBySim3`），更新`vpMapPointMatches`；\n\n4. 使用更新后的匹配，使用g2o**优化Sim3位姿**（`OptimizeSim3`），优化的结果足够好的话（内点数nInliers>20）就把候选的关键帧作为当前帧的闭环帧`mpMatchedKF`，break，跳过对其他候选闭环帧的判断，同时也得到了`mScw`；\n\n5. 获取`mpMatchedKF`及其相连关键帧对应的地图点。调用`SearchByProjection`将这些地图点通过上面优化得到的`mScw`变换投影（重投影）到当前关键帧进行匹配，若匹配点>=40个，则返回ture，进行闭环调整；否则，返回false，线程暂停5ms后继续检查Tracking发送来的关键帧队列。\n\n   > 注意`SearchByProjection`得到的当前关键帧中匹配上闭环关键帧共视地图点（**mvpCurrentMatchedPoints**），将用于后面CorrectLoop时当前关键帧地图点的冲突融合。\n\n至此，完成第4、5操作后，不仅确保了当前关键帧与闭环帧之间匹配度高，而且保证了闭环帧的共视图中的地图点和当前关键帧的特征点匹配度更高（20--->40），说明该闭环帧是正确的。\n\n### 闭环矫正\n\n对应`LoopClosing::CorrectLoop()`函数，完成回环地图点融合和位姿图优化。具体来说，在回环检测到之后，对当前帧（回环帧）周围的帧的影响、回边的连接以及地图点做出的相应的改变。闭环矫正时，LocalMapper和Global BA必须停止。注意Global BA使用的是单独的线程。主要过程如下：\n\n1. 使用计算出的当前帧的相似变换Sim3，即`mScw`，对当前位姿进行调整，并且传播到当前关键帧相连的关键帧（相连关键帧之间相对位姿是知道的，通过当前关键帧的Sim3计算相连关键帧的Sim3）；\n2. 经过上一步处理，回环两侧的关键帧完成对齐，然后利用调整过的位姿更新这些相连关键帧对应的地图点（修正关键帧看到的地图点）；\n3. 将闭环帧及其相连帧的地图点都投影到当前帧以及相连帧上，投影匹配上的和Sim3计算过的地图点进行融合（就是替换成质量高的）；\n4. 涉及融合的关键帧还需要更新其在共视地图中的观测边关系，因为找到了闭环，需要在covisibility里面增加闭环边（不止一条边）。这是为了剥离出因为闭环产生的新的连接关系LoopConnections，用于优化Essential Graph。添加当前帧与闭环匹配帧之间的边，该边不参与优化；\n5. 然后进行EssentialGraph优化（只是优化一些主要关键帧）；\n6. 新开一个线程进行全局优化，优化所有的位姿与MapPoints。\n\n## 参考资料\n\n1. [ORB-SLAM2学习7 LocalClosing.h](https://www.cnblogs.com/panda1/p/7001042.html)\n2. [ORB-SLAM（十）LoopClosing](https://www.cnblogs.com/shang-slam/p/6444037.html)\n3. [ORB-SLAM（六）回环检测](https://www.cnblogs.com/luyb/p/5599042.html)\n4. [ORBSlam2学习研究(Code analysis)-ORBSlam2中的闭环检测和后端优化LoopClosing](https://blog.csdn.net/chishuideyu/article/details/76165461)\n5. [单目slam LoopClosing之Sim3优化](https://blog.csdn.net/stihy/article/details/62219842?locationNum=8&fps=1)","source":"_posts/ORB-SLAM2学习之源码分析七-LocalClosing.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析七-LocalClosing\ndate: 2018-08-23 12:38:31\ntags: \n  - ORB_SLAM2\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalClosing模块部分。\n\n<!--more--->\n\n## 概述\n\nLocalClosing模块是SLAM系统非常重要的一部分，由于VO过程存在累计误差（漂移），LocalClosing模块主要任务是检测闭环，即确定是否曾到达过此处，并在找到闭环之后计算Sim3变换，进行关键帧位姿、地图点的优化（后端优化），可以将这个累计误差缩小到一个可接受的范围内。闭环检测模块使用LocalMapping模块传送过来的关键帧，插入关键帧的操作是在LocalMapping线程主循环剔除冗余关键帧之后进行的，执行语句`mpLoopCloser->InsertKeyFrame(mpCurrentKeyFrame)`。\n\n## 具体操作\n\n{% asset_img LocalClosing.png %}\n\n### 检测闭环\n\n对应`LoopClosing::DetectLoop()`函数。检测回环候选（在`KeyFrameDataBase`中找到与`mlpLoopKeyFrameQueue`相似的闭环候选帧）并检查共视关系（检查候选帧连续性），函数会将所有通过一致性检测的候选关键帧统一放到集合`mvpEnoughConsistentCandidates`中，由下一步最终确定闭环帧。主要过程如下：\n\n1. 计算当前帧`mpCurrentKF`和所有与当前帧有共视关系的关键帧的Bow得分，得到最小得分**`minScore`** ；\n\n2. 根据这个最小得分`minScore` 从`mpKeyFrameDB`（关键帧库）中找出候选的关键帧集合**`vpCandidateKFs`**；\n\n   > 使用`KeyFrameDatabase::DetectLoopCandidates`完成候选帧的筛选，具体过程：\n   >\n   > - Bow得分>minScore；\n   > - 统计满足1的关键帧中有共同单词最多的单词数maxcommonwords；\n   > - 筛选出共同单词数大于mincommons(=0.8*maxcommons)的关键帧；*\n   > - 相连的关键帧分为一组，计算组得分（总分），得到最大总分bestAccScore，筛选出总分大于minScoreToRetain(=0.75*bestAccScore)的组，用组中得分最高的候选帧lAccScoreAndMatch代表该组。计算组得分的目的是剔除单独一帧得分较高，但是没有共视关键帧，作为闭环来说不够鲁棒。\n\n   ​\n\n3. 对于**`vpCandidateKFs`**里面的每一个关键帧，作为当前关键帧。找出其有共视关系的关键帧组成一个当前集合**`spCandidateGroup`。如果当前关键帧是`vpCandidateKFs`中第一帧的话，直接把这个`spCandidateGroup`集合，以分数0直接放到`mvConsistentGroups`中。**如果不是第一帧的话，就从**`mvConsistentGroups`**中依次取出里面的元素`pair<set<KeyFrame*>,int>`的`first`，这些元素也是关键帧们组成**以前集合`sPreviousGroup`**。只要是当前集合中的任意一个关键帧能在以前集合里面找到，就要将当前集合的得分加1，并把当前集合放到`mvConsistentGroups`里面**。**如果当前集合的得分大于3（`mnCovisibilityConsistencyTh`）的话**，当前帧就通过了一致性检测**，把当前帧放到**`mvpEnoughConsistentCandidates`，最后会找到很多候选的关键帧。下一步用sim3找出闭环帧。**\n\n   > 注意该函数改变的就是**`mvpEnoughConsistentCandidates`**，`mvpEnoughConsistentCandidates`作为**该函数的输出**。\n\n### 计算Sim3\n\n对应`LoopClosing::ComputeSim3()`函数。该函数计算相似变换，从`mvpEnoughConsistentCandidates`中找出真正的闭环帧`mpMatchedKF`。主要过程如下：\n\n1. 通过`SearchByBow`，搜索当前关键帧中和候选帧匹配的地图点，当匹配的数目超过20，就为该候选帧和当前帧构造一个`sim3Solver`，即相似求解器；\n\n2. 用相似求解器`Sim3Solver`求解出候选帧与当前帧之间的相似变换`Scm`，这里使用RANSAC方法；\n\n3. 根据计算出的位姿，通过相似变换求找出更多的匹配地图点（`SearchBySim3`），更新`vpMapPointMatches`；\n\n4. 使用更新后的匹配，使用g2o**优化Sim3位姿**（`OptimizeSim3`），优化的结果足够好的话（内点数nInliers>20）就把候选的关键帧作为当前帧的闭环帧`mpMatchedKF`，break，跳过对其他候选闭环帧的判断，同时也得到了`mScw`；\n\n5. 获取`mpMatchedKF`及其相连关键帧对应的地图点。调用`SearchByProjection`将这些地图点通过上面优化得到的`mScw`变换投影（重投影）到当前关键帧进行匹配，若匹配点>=40个，则返回ture，进行闭环调整；否则，返回false，线程暂停5ms后继续检查Tracking发送来的关键帧队列。\n\n   > 注意`SearchByProjection`得到的当前关键帧中匹配上闭环关键帧共视地图点（**mvpCurrentMatchedPoints**），将用于后面CorrectLoop时当前关键帧地图点的冲突融合。\n\n至此，完成第4、5操作后，不仅确保了当前关键帧与闭环帧之间匹配度高，而且保证了闭环帧的共视图中的地图点和当前关键帧的特征点匹配度更高（20--->40），说明该闭环帧是正确的。\n\n### 闭环矫正\n\n对应`LoopClosing::CorrectLoop()`函数，完成回环地图点融合和位姿图优化。具体来说，在回环检测到之后，对当前帧（回环帧）周围的帧的影响、回边的连接以及地图点做出的相应的改变。闭环矫正时，LocalMapper和Global BA必须停止。注意Global BA使用的是单独的线程。主要过程如下：\n\n1. 使用计算出的当前帧的相似变换Sim3，即`mScw`，对当前位姿进行调整，并且传播到当前关键帧相连的关键帧（相连关键帧之间相对位姿是知道的，通过当前关键帧的Sim3计算相连关键帧的Sim3）；\n2. 经过上一步处理，回环两侧的关键帧完成对齐，然后利用调整过的位姿更新这些相连关键帧对应的地图点（修正关键帧看到的地图点）；\n3. 将闭环帧及其相连帧的地图点都投影到当前帧以及相连帧上，投影匹配上的和Sim3计算过的地图点进行融合（就是替换成质量高的）；\n4. 涉及融合的关键帧还需要更新其在共视地图中的观测边关系，因为找到了闭环，需要在covisibility里面增加闭环边（不止一条边）。这是为了剥离出因为闭环产生的新的连接关系LoopConnections，用于优化Essential Graph。添加当前帧与闭环匹配帧之间的边，该边不参与优化；\n5. 然后进行EssentialGraph优化（只是优化一些主要关键帧）；\n6. 新开一个线程进行全局优化，优化所有的位姿与MapPoints。\n\n## 参考资料\n\n1. [ORB-SLAM2学习7 LocalClosing.h](https://www.cnblogs.com/panda1/p/7001042.html)\n2. [ORB-SLAM（十）LoopClosing](https://www.cnblogs.com/shang-slam/p/6444037.html)\n3. [ORB-SLAM（六）回环检测](https://www.cnblogs.com/luyb/p/5599042.html)\n4. [ORBSlam2学习研究(Code analysis)-ORBSlam2中的闭环检测和后端优化LoopClosing](https://blog.csdn.net/chishuideyu/article/details/76165461)\n5. [单目slam LoopClosing之Sim3优化](https://blog.csdn.net/stihy/article/details/62219842?locationNum=8&fps=1)","slug":"ORB-SLAM2学习之源码分析七-LocalClosing","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuh000xqlcreih2ab4e","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalClosing模块部分。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>LocalClosing模块是SLAM系统非常重要的一部分，由于VO过程存在累计误差（漂移），LocalClosing模块主要任务是检测闭环，即确定是否曾到达过此处，并在找到闭环之后计算Sim3变换，进行关键帧位姿、地图点的优化（后端优化），可以将这个累计误差缩小到一个可接受的范围内。闭环检测模块使用LocalMapping模块传送过来的关键帧，插入关键帧的操作是在LocalMapping线程主循环剔除冗余关键帧之后进行的，执行语句<code>mpLoopCloser-&gt;InsertKeyFrame(mpCurrentKeyFrame)</code>。</p>\n<h2 id=\"具体操作\"><a href=\"#具体操作\" class=\"headerlink\" title=\"具体操作\"></a>具体操作</h2><img src=\"/2018/08/23/ORB-SLAM2学习之源码分析七-LocalClosing/LocalClosing.png\">\n<h3 id=\"检测闭环\"><a href=\"#检测闭环\" class=\"headerlink\" title=\"检测闭环\"></a>检测闭环</h3><p>对应<code>LoopClosing::DetectLoop()</code>函数。检测回环候选（在<code>KeyFrameDataBase</code>中找到与<code>mlpLoopKeyFrameQueue</code>相似的闭环候选帧）并检查共视关系（检查候选帧连续性），函数会将所有通过一致性检测的候选关键帧统一放到集合<code>mvpEnoughConsistentCandidates</code>中，由下一步最终确定闭环帧。主要过程如下：</p>\n<ol>\n<li><p>计算当前帧<code>mpCurrentKF</code>和所有与当前帧有共视关系的关键帧的Bow得分，得到最小得分<strong><code>minScore</code></strong> ；</p>\n</li>\n<li><p>根据这个最小得分<code>minScore</code> 从<code>mpKeyFrameDB</code>（关键帧库）中找出候选的关键帧集合<strong><code>vpCandidateKFs</code></strong>；</p>\n<blockquote>\n<p>使用<code>KeyFrameDatabase::DetectLoopCandidates</code>完成候选帧的筛选，具体过程：</p>\n<ul>\n<li>Bow得分&gt;minScore；</li>\n<li>统计满足1的关键帧中有共同单词最多的单词数maxcommonwords；</li>\n<li>筛选出共同单词数大于mincommons(=0.8<em>maxcommons)的关键帧；</em></li>\n<li>相连的关键帧分为一组，计算组得分（总分），得到最大总分bestAccScore，筛选出总分大于minScoreToRetain(=0.75*bestAccScore)的组，用组中得分最高的候选帧lAccScoreAndMatch代表该组。计算组得分的目的是剔除单独一帧得分较高，但是没有共视关键帧，作为闭环来说不够鲁棒。</li>\n</ul>\n</blockquote>\n<p>​</p>\n</li>\n<li><p>对于<strong><code>vpCandidateKFs</code></strong>里面的每一个关键帧，作为当前关键帧。找出其有共视关系的关键帧组成一个当前集合<strong><code>spCandidateGroup</code>。如果当前关键帧是<code>vpCandidateKFs</code>中第一帧的话，直接把这个<code>spCandidateGroup</code>集合，以分数0直接放到<code>mvConsistentGroups</code>中。</strong>如果不是第一帧的话，就从<strong><code>mvConsistentGroups</code></strong>中依次取出里面的元素<code>pair&lt;set&lt;KeyFrame*&gt;,int&gt;</code>的<code>first</code>，这些元素也是关键帧们组成<strong>以前集合<code>sPreviousGroup</code></strong>。只要是当前集合中的任意一个关键帧能在以前集合里面找到，就要将当前集合的得分加1，并把当前集合放到<code>mvConsistentGroups</code>里面<strong>。</strong>如果当前集合的得分大于3（<code>mnCovisibilityConsistencyTh</code>）的话<strong>，当前帧就通过了一致性检测</strong>，把当前帧放到<strong><code>mvpEnoughConsistentCandidates</code>，最后会找到很多候选的关键帧。下一步用sim3找出闭环帧。</strong></p>\n<blockquote>\n<p>注意该函数改变的就是<strong><code>mvpEnoughConsistentCandidates</code></strong>，<code>mvpEnoughConsistentCandidates</code>作为<strong>该函数的输出</strong>。</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"计算Sim3\"><a href=\"#计算Sim3\" class=\"headerlink\" title=\"计算Sim3\"></a>计算Sim3</h3><p>对应<code>LoopClosing::ComputeSim3()</code>函数。该函数计算相似变换，从<code>mvpEnoughConsistentCandidates</code>中找出真正的闭环帧<code>mpMatchedKF</code>。主要过程如下：</p>\n<ol>\n<li><p>通过<code>SearchByBow</code>，搜索当前关键帧中和候选帧匹配的地图点，当匹配的数目超过20，就为该候选帧和当前帧构造一个<code>sim3Solver</code>，即相似求解器；</p>\n</li>\n<li><p>用相似求解器<code>Sim3Solver</code>求解出候选帧与当前帧之间的相似变换<code>Scm</code>，这里使用RANSAC方法；</p>\n</li>\n<li><p>根据计算出的位姿，通过相似变换求找出更多的匹配地图点（<code>SearchBySim3</code>），更新<code>vpMapPointMatches</code>；</p>\n</li>\n<li><p>使用更新后的匹配，使用g2o<strong>优化Sim3位姿</strong>（<code>OptimizeSim3</code>），优化的结果足够好的话（内点数nInliers&gt;20）就把候选的关键帧作为当前帧的闭环帧<code>mpMatchedKF</code>，break，跳过对其他候选闭环帧的判断，同时也得到了<code>mScw</code>；</p>\n</li>\n<li><p>获取<code>mpMatchedKF</code>及其相连关键帧对应的地图点。调用<code>SearchByProjection</code>将这些地图点通过上面优化得到的<code>mScw</code>变换投影（重投影）到当前关键帧进行匹配，若匹配点&gt;=40个，则返回ture，进行闭环调整；否则，返回false，线程暂停5ms后继续检查Tracking发送来的关键帧队列。</p>\n<blockquote>\n<p>注意<code>SearchByProjection</code>得到的当前关键帧中匹配上闭环关键帧共视地图点（<strong>mvpCurrentMatchedPoints</strong>），将用于后面CorrectLoop时当前关键帧地图点的冲突融合。</p>\n</blockquote>\n</li>\n</ol>\n<p>至此，完成第4、5操作后，不仅确保了当前关键帧与闭环帧之间匹配度高，而且保证了闭环帧的共视图中的地图点和当前关键帧的特征点匹配度更高（20—-&gt;40），说明该闭环帧是正确的。</p>\n<h3 id=\"闭环矫正\"><a href=\"#闭环矫正\" class=\"headerlink\" title=\"闭环矫正\"></a>闭环矫正</h3><p>对应<code>LoopClosing::CorrectLoop()</code>函数，完成回环地图点融合和位姿图优化。具体来说，在回环检测到之后，对当前帧（回环帧）周围的帧的影响、回边的连接以及地图点做出的相应的改变。闭环矫正时，LocalMapper和Global BA必须停止。注意Global BA使用的是单独的线程。主要过程如下：</p>\n<ol>\n<li>使用计算出的当前帧的相似变换Sim3，即<code>mScw</code>，对当前位姿进行调整，并且传播到当前关键帧相连的关键帧（相连关键帧之间相对位姿是知道的，通过当前关键帧的Sim3计算相连关键帧的Sim3）；</li>\n<li>经过上一步处理，回环两侧的关键帧完成对齐，然后利用调整过的位姿更新这些相连关键帧对应的地图点（修正关键帧看到的地图点）；</li>\n<li>将闭环帧及其相连帧的地图点都投影到当前帧以及相连帧上，投影匹配上的和Sim3计算过的地图点进行融合（就是替换成质量高的）；</li>\n<li>涉及融合的关键帧还需要更新其在共视地图中的观测边关系，因为找到了闭环，需要在covisibility里面增加闭环边（不止一条边）。这是为了剥离出因为闭环产生的新的连接关系LoopConnections，用于优化Essential Graph。添加当前帧与闭环匹配帧之间的边，该边不参与优化；</li>\n<li>然后进行EssentialGraph优化（只是优化一些主要关键帧）；</li>\n<li>新开一个线程进行全局优化，优化所有的位姿与MapPoints。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/panda1/p/7001042.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM2学习7 LocalClosing.h</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6444037.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（十）LoopClosing</a></li>\n<li><a href=\"https://www.cnblogs.com/luyb/p/5599042.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（六）回环检测</a></li>\n<li><a href=\"https://blog.csdn.net/chishuideyu/article/details/76165461\" target=\"_blank\" rel=\"noopener\">ORBSlam2学习研究(Code analysis)-ORBSlam2中的闭环检测和后端优化LoopClosing</a></li>\n<li><a href=\"https://blog.csdn.net/stihy/article/details/62219842?locationNum=8&amp;fps=1\" target=\"_blank\" rel=\"noopener\">单目slam LoopClosing之Sim3优化</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalClosing模块部分。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>LocalClosing模块是SLAM系统非常重要的一部分，由于VO过程存在累计误差（漂移），LocalClosing模块主要任务是检测闭环，即确定是否曾到达过此处，并在找到闭环之后计算Sim3变换，进行关键帧位姿、地图点的优化（后端优化），可以将这个累计误差缩小到一个可接受的范围内。闭环检测模块使用LocalMapping模块传送过来的关键帧，插入关键帧的操作是在LocalMapping线程主循环剔除冗余关键帧之后进行的，执行语句<code>mpLoopCloser-&gt;InsertKeyFrame(mpCurrentKeyFrame)</code>。</p>\n<h2 id=\"具体操作\"><a href=\"#具体操作\" class=\"headerlink\" title=\"具体操作\"></a>具体操作</h2><img src=\"/2018/08/23/ORB-SLAM2学习之源码分析七-LocalClosing/LocalClosing.png\">\n<h3 id=\"检测闭环\"><a href=\"#检测闭环\" class=\"headerlink\" title=\"检测闭环\"></a>检测闭环</h3><p>对应<code>LoopClosing::DetectLoop()</code>函数。检测回环候选（在<code>KeyFrameDataBase</code>中找到与<code>mlpLoopKeyFrameQueue</code>相似的闭环候选帧）并检查共视关系（检查候选帧连续性），函数会将所有通过一致性检测的候选关键帧统一放到集合<code>mvpEnoughConsistentCandidates</code>中，由下一步最终确定闭环帧。主要过程如下：</p>\n<ol>\n<li><p>计算当前帧<code>mpCurrentKF</code>和所有与当前帧有共视关系的关键帧的Bow得分，得到最小得分<strong><code>minScore</code></strong> ；</p>\n</li>\n<li><p>根据这个最小得分<code>minScore</code> 从<code>mpKeyFrameDB</code>（关键帧库）中找出候选的关键帧集合<strong><code>vpCandidateKFs</code></strong>；</p>\n<blockquote>\n<p>使用<code>KeyFrameDatabase::DetectLoopCandidates</code>完成候选帧的筛选，具体过程：</p>\n<ul>\n<li>Bow得分&gt;minScore；</li>\n<li>统计满足1的关键帧中有共同单词最多的单词数maxcommonwords；</li>\n<li>筛选出共同单词数大于mincommons(=0.8<em>maxcommons)的关键帧；</em></li>\n<li>相连的关键帧分为一组，计算组得分（总分），得到最大总分bestAccScore，筛选出总分大于minScoreToRetain(=0.75*bestAccScore)的组，用组中得分最高的候选帧lAccScoreAndMatch代表该组。计算组得分的目的是剔除单独一帧得分较高，但是没有共视关键帧，作为闭环来说不够鲁棒。</li>\n</ul>\n</blockquote>\n<p>​</p>\n</li>\n<li><p>对于<strong><code>vpCandidateKFs</code></strong>里面的每一个关键帧，作为当前关键帧。找出其有共视关系的关键帧组成一个当前集合<strong><code>spCandidateGroup</code>。如果当前关键帧是<code>vpCandidateKFs</code>中第一帧的话，直接把这个<code>spCandidateGroup</code>集合，以分数0直接放到<code>mvConsistentGroups</code>中。</strong>如果不是第一帧的话，就从<strong><code>mvConsistentGroups</code></strong>中依次取出里面的元素<code>pair&lt;set&lt;KeyFrame*&gt;,int&gt;</code>的<code>first</code>，这些元素也是关键帧们组成<strong>以前集合<code>sPreviousGroup</code></strong>。只要是当前集合中的任意一个关键帧能在以前集合里面找到，就要将当前集合的得分加1，并把当前集合放到<code>mvConsistentGroups</code>里面<strong>。</strong>如果当前集合的得分大于3（<code>mnCovisibilityConsistencyTh</code>）的话<strong>，当前帧就通过了一致性检测</strong>，把当前帧放到<strong><code>mvpEnoughConsistentCandidates</code>，最后会找到很多候选的关键帧。下一步用sim3找出闭环帧。</strong></p>\n<blockquote>\n<p>注意该函数改变的就是<strong><code>mvpEnoughConsistentCandidates</code></strong>，<code>mvpEnoughConsistentCandidates</code>作为<strong>该函数的输出</strong>。</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"计算Sim3\"><a href=\"#计算Sim3\" class=\"headerlink\" title=\"计算Sim3\"></a>计算Sim3</h3><p>对应<code>LoopClosing::ComputeSim3()</code>函数。该函数计算相似变换，从<code>mvpEnoughConsistentCandidates</code>中找出真正的闭环帧<code>mpMatchedKF</code>。主要过程如下：</p>\n<ol>\n<li><p>通过<code>SearchByBow</code>，搜索当前关键帧中和候选帧匹配的地图点，当匹配的数目超过20，就为该候选帧和当前帧构造一个<code>sim3Solver</code>，即相似求解器；</p>\n</li>\n<li><p>用相似求解器<code>Sim3Solver</code>求解出候选帧与当前帧之间的相似变换<code>Scm</code>，这里使用RANSAC方法；</p>\n</li>\n<li><p>根据计算出的位姿，通过相似变换求找出更多的匹配地图点（<code>SearchBySim3</code>），更新<code>vpMapPointMatches</code>；</p>\n</li>\n<li><p>使用更新后的匹配，使用g2o<strong>优化Sim3位姿</strong>（<code>OptimizeSim3</code>），优化的结果足够好的话（内点数nInliers&gt;20）就把候选的关键帧作为当前帧的闭环帧<code>mpMatchedKF</code>，break，跳过对其他候选闭环帧的判断，同时也得到了<code>mScw</code>；</p>\n</li>\n<li><p>获取<code>mpMatchedKF</code>及其相连关键帧对应的地图点。调用<code>SearchByProjection</code>将这些地图点通过上面优化得到的<code>mScw</code>变换投影（重投影）到当前关键帧进行匹配，若匹配点&gt;=40个，则返回ture，进行闭环调整；否则，返回false，线程暂停5ms后继续检查Tracking发送来的关键帧队列。</p>\n<blockquote>\n<p>注意<code>SearchByProjection</code>得到的当前关键帧中匹配上闭环关键帧共视地图点（<strong>mvpCurrentMatchedPoints</strong>），将用于后面CorrectLoop时当前关键帧地图点的冲突融合。</p>\n</blockquote>\n</li>\n</ol>\n<p>至此，完成第4、5操作后，不仅确保了当前关键帧与闭环帧之间匹配度高，而且保证了闭环帧的共视图中的地图点和当前关键帧的特征点匹配度更高（20—-&gt;40），说明该闭环帧是正确的。</p>\n<h3 id=\"闭环矫正\"><a href=\"#闭环矫正\" class=\"headerlink\" title=\"闭环矫正\"></a>闭环矫正</h3><p>对应<code>LoopClosing::CorrectLoop()</code>函数，完成回环地图点融合和位姿图优化。具体来说，在回环检测到之后，对当前帧（回环帧）周围的帧的影响、回边的连接以及地图点做出的相应的改变。闭环矫正时，LocalMapper和Global BA必须停止。注意Global BA使用的是单独的线程。主要过程如下：</p>\n<ol>\n<li>使用计算出的当前帧的相似变换Sim3，即<code>mScw</code>，对当前位姿进行调整，并且传播到当前关键帧相连的关键帧（相连关键帧之间相对位姿是知道的，通过当前关键帧的Sim3计算相连关键帧的Sim3）；</li>\n<li>经过上一步处理，回环两侧的关键帧完成对齐，然后利用调整过的位姿更新这些相连关键帧对应的地图点（修正关键帧看到的地图点）；</li>\n<li>将闭环帧及其相连帧的地图点都投影到当前帧以及相连帧上，投影匹配上的和Sim3计算过的地图点进行融合（就是替换成质量高的）；</li>\n<li>涉及融合的关键帧还需要更新其在共视地图中的观测边关系，因为找到了闭环，需要在covisibility里面增加闭环边（不止一条边）。这是为了剥离出因为闭环产生的新的连接关系LoopConnections，用于优化Essential Graph。添加当前帧与闭环匹配帧之间的边，该边不参与优化；</li>\n<li>然后进行EssentialGraph优化（只是优化一些主要关键帧）；</li>\n<li>新开一个线程进行全局优化，优化所有的位姿与MapPoints。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/panda1/p/7001042.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM2学习7 LocalClosing.h</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6444037.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（十）LoopClosing</a></li>\n<li><a href=\"https://www.cnblogs.com/luyb/p/5599042.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（六）回环检测</a></li>\n<li><a href=\"https://blog.csdn.net/chishuideyu/article/details/76165461\" target=\"_blank\" rel=\"noopener\">ORBSlam2学习研究(Code analysis)-ORBSlam2中的闭环检测和后端优化LoopClosing</a></li>\n<li><a href=\"https://blog.csdn.net/stihy/article/details/62219842?locationNum=8&amp;fps=1\" target=\"_blank\" rel=\"noopener\">单目slam LoopClosing之Sim3优化</a></li>\n</ol>"},{"title":"ORB-SLAM2学习之源码分析五-一个变量引发的探索","date":"2018-08-20T09:12:28.000Z","mathjax":true,"copyright":true,"_content":"\n-----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录`KeyFrame::mvuRight`有关的内容。\n\n<!--more--->\n\n## 问题的引出\n\n\n{% fold +点击查看 %}\n~~~c++\nvoid MapPoint::AddObservation(KeyFrame* pKF, size_t idx)\n{\n    unique_lock<mutex> lock(mMutexFeatures);\n    if(mObservations.count(pKF))//count是map映射，使用key查找元素\n        return;\n    mObservations[pKF]=idx;//idx是当前地图点在该pKF中对应的关键点的编号\n\n    if(pKF->mvuRight[idx]>=0)//mvuRight？？\n        nObs+=2;\n    else\n        nObs++;//观测到该地图点的关键帧数目\n}\n~~~\n{% endfold %}\n\n\n在阅读`MapPoint::AddObservation`函数时，注意到`mvuRight`这个变量，程序中通过判断其值对`nObs`变量进行相关操作。一直没搞明白它的意思。终于在[知乎这个问题](https://www.zhihu.com/question/280964049/answer/418426500)找到了答案。这里稍微整理一下内容，并记录下自己由此理解的一些东西。\n\n在构造关键帧时，地图点和关键帧之间的观测关系是很重要的一个点，参考关键帧是哪一帧，该地图点被哪些关键帧观测到，对应的哪些（`idx`）特征点，都是通过一下两个成员变量维护：\n\n~~~c++\n//观测到该地图点的关键帧集合\nstd::map<KeyFrame*,size_t> mObservations;\n// 观测到该地图点的关键帧数\nint nObs; \n~~~\n\n通过`MapPoint::AddObservation()`函数添加地图点观测，即将能够观测到同一个地图点的关键帧（它们之间存在共视关系）加入到该地图点的`mObservations`集合中。函数中对于`mvuRight`的使用其实是RGB-D和双目模式使用到的”双目信息“之一。\n\n## 分析\n\n首先需要知道的是，RGBD虽然具有深度信息，但是深度图和RGB图不是完全匹配，其中还是有无深度值的区域，中间也存在空洞。在ORB_SLAM优化过程中，无深度信息的特征点是一条射线，就视作Mono模式一同处理；有深度信息的特征点，视作与Stereo模式一同处理。\n\n具体说来，为了让RGB-D模式与Mono和Stereo模式保持一致，在创建图像帧时，会调用`Frame::ComputeStereoFromRGBD`函数，如果有深度就设置`mvuRight`和`mvDepth`的对应值，下面一行代码就是设置**虚拟右图像**上的 u 坐标值，即`mvuRight`。\n\n~~~c++\nmvuRight[i] = kpU.pt.x-mbf/d;\n~~~\n\n对应公式：\n\n$u_R=u_L-\\frac{bf}{d}$\n\n其中$f$是$u$方向上的焦距（即$f_x$），$d$是左图像上的深度，$b$是左右图像基线，$\\frac{bf}{d}$是视差（disparity）。\n\n生成 Frame 之后就是调用 `Tracking::Track()`函数，通过特征匹配和局部地图追踪进行初步位姿估计。首先，初始化 `Tracking::StereoInitialization()`只会使用那些有深度的 Stereo 点。初始化完成之后，不论是 `Tracking::TrackWithMotionModel()`与上一普通帧匹配，还是 `Tracking::TrackReferenceKeyFrame()`与上一关键帧匹配，或是`Tracking::Relocalization()`与窗口中所有的关键帧匹配，或者`Tracking::TrackLocalMap`局部地图追踪，都会调用函数 `Optimizer::PoseOptimization()`函数，进行优化。此函数中，对于Mono模式会使用`g2o::EdgeSE3ProjectXYZOnlyPose`，对于Stereo模式会使用` g2o::EdgeStereoSE3ProjectXYZOnlyPose`，具体的代码部分如下。\n\n~~~c++\nint Optimizer::PoseOptimization(Frame *pFrame)\n{\n    //...\n\tfor(int i=0; i<N; i++)\n    {\n        MapPoint* pMP = pFrame->mvpMapPoints[i];\n        if(pMP)\n        {\n            // Monocular observation  单目模式观测到的地图点\n            if(pFrame->mvuRight[i]<0)\n            {\n            \t//...\n                g2o::EdgeSE3ProjectXYZOnlyPose* e = new g2o::EdgeSE3ProjectXYZOnlyPose();\n                //...\n            }\n            else  // Stereo observation  双目观测到的地图点\n            {\n                //...\n                g2o::EdgeStereoSE3ProjectXYZOnlyPose* e = new g2o::EdgeStereoSE3ProjectXYZOnlyPose();\n                //...\n            }\n        }\n    }\n    //...\n}\n~~~\n\n上述两个函数中有`computeError()`函数，分别返回`Vector2d`、`Vector3d`，具体代码如下：\n\n~~~c++\nVector2d EdgeSE3ProjectXYZ::cam_project(const Vector3d & trans_xyz) const{\n  Vector2d proj = project2d(trans_xyz);\n  Vector2d res;\n  res[0] = proj[0]*fx + cx;\n  res[1] = proj[1]*fy + cy;\n  return res;\n}\n~~~\n\n~~~c++\nVector3d EdgeStereoSE3ProjectXYZ::cam_project(const Vector3d & trans_xyz, const float &bf) const{\n  const float invz = 1.0f/trans_xyz[2];\n  Vector3d res;\n  res[0] = trans_xyz[0]*invz*fx + cx;\n  res[1] = trans_xyz[1]*invz*fy + cy;\n  res[2] = res[0] - bf*invz;\n  return res;\n}\n~~~\n\n`res[0]`、` res[1]` 是$u_L$、$v_L$，`res[2]` 是$u_R=u_L-\\frac{bf}{d}$。\n\n## 延伸思考\n\n正如在[源码分析二-初始化](http://ttshun.com/2018/08/16/ORB-SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C-%E5%88%9D%E5%A7%8B%E5%8C%96/)中所述，SLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成图像帧，为图像帧的各种信息赋值（使用原始图像进行ORB特征提取在这个过程中完成），之后原始图像就被丢弃，之后的处理过程和原始图像没有关系了。创建图像帧之后进行初始化，再之后的处理过程，除了优化过程（`Optimizer::PoseOptimization`）外，不再区分单目、双目模式**（真是这样吗？？？？）**。\n\n## 参考资料\n\n1. [ORB-SLAM六MapPoint与Map](https://www.cnblogs.com/shang-slam/p/6420575.html)\n2. [ORB-SLAM的RGBD为什么要分Mono和Stereo?](https://www.zhihu.com/question/280964049/answer/418426500)","source":"_posts/ORB-SLAM2学习之源码分析五-一个变量引发的探索.md","raw":"---\ntitle: ORB-SLAM2学习之源码分析五-一个变量引发的探索\ndate: 2018-08-20 17:12:28\ntags: \n  - ORB_SLAM2\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录`KeyFrame::mvuRight`有关的内容。\n\n<!--more--->\n\n## 问题的引出\n\n\n{% fold +点击查看 %}\n~~~c++\nvoid MapPoint::AddObservation(KeyFrame* pKF, size_t idx)\n{\n    unique_lock<mutex> lock(mMutexFeatures);\n    if(mObservations.count(pKF))//count是map映射，使用key查找元素\n        return;\n    mObservations[pKF]=idx;//idx是当前地图点在该pKF中对应的关键点的编号\n\n    if(pKF->mvuRight[idx]>=0)//mvuRight？？\n        nObs+=2;\n    else\n        nObs++;//观测到该地图点的关键帧数目\n}\n~~~\n{% endfold %}\n\n\n在阅读`MapPoint::AddObservation`函数时，注意到`mvuRight`这个变量，程序中通过判断其值对`nObs`变量进行相关操作。一直没搞明白它的意思。终于在[知乎这个问题](https://www.zhihu.com/question/280964049/answer/418426500)找到了答案。这里稍微整理一下内容，并记录下自己由此理解的一些东西。\n\n在构造关键帧时，地图点和关键帧之间的观测关系是很重要的一个点，参考关键帧是哪一帧，该地图点被哪些关键帧观测到，对应的哪些（`idx`）特征点，都是通过一下两个成员变量维护：\n\n~~~c++\n//观测到该地图点的关键帧集合\nstd::map<KeyFrame*,size_t> mObservations;\n// 观测到该地图点的关键帧数\nint nObs; \n~~~\n\n通过`MapPoint::AddObservation()`函数添加地图点观测，即将能够观测到同一个地图点的关键帧（它们之间存在共视关系）加入到该地图点的`mObservations`集合中。函数中对于`mvuRight`的使用其实是RGB-D和双目模式使用到的”双目信息“之一。\n\n## 分析\n\n首先需要知道的是，RGBD虽然具有深度信息，但是深度图和RGB图不是完全匹配，其中还是有无深度值的区域，中间也存在空洞。在ORB_SLAM优化过程中，无深度信息的特征点是一条射线，就视作Mono模式一同处理；有深度信息的特征点，视作与Stereo模式一同处理。\n\n具体说来，为了让RGB-D模式与Mono和Stereo模式保持一致，在创建图像帧时，会调用`Frame::ComputeStereoFromRGBD`函数，如果有深度就设置`mvuRight`和`mvDepth`的对应值，下面一行代码就是设置**虚拟右图像**上的 u 坐标值，即`mvuRight`。\n\n~~~c++\nmvuRight[i] = kpU.pt.x-mbf/d;\n~~~\n\n对应公式：\n\n$u_R=u_L-\\frac{bf}{d}$\n\n其中$f$是$u$方向上的焦距（即$f_x$），$d$是左图像上的深度，$b$是左右图像基线，$\\frac{bf}{d}$是视差（disparity）。\n\n生成 Frame 之后就是调用 `Tracking::Track()`函数，通过特征匹配和局部地图追踪进行初步位姿估计。首先，初始化 `Tracking::StereoInitialization()`只会使用那些有深度的 Stereo 点。初始化完成之后，不论是 `Tracking::TrackWithMotionModel()`与上一普通帧匹配，还是 `Tracking::TrackReferenceKeyFrame()`与上一关键帧匹配，或是`Tracking::Relocalization()`与窗口中所有的关键帧匹配，或者`Tracking::TrackLocalMap`局部地图追踪，都会调用函数 `Optimizer::PoseOptimization()`函数，进行优化。此函数中，对于Mono模式会使用`g2o::EdgeSE3ProjectXYZOnlyPose`，对于Stereo模式会使用` g2o::EdgeStereoSE3ProjectXYZOnlyPose`，具体的代码部分如下。\n\n~~~c++\nint Optimizer::PoseOptimization(Frame *pFrame)\n{\n    //...\n\tfor(int i=0; i<N; i++)\n    {\n        MapPoint* pMP = pFrame->mvpMapPoints[i];\n        if(pMP)\n        {\n            // Monocular observation  单目模式观测到的地图点\n            if(pFrame->mvuRight[i]<0)\n            {\n            \t//...\n                g2o::EdgeSE3ProjectXYZOnlyPose* e = new g2o::EdgeSE3ProjectXYZOnlyPose();\n                //...\n            }\n            else  // Stereo observation  双目观测到的地图点\n            {\n                //...\n                g2o::EdgeStereoSE3ProjectXYZOnlyPose* e = new g2o::EdgeStereoSE3ProjectXYZOnlyPose();\n                //...\n            }\n        }\n    }\n    //...\n}\n~~~\n\n上述两个函数中有`computeError()`函数，分别返回`Vector2d`、`Vector3d`，具体代码如下：\n\n~~~c++\nVector2d EdgeSE3ProjectXYZ::cam_project(const Vector3d & trans_xyz) const{\n  Vector2d proj = project2d(trans_xyz);\n  Vector2d res;\n  res[0] = proj[0]*fx + cx;\n  res[1] = proj[1]*fy + cy;\n  return res;\n}\n~~~\n\n~~~c++\nVector3d EdgeStereoSE3ProjectXYZ::cam_project(const Vector3d & trans_xyz, const float &bf) const{\n  const float invz = 1.0f/trans_xyz[2];\n  Vector3d res;\n  res[0] = trans_xyz[0]*invz*fx + cx;\n  res[1] = trans_xyz[1]*invz*fy + cy;\n  res[2] = res[0] - bf*invz;\n  return res;\n}\n~~~\n\n`res[0]`、` res[1]` 是$u_L$、$v_L$，`res[2]` 是$u_R=u_L-\\frac{bf}{d}$。\n\n## 延伸思考\n\n正如在[源码分析二-初始化](http://ttshun.com/2018/08/16/ORB-SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C-%E5%88%9D%E5%A7%8B%E5%8C%96/)中所述，SLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成图像帧，为图像帧的各种信息赋值（使用原始图像进行ORB特征提取在这个过程中完成），之后原始图像就被丢弃，之后的处理过程和原始图像没有关系了。创建图像帧之后进行初始化，再之后的处理过程，除了优化过程（`Optimizer::PoseOptimization`）外，不再区分单目、双目模式**（真是这样吗？？？？）**。\n\n## 参考资料\n\n1. [ORB-SLAM六MapPoint与Map](https://www.cnblogs.com/shang-slam/p/6420575.html)\n2. [ORB-SLAM的RGBD为什么要分Mono和Stereo?](https://www.zhihu.com/question/280964049/answer/418426500)","slug":"ORB-SLAM2学习之源码分析五-一个变量引发的探索","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuj0010qlcrwdy845p3","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录<code>KeyFrame::mvuRight</code>有关的内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"问题的引出\"><a href=\"#问题的引出\" class=\"headerlink\" title=\"问题的引出\"></a>问题的引出</h2><div><div class=\"fold_hider\"><div class=\"close hider_title\">+点击查看</div></div><div class=\"fold\">\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> MapPoint::AddObservation(KeyFrame* pKF, <span class=\"keyword\">size_t</span> idx)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    unique_lock&lt;mutex&gt; lock(mMutexFeatures);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(mObservations.count(pKF))<span class=\"comment\">//count是map映射，使用key查找元素</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    mObservations[pKF]=idx;<span class=\"comment\">//idx是当前地图点在该pKF中对应的关键点的编号</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(pKF-&gt;mvuRight[idx]&gt;=<span class=\"number\">0</span>)<span class=\"comment\">//mvuRight？？</span></span><br><span class=\"line\">        nObs+=<span class=\"number\">2</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        nObs++;<span class=\"comment\">//观测到该地图点的关键帧数目</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</div></div>\n<p>在阅读<code>MapPoint::AddObservation</code>函数时，注意到<code>mvuRight</code>这个变量，程序中通过判断其值对<code>nObs</code>变量进行相关操作。一直没搞明白它的意思。终于在<a href=\"https://www.zhihu.com/question/280964049/answer/418426500\" target=\"_blank\" rel=\"noopener\">知乎这个问题</a>找到了答案。这里稍微整理一下内容，并记录下自己由此理解的一些东西。</p>\n<p>在构造关键帧时，地图点和关键帧之间的观测关系是很重要的一个点，参考关键帧是哪一帧，该地图点被哪些关键帧观测到，对应的哪些（<code>idx</code>）特征点，都是通过一下两个成员变量维护：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//观测到该地图点的关键帧集合</span></span><br><span class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">map</span>&lt;KeyFrame*,<span class=\"keyword\">size_t</span>&gt; mObservations;</span><br><span class=\"line\"><span class=\"comment\">// 观测到该地图点的关键帧数</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> nObs;</span><br></pre></td></tr></table></figure>\n<p>通过<code>MapPoint::AddObservation()</code>函数添加地图点观测，即将能够观测到同一个地图点的关键帧（它们之间存在共视关系）加入到该地图点的<code>mObservations</code>集合中。函数中对于<code>mvuRight</code>的使用其实是RGB-D和双目模式使用到的”双目信息“之一。</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>首先需要知道的是，RGBD虽然具有深度信息，但是深度图和RGB图不是完全匹配，其中还是有无深度值的区域，中间也存在空洞。在ORB_SLAM优化过程中，无深度信息的特征点是一条射线，就视作Mono模式一同处理；有深度信息的特征点，视作与Stereo模式一同处理。</p>\n<p>具体说来，为了让RGB-D模式与Mono和Stereo模式保持一致，在创建图像帧时，会调用<code>Frame::ComputeStereoFromRGBD</code>函数，如果有深度就设置<code>mvuRight</code>和<code>mvDepth</code>的对应值，下面一行代码就是设置<strong>虚拟右图像</strong>上的 u 坐标值，即<code>mvuRight</code>。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvuRight[i] = kpU.pt.x-mbf/d;</span><br></pre></td></tr></table></figure>\n<p>对应公式：</p>\n<p>$u_R=u_L-\\frac{bf}{d}$</p>\n<p>其中$f$是$u$方向上的焦距（即$f_x$），$d$是左图像上的深度，$b$是左右图像基线，$\\frac{bf}{d}$是视差（disparity）。</p>\n<p>生成 Frame 之后就是调用 <code>Tracking::Track()</code>函数，通过特征匹配和局部地图追踪进行初步位姿估计。首先，初始化 <code>Tracking::StereoInitialization()</code>只会使用那些有深度的 Stereo 点。初始化完成之后，不论是 <code>Tracking::TrackWithMotionModel()</code>与上一普通帧匹配，还是 <code>Tracking::TrackReferenceKeyFrame()</code>与上一关键帧匹配，或是<code>Tracking::Relocalization()</code>与窗口中所有的关键帧匹配，或者<code>Tracking::TrackLocalMap</code>局部地图追踪，都会调用函数 <code>Optimizer::PoseOptimization()</code>函数，进行优化。此函数中，对于Mono模式会使用<code>g2o::EdgeSE3ProjectXYZOnlyPose</code>，对于Stereo模式会使用<code>g2o::EdgeStereoSE3ProjectXYZOnlyPose</code>，具体的代码部分如下。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> Optimizer::PoseOptimization(Frame *pFrame)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;N; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        MapPoint* pMP = pFrame-&gt;mvpMapPoints[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pMP)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">// Monocular observation  单目模式观测到的地图点</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pFrame-&gt;mvuRight[i]&lt;<span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \t<span class=\"comment\">//...</span></span><br><span class=\"line\">                g2o::EdgeSE3ProjectXYZOnlyPose* e = <span class=\"keyword\">new</span> g2o::EdgeSE3ProjectXYZOnlyPose();</span><br><span class=\"line\">                <span class=\"comment\">//...</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span>  <span class=\"comment\">// Stereo observation  双目观测到的地图点</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"comment\">//...</span></span><br><span class=\"line\">                g2o::EdgeStereoSE3ProjectXYZOnlyPose* e = <span class=\"keyword\">new</span> g2o::EdgeStereoSE3ProjectXYZOnlyPose();</span><br><span class=\"line\">                <span class=\"comment\">//...</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述两个函数中有<code>computeError()</code>函数，分别返回<code>Vector2d</code>、<code>Vector3d</code>，具体代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Vector2d EdgeSE3ProjectXYZ::cam_project(<span class=\"keyword\">const</span> Vector3d &amp; trans_xyz) <span class=\"keyword\">const</span>&#123;</span><br><span class=\"line\">  Vector2d proj = project2d(trans_xyz);</span><br><span class=\"line\">  Vector2d res;</span><br><span class=\"line\">  res[<span class=\"number\">0</span>] = proj[<span class=\"number\">0</span>]*fx + cx;</span><br><span class=\"line\">  res[<span class=\"number\">1</span>] = proj[<span class=\"number\">1</span>]*fy + cy;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Vector3d EdgeStereoSE3ProjectXYZ::cam_project(<span class=\"keyword\">const</span> Vector3d &amp; trans_xyz, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> &amp;bf) <span class=\"keyword\">const</span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> invz = <span class=\"number\">1.0f</span>/trans_xyz[<span class=\"number\">2</span>];</span><br><span class=\"line\">  Vector3d res;</span><br><span class=\"line\">  res[<span class=\"number\">0</span>] = trans_xyz[<span class=\"number\">0</span>]*invz*fx + cx;</span><br><span class=\"line\">  res[<span class=\"number\">1</span>] = trans_xyz[<span class=\"number\">1</span>]*invz*fy + cy;</span><br><span class=\"line\">  res[<span class=\"number\">2</span>] = res[<span class=\"number\">0</span>] - bf*invz;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>res[0]</code>、<code>res[1]</code> 是$u_L$、$v_L$，<code>res[2]</code> 是$u_R=u_L-\\frac{bf}{d}$。</p>\n<h2 id=\"延伸思考\"><a href=\"#延伸思考\" class=\"headerlink\" title=\"延伸思考\"></a>延伸思考</h2><p>正如在<a href=\"http://ttshun.com/2018/08/16/ORB-SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C-%E5%88%9D%E5%A7%8B%E5%8C%96/\">源码分析二-初始化</a>中所述，SLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成图像帧，为图像帧的各种信息赋值（使用原始图像进行ORB特征提取在这个过程中完成），之后原始图像就被丢弃，之后的处理过程和原始图像没有关系了。创建图像帧之后进行初始化，再之后的处理过程，除了优化过程（<code>Optimizer::PoseOptimization</code>）外，不再区分单目、双目模式<strong>（真是这样吗？？？？）</strong>。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6420575.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM六MapPoint与Map</a></li>\n<li><a href=\"https://www.zhihu.com/question/280964049/answer/418426500\" target=\"_blank\" rel=\"noopener\">ORB-SLAM的RGBD为什么要分Mono和Stereo?</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录<code>KeyFrame::mvuRight</code>有关的内容。</p>","more":"<h2 id=\"问题的引出\"><a href=\"#问题的引出\" class=\"headerlink\" title=\"问题的引出\"></a>问题的引出</h2><div><div class=\"fold_hider\"><div class=\"close hider_title\">+点击查看</div></div><div class=\"fold\">\n<!--�24-->\n\n</div></div>\n<p>在阅读<code>MapPoint::AddObservation</code>函数时，注意到<code>mvuRight</code>这个变量，程序中通过判断其值对<code>nObs</code>变量进行相关操作。一直没搞明白它的意思。终于在<a href=\"https://www.zhihu.com/question/280964049/answer/418426500\" target=\"_blank\" rel=\"noopener\">知乎这个问题</a>找到了答案。这里稍微整理一下内容，并记录下自己由此理解的一些东西。</p>\n<p>在构造关键帧时，地图点和关键帧之间的观测关系是很重要的一个点，参考关键帧是哪一帧，该地图点被哪些关键帧观测到，对应的哪些（<code>idx</code>）特征点，都是通过一下两个成员变量维护：</p>\n<!--�25-->\n<p>通过<code>MapPoint::AddObservation()</code>函数添加地图点观测，即将能够观测到同一个地图点的关键帧（它们之间存在共视关系）加入到该地图点的<code>mObservations</code>集合中。函数中对于<code>mvuRight</code>的使用其实是RGB-D和双目模式使用到的”双目信息“之一。</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>首先需要知道的是，RGBD虽然具有深度信息，但是深度图和RGB图不是完全匹配，其中还是有无深度值的区域，中间也存在空洞。在ORB_SLAM优化过程中，无深度信息的特征点是一条射线，就视作Mono模式一同处理；有深度信息的特征点，视作与Stereo模式一同处理。</p>\n<p>具体说来，为了让RGB-D模式与Mono和Stereo模式保持一致，在创建图像帧时，会调用<code>Frame::ComputeStereoFromRGBD</code>函数，如果有深度就设置<code>mvuRight</code>和<code>mvDepth</code>的对应值，下面一行代码就是设置<strong>虚拟右图像</strong>上的 u 坐标值，即<code>mvuRight</code>。</p>\n<!--�26-->\n<p>对应公式：</p>\n<p>$u_R=u_L-\\frac{bf}{d}$</p>\n<p>其中$f$是$u$方向上的焦距（即$f_x$），$d$是左图像上的深度，$b$是左右图像基线，$\\frac{bf}{d}$是视差（disparity）。</p>\n<p>生成 Frame 之后就是调用 <code>Tracking::Track()</code>函数，通过特征匹配和局部地图追踪进行初步位姿估计。首先，初始化 <code>Tracking::StereoInitialization()</code>只会使用那些有深度的 Stereo 点。初始化完成之后，不论是 <code>Tracking::TrackWithMotionModel()</code>与上一普通帧匹配，还是 <code>Tracking::TrackReferenceKeyFrame()</code>与上一关键帧匹配，或是<code>Tracking::Relocalization()</code>与窗口中所有的关键帧匹配，或者<code>Tracking::TrackLocalMap</code>局部地图追踪，都会调用函数 <code>Optimizer::PoseOptimization()</code>函数，进行优化。此函数中，对于Mono模式会使用<code>g2o::EdgeSE3ProjectXYZOnlyPose</code>，对于Stereo模式会使用<code>g2o::EdgeStereoSE3ProjectXYZOnlyPose</code>，具体的代码部分如下。</p>\n<!--�27-->\n<p>上述两个函数中有<code>computeError()</code>函数，分别返回<code>Vector2d</code>、<code>Vector3d</code>，具体代码如下：</p>\n<!--�28-->\n<!--�29-->\n<p><code>res[0]</code>、<code>res[1]</code> 是$u_L$、$v_L$，<code>res[2]</code> 是$u_R=u_L-\\frac{bf}{d}$。</p>\n<h2 id=\"延伸思考\"><a href=\"#延伸思考\" class=\"headerlink\" title=\"延伸思考\"></a>延伸思考</h2><p>正如在<a href=\"http://ttshun.com/2018/08/16/ORB-SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C-%E5%88%9D%E5%A7%8B%E5%8C%96/\">源码分析二-初始化</a>中所述，SLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成图像帧，为图像帧的各种信息赋值（使用原始图像进行ORB特征提取在这个过程中完成），之后原始图像就被丢弃，之后的处理过程和原始图像没有关系了。创建图像帧之后进行初始化，再之后的处理过程，除了优化过程（<code>Optimizer::PoseOptimization</code>）外，不再区分单目、双目模式<strong>（真是这样吗？？？？）</strong>。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6420575.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM六MapPoint与Map</a></li>\n<li><a href=\"https://www.zhihu.com/question/280964049/answer/418426500\" target=\"_blank\" rel=\"noopener\">ORB-SLAM的RGBD为什么要分Mono和Stereo?</a></li>\n</ol>"},{"title":"ORB_SLAM2学习之源码分析六-LocalMapping","date":"2018-08-22T00:38:10.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalMapping模块部分。\n\n<!--more--->\n\n## 概述\n\nLocalMapping模块作用是将Tracking中送来的关键帧放在`mlNewKeyFrame`列表中；处理新关键帧、地图点检查剔除、生成新地图点、Local BA、关键帧剔除。主要工作在于维护地图，也就是SLAM中的`Map`。\n\n前面的记录中提到，Tracking模块会将满足一定条件的图像帧加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度。同时LocalMapping线程会对关键帧进行剔除，确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。Tracking模块会判断是否需要将当前帧创建为关键帧，对地图中的关键帧、地图点具体的处理，包括如何加入、如何删除的工作是在LocalMapping线程完成的。论文中的图：\n\n{% asset_img slam框架.png %}\n\n## 具体操作\n\n{% asset_img LocalMapping.png %}\n\n### 处理新关键帧\n\n对应`LocalMapping::ProcessNewKeyFrame()`函数。处理新关键帧与局部地图点之间的关系。具体步骤如下：\n\n1. **获取关键帧。**从`mlNewKeyFrame`队列（待插入的关键帧）中弹出队首的关键帧做为当前帧，并计算该关键帧的BoW，后面三角化恢复地图点有用；\n2. **获取关键帧中与关键点关联的地图点。**将TrackLocalMap中跟踪局部地图匹配上的地图点关联到当前关键帧（在Tracking线程中只是利用关键点的匹配关系进行位姿计算，优化当前关键帧姿态）。具体来说，可以分两种情况，地图点没有关联到关键帧，则完成关联（`AddObservation`），更新地图点normal和描述子，这种地图点是在追踪过程创建并被关键帧关联的，它们在`UpdateLastFrame`过程就已经有了空间位置；否则记录该地图点为最新添加（这些地图点是在创建关键帧时创建的，已经关联到关键帧），加入`mlpRecentAddedMapPoints`；\n3. **更新共视图连接关系。**使用`UpdateConnections`函数更新加入当前关键帧之后关键帧之间的连接关系，包括更新Covisibility图和Essential图（最小生成树spanning tree）；\n4. **关键帧插入地图。**\n\n### 地图点剔除\n\n对应`LocalMapping::MapPointCulling()`函数。任务是对上一函数获取到的最新加入的局部地图点`mlpRecentAddedMapPoints`进行检查，每个地图点要被保留，在该地图点被创建后的三个关键帧里必须要经过严格的测试，这样保证其能被正确的跟踪和三角化。满足如下条件之一就被剔除：\n\n1. 该地图点是坏点，直接从检查列表去掉；\n2. 跟踪（匹配上）到该地图点的普通帧帧数（IncreaseFound）<应该观测到该地图点的普通帧数量（25%*IncreaseVisible），即比值mnFound/mnVisible<0.25，设置为坏点，并从检查列表去掉。比值低说明这样的地图点该地图点虽在视野范围内，但很少被普通帧检测到；\n3. 从添加该地图点的关键帧算起，当前关键帧至少是第三个添加该地图点的关键帧的条件下，看到该地图点的帧数<=2（双目和RGBD模式是帧数<=3），设置为坏点，并从检查列表去掉；因此在地图点刚建立的阶段，要求比较严格，很容易被剔除；而且单目的要求更严格，需要三帧都看到；\n4. 若从添加该地图点的关键帧算起，一共有了大于三个关键帧，还存在列表中，则说明该地图点是高质量的，从检查列表中去掉。\n\n一旦经过了这样比较严格的筛选，地图点只有在观测到它的关键帧<3时才会被剔除，这主要发生在关键帧被剔除（90%以上匹配点可以被其他帧检测到）；或者局部捆集优化时，将地图点归为外点从观测中剔除了的情况。因此地图点中的外点是比较少的，所以整套ORB-SLAM中除了重定位和闭环很少去使用RANSAC。\n\nORB-SLAM中关键帧和地图点的加入和删除秉承的是送入严出的标准，因此在提高了定位建图准确性的前提下又很好地限制了计算量，可以用于large scale的场景。 \n\n### 生成新地图点（三角化方法）\n\n对应`LocalMapping::CreateNewMapPoints()`函数。任务是根据当前关键帧恢复出一些新的地图点，不包括和当前关键帧匹配的局部地图点（已经在ProcessNewKeyFrame中处理，单目模式除了初始化过程会生成地图点外，其它地图点都在这里生成）。具体步骤如下：\n\n1. 找出与当前帧有共视关系的10个（单目模式是20个）关键帧，准备使用对极约束搜索匹配并进行三角化，循环进行以下操作，注意是在当前帧和每一帧共视关键帧之间进行；\n2. 检测基线是否过短；\n3. 计算基础矩阵F；\n4. 搜索满足对极约束的匹配；\n5. 通过各种条件判断是不是要三角化这些地图点；\n6. 完成对匹配结果的三角化，创建新的地图点；\n7. 为新的地图点进行一系列配置。\n\n跟论文里面提到的一样。1、三角化的地图点在两帧都有正深度。2、视差、在每个帧的投影误差、尺度一致性都有被检测。三角化过程还要再深入学习。\n\n### 临近关键帧搜索更多匹配\n\n对应`LocalMapping::SearchInNeighbors()`函数。如果关键帧队列中还有新的关键帧，则进行该操作，即在临近的关键帧中搜索到更多的匹配，更新并融合当前关键帧以及两级相连（共视关键帧及其共视关键帧）的关键帧的地图点。\n\n### Local Bundle Adjustment\n\n对应`Optimizer::LocalBundleAdjustment()`函数。这里优化的是当前帧，以及与当前帧在covisibility graph里面有连接关系的那些关键帧的位姿，以及这些帧看到的地图点，其实就是对局部地图进行优化。详细分析参见优化部分博客。\n\n### 冗余关键帧剔除\n\n对应`LocalMapping::KeyFrameCulling()`函数。候选的pKF是LocalMapping中当前处理的关键帧的共视关键帧，不包括第一帧关键帧与当前关键帧。如果一个关键帧检测到的90%的地图点，在其他不少于三个具有相同或更精确尺度的关键帧里面都被检测到，就认定该关键帧冗余（该关键帧的存在提供的地图点观测信息有限），并剔除。\n\n## 参考资料\n\n1. [ORB_SLAM(九) LocalMapping](https://www.cnblogs.com/shang-slam/p/6435124.html)\n2. [ORB_SLAM2学习6 LocalMapping](https://www.cnblogs.com/panda1/p/6986758.html)","source":"_posts/ORB-SLAM2学习之源码分析六-LocalMapping.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析六-LocalMapping\ndate: 2018-08-22 08:38:10\ntags: \n  - ORB_SLAM2\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalMapping模块部分。\n\n<!--more--->\n\n## 概述\n\nLocalMapping模块作用是将Tracking中送来的关键帧放在`mlNewKeyFrame`列表中；处理新关键帧、地图点检查剔除、生成新地图点、Local BA、关键帧剔除。主要工作在于维护地图，也就是SLAM中的`Map`。\n\n前面的记录中提到，Tracking模块会将满足一定条件的图像帧加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度。同时LocalMapping线程会对关键帧进行剔除，确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。Tracking模块会判断是否需要将当前帧创建为关键帧，对地图中的关键帧、地图点具体的处理，包括如何加入、如何删除的工作是在LocalMapping线程完成的。论文中的图：\n\n{% asset_img slam框架.png %}\n\n## 具体操作\n\n{% asset_img LocalMapping.png %}\n\n### 处理新关键帧\n\n对应`LocalMapping::ProcessNewKeyFrame()`函数。处理新关键帧与局部地图点之间的关系。具体步骤如下：\n\n1. **获取关键帧。**从`mlNewKeyFrame`队列（待插入的关键帧）中弹出队首的关键帧做为当前帧，并计算该关键帧的BoW，后面三角化恢复地图点有用；\n2. **获取关键帧中与关键点关联的地图点。**将TrackLocalMap中跟踪局部地图匹配上的地图点关联到当前关键帧（在Tracking线程中只是利用关键点的匹配关系进行位姿计算，优化当前关键帧姿态）。具体来说，可以分两种情况，地图点没有关联到关键帧，则完成关联（`AddObservation`），更新地图点normal和描述子，这种地图点是在追踪过程创建并被关键帧关联的，它们在`UpdateLastFrame`过程就已经有了空间位置；否则记录该地图点为最新添加（这些地图点是在创建关键帧时创建的，已经关联到关键帧），加入`mlpRecentAddedMapPoints`；\n3. **更新共视图连接关系。**使用`UpdateConnections`函数更新加入当前关键帧之后关键帧之间的连接关系，包括更新Covisibility图和Essential图（最小生成树spanning tree）；\n4. **关键帧插入地图。**\n\n### 地图点剔除\n\n对应`LocalMapping::MapPointCulling()`函数。任务是对上一函数获取到的最新加入的局部地图点`mlpRecentAddedMapPoints`进行检查，每个地图点要被保留，在该地图点被创建后的三个关键帧里必须要经过严格的测试，这样保证其能被正确的跟踪和三角化。满足如下条件之一就被剔除：\n\n1. 该地图点是坏点，直接从检查列表去掉；\n2. 跟踪（匹配上）到该地图点的普通帧帧数（IncreaseFound）<应该观测到该地图点的普通帧数量（25%*IncreaseVisible），即比值mnFound/mnVisible<0.25，设置为坏点，并从检查列表去掉。比值低说明这样的地图点该地图点虽在视野范围内，但很少被普通帧检测到；\n3. 从添加该地图点的关键帧算起，当前关键帧至少是第三个添加该地图点的关键帧的条件下，看到该地图点的帧数<=2（双目和RGBD模式是帧数<=3），设置为坏点，并从检查列表去掉；因此在地图点刚建立的阶段，要求比较严格，很容易被剔除；而且单目的要求更严格，需要三帧都看到；\n4. 若从添加该地图点的关键帧算起，一共有了大于三个关键帧，还存在列表中，则说明该地图点是高质量的，从检查列表中去掉。\n\n一旦经过了这样比较严格的筛选，地图点只有在观测到它的关键帧<3时才会被剔除，这主要发生在关键帧被剔除（90%以上匹配点可以被其他帧检测到）；或者局部捆集优化时，将地图点归为外点从观测中剔除了的情况。因此地图点中的外点是比较少的，所以整套ORB-SLAM中除了重定位和闭环很少去使用RANSAC。\n\nORB-SLAM中关键帧和地图点的加入和删除秉承的是送入严出的标准，因此在提高了定位建图准确性的前提下又很好地限制了计算量，可以用于large scale的场景。 \n\n### 生成新地图点（三角化方法）\n\n对应`LocalMapping::CreateNewMapPoints()`函数。任务是根据当前关键帧恢复出一些新的地图点，不包括和当前关键帧匹配的局部地图点（已经在ProcessNewKeyFrame中处理，单目模式除了初始化过程会生成地图点外，其它地图点都在这里生成）。具体步骤如下：\n\n1. 找出与当前帧有共视关系的10个（单目模式是20个）关键帧，准备使用对极约束搜索匹配并进行三角化，循环进行以下操作，注意是在当前帧和每一帧共视关键帧之间进行；\n2. 检测基线是否过短；\n3. 计算基础矩阵F；\n4. 搜索满足对极约束的匹配；\n5. 通过各种条件判断是不是要三角化这些地图点；\n6. 完成对匹配结果的三角化，创建新的地图点；\n7. 为新的地图点进行一系列配置。\n\n跟论文里面提到的一样。1、三角化的地图点在两帧都有正深度。2、视差、在每个帧的投影误差、尺度一致性都有被检测。三角化过程还要再深入学习。\n\n### 临近关键帧搜索更多匹配\n\n对应`LocalMapping::SearchInNeighbors()`函数。如果关键帧队列中还有新的关键帧，则进行该操作，即在临近的关键帧中搜索到更多的匹配，更新并融合当前关键帧以及两级相连（共视关键帧及其共视关键帧）的关键帧的地图点。\n\n### Local Bundle Adjustment\n\n对应`Optimizer::LocalBundleAdjustment()`函数。这里优化的是当前帧，以及与当前帧在covisibility graph里面有连接关系的那些关键帧的位姿，以及这些帧看到的地图点，其实就是对局部地图进行优化。详细分析参见优化部分博客。\n\n### 冗余关键帧剔除\n\n对应`LocalMapping::KeyFrameCulling()`函数。候选的pKF是LocalMapping中当前处理的关键帧的共视关键帧，不包括第一帧关键帧与当前关键帧。如果一个关键帧检测到的90%的地图点，在其他不少于三个具有相同或更精确尺度的关键帧里面都被检测到，就认定该关键帧冗余（该关键帧的存在提供的地图点观测信息有限），并剔除。\n\n## 参考资料\n\n1. [ORB_SLAM(九) LocalMapping](https://www.cnblogs.com/shang-slam/p/6435124.html)\n2. [ORB_SLAM2学习6 LocalMapping](https://www.cnblogs.com/panda1/p/6986758.html)","slug":"ORB-SLAM2学习之源码分析六-LocalMapping","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbul0014qlcrzqzz4r0g","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalMapping模块部分。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>LocalMapping模块作用是将Tracking中送来的关键帧放在<code>mlNewKeyFrame</code>列表中；处理新关键帧、地图点检查剔除、生成新地图点、Local BA、关键帧剔除。主要工作在于维护地图，也就是SLAM中的<code>Map</code>。</p>\n<p>前面的记录中提到，Tracking模块会将满足一定条件的图像帧加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度。同时LocalMapping线程会对关键帧进行剔除，确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。Tracking模块会判断是否需要将当前帧创建为关键帧，对地图中的关键帧、地图点具体的处理，包括如何加入、如何删除的工作是在LocalMapping线程完成的。论文中的图：</p>\n<img src=\"/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/slam框架.png\">\n<h2 id=\"具体操作\"><a href=\"#具体操作\" class=\"headerlink\" title=\"具体操作\"></a>具体操作</h2><img src=\"/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/LocalMapping.png\">\n<h3 id=\"处理新关键帧\"><a href=\"#处理新关键帧\" class=\"headerlink\" title=\"处理新关键帧\"></a>处理新关键帧</h3><p>对应<code>LocalMapping::ProcessNewKeyFrame()</code>函数。处理新关键帧与局部地图点之间的关系。具体步骤如下：</p>\n<ol>\n<li><strong>获取关键帧。</strong>从<code>mlNewKeyFrame</code>队列（待插入的关键帧）中弹出队首的关键帧做为当前帧，并计算该关键帧的BoW，后面三角化恢复地图点有用；</li>\n<li><strong>获取关键帧中与关键点关联的地图点。</strong>将TrackLocalMap中跟踪局部地图匹配上的地图点关联到当前关键帧（在Tracking线程中只是利用关键点的匹配关系进行位姿计算，优化当前关键帧姿态）。具体来说，可以分两种情况，地图点没有关联到关键帧，则完成关联（<code>AddObservation</code>），更新地图点normal和描述子，这种地图点是在追踪过程创建并被关键帧关联的，它们在<code>UpdateLastFrame</code>过程就已经有了空间位置；否则记录该地图点为最新添加（这些地图点是在创建关键帧时创建的，已经关联到关键帧），加入<code>mlpRecentAddedMapPoints</code>；</li>\n<li><strong>更新共视图连接关系。</strong>使用<code>UpdateConnections</code>函数更新加入当前关键帧之后关键帧之间的连接关系，包括更新Covisibility图和Essential图（最小生成树spanning tree）；</li>\n<li><strong>关键帧插入地图。</strong></li>\n</ol>\n<h3 id=\"地图点剔除\"><a href=\"#地图点剔除\" class=\"headerlink\" title=\"地图点剔除\"></a>地图点剔除</h3><p>对应<code>LocalMapping::MapPointCulling()</code>函数。任务是对上一函数获取到的最新加入的局部地图点<code>mlpRecentAddedMapPoints</code>进行检查，每个地图点要被保留，在该地图点被创建后的三个关键帧里必须要经过严格的测试，这样保证其能被正确的跟踪和三角化。满足如下条件之一就被剔除：</p>\n<ol>\n<li>该地图点是坏点，直接从检查列表去掉；</li>\n<li>跟踪（匹配上）到该地图点的普通帧帧数（IncreaseFound）&lt;应该观测到该地图点的普通帧数量（25%*IncreaseVisible），即比值mnFound/mnVisible&lt;0.25，设置为坏点，并从检查列表去掉。比值低说明这样的地图点该地图点虽在视野范围内，但很少被普通帧检测到；</li>\n<li>从添加该地图点的关键帧算起，当前关键帧至少是第三个添加该地图点的关键帧的条件下，看到该地图点的帧数&lt;=2（双目和RGBD模式是帧数&lt;=3），设置为坏点，并从检查列表去掉；因此在地图点刚建立的阶段，要求比较严格，很容易被剔除；而且单目的要求更严格，需要三帧都看到；</li>\n<li>若从添加该地图点的关键帧算起，一共有了大于三个关键帧，还存在列表中，则说明该地图点是高质量的，从检查列表中去掉。</li>\n</ol>\n<p>一旦经过了这样比较严格的筛选，地图点只有在观测到它的关键帧&lt;3时才会被剔除，这主要发生在关键帧被剔除（90%以上匹配点可以被其他帧检测到）；或者局部捆集优化时，将地图点归为外点从观测中剔除了的情况。因此地图点中的外点是比较少的，所以整套ORB-SLAM中除了重定位和闭环很少去使用RANSAC。</p>\n<p>ORB-SLAM中关键帧和地图点的加入和删除秉承的是送入严出的标准，因此在提高了定位建图准确性的前提下又很好地限制了计算量，可以用于large scale的场景。 </p>\n<h3 id=\"生成新地图点（三角化方法）\"><a href=\"#生成新地图点（三角化方法）\" class=\"headerlink\" title=\"生成新地图点（三角化方法）\"></a>生成新地图点（三角化方法）</h3><p>对应<code>LocalMapping::CreateNewMapPoints()</code>函数。任务是根据当前关键帧恢复出一些新的地图点，不包括和当前关键帧匹配的局部地图点（已经在ProcessNewKeyFrame中处理，单目模式除了初始化过程会生成地图点外，其它地图点都在这里生成）。具体步骤如下：</p>\n<ol>\n<li>找出与当前帧有共视关系的10个（单目模式是20个）关键帧，准备使用对极约束搜索匹配并进行三角化，循环进行以下操作，注意是在当前帧和每一帧共视关键帧之间进行；</li>\n<li>检测基线是否过短；</li>\n<li>计算基础矩阵F；</li>\n<li>搜索满足对极约束的匹配；</li>\n<li>通过各种条件判断是不是要三角化这些地图点；</li>\n<li>完成对匹配结果的三角化，创建新的地图点；</li>\n<li>为新的地图点进行一系列配置。</li>\n</ol>\n<p>跟论文里面提到的一样。1、三角化的地图点在两帧都有正深度。2、视差、在每个帧的投影误差、尺度一致性都有被检测。三角化过程还要再深入学习。</p>\n<h3 id=\"临近关键帧搜索更多匹配\"><a href=\"#临近关键帧搜索更多匹配\" class=\"headerlink\" title=\"临近关键帧搜索更多匹配\"></a>临近关键帧搜索更多匹配</h3><p>对应<code>LocalMapping::SearchInNeighbors()</code>函数。如果关键帧队列中还有新的关键帧，则进行该操作，即在临近的关键帧中搜索到更多的匹配，更新并融合当前关键帧以及两级相连（共视关键帧及其共视关键帧）的关键帧的地图点。</p>\n<h3 id=\"Local-Bundle-Adjustment\"><a href=\"#Local-Bundle-Adjustment\" class=\"headerlink\" title=\"Local Bundle Adjustment\"></a>Local Bundle Adjustment</h3><p>对应<code>Optimizer::LocalBundleAdjustment()</code>函数。这里优化的是当前帧，以及与当前帧在covisibility graph里面有连接关系的那些关键帧的位姿，以及这些帧看到的地图点，其实就是对局部地图进行优化。详细分析参见优化部分博客。</p>\n<h3 id=\"冗余关键帧剔除\"><a href=\"#冗余关键帧剔除\" class=\"headerlink\" title=\"冗余关键帧剔除\"></a>冗余关键帧剔除</h3><p>对应<code>LocalMapping::KeyFrameCulling()</code>函数。候选的pKF是LocalMapping中当前处理的关键帧的共视关键帧，不包括第一帧关键帧与当前关键帧。如果一个关键帧检测到的90%的地图点，在其他不少于三个具有相同或更精确尺度的关键帧里面都被检测到，就认定该关键帧冗余（该关键帧的存在提供的地图点观测信息有限），并剔除。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6435124.html\" target=\"_blank\" rel=\"noopener\">ORB_SLAM(九) LocalMapping</a></li>\n<li><a href=\"https://www.cnblogs.com/panda1/p/6986758.html\" target=\"_blank\" rel=\"noopener\">ORB_SLAM2学习6 LocalMapping</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录LocalMapping模块部分。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>LocalMapping模块作用是将Tracking中送来的关键帧放在<code>mlNewKeyFrame</code>列表中；处理新关键帧、地图点检查剔除、生成新地图点、Local BA、关键帧剔除。主要工作在于维护地图，也就是SLAM中的<code>Map</code>。</p>\n<p>前面的记录中提到，Tracking模块会将满足一定条件的图像帧加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度。同时LocalMapping线程会对关键帧进行剔除，确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。Tracking模块会判断是否需要将当前帧创建为关键帧，对地图中的关键帧、地图点具体的处理，包括如何加入、如何删除的工作是在LocalMapping线程完成的。论文中的图：</p>\n<img src=\"/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/slam框架.png\">\n<h2 id=\"具体操作\"><a href=\"#具体操作\" class=\"headerlink\" title=\"具体操作\"></a>具体操作</h2><img src=\"/2018/08/22/ORB-SLAM2学习之源码分析六-LocalMapping/LocalMapping.png\">\n<h3 id=\"处理新关键帧\"><a href=\"#处理新关键帧\" class=\"headerlink\" title=\"处理新关键帧\"></a>处理新关键帧</h3><p>对应<code>LocalMapping::ProcessNewKeyFrame()</code>函数。处理新关键帧与局部地图点之间的关系。具体步骤如下：</p>\n<ol>\n<li><strong>获取关键帧。</strong>从<code>mlNewKeyFrame</code>队列（待插入的关键帧）中弹出队首的关键帧做为当前帧，并计算该关键帧的BoW，后面三角化恢复地图点有用；</li>\n<li><strong>获取关键帧中与关键点关联的地图点。</strong>将TrackLocalMap中跟踪局部地图匹配上的地图点关联到当前关键帧（在Tracking线程中只是利用关键点的匹配关系进行位姿计算，优化当前关键帧姿态）。具体来说，可以分两种情况，地图点没有关联到关键帧，则完成关联（<code>AddObservation</code>），更新地图点normal和描述子，这种地图点是在追踪过程创建并被关键帧关联的，它们在<code>UpdateLastFrame</code>过程就已经有了空间位置；否则记录该地图点为最新添加（这些地图点是在创建关键帧时创建的，已经关联到关键帧），加入<code>mlpRecentAddedMapPoints</code>；</li>\n<li><strong>更新共视图连接关系。</strong>使用<code>UpdateConnections</code>函数更新加入当前关键帧之后关键帧之间的连接关系，包括更新Covisibility图和Essential图（最小生成树spanning tree）；</li>\n<li><strong>关键帧插入地图。</strong></li>\n</ol>\n<h3 id=\"地图点剔除\"><a href=\"#地图点剔除\" class=\"headerlink\" title=\"地图点剔除\"></a>地图点剔除</h3><p>对应<code>LocalMapping::MapPointCulling()</code>函数。任务是对上一函数获取到的最新加入的局部地图点<code>mlpRecentAddedMapPoints</code>进行检查，每个地图点要被保留，在该地图点被创建后的三个关键帧里必须要经过严格的测试，这样保证其能被正确的跟踪和三角化。满足如下条件之一就被剔除：</p>\n<ol>\n<li>该地图点是坏点，直接从检查列表去掉；</li>\n<li>跟踪（匹配上）到该地图点的普通帧帧数（IncreaseFound）&lt;应该观测到该地图点的普通帧数量（25%*IncreaseVisible），即比值mnFound/mnVisible&lt;0.25，设置为坏点，并从检查列表去掉。比值低说明这样的地图点该地图点虽在视野范围内，但很少被普通帧检测到；</li>\n<li>从添加该地图点的关键帧算起，当前关键帧至少是第三个添加该地图点的关键帧的条件下，看到该地图点的帧数&lt;=2（双目和RGBD模式是帧数&lt;=3），设置为坏点，并从检查列表去掉；因此在地图点刚建立的阶段，要求比较严格，很容易被剔除；而且单目的要求更严格，需要三帧都看到；</li>\n<li>若从添加该地图点的关键帧算起，一共有了大于三个关键帧，还存在列表中，则说明该地图点是高质量的，从检查列表中去掉。</li>\n</ol>\n<p>一旦经过了这样比较严格的筛选，地图点只有在观测到它的关键帧&lt;3时才会被剔除，这主要发生在关键帧被剔除（90%以上匹配点可以被其他帧检测到）；或者局部捆集优化时，将地图点归为外点从观测中剔除了的情况。因此地图点中的外点是比较少的，所以整套ORB-SLAM中除了重定位和闭环很少去使用RANSAC。</p>\n<p>ORB-SLAM中关键帧和地图点的加入和删除秉承的是送入严出的标准，因此在提高了定位建图准确性的前提下又很好地限制了计算量，可以用于large scale的场景。 </p>\n<h3 id=\"生成新地图点（三角化方法）\"><a href=\"#生成新地图点（三角化方法）\" class=\"headerlink\" title=\"生成新地图点（三角化方法）\"></a>生成新地图点（三角化方法）</h3><p>对应<code>LocalMapping::CreateNewMapPoints()</code>函数。任务是根据当前关键帧恢复出一些新的地图点，不包括和当前关键帧匹配的局部地图点（已经在ProcessNewKeyFrame中处理，单目模式除了初始化过程会生成地图点外，其它地图点都在这里生成）。具体步骤如下：</p>\n<ol>\n<li>找出与当前帧有共视关系的10个（单目模式是20个）关键帧，准备使用对极约束搜索匹配并进行三角化，循环进行以下操作，注意是在当前帧和每一帧共视关键帧之间进行；</li>\n<li>检测基线是否过短；</li>\n<li>计算基础矩阵F；</li>\n<li>搜索满足对极约束的匹配；</li>\n<li>通过各种条件判断是不是要三角化这些地图点；</li>\n<li>完成对匹配结果的三角化，创建新的地图点；</li>\n<li>为新的地图点进行一系列配置。</li>\n</ol>\n<p>跟论文里面提到的一样。1、三角化的地图点在两帧都有正深度。2、视差、在每个帧的投影误差、尺度一致性都有被检测。三角化过程还要再深入学习。</p>\n<h3 id=\"临近关键帧搜索更多匹配\"><a href=\"#临近关键帧搜索更多匹配\" class=\"headerlink\" title=\"临近关键帧搜索更多匹配\"></a>临近关键帧搜索更多匹配</h3><p>对应<code>LocalMapping::SearchInNeighbors()</code>函数。如果关键帧队列中还有新的关键帧，则进行该操作，即在临近的关键帧中搜索到更多的匹配，更新并融合当前关键帧以及两级相连（共视关键帧及其共视关键帧）的关键帧的地图点。</p>\n<h3 id=\"Local-Bundle-Adjustment\"><a href=\"#Local-Bundle-Adjustment\" class=\"headerlink\" title=\"Local Bundle Adjustment\"></a>Local Bundle Adjustment</h3><p>对应<code>Optimizer::LocalBundleAdjustment()</code>函数。这里优化的是当前帧，以及与当前帧在covisibility graph里面有连接关系的那些关键帧的位姿，以及这些帧看到的地图点，其实就是对局部地图进行优化。详细分析参见优化部分博客。</p>\n<h3 id=\"冗余关键帧剔除\"><a href=\"#冗余关键帧剔除\" class=\"headerlink\" title=\"冗余关键帧剔除\"></a>冗余关键帧剔除</h3><p>对应<code>LocalMapping::KeyFrameCulling()</code>函数。候选的pKF是LocalMapping中当前处理的关键帧的共视关键帧，不包括第一帧关键帧与当前关键帧。如果一个关键帧检测到的90%的地图点，在其他不少于三个具有相同或更精确尺度的关键帧里面都被检测到，就认定该关键帧冗余（该关键帧的存在提供的地图点观测信息有限），并剔除。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6435124.html\" target=\"_blank\" rel=\"noopener\">ORB_SLAM(九) LocalMapping</a></li>\n<li><a href=\"https://www.cnblogs.com/panda1/p/6986758.html\" target=\"_blank\" rel=\"noopener\">ORB_SLAM2学习6 LocalMapping</a></li>\n</ol>"},{"title":"ORB_SLAM2系统Rviz可视化方案","date":"2018-10-14T03:14:57.000Z","copyright":true,"_content":"\n---\n\n本篇记录ORB_SLAM2系统嵌入Rviz可视化模块的方案实现。\n\n<!--more--->\n\n## 概述\n\nORB-SLAM的地图和定位可视化是通过Rviz进行展示的，而在ORB-SLAM2中，为了不依赖于ROS，ORB-SLAM2的可视化采用了pangolin库。而我的硕士课题有个需求，就是要使ORB-SLAM2的结果和Cartographer的结果同时显示在同一个可视化工具中，而Cartographer是采用Rviz显示的，还定制了专用的Rviz插件。思考再三，决定为ORB-SLAM2重新添加基于Rviz的可视化模块。\n\n## ORB-SLAM2的Rviz可视化\n\nORB-SLAM中关于Rviz的可视化：\n\n1. ORB-SLAM的Rviz可视化使用单独的一个类来完成可视化信息的发布：MapPublisher类\n2. 所有的可视化信息都是Rviz的Mark类型，根据发布的地图点、关键帧、Covisibility Graph、Spanning Tree和相机轨迹，使用了不同的Mark类型。\n3. 所有的可视化信息，包括地图、轨迹等都是从ORB-SLAM中的Map类中获取的。\n4. 每次获得一帧图像，进行Track后，利用MapPublisher类发布可视化信息。\n5. 在配置相应的Rviz，使其可以接收可视化信息。\n\n明白了这几点之后，在ORB-SLAM2中添加Rviz可视化模块就很简单了，主要对源代码做以下改动：\n\n1. 添加MapPublisher类和配置Rviz，可以直接复用ORB-SLAM中的MapPublisher类和Rviz文件；并在每次Track之后（执行完`mpSLAM->TrackStereo()`）利用MapPublisher类发布可视化信息。\n2. 为Map类添加返回相关信息的接口。\n3. 特别要注意ORB-SLAM2的坐标系下，z轴是朝前的，而Rviz的坐标系下，z轴是朝上的，因此要做相应的转换。\n4. 以上改动可以基于[我的这篇文章](http://ttshun.com/2018/08/12/ORB_SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%BF%90%E8%A1%8CROS%E6%A8%A1%E5%9D%97/)完成。\n\n## ORB_SLAM2中的坐标系\n\nORB_SLAM2中的世界坐标系z轴是朝前的，Rviz坐标系z轴是朝上的，如下图所示。要把ORB_SLAM2中得到的地图（地图点、轨迹、相机、关键帧等）和相机位姿正确显示在Rviz中，需要将数据进行坐标转换。\n\n{% asset_img ORB世界坐标系.png %}\n\n{% asset_img Rviz世界坐标系.png %}\n\n关键帧或相机的显示是以相机坐标系原点为参照，如下图所示，构造了一个四角锥体，以原点为顶点，底面的四个顶点z值大于0。在获取到位姿，将相机或关键帧转换到ORB_SLAM2世界坐标系统之后，再转换到Rviz世界坐标系。\n\n{% asset_img 相机坐标系.png %}\n\n通过以上几个修改，就能在Rviz中显示ORB-SLAM2的地图构建结果和相机位姿了。\n\n## 运行结果\n\n基于之前的内容，修改启动文件如下：\n\n~~~xml\n<launch>\n  <node name=\"stereo_left_kitti\" pkg=\"my_image_transport\" type=\"stereo_left_kitti\">\n  </node>\n  <node name=\"stereo_right_kitti\" pkg=\"my_image_transport\" type=\"stereo_right_kitti\">\n  </node>\n  <node name=\"Stereo_eric\" pkg=\"ORB_SLAM2\" type=\"Stereo_eric\" output=\"screen\">\n  </node>\n  <node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" output=\"log\" args=\"-d $(find ORB_SLAM2)/config/rviz.rviz\" >\n  </node>\n</launch>\n~~~\n\n其中`rviz.rviz`文件使用的ORB_SLAM中的，只需要将line 50修改为：\n\n~~~xml\n    Fixed Frame: ORB_SLAM/World\n~~~\n\n执行命令：`roslaunch my_image_transport stereo_image_transport.launch`\n\n运行结果：\n\n{% asset_img 运行结果.png %}\n\n## 使用PCL库显示地图点\n\n目前我的课题考虑基于ORB_SLAM2生成的点云数据生成二维栅格地图再结合Cartographer的地图，调研后发现可以有两种方案。\n\n- 方案一：使用`pointcloud_to_laserscan`包将点云数据转成模拟激光扫描数据，进而可以作为gmapping的输入数据生成二维栅格地图，然后与Cartographer的地图融合。\n\n- 方案二：使用文章[1]中提出的方法直接将点云数据生成二维栅格地图，融合Cartographer的地图。\n\n### 方案一实施\n\n注意：ORB_SLAM2系统`Map`类中的地图点是世界坐标系中的所有地图点，而不是每个关键\n\nROS`pointcloud_to_laserscan`包`pointcloud_to_laserscan_node`节点将点云`PointCloud`转成2D激光扫描\n\n- 订阅节点：`cloud_in(sensor_msgs/PointCloud2)`\n- 发布节点：`scan(sensor_msg/LaserScan)`\n\n参考[here1](https://www.ncnynl.com/archives/201701/1224.html)和[here2](https://www.cnblogs.com/zxouxuewei/p/5307736.html)配置好ROS程序包，在`MapPulisher`类中稍作修改，参照如下内容：\n\n~~~c++\n#include<ros/ros.h>\n#include<pcl/point_cloud.h>\n#include<pcl_conversions/pcl_conversions.h>\n#include<sensor_msgs/PointCloud2.h>\n\nmain (int argc, char **argv)\n{\n  ros::init (argc, argv, \"pcl_create\");\n  ros::NodeHandle nh;\n  ros::Publisher pcl_pub = nh.advertise<sensor_msgs::PointCloud2> (\"pcl_output\", 1);\n  pcl::PointCloud<pcl::PointXYZ> cloud;\n  sensor_msgs::PointCloud2 output;\n  // Fill in the cloud data\n  cloud.width = 100;\n  cloud.height = 1;\n  cloud.points.resize(cloud.width * cloud.height);\n  for (size_t i = 0; i < cloud.points.size(); ++i)\n  {\n    cloud.points[i].x = 1024 * rand () / (RAND_MAX + 1.0f);\n    cloud.points[i].y = 1024 * rand () / (RAND_MAX + 1.0f);\n    cloud.points[i].z = 1024 * rand () / (RAND_MAX + 1.0f);\n  }\n\n  //Convert the cloud to ROS message\n  pcl::toROSMsg(cloud, output);\n  output.header.frame_id = \"odom\";//this has been done in order to be able to visualize our PointCloud2 message on the RViz visualizer\n  ros::Rate loop_rate(1);\n  while (ros::ok())\n  {\n    pcl_pub.publish(output);\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  return 0;\n}\n~~~\n\n展示效果：\n\n{% asset_img pcl点云显示.png %}\n\n## 参考资料\n\n[1] 2D Grid Mapping and Navigation with ORB SLAM. Abhineet Kumar Singh, Ali Jahani Amiri.\n\n","source":"_posts/ORB-SLAM2系统Rviz可视化方案.md","raw":"---\ntitle: ORB_SLAM2系统Rviz可视化方案\ndate: 2018-10-14 11:14:57\ntags: \n  - ORB_SLAM2\n  - Rviz\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n---\n\n本篇记录ORB_SLAM2系统嵌入Rviz可视化模块的方案实现。\n\n<!--more--->\n\n## 概述\n\nORB-SLAM的地图和定位可视化是通过Rviz进行展示的，而在ORB-SLAM2中，为了不依赖于ROS，ORB-SLAM2的可视化采用了pangolin库。而我的硕士课题有个需求，就是要使ORB-SLAM2的结果和Cartographer的结果同时显示在同一个可视化工具中，而Cartographer是采用Rviz显示的，还定制了专用的Rviz插件。思考再三，决定为ORB-SLAM2重新添加基于Rviz的可视化模块。\n\n## ORB-SLAM2的Rviz可视化\n\nORB-SLAM中关于Rviz的可视化：\n\n1. ORB-SLAM的Rviz可视化使用单独的一个类来完成可视化信息的发布：MapPublisher类\n2. 所有的可视化信息都是Rviz的Mark类型，根据发布的地图点、关键帧、Covisibility Graph、Spanning Tree和相机轨迹，使用了不同的Mark类型。\n3. 所有的可视化信息，包括地图、轨迹等都是从ORB-SLAM中的Map类中获取的。\n4. 每次获得一帧图像，进行Track后，利用MapPublisher类发布可视化信息。\n5. 在配置相应的Rviz，使其可以接收可视化信息。\n\n明白了这几点之后，在ORB-SLAM2中添加Rviz可视化模块就很简单了，主要对源代码做以下改动：\n\n1. 添加MapPublisher类和配置Rviz，可以直接复用ORB-SLAM中的MapPublisher类和Rviz文件；并在每次Track之后（执行完`mpSLAM->TrackStereo()`）利用MapPublisher类发布可视化信息。\n2. 为Map类添加返回相关信息的接口。\n3. 特别要注意ORB-SLAM2的坐标系下，z轴是朝前的，而Rviz的坐标系下，z轴是朝上的，因此要做相应的转换。\n4. 以上改动可以基于[我的这篇文章](http://ttshun.com/2018/08/12/ORB_SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%BF%90%E8%A1%8CROS%E6%A8%A1%E5%9D%97/)完成。\n\n## ORB_SLAM2中的坐标系\n\nORB_SLAM2中的世界坐标系z轴是朝前的，Rviz坐标系z轴是朝上的，如下图所示。要把ORB_SLAM2中得到的地图（地图点、轨迹、相机、关键帧等）和相机位姿正确显示在Rviz中，需要将数据进行坐标转换。\n\n{% asset_img ORB世界坐标系.png %}\n\n{% asset_img Rviz世界坐标系.png %}\n\n关键帧或相机的显示是以相机坐标系原点为参照，如下图所示，构造了一个四角锥体，以原点为顶点，底面的四个顶点z值大于0。在获取到位姿，将相机或关键帧转换到ORB_SLAM2世界坐标系统之后，再转换到Rviz世界坐标系。\n\n{% asset_img 相机坐标系.png %}\n\n通过以上几个修改，就能在Rviz中显示ORB-SLAM2的地图构建结果和相机位姿了。\n\n## 运行结果\n\n基于之前的内容，修改启动文件如下：\n\n~~~xml\n<launch>\n  <node name=\"stereo_left_kitti\" pkg=\"my_image_transport\" type=\"stereo_left_kitti\">\n  </node>\n  <node name=\"stereo_right_kitti\" pkg=\"my_image_transport\" type=\"stereo_right_kitti\">\n  </node>\n  <node name=\"Stereo_eric\" pkg=\"ORB_SLAM2\" type=\"Stereo_eric\" output=\"screen\">\n  </node>\n  <node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" output=\"log\" args=\"-d $(find ORB_SLAM2)/config/rviz.rviz\" >\n  </node>\n</launch>\n~~~\n\n其中`rviz.rviz`文件使用的ORB_SLAM中的，只需要将line 50修改为：\n\n~~~xml\n    Fixed Frame: ORB_SLAM/World\n~~~\n\n执行命令：`roslaunch my_image_transport stereo_image_transport.launch`\n\n运行结果：\n\n{% asset_img 运行结果.png %}\n\n## 使用PCL库显示地图点\n\n目前我的课题考虑基于ORB_SLAM2生成的点云数据生成二维栅格地图再结合Cartographer的地图，调研后发现可以有两种方案。\n\n- 方案一：使用`pointcloud_to_laserscan`包将点云数据转成模拟激光扫描数据，进而可以作为gmapping的输入数据生成二维栅格地图，然后与Cartographer的地图融合。\n\n- 方案二：使用文章[1]中提出的方法直接将点云数据生成二维栅格地图，融合Cartographer的地图。\n\n### 方案一实施\n\n注意：ORB_SLAM2系统`Map`类中的地图点是世界坐标系中的所有地图点，而不是每个关键\n\nROS`pointcloud_to_laserscan`包`pointcloud_to_laserscan_node`节点将点云`PointCloud`转成2D激光扫描\n\n- 订阅节点：`cloud_in(sensor_msgs/PointCloud2)`\n- 发布节点：`scan(sensor_msg/LaserScan)`\n\n参考[here1](https://www.ncnynl.com/archives/201701/1224.html)和[here2](https://www.cnblogs.com/zxouxuewei/p/5307736.html)配置好ROS程序包，在`MapPulisher`类中稍作修改，参照如下内容：\n\n~~~c++\n#include<ros/ros.h>\n#include<pcl/point_cloud.h>\n#include<pcl_conversions/pcl_conversions.h>\n#include<sensor_msgs/PointCloud2.h>\n\nmain (int argc, char **argv)\n{\n  ros::init (argc, argv, \"pcl_create\");\n  ros::NodeHandle nh;\n  ros::Publisher pcl_pub = nh.advertise<sensor_msgs::PointCloud2> (\"pcl_output\", 1);\n  pcl::PointCloud<pcl::PointXYZ> cloud;\n  sensor_msgs::PointCloud2 output;\n  // Fill in the cloud data\n  cloud.width = 100;\n  cloud.height = 1;\n  cloud.points.resize(cloud.width * cloud.height);\n  for (size_t i = 0; i < cloud.points.size(); ++i)\n  {\n    cloud.points[i].x = 1024 * rand () / (RAND_MAX + 1.0f);\n    cloud.points[i].y = 1024 * rand () / (RAND_MAX + 1.0f);\n    cloud.points[i].z = 1024 * rand () / (RAND_MAX + 1.0f);\n  }\n\n  //Convert the cloud to ROS message\n  pcl::toROSMsg(cloud, output);\n  output.header.frame_id = \"odom\";//this has been done in order to be able to visualize our PointCloud2 message on the RViz visualizer\n  ros::Rate loop_rate(1);\n  while (ros::ok())\n  {\n    pcl_pub.publish(output);\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  return 0;\n}\n~~~\n\n展示效果：\n\n{% asset_img pcl点云显示.png %}\n\n## 参考资料\n\n[1] 2D Grid Mapping and Navigation with ORB SLAM. Abhineet Kumar Singh, Ali Jahani Amiri.\n\n","slug":"ORB-SLAM2系统Rviz可视化方案","published":1,"updated":"2019-05-30T12:29:26.287Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbun0017qlcra7hg137z","content":"<hr>\n<p>本篇记录ORB_SLAM2系统嵌入Rviz可视化模块的方案实现。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>ORB-SLAM的地图和定位可视化是通过Rviz进行展示的，而在ORB-SLAM2中，为了不依赖于ROS，ORB-SLAM2的可视化采用了pangolin库。而我的硕士课题有个需求，就是要使ORB-SLAM2的结果和Cartographer的结果同时显示在同一个可视化工具中，而Cartographer是采用Rviz显示的，还定制了专用的Rviz插件。思考再三，决定为ORB-SLAM2重新添加基于Rviz的可视化模块。</p>\n<h2 id=\"ORB-SLAM2的Rviz可视化\"><a href=\"#ORB-SLAM2的Rviz可视化\" class=\"headerlink\" title=\"ORB-SLAM2的Rviz可视化\"></a>ORB-SLAM2的Rviz可视化</h2><p>ORB-SLAM中关于Rviz的可视化：</p>\n<ol>\n<li>ORB-SLAM的Rviz可视化使用单独的一个类来完成可视化信息的发布：MapPublisher类</li>\n<li>所有的可视化信息都是Rviz的Mark类型，根据发布的地图点、关键帧、Covisibility Graph、Spanning Tree和相机轨迹，使用了不同的Mark类型。</li>\n<li>所有的可视化信息，包括地图、轨迹等都是从ORB-SLAM中的Map类中获取的。</li>\n<li>每次获得一帧图像，进行Track后，利用MapPublisher类发布可视化信息。</li>\n<li>在配置相应的Rviz，使其可以接收可视化信息。</li>\n</ol>\n<p>明白了这几点之后，在ORB-SLAM2中添加Rviz可视化模块就很简单了，主要对源代码做以下改动：</p>\n<ol>\n<li>添加MapPublisher类和配置Rviz，可以直接复用ORB-SLAM中的MapPublisher类和Rviz文件；并在每次Track之后（执行完<code>mpSLAM-&gt;TrackStereo()</code>）利用MapPublisher类发布可视化信息。</li>\n<li>为Map类添加返回相关信息的接口。</li>\n<li>特别要注意ORB-SLAM2的坐标系下，z轴是朝前的，而Rviz的坐标系下，z轴是朝上的，因此要做相应的转换。</li>\n<li>以上改动可以基于<a href=\"http://ttshun.com/2018/08/12/ORB_SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%BF%90%E8%A1%8CROS%E6%A8%A1%E5%9D%97/\">我的这篇文章</a>完成。</li>\n</ol>\n<h2 id=\"ORB-SLAM2中的坐标系\"><a href=\"#ORB-SLAM2中的坐标系\" class=\"headerlink\" title=\"ORB_SLAM2中的坐标系\"></a>ORB_SLAM2中的坐标系</h2><p>ORB_SLAM2中的世界坐标系z轴是朝前的，Rviz坐标系z轴是朝上的，如下图所示。要把ORB_SLAM2中得到的地图（地图点、轨迹、相机、关键帧等）和相机位姿正确显示在Rviz中，需要将数据进行坐标转换。</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/ORB世界坐标系.png\">\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/Rviz世界坐标系.png\">\n<p>关键帧或相机的显示是以相机坐标系原点为参照，如下图所示，构造了一个四角锥体，以原点为顶点，底面的四个顶点z值大于0。在获取到位姿，将相机或关键帧转换到ORB_SLAM2世界坐标系统之后，再转换到Rviz世界坐标系。</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/相机坐标系.png\">\n<p>通过以上几个修改，就能在Rviz中显示ORB-SLAM2的地图构建结果和相机位姿了。</p>\n<h2 id=\"运行结果\"><a href=\"#运行结果\" class=\"headerlink\" title=\"运行结果\"></a>运行结果</h2><p>基于之前的内容，修改启动文件如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">launch</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"stereo_left_kitti\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"my_image_transport\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"stereo_left_kitti\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"stereo_right_kitti\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"my_image_transport\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"stereo_right_kitti\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"Stereo_eric\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"ORB_SLAM2\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"Stereo_eric\"</span> <span class=\"attr\">output</span>=<span class=\"string\">\"screen\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"rviz\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"rviz\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"rviz\"</span> <span class=\"attr\">output</span>=<span class=\"string\">\"log\"</span> <span class=\"attr\">args</span>=<span class=\"string\">\"-d $(find ORB_SLAM2)/config/rviz.rviz\"</span> &gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">launch</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>其中<code>rviz.rviz</code>文件使用的ORB_SLAM中的，只需要将line 50修改为：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Fixed Frame: ORB_SLAM/World</span><br></pre></td></tr></table></figure>\n<p>执行命令：<code>roslaunch my_image_transport stereo_image_transport.launch</code></p>\n<p>运行结果：</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/运行结果.png\">\n<h2 id=\"使用PCL库显示地图点\"><a href=\"#使用PCL库显示地图点\" class=\"headerlink\" title=\"使用PCL库显示地图点\"></a>使用PCL库显示地图点</h2><p>目前我的课题考虑基于ORB_SLAM2生成的点云数据生成二维栅格地图再结合Cartographer的地图，调研后发现可以有两种方案。</p>\n<ul>\n<li><p>方案一：使用<code>pointcloud_to_laserscan</code>包将点云数据转成模拟激光扫描数据，进而可以作为gmapping的输入数据生成二维栅格地图，然后与Cartographer的地图融合。</p>\n</li>\n<li><p>方案二：使用文章[1]中提出的方法直接将点云数据生成二维栅格地图，融合Cartographer的地图。</p>\n</li>\n</ul>\n<h3 id=\"方案一实施\"><a href=\"#方案一实施\" class=\"headerlink\" title=\"方案一实施\"></a>方案一实施</h3><p>注意：ORB_SLAM2系统<code>Map</code>类中的地图点是世界坐标系中的所有地图点，而不是每个关键</p>\n<p>ROS<code>pointcloud_to_laserscan</code>包<code>pointcloud_to_laserscan_node</code>节点将点云<code>PointCloud</code>转成2D激光扫描</p>\n<ul>\n<li>订阅节点：<code>cloud_in(sensor_msgs/PointCloud2)</code></li>\n<li>发布节点：<code>scan(sensor_msg/LaserScan)</code></li>\n</ul>\n<p>参考<a href=\"https://www.ncnynl.com/archives/201701/1224.html\" target=\"_blank\" rel=\"noopener\">here1</a>和<a href=\"https://www.cnblogs.com/zxouxuewei/p/5307736.html\" target=\"_blank\" rel=\"noopener\">here2</a>配置好ROS程序包，在<code>MapPulisher</code>类中稍作修改，参照如下内容：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;pcl/point_cloud.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;pcl_conversions/pcl_conversions.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;sensor_msgs/PointCloud2.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">main (<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  ros::init (argc, argv, <span class=\"string\">\"pcl_create\"</span>);</span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  ros::Publisher pcl_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt; (<span class=\"string\">\"pcl_output\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">  pcl::PointCloud&lt;pcl::PointXYZ&gt; cloud;</span><br><span class=\"line\">  sensor_msgs::PointCloud2 output;</span><br><span class=\"line\">  <span class=\"comment\">// Fill in the cloud data</span></span><br><span class=\"line\">  cloud.width = <span class=\"number\">100</span>;</span><br><span class=\"line\">  cloud.height = <span class=\"number\">1</span>;</span><br><span class=\"line\">  cloud.points.resize(cloud.width * cloud.height);</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">size_t</span> i = <span class=\"number\">0</span>; i &lt; cloud.points.size(); ++i)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    cloud.points[i].x = <span class=\"number\">1024</span> * rand () / (RAND_MAX + <span class=\"number\">1.0f</span>);</span><br><span class=\"line\">    cloud.points[i].y = <span class=\"number\">1024</span> * rand () / (RAND_MAX + <span class=\"number\">1.0f</span>);</span><br><span class=\"line\">    cloud.points[i].z = <span class=\"number\">1024</span> * rand () / (RAND_MAX + <span class=\"number\">1.0f</span>);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//Convert the cloud to ROS message</span></span><br><span class=\"line\">  pcl::toROSMsg(cloud, output);</span><br><span class=\"line\">  output.header.frame_id = <span class=\"string\">\"odom\"</span>;<span class=\"comment\">//this has been done in order to be able to visualize our PointCloud2 message on the RViz visualizer</span></span><br><span class=\"line\">  ros::<span class=\"function\">Rate <span class=\"title\">loop_rate</span><span class=\"params\">(<span class=\"number\">1</span>)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">while</span> (ros::ok())</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    pcl_pub.publish(output);</span><br><span class=\"line\">    ros::spinOnce();</span><br><span class=\"line\">    loop_rate.sleep();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>展示效果：</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/pcl点云显示.png\">\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1] 2D Grid Mapping and Navigation with ORB SLAM. Abhineet Kumar Singh, Ali Jahani Amiri.</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本篇记录ORB_SLAM2系统嵌入Rviz可视化模块的方案实现。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>ORB-SLAM的地图和定位可视化是通过Rviz进行展示的，而在ORB-SLAM2中，为了不依赖于ROS，ORB-SLAM2的可视化采用了pangolin库。而我的硕士课题有个需求，就是要使ORB-SLAM2的结果和Cartographer的结果同时显示在同一个可视化工具中，而Cartographer是采用Rviz显示的，还定制了专用的Rviz插件。思考再三，决定为ORB-SLAM2重新添加基于Rviz的可视化模块。</p>\n<h2 id=\"ORB-SLAM2的Rviz可视化\"><a href=\"#ORB-SLAM2的Rviz可视化\" class=\"headerlink\" title=\"ORB-SLAM2的Rviz可视化\"></a>ORB-SLAM2的Rviz可视化</h2><p>ORB-SLAM中关于Rviz的可视化：</p>\n<ol>\n<li>ORB-SLAM的Rviz可视化使用单独的一个类来完成可视化信息的发布：MapPublisher类</li>\n<li>所有的可视化信息都是Rviz的Mark类型，根据发布的地图点、关键帧、Covisibility Graph、Spanning Tree和相机轨迹，使用了不同的Mark类型。</li>\n<li>所有的可视化信息，包括地图、轨迹等都是从ORB-SLAM中的Map类中获取的。</li>\n<li>每次获得一帧图像，进行Track后，利用MapPublisher类发布可视化信息。</li>\n<li>在配置相应的Rviz，使其可以接收可视化信息。</li>\n</ol>\n<p>明白了这几点之后，在ORB-SLAM2中添加Rviz可视化模块就很简单了，主要对源代码做以下改动：</p>\n<ol>\n<li>添加MapPublisher类和配置Rviz，可以直接复用ORB-SLAM中的MapPublisher类和Rviz文件；并在每次Track之后（执行完<code>mpSLAM-&gt;TrackStereo()</code>）利用MapPublisher类发布可视化信息。</li>\n<li>为Map类添加返回相关信息的接口。</li>\n<li>特别要注意ORB-SLAM2的坐标系下，z轴是朝前的，而Rviz的坐标系下，z轴是朝上的，因此要做相应的转换。</li>\n<li>以上改动可以基于<a href=\"http://ttshun.com/2018/08/12/ORB_SLAM2%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%BF%90%E8%A1%8CROS%E6%A8%A1%E5%9D%97/\">我的这篇文章</a>完成。</li>\n</ol>\n<h2 id=\"ORB-SLAM2中的坐标系\"><a href=\"#ORB-SLAM2中的坐标系\" class=\"headerlink\" title=\"ORB_SLAM2中的坐标系\"></a>ORB_SLAM2中的坐标系</h2><p>ORB_SLAM2中的世界坐标系z轴是朝前的，Rviz坐标系z轴是朝上的，如下图所示。要把ORB_SLAM2中得到的地图（地图点、轨迹、相机、关键帧等）和相机位姿正确显示在Rviz中，需要将数据进行坐标转换。</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/ORB世界坐标系.png\">\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/Rviz世界坐标系.png\">\n<p>关键帧或相机的显示是以相机坐标系原点为参照，如下图所示，构造了一个四角锥体，以原点为顶点，底面的四个顶点z值大于0。在获取到位姿，将相机或关键帧转换到ORB_SLAM2世界坐标系统之后，再转换到Rviz世界坐标系。</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/相机坐标系.png\">\n<p>通过以上几个修改，就能在Rviz中显示ORB-SLAM2的地图构建结果和相机位姿了。</p>\n<h2 id=\"运行结果\"><a href=\"#运行结果\" class=\"headerlink\" title=\"运行结果\"></a>运行结果</h2><p>基于之前的内容，修改启动文件如下：</p>\n<!--�30-->\n<p>其中<code>rviz.rviz</code>文件使用的ORB_SLAM中的，只需要将line 50修改为：</p>\n<!--�31-->\n<p>执行命令：<code>roslaunch my_image_transport stereo_image_transport.launch</code></p>\n<p>运行结果：</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/运行结果.png\">\n<h2 id=\"使用PCL库显示地图点\"><a href=\"#使用PCL库显示地图点\" class=\"headerlink\" title=\"使用PCL库显示地图点\"></a>使用PCL库显示地图点</h2><p>目前我的课题考虑基于ORB_SLAM2生成的点云数据生成二维栅格地图再结合Cartographer的地图，调研后发现可以有两种方案。</p>\n<ul>\n<li><p>方案一：使用<code>pointcloud_to_laserscan</code>包将点云数据转成模拟激光扫描数据，进而可以作为gmapping的输入数据生成二维栅格地图，然后与Cartographer的地图融合。</p>\n</li>\n<li><p>方案二：使用文章[1]中提出的方法直接将点云数据生成二维栅格地图，融合Cartographer的地图。</p>\n</li>\n</ul>\n<h3 id=\"方案一实施\"><a href=\"#方案一实施\" class=\"headerlink\" title=\"方案一实施\"></a>方案一实施</h3><p>注意：ORB_SLAM2系统<code>Map</code>类中的地图点是世界坐标系中的所有地图点，而不是每个关键</p>\n<p>ROS<code>pointcloud_to_laserscan</code>包<code>pointcloud_to_laserscan_node</code>节点将点云<code>PointCloud</code>转成2D激光扫描</p>\n<ul>\n<li>订阅节点：<code>cloud_in(sensor_msgs/PointCloud2)</code></li>\n<li>发布节点：<code>scan(sensor_msg/LaserScan)</code></li>\n</ul>\n<p>参考<a href=\"https://www.ncnynl.com/archives/201701/1224.html\" target=\"_blank\" rel=\"noopener\">here1</a>和<a href=\"https://www.cnblogs.com/zxouxuewei/p/5307736.html\" target=\"_blank\" rel=\"noopener\">here2</a>配置好ROS程序包，在<code>MapPulisher</code>类中稍作修改，参照如下内容：</p>\n<!--�32-->\n<p>展示效果：</p>\n<img src=\"/2018/10/14/ORB-SLAM2系统Rviz可视化方案/pcl点云显示.png\">\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1] 2D Grid Mapping and Navigation with ORB SLAM. Abhineet Kumar Singh, Ali Jahani Amiri.</p>"},{"title":"ORB_SLAM2学习之源码分析四-ORB特征及其提取","date":"2018-08-19T05:21:54.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征的简单原理和提取有关的内容。\n\n<!--more--->\n\n## ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\n\n一种直观的提取特征的方式就是在不同图像之间辨认角点，确认它们的对应关系，角点就是所谓的特征。但是单纯的角点无法满足需求，为此设计的许多更加稳定的局部图像特征，如著名的SIFT、SURF、ORB，相比于朴素的角点这些人工设计的特征点具备可重复性、可区分性、高效率、本地性等优点。特征点由**关键点（Key-point）**和**描述子（Descriptor）**组成。如当提及SIFT特征时，是指“提取SIFT关键点，计算SIFT描述子”。\n\nORB特征包括Oriented FAST关键点和rBRIEF描述子，是在FAST关键点和BRIEF描述描述子基础上改进而来。\n\n- 改进FAST关键点（它没有描述子）：FAST关键点不具有尺度不变性，ORB特征提取方法中，通过构建高斯金字塔，然后在每一层金字塔图像上检测角点，nlevels幅不同比例的图像提取特征点总和作为这幅图像的oFAST（FAST Keypoint Orientation，改进后的FAST关键点）关键点，来实现尺度不变性；FAST关键点也不具有旋转不变性，ORB特征提出使用[矩（moment）](https://www.cnblogs.com/ronny/p/3985810.html)法（灰度质心法）来确定FAST关键点的方向，即通过矩来计算特征点（该图像块的几何中心）以r为半径范围内的质心（该图像块的灰度质心），特征点坐标到质心形成一个向量作为该关键点的方向。\n- 改进BRIEF描述子：首先进行旋转不变性改进，加入旋转因子得到steered BRIEF；然后改进特征点描述子的相关性（即描述子可区分性，对误匹配率影响较大），得到rBRIEF特征描述子。\n\n## 在SLAM视觉里程计中的应用--特征点法\n\n{% asset_img SLAM视觉里程计.png %}\n\n{% asset_img SLAM视觉里程计特征点法.png %}\n\n## ORB_SLAM中的特征提取\n\nSLAM初始化过程，首先需要创建图像帧，其关键一步就是对图像进行ORB特征提取，调用函数`ExtractORB()`，其内部调用了`ORBextractor`类中的重载操作符`void operator()`，完成特征提取，提取结果被保存在`Frame`类的成员变量`std::vector<cv:KeyPoint> mvKeys`和`cv:Mat mDescriptors`中，即提取出特征的关键点和描述子。操作符重载的函数如下：\n\n~~~c++\nvoid ORBextractor::operator()( InputArray _image, InputArray _mask, vector<KeyPoint>& _keypoints, OutputArray _descriptors)\n{\n    if(_image.empty())\n        return;\n\n    Mat image = _image.getMat();\n    assert(image.type() == CV_8UC1 );\n\n    // Pre-compute the scale pyramid\n    ComputePyramid(image);//计算图像尺度金字塔\n\n    vector < vector<KeyPoint> > allKeypoints;\n    ComputeKeyPointsOctTree(allKeypoints);//提取图像关键点 并保存在八叉树\n    //ComputeKeyPointsOld(allKeypoints);\n\n    Mat descriptors;\n\n    int nkeypoints = 0;\n    for (int level = 0; level < nlevels; ++level)\n        nkeypoints += (int)allKeypoints[level].size();\n    if( nkeypoints == 0 )\n        _descriptors.release();\n    else\n    {\n        _descriptors.create(nkeypoints, 32, CV_8U);\n        descriptors = _descriptors.getMat();\n    }\n\n    _keypoints.clear();\n    _keypoints.reserve(nkeypoints);\n\t//计算每个关键点对应的描述子\n    int offset = 0;\n    for (int level = 0; level < nlevels; ++level)\n    {\n        vector<KeyPoint>& keypoints = allKeypoints[level];\n        int nkeypointsLevel = (int)keypoints.size();\n\n        if(nkeypointsLevel==0)\n            continue;\n\n        // preprocess the resized image 进行高斯模糊，用BORDER_REFLECT_101方法处理边缘\n        Mat workingMat = mvImagePyramid[level].clone();\n        GaussianBlur(workingMat, workingMat, Size(7, 7), 2, 2, BORDER_REFLECT_101);\n\n        // Compute the descriptors 计算描述子\n        Mat desc = descriptors.rowRange(offset, offset + nkeypointsLevel);\n        computeDescriptors(workingMat, keypoints, desc, pattern);\n\n        offset += nkeypointsLevel;\n\n        // Scale keypoint coordinates\n        if (level != 0)\n        {\n            float scale = mvScaleFactor[level]; //getScale(level, firstLevel, scaleFactor);\n            for (vector<KeyPoint>::iterator keypoint = keypoints.begin(),\n                 keypointEnd = keypoints.end(); keypoint != keypointEnd; ++keypoint)\n                keypoint->pt *= scale;\n        }\n        // And add the keypoints to the output\n        _keypoints.insert(_keypoints.end(), keypoints.begin(), keypoints.end());\n    }\n}\n~~~\n\nORB特征提取主要过程\n\n- 构建图像尺度金字塔（构造过程另作详细记录）\n- 提取ORB关键点、生成八叉树并保存关键点\n- 计算每个关键点对应的描述子\n\n提取ORB特征时，每一帧图像共提取1000个特征点，分布在金字塔8层中，层间尺度比例1.2，计算下来金字塔0层大约有217个特征点，7层大约有50个特征点。\n\n同时，为了提取出的特征点能够在图像中分布比较均匀（实际情况中，特征点通常分布得比较集中，这样不利于进行匹配，也不利于精确地求解相机间的位姿从而得到精确的VO轨迹），使用了八叉树（其实是平面上的四叉树）的数据结构来存储提取出的特征点。\n\n这部分内容在`ORBextractor.h`和`ORBextractor.cc`中，代码详细理解可以参考[一起学ORBSLAM2ORB特征点提取](https://blog.csdn.net/qq_30356613/article/details/75231440)这篇文章和参考资料11学习，有时间再详细学习。\n\n## 参考资料（有待详细阅读）\n\n1. [ORB特征提取详解](https://blog.csdn.net/zouzoupaopao229/article/details/52625678)\n2. [ORB特征点检测](http://www.cnblogs.com/ronny/p/4083537.html )（墙裂推荐，作者博客里有很多图像特征检测相关的介绍，包括斑点、角点检测和SIFT特征、SURF特征、BRIEF特征描述子等）\n4. 视觉SLAM十四讲P132-特征点法（推荐，关于特征点的内容比较清晰整洁）\n5. [Fast源码分析](https://blog.csdn.net/zhaocj/article/details/40301561)\n5. [Fast API](http://opencv.jp/opencv-2.2_org/cpp/features2d_feature_detection_and_description.html?highlight=fast#StarDetector)\n6. [ORBextractor特征提取](https://www.cnblogs.com/shang-slam/p/6421940.html)\n7. SIFT：*Distinctive image features from scale-invariant keypoints*\n8. SURF：*Surf: Speededup robust features*\n9. ORB：*Orb: an efficient alternative to sift or surf*\n10. Brief：*Brief: Binary robust independent elementary features*\n\n## 尺度金字塔(Scale pyramid)构建\n\n> 层数(ScaleLevels)：金字塔层数，金字塔中包含的不同尺度的图像层数\n>\n> 尺度因子(ScaleFactor)：金字塔层与层图像之间的尺度参数，缩放比例\n\n`ORBextractor::ComputePyramid`就是根据尺度因子对图像进行缩放处理。\n\n### 供学习参考资料\n\n1. [尺度空间理论](http://www.cnblogs.com/ronny/p/3886013.html)\n2. [OpenCV 图像金字塔](http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/imgproc/pyramids/pyramids.html)\n3. [数字图像处理9--尺度空间](https://blog.csdn.net/samkieth/article/details/50407655)\n\n### ","source":"_posts/ORB-SLAM2学习之源码分析四-ORB特征及其提取.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析四-ORB特征及其提取\ndate: 2018-08-19 13:21:54\ntags: \n  - ORB_SLAM2\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征的简单原理和提取有关的内容。\n\n<!--more--->\n\n## ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\n\n一种直观的提取特征的方式就是在不同图像之间辨认角点，确认它们的对应关系，角点就是所谓的特征。但是单纯的角点无法满足需求，为此设计的许多更加稳定的局部图像特征，如著名的SIFT、SURF、ORB，相比于朴素的角点这些人工设计的特征点具备可重复性、可区分性、高效率、本地性等优点。特征点由**关键点（Key-point）**和**描述子（Descriptor）**组成。如当提及SIFT特征时，是指“提取SIFT关键点，计算SIFT描述子”。\n\nORB特征包括Oriented FAST关键点和rBRIEF描述子，是在FAST关键点和BRIEF描述描述子基础上改进而来。\n\n- 改进FAST关键点（它没有描述子）：FAST关键点不具有尺度不变性，ORB特征提取方法中，通过构建高斯金字塔，然后在每一层金字塔图像上检测角点，nlevels幅不同比例的图像提取特征点总和作为这幅图像的oFAST（FAST Keypoint Orientation，改进后的FAST关键点）关键点，来实现尺度不变性；FAST关键点也不具有旋转不变性，ORB特征提出使用[矩（moment）](https://www.cnblogs.com/ronny/p/3985810.html)法（灰度质心法）来确定FAST关键点的方向，即通过矩来计算特征点（该图像块的几何中心）以r为半径范围内的质心（该图像块的灰度质心），特征点坐标到质心形成一个向量作为该关键点的方向。\n- 改进BRIEF描述子：首先进行旋转不变性改进，加入旋转因子得到steered BRIEF；然后改进特征点描述子的相关性（即描述子可区分性，对误匹配率影响较大），得到rBRIEF特征描述子。\n\n## 在SLAM视觉里程计中的应用--特征点法\n\n{% asset_img SLAM视觉里程计.png %}\n\n{% asset_img SLAM视觉里程计特征点法.png %}\n\n## ORB_SLAM中的特征提取\n\nSLAM初始化过程，首先需要创建图像帧，其关键一步就是对图像进行ORB特征提取，调用函数`ExtractORB()`，其内部调用了`ORBextractor`类中的重载操作符`void operator()`，完成特征提取，提取结果被保存在`Frame`类的成员变量`std::vector<cv:KeyPoint> mvKeys`和`cv:Mat mDescriptors`中，即提取出特征的关键点和描述子。操作符重载的函数如下：\n\n~~~c++\nvoid ORBextractor::operator()( InputArray _image, InputArray _mask, vector<KeyPoint>& _keypoints, OutputArray _descriptors)\n{\n    if(_image.empty())\n        return;\n\n    Mat image = _image.getMat();\n    assert(image.type() == CV_8UC1 );\n\n    // Pre-compute the scale pyramid\n    ComputePyramid(image);//计算图像尺度金字塔\n\n    vector < vector<KeyPoint> > allKeypoints;\n    ComputeKeyPointsOctTree(allKeypoints);//提取图像关键点 并保存在八叉树\n    //ComputeKeyPointsOld(allKeypoints);\n\n    Mat descriptors;\n\n    int nkeypoints = 0;\n    for (int level = 0; level < nlevels; ++level)\n        nkeypoints += (int)allKeypoints[level].size();\n    if( nkeypoints == 0 )\n        _descriptors.release();\n    else\n    {\n        _descriptors.create(nkeypoints, 32, CV_8U);\n        descriptors = _descriptors.getMat();\n    }\n\n    _keypoints.clear();\n    _keypoints.reserve(nkeypoints);\n\t//计算每个关键点对应的描述子\n    int offset = 0;\n    for (int level = 0; level < nlevels; ++level)\n    {\n        vector<KeyPoint>& keypoints = allKeypoints[level];\n        int nkeypointsLevel = (int)keypoints.size();\n\n        if(nkeypointsLevel==0)\n            continue;\n\n        // preprocess the resized image 进行高斯模糊，用BORDER_REFLECT_101方法处理边缘\n        Mat workingMat = mvImagePyramid[level].clone();\n        GaussianBlur(workingMat, workingMat, Size(7, 7), 2, 2, BORDER_REFLECT_101);\n\n        // Compute the descriptors 计算描述子\n        Mat desc = descriptors.rowRange(offset, offset + nkeypointsLevel);\n        computeDescriptors(workingMat, keypoints, desc, pattern);\n\n        offset += nkeypointsLevel;\n\n        // Scale keypoint coordinates\n        if (level != 0)\n        {\n            float scale = mvScaleFactor[level]; //getScale(level, firstLevel, scaleFactor);\n            for (vector<KeyPoint>::iterator keypoint = keypoints.begin(),\n                 keypointEnd = keypoints.end(); keypoint != keypointEnd; ++keypoint)\n                keypoint->pt *= scale;\n        }\n        // And add the keypoints to the output\n        _keypoints.insert(_keypoints.end(), keypoints.begin(), keypoints.end());\n    }\n}\n~~~\n\nORB特征提取主要过程\n\n- 构建图像尺度金字塔（构造过程另作详细记录）\n- 提取ORB关键点、生成八叉树并保存关键点\n- 计算每个关键点对应的描述子\n\n提取ORB特征时，每一帧图像共提取1000个特征点，分布在金字塔8层中，层间尺度比例1.2，计算下来金字塔0层大约有217个特征点，7层大约有50个特征点。\n\n同时，为了提取出的特征点能够在图像中分布比较均匀（实际情况中，特征点通常分布得比较集中，这样不利于进行匹配，也不利于精确地求解相机间的位姿从而得到精确的VO轨迹），使用了八叉树（其实是平面上的四叉树）的数据结构来存储提取出的特征点。\n\n这部分内容在`ORBextractor.h`和`ORBextractor.cc`中，代码详细理解可以参考[一起学ORBSLAM2ORB特征点提取](https://blog.csdn.net/qq_30356613/article/details/75231440)这篇文章和参考资料11学习，有时间再详细学习。\n\n## 参考资料（有待详细阅读）\n\n1. [ORB特征提取详解](https://blog.csdn.net/zouzoupaopao229/article/details/52625678)\n2. [ORB特征点检测](http://www.cnblogs.com/ronny/p/4083537.html )（墙裂推荐，作者博客里有很多图像特征检测相关的介绍，包括斑点、角点检测和SIFT特征、SURF特征、BRIEF特征描述子等）\n4. 视觉SLAM十四讲P132-特征点法（推荐，关于特征点的内容比较清晰整洁）\n5. [Fast源码分析](https://blog.csdn.net/zhaocj/article/details/40301561)\n5. [Fast API](http://opencv.jp/opencv-2.2_org/cpp/features2d_feature_detection_and_description.html?highlight=fast#StarDetector)\n6. [ORBextractor特征提取](https://www.cnblogs.com/shang-slam/p/6421940.html)\n7. SIFT：*Distinctive image features from scale-invariant keypoints*\n8. SURF：*Surf: Speededup robust features*\n9. ORB：*Orb: an efficient alternative to sift or surf*\n10. Brief：*Brief: Binary robust independent elementary features*\n\n## 尺度金字塔(Scale pyramid)构建\n\n> 层数(ScaleLevels)：金字塔层数，金字塔中包含的不同尺度的图像层数\n>\n> 尺度因子(ScaleFactor)：金字塔层与层图像之间的尺度参数，缩放比例\n\n`ORBextractor::ComputePyramid`就是根据尺度因子对图像进行缩放处理。\n\n### 供学习参考资料\n\n1. [尺度空间理论](http://www.cnblogs.com/ronny/p/3886013.html)\n2. [OpenCV 图像金字塔](http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/imgproc/pyramids/pyramids.html)\n3. [数字图像处理9--尺度空间](https://blog.csdn.net/samkieth/article/details/50407655)\n\n### ","slug":"ORB-SLAM2学习之源码分析四-ORB特征及其提取","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbup001bqlcrzgaaxcv6","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征的简单原理和提取有关的内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\"><a href=\"#ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\" class=\"headerlink\" title=\"ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\"></a>ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）</h2><p>一种直观的提取特征的方式就是在不同图像之间辨认角点，确认它们的对应关系，角点就是所谓的特征。但是单纯的角点无法满足需求，为此设计的许多更加稳定的局部图像特征，如著名的SIFT、SURF、ORB，相比于朴素的角点这些人工设计的特征点具备可重复性、可区分性、高效率、本地性等优点。特征点由<strong>关键点（Key-point）</strong>和<strong>描述子（Descriptor）</strong>组成。如当提及SIFT特征时，是指“提取SIFT关键点，计算SIFT描述子”。</p>\n<p>ORB特征包括Oriented FAST关键点和rBRIEF描述子，是在FAST关键点和BRIEF描述描述子基础上改进而来。</p>\n<ul>\n<li>改进FAST关键点（它没有描述子）：FAST关键点不具有尺度不变性，ORB特征提取方法中，通过构建高斯金字塔，然后在每一层金字塔图像上检测角点，nlevels幅不同比例的图像提取特征点总和作为这幅图像的oFAST（FAST Keypoint Orientation，改进后的FAST关键点）关键点，来实现尺度不变性；FAST关键点也不具有旋转不变性，ORB特征提出使用<a href=\"https://www.cnblogs.com/ronny/p/3985810.html\" target=\"_blank\" rel=\"noopener\">矩（moment）</a>法（灰度质心法）来确定FAST关键点的方向，即通过矩来计算特征点（该图像块的几何中心）以r为半径范围内的质心（该图像块的灰度质心），特征点坐标到质心形成一个向量作为该关键点的方向。</li>\n<li>改进BRIEF描述子：首先进行旋转不变性改进，加入旋转因子得到steered BRIEF；然后改进特征点描述子的相关性（即描述子可区分性，对误匹配率影响较大），得到rBRIEF特征描述子。</li>\n</ul>\n<h2 id=\"在SLAM视觉里程计中的应用—特征点法\"><a href=\"#在SLAM视觉里程计中的应用—特征点法\" class=\"headerlink\" title=\"在SLAM视觉里程计中的应用—特征点法\"></a>在SLAM视觉里程计中的应用—特征点法</h2>\n\n<h2 id=\"ORB-SLAM中的特征提取\"><a href=\"#ORB-SLAM中的特征提取\" class=\"headerlink\" title=\"ORB_SLAM中的特征提取\"></a>ORB_SLAM中的特征提取</h2><p>SLAM初始化过程，首先需要创建图像帧，其关键一步就是对图像进行ORB特征提取，调用函数<code>ExtractORB()</code>，其内部调用了<code>ORBextractor</code>类中的重载操作符<code>void operator()</code>，完成特征提取，提取结果被保存在<code>Frame</code>类的成员变量<code>std::vector&lt;cv:KeyPoint&gt; mvKeys</code>和<code>cv:Mat mDescriptors</code>中，即提取出特征的关键点和描述子。操作符重载的函数如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> ORBextractor::<span class=\"keyword\">operator</span>()( InputArray _image, InputArray _mask, <span class=\"built_in\">vector</span>&lt;KeyPoint&gt;&amp; _keypoints, OutputArray _descriptors)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(_image.empty())</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    Mat image = _image.getMat();</span><br><span class=\"line\">    assert(image.type() == CV_8UC1 );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Pre-compute the scale pyramid</span></span><br><span class=\"line\">    ComputePyramid(image);<span class=\"comment\">//计算图像尺度金字塔</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">vector</span> &lt; <span class=\"built_in\">vector</span>&lt;KeyPoint&gt; &gt; allKeypoints;</span><br><span class=\"line\">    ComputeKeyPointsOctTree(allKeypoints);<span class=\"comment\">//提取图像关键点 并保存在八叉树</span></span><br><span class=\"line\">    <span class=\"comment\">//ComputeKeyPointsOld(allKeypoints);</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Mat descriptors;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> nkeypoints = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> level = <span class=\"number\">0</span>; level &lt; nlevels; ++level)</span><br><span class=\"line\">        nkeypoints += (<span class=\"keyword\">int</span>)allKeypoints[level].size();</span><br><span class=\"line\">    <span class=\"keyword\">if</span>( nkeypoints == <span class=\"number\">0</span> )</span><br><span class=\"line\">        _descriptors.release();</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        _descriptors.create(nkeypoints, <span class=\"number\">32</span>, CV_8U);</span><br><span class=\"line\">        descriptors = _descriptors.getMat();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    _keypoints.clear();</span><br><span class=\"line\">    _keypoints.reserve(nkeypoints);</span><br><span class=\"line\">\t<span class=\"comment\">//计算每个关键点对应的描述子</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> offset = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> level = <span class=\"number\">0</span>; level &lt; nlevels; ++level)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;KeyPoint&gt;&amp; keypoints = allKeypoints[level];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> nkeypointsLevel = (<span class=\"keyword\">int</span>)keypoints.size();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(nkeypointsLevel==<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// preprocess the resized image 进行高斯模糊，用BORDER_REFLECT_101方法处理边缘</span></span><br><span class=\"line\">        Mat workingMat = mvImagePyramid[level].clone();</span><br><span class=\"line\">        GaussianBlur(workingMat, workingMat, Size(<span class=\"number\">7</span>, <span class=\"number\">7</span>), <span class=\"number\">2</span>, <span class=\"number\">2</span>, BORDER_REFLECT_101);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// Compute the descriptors 计算描述子</span></span><br><span class=\"line\">        Mat desc = descriptors.rowRange(offset, offset + nkeypointsLevel);</span><br><span class=\"line\">        computeDescriptors(workingMat, keypoints, desc, pattern);</span><br><span class=\"line\"></span><br><span class=\"line\">        offset += nkeypointsLevel;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// Scale keypoint coordinates</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (level != <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">float</span> scale = mvScaleFactor[level]; <span class=\"comment\">//getScale(level, firstLevel, scaleFactor);</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"built_in\">vector</span>&lt;KeyPoint&gt;::iterator keypoint = keypoints.begin(),</span><br><span class=\"line\">                 keypointEnd = keypoints.end(); keypoint != keypointEnd; ++keypoint)</span><br><span class=\"line\">                keypoint-&gt;pt *= scale;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// And add the keypoints to the output</span></span><br><span class=\"line\">        _keypoints.insert(_keypoints.end(), keypoints.begin(), keypoints.end());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>ORB特征提取主要过程</p>\n<ul>\n<li>构建图像尺度金字塔（构造过程另作详细记录）</li>\n<li>提取ORB关键点、生成八叉树并保存关键点</li>\n<li>计算每个关键点对应的描述子</li>\n</ul>\n<p>提取ORB特征时，每一帧图像共提取1000个特征点，分布在金字塔8层中，层间尺度比例1.2，计算下来金字塔0层大约有217个特征点，7层大约有50个特征点。</p>\n<p>同时，为了提取出的特征点能够在图像中分布比较均匀（实际情况中，特征点通常分布得比较集中，这样不利于进行匹配，也不利于精确地求解相机间的位姿从而得到精确的VO轨迹），使用了八叉树（其实是平面上的四叉树）的数据结构来存储提取出的特征点。</p>\n<p>这部分内容在<code>ORBextractor.h</code>和<code>ORBextractor.cc</code>中，代码详细理解可以参考<a href=\"https://blog.csdn.net/qq_30356613/article/details/75231440\" target=\"_blank\" rel=\"noopener\">一起学ORBSLAM2ORB特征点提取</a>这篇文章和参考资料11学习，有时间再详细学习。</p>\n<h2 id=\"参考资料（有待详细阅读）\"><a href=\"#参考资料（有待详细阅读）\" class=\"headerlink\" title=\"参考资料（有待详细阅读）\"></a>参考资料（有待详细阅读）</h2><ol>\n<li><a href=\"https://blog.csdn.net/zouzoupaopao229/article/details/52625678\" target=\"_blank\" rel=\"noopener\">ORB特征提取详解</a></li>\n<li><a href=\"http://www.cnblogs.com/ronny/p/4083537.html\" target=\"_blank\" rel=\"noopener\">ORB特征点检测</a>（墙裂推荐，作者博客里有很多图像特征检测相关的介绍，包括斑点、角点检测和SIFT特征、SURF特征、BRIEF特征描述子等）</li>\n<li>视觉SLAM十四讲P132-特征点法（推荐，关于特征点的内容比较清晰整洁）</li>\n<li><a href=\"https://blog.csdn.net/zhaocj/article/details/40301561\" target=\"_blank\" rel=\"noopener\">Fast源码分析</a></li>\n<li><a href=\"http://opencv.jp/opencv-2.2_org/cpp/features2d_feature_detection_and_description.html?highlight=fast#StarDetector\" target=\"_blank\" rel=\"noopener\">Fast API</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6421940.html\" target=\"_blank\" rel=\"noopener\">ORBextractor特征提取</a></li>\n<li>SIFT：<em>Distinctive image features from scale-invariant keypoints</em></li>\n<li>SURF：<em>Surf: Speededup robust features</em></li>\n<li>ORB：<em>Orb: an efficient alternative to sift or surf</em></li>\n<li>Brief：<em>Brief: Binary robust independent elementary features</em></li>\n</ol>\n<h2 id=\"尺度金字塔-Scale-pyramid-构建\"><a href=\"#尺度金字塔-Scale-pyramid-构建\" class=\"headerlink\" title=\"尺度金字塔(Scale pyramid)构建\"></a>尺度金字塔(Scale pyramid)构建</h2><blockquote>\n<p>层数(ScaleLevels)：金字塔层数，金字塔中包含的不同尺度的图像层数</p>\n<p>尺度因子(ScaleFactor)：金字塔层与层图像之间的尺度参数，缩放比例</p>\n</blockquote>\n<p><code>ORBextractor::ComputePyramid</code>就是根据尺度因子对图像进行缩放处理。</p>\n<h3 id=\"供学习参考资料\"><a href=\"#供学习参考资料\" class=\"headerlink\" title=\"供学习参考资料\"></a>供学习参考资料</h3><ol>\n<li><a href=\"http://www.cnblogs.com/ronny/p/3886013.html\" target=\"_blank\" rel=\"noopener\">尺度空间理论</a></li>\n<li><a href=\"http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/imgproc/pyramids/pyramids.html\" target=\"_blank\" rel=\"noopener\">OpenCV 图像金字塔</a></li>\n<li><a href=\"https://blog.csdn.net/samkieth/article/details/50407655\" target=\"_blank\" rel=\"noopener\">数字图像处理9—尺度空间</a></li>\n</ol>\n<h3 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3>","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征的简单原理和提取有关的内容。</p>","more":"<h2 id=\"ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\"><a href=\"#ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\" class=\"headerlink\" title=\"ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）\"></a>ORB特征提取（涉及到Fast关键点、rBRIEF描述子、SIFT特征）</h2><p>一种直观的提取特征的方式就是在不同图像之间辨认角点，确认它们的对应关系，角点就是所谓的特征。但是单纯的角点无法满足需求，为此设计的许多更加稳定的局部图像特征，如著名的SIFT、SURF、ORB，相比于朴素的角点这些人工设计的特征点具备可重复性、可区分性、高效率、本地性等优点。特征点由<strong>关键点（Key-point）</strong>和<strong>描述子（Descriptor）</strong>组成。如当提及SIFT特征时，是指“提取SIFT关键点，计算SIFT描述子”。</p>\n<p>ORB特征包括Oriented FAST关键点和rBRIEF描述子，是在FAST关键点和BRIEF描述描述子基础上改进而来。</p>\n<ul>\n<li>改进FAST关键点（它没有描述子）：FAST关键点不具有尺度不变性，ORB特征提取方法中，通过构建高斯金字塔，然后在每一层金字塔图像上检测角点，nlevels幅不同比例的图像提取特征点总和作为这幅图像的oFAST（FAST Keypoint Orientation，改进后的FAST关键点）关键点，来实现尺度不变性；FAST关键点也不具有旋转不变性，ORB特征提出使用<a href=\"https://www.cnblogs.com/ronny/p/3985810.html\" target=\"_blank\" rel=\"noopener\">矩（moment）</a>法（灰度质心法）来确定FAST关键点的方向，即通过矩来计算特征点（该图像块的几何中心）以r为半径范围内的质心（该图像块的灰度质心），特征点坐标到质心形成一个向量作为该关键点的方向。</li>\n<li>改进BRIEF描述子：首先进行旋转不变性改进，加入旋转因子得到steered BRIEF；然后改进特征点描述子的相关性（即描述子可区分性，对误匹配率影响较大），得到rBRIEF特征描述子。</li>\n</ul>\n<h2 id=\"在SLAM视觉里程计中的应用—特征点法\"><a href=\"#在SLAM视觉里程计中的应用—特征点法\" class=\"headerlink\" title=\"在SLAM视觉里程计中的应用—特征点法\"></a>在SLAM视觉里程计中的应用—特征点法</h2>\n\n<h2 id=\"ORB-SLAM中的特征提取\"><a href=\"#ORB-SLAM中的特征提取\" class=\"headerlink\" title=\"ORB_SLAM中的特征提取\"></a>ORB_SLAM中的特征提取</h2><p>SLAM初始化过程，首先需要创建图像帧，其关键一步就是对图像进行ORB特征提取，调用函数<code>ExtractORB()</code>，其内部调用了<code>ORBextractor</code>类中的重载操作符<code>void operator()</code>，完成特征提取，提取结果被保存在<code>Frame</code>类的成员变量<code>std::vector&lt;cv:KeyPoint&gt; mvKeys</code>和<code>cv:Mat mDescriptors</code>中，即提取出特征的关键点和描述子。操作符重载的函数如下：</p>\n<!--�33-->\n<p>ORB特征提取主要过程</p>\n<ul>\n<li>构建图像尺度金字塔（构造过程另作详细记录）</li>\n<li>提取ORB关键点、生成八叉树并保存关键点</li>\n<li>计算每个关键点对应的描述子</li>\n</ul>\n<p>提取ORB特征时，每一帧图像共提取1000个特征点，分布在金字塔8层中，层间尺度比例1.2，计算下来金字塔0层大约有217个特征点，7层大约有50个特征点。</p>\n<p>同时，为了提取出的特征点能够在图像中分布比较均匀（实际情况中，特征点通常分布得比较集中，这样不利于进行匹配，也不利于精确地求解相机间的位姿从而得到精确的VO轨迹），使用了八叉树（其实是平面上的四叉树）的数据结构来存储提取出的特征点。</p>\n<p>这部分内容在<code>ORBextractor.h</code>和<code>ORBextractor.cc</code>中，代码详细理解可以参考<a href=\"https://blog.csdn.net/qq_30356613/article/details/75231440\" target=\"_blank\" rel=\"noopener\">一起学ORBSLAM2ORB特征点提取</a>这篇文章和参考资料11学习，有时间再详细学习。</p>\n<h2 id=\"参考资料（有待详细阅读）\"><a href=\"#参考资料（有待详细阅读）\" class=\"headerlink\" title=\"参考资料（有待详细阅读）\"></a>参考资料（有待详细阅读）</h2><ol>\n<li><a href=\"https://blog.csdn.net/zouzoupaopao229/article/details/52625678\" target=\"_blank\" rel=\"noopener\">ORB特征提取详解</a></li>\n<li><a href=\"http://www.cnblogs.com/ronny/p/4083537.html\" target=\"_blank\" rel=\"noopener\">ORB特征点检测</a>（墙裂推荐，作者博客里有很多图像特征检测相关的介绍，包括斑点、角点检测和SIFT特征、SURF特征、BRIEF特征描述子等）</li>\n<li>视觉SLAM十四讲P132-特征点法（推荐，关于特征点的内容比较清晰整洁）</li>\n<li><a href=\"https://blog.csdn.net/zhaocj/article/details/40301561\" target=\"_blank\" rel=\"noopener\">Fast源码分析</a></li>\n<li><a href=\"http://opencv.jp/opencv-2.2_org/cpp/features2d_feature_detection_and_description.html?highlight=fast#StarDetector\" target=\"_blank\" rel=\"noopener\">Fast API</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6421940.html\" target=\"_blank\" rel=\"noopener\">ORBextractor特征提取</a></li>\n<li>SIFT：<em>Distinctive image features from scale-invariant keypoints</em></li>\n<li>SURF：<em>Surf: Speededup robust features</em></li>\n<li>ORB：<em>Orb: an efficient alternative to sift or surf</em></li>\n<li>Brief：<em>Brief: Binary robust independent elementary features</em></li>\n</ol>\n<h2 id=\"尺度金字塔-Scale-pyramid-构建\"><a href=\"#尺度金字塔-Scale-pyramid-构建\" class=\"headerlink\" title=\"尺度金字塔(Scale pyramid)构建\"></a>尺度金字塔(Scale pyramid)构建</h2><blockquote>\n<p>层数(ScaleLevels)：金字塔层数，金字塔中包含的不同尺度的图像层数</p>\n<p>尺度因子(ScaleFactor)：金字塔层与层图像之间的尺度参数，缩放比例</p>\n</blockquote>\n<p><code>ORBextractor::ComputePyramid</code>就是根据尺度因子对图像进行缩放处理。</p>\n<h3 id=\"供学习参考资料\"><a href=\"#供学习参考资料\" class=\"headerlink\" title=\"供学习参考资料\"></a>供学习参考资料</h3><ol>\n<li><a href=\"http://www.cnblogs.com/ronny/p/3886013.html\" target=\"_blank\" rel=\"noopener\">尺度空间理论</a></li>\n<li><a href=\"http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/imgproc/pyramids/pyramids.html\" target=\"_blank\" rel=\"noopener\">OpenCV 图像金字塔</a></li>\n<li><a href=\"https://blog.csdn.net/samkieth/article/details/50407655\" target=\"_blank\" rel=\"noopener\">数字图像处理9—尺度空间</a></li>\n</ol>\n<h3 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3>"},{"title":"ROS学习之Timer类","date":"2018-03-29T02:46:28.000Z","copyright":true,"_content":"\n----\n\n这篇文章是有关ROS 定时器类`Timer`类的内容。\n\n<!--more--->\n\n测试程序：\n\n~~~c++\n#include \"ros/ros.h\"\nvoid callback1(const ros::TimerEvent&)\n{\n  ROS_INFO(\"Callback 1 triggered\");\n}\n\nvoid callback2(const ros::TimerEvent&)\n{\n  ROS_INFO(\"Callback 2 triggered\");\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"talker\");\n  ros::NodeHandle n;\n  ros::Timer timer1 = n.createTimer(ros::Duration(0.1), callback1);//每隔0.1秒执行一次回调函数\n  ros::Timer timer2 = n.createTimer(ros::Duration(1.0), callback2);//每隔1秒执行一次回调函数\n  ros::spin();\n  return 0;\n}\n~~~\n\n","source":"_posts/ROS学习之Timer类.md","raw":"---\ntitle: ROS学习之Timer类\ndate: 2018-03-29 10:46:28\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n----\n\n这篇文章是有关ROS 定时器类`Timer`类的内容。\n\n<!--more--->\n\n测试程序：\n\n~~~c++\n#include \"ros/ros.h\"\nvoid callback1(const ros::TimerEvent&)\n{\n  ROS_INFO(\"Callback 1 triggered\");\n}\n\nvoid callback2(const ros::TimerEvent&)\n{\n  ROS_INFO(\"Callback 2 triggered\");\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"talker\");\n  ros::NodeHandle n;\n  ros::Timer timer1 = n.createTimer(ros::Duration(0.1), callback1);//每隔0.1秒执行一次回调函数\n  ros::Timer timer2 = n.createTimer(ros::Duration(1.0), callback2);//每隔1秒执行一次回调函数\n  ros::spin();\n  return 0;\n}\n~~~\n\n","slug":"ROS学习之Timer类","published":1,"updated":"2019-05-30T12:29:26.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuq001eqlcrqn0ajb23","content":"<hr>\n<p>这篇文章是有关ROS 定时器类<code>Timer</code>类的内容。</p>\n<a id=\"more\"></a>\n<p>测试程序：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"ros/ros.h\"</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">callback1</span><span class=\"params\">(<span class=\"keyword\">const</span> ros::TimerEvent&amp;)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Callback 1 triggered\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">callback2</span><span class=\"params\">(<span class=\"keyword\">const</span> ros::TimerEvent&amp;)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Callback 2 triggered\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"talker\"</span>);</span><br><span class=\"line\">  ros::NodeHandle n;</span><br><span class=\"line\">  ros::Timer timer1 = n.createTimer(ros::Duration(<span class=\"number\">0.1</span>), callback1);<span class=\"comment\">//每隔0.1秒执行一次回调函数</span></span><br><span class=\"line\">  ros::Timer timer2 = n.createTimer(ros::Duration(<span class=\"number\">1.0</span>), callback2);<span class=\"comment\">//每隔1秒执行一次回调函数</span></span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS 定时器类<code>Timer</code>类的内容。</p>","more":"<p>测试程序：</p>\n<!--�34-->"},{"title":"ROS学习之OpenCV图像、ROS Image转换接口cv_bridge","date":"2018-08-11T13:32:14.000Z","copyright":true,"_content":"\n这篇文章是有关OpenCV图像与ROS Image转换接口ROS cv_bridge的学习内容。\n\n<!--more--->\n\n由于项目中需要使用ROS消息发布器、接收器分别发布和接收图像消息，一般情况下发布消息之前需要将`cv::Mat`格式的图像转化为ROS Image message，接收到消息后也需要再转化到`cv::Mat`格式。这个过程就需要使用ROS cv_bridge，即是一个ROS和OpenCV库之间提供接口的开发包。\n\n![img](https://images2015.cnblogs.com/blog/976394/201703/976394-20170329110339701-1788396407.png)\n\n\n\n## ROS Image message转OpenCV图像\n\n示例代码：\n\n~~~c++\nvoid imageCallback(const sensor_msgs::ImageConstPtr& msg)\n{\n    cv_bridge::CvImageConstPtr cv_ptr_image;\n    try\n    {\n        cv_ptr_image = cv_bridge::toCvShare(msg, \"mono8\");\n        cv::Mat = cv_ptr_image->image;\n        cv::waitKey(30);\n    }\n    catch (cv_bridge::Exception& e)\n    {\n        ROS_ERROR(\"cv_bridge exception: %s\", e.what());\n        ROS_ERROR(\"Could not convert from '%s' to 'bgr8'.\", msg->encoding.c_str());\n    }\n}\n~~~\n\n### CvImage类\n\ncvbridge定义了一个opencv图像CvImage的类型、包含了编码和ROS的信息头。CvImage包含准确的信息sensor_msgs /image，因此我们可以将两种数据类型进行转换。`cv_bridge::CvImage`类（`#include <cv_bridge.h>`）定义：\n\n```c++\nnamespace cv_bridge {\nclass CvImage\n{\n//Public Attributes\npublic:\n  std_msgs::Header header;\t// \tROS header. \n  std::string encoding;\t\t//\tImage encoding (\"mono8\", \"bgr8\", etc.)\n  cv::Mat image;\t\t\t// \tImage data for use with OpenCV. \n};\ntypedef boost::shared_ptr<CvImage> CvImagePtr;\ntypedef boost::shared_ptr<CvImage const> CvImageConstPtr;\n}\n```\n\n### toCvShare()函数原型\n\n~~~c++\nCvImageConstPtr cv_bridge::toCvShare(const sensor_msgs::ImageConstPtr & source,\n\t\t\t\t\t\t\t\t\t const std::string & encoding = std::string()) \t\n~~~\n\n- 函数功能：将`sensor_msgs::Image`类型的message转化为与OpenCV兼容的`cv_bridge::CvImage`类型；\n- 输入：图像消息指针、可选的编码参数（编码是指CvImage的类型）；如果没有输入编码（或更确切地说，空字符串），则目标图像编码将与图像消息编码相同（即与消息发布器发布消息时转化图像时的图像编码）；\n- 输出：CvImageConstPtr智能指针，指向CvImage类型的数据。\n\n介绍几种cvbridge中常见的数据编码的形式，cv_bridge可以有选择的对颜色和深度信息进行转化。为了使用指定的特征编码，就有下面集中的编码形式：\n\n- mono8:  CV_8UC1， 灰度图像\n- mono16: CV_16UC1,16位灰度图像\n- bgr8: CV_8UC3,带有颜色信息并且颜色的顺序是BGR顺序\n- rgb8: CV_8UC3,带有颜色信息并且颜色的顺序是RGB顺序\n- bgra8: CV_8UC4, BGR的彩色图像，并且带alpha通道\n- rgba8: CV_8UC4,CV，RGB彩色图像，并且带alpha通道\n\n注：这其中mono8和bgr8两种图像编码格式是大多数OpenCV的编码格式。\n\nOpenCV图像编码格式：\n\n```\n8UC[1-4]\n8SC[1-4]\n16UC[1-4]\n16SC[1-4]\n32SC[1-4]\n32FC[1-4]\n64FC[1-4]\n```\n\n### 补充\n\n使用`rosmsg show Header`命令查看消息详细信息：\n\n~~~shell\n[std_msgs/Header]:\nuint32 seq\ntime stamp  #ros::Time\nstring frame_id \n~~~\n\n## OpenCV图像转ROS Image message\n\n示例代码：\n\n```c++\n#include <cv_bridge/cv_bridge.h>\n\nint main()\n{\n    cv::Mat imRight;\n    sensor_msgs::ImagePtr msg;\n  \tstd_msgs::Header header;\n\timRight = cv::imread(\"image_path\",CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(\"time_stamp\");//不需要传时间戳就不用设置\n    if(imRight.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(\"image_path\") << endl;\n        return 1;\n    }\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"mono8\", imRight).toImageMsg();//如果不需要传时间戳，第一参数可以为std_msgs::Header()\n}\n```\n\n实现这个过程，重点是调用了CvImage类的toImageMsg()函数。\n\n~~~c++\nclass CvImage\n{\n  sensor_msgs::ImagePtr toImageMsg() const;\n\n  // Overload mainly intended for aggregate messages that contain\n  // a sensor_msgs::Image as a member.\n  void toImageMsg(sensor_msgs::Image& ros_image) const;\n};\n~~~\n\n\n\n## 参考资料\n\n1. http://docs.ros.org/hydro/api/cv_bridge/html/c++/namespacecv__bridge.html#aafa38a1d9be98d9efaefe45fd873133c\n2. https://www.cnblogs.com/li-yao7758258/p/6637079.html\n3. http://docs.ros.org/hydro/api/cv_bridge/html/c++/cv__bridge_8cpp.html","source":"_posts/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge.md","raw":"---\ntitle: ROS学习之OpenCV图像、ROS Image转换接口cv_bridge\ndate: 2018-08-11 21:32:14\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n这篇文章是有关OpenCV图像与ROS Image转换接口ROS cv_bridge的学习内容。\n\n<!--more--->\n\n由于项目中需要使用ROS消息发布器、接收器分别发布和接收图像消息，一般情况下发布消息之前需要将`cv::Mat`格式的图像转化为ROS Image message，接收到消息后也需要再转化到`cv::Mat`格式。这个过程就需要使用ROS cv_bridge，即是一个ROS和OpenCV库之间提供接口的开发包。\n\n![img](https://images2015.cnblogs.com/blog/976394/201703/976394-20170329110339701-1788396407.png)\n\n\n\n## ROS Image message转OpenCV图像\n\n示例代码：\n\n~~~c++\nvoid imageCallback(const sensor_msgs::ImageConstPtr& msg)\n{\n    cv_bridge::CvImageConstPtr cv_ptr_image;\n    try\n    {\n        cv_ptr_image = cv_bridge::toCvShare(msg, \"mono8\");\n        cv::Mat = cv_ptr_image->image;\n        cv::waitKey(30);\n    }\n    catch (cv_bridge::Exception& e)\n    {\n        ROS_ERROR(\"cv_bridge exception: %s\", e.what());\n        ROS_ERROR(\"Could not convert from '%s' to 'bgr8'.\", msg->encoding.c_str());\n    }\n}\n~~~\n\n### CvImage类\n\ncvbridge定义了一个opencv图像CvImage的类型、包含了编码和ROS的信息头。CvImage包含准确的信息sensor_msgs /image，因此我们可以将两种数据类型进行转换。`cv_bridge::CvImage`类（`#include <cv_bridge.h>`）定义：\n\n```c++\nnamespace cv_bridge {\nclass CvImage\n{\n//Public Attributes\npublic:\n  std_msgs::Header header;\t// \tROS header. \n  std::string encoding;\t\t//\tImage encoding (\"mono8\", \"bgr8\", etc.)\n  cv::Mat image;\t\t\t// \tImage data for use with OpenCV. \n};\ntypedef boost::shared_ptr<CvImage> CvImagePtr;\ntypedef boost::shared_ptr<CvImage const> CvImageConstPtr;\n}\n```\n\n### toCvShare()函数原型\n\n~~~c++\nCvImageConstPtr cv_bridge::toCvShare(const sensor_msgs::ImageConstPtr & source,\n\t\t\t\t\t\t\t\t\t const std::string & encoding = std::string()) \t\n~~~\n\n- 函数功能：将`sensor_msgs::Image`类型的message转化为与OpenCV兼容的`cv_bridge::CvImage`类型；\n- 输入：图像消息指针、可选的编码参数（编码是指CvImage的类型）；如果没有输入编码（或更确切地说，空字符串），则目标图像编码将与图像消息编码相同（即与消息发布器发布消息时转化图像时的图像编码）；\n- 输出：CvImageConstPtr智能指针，指向CvImage类型的数据。\n\n介绍几种cvbridge中常见的数据编码的形式，cv_bridge可以有选择的对颜色和深度信息进行转化。为了使用指定的特征编码，就有下面集中的编码形式：\n\n- mono8:  CV_8UC1， 灰度图像\n- mono16: CV_16UC1,16位灰度图像\n- bgr8: CV_8UC3,带有颜色信息并且颜色的顺序是BGR顺序\n- rgb8: CV_8UC3,带有颜色信息并且颜色的顺序是RGB顺序\n- bgra8: CV_8UC4, BGR的彩色图像，并且带alpha通道\n- rgba8: CV_8UC4,CV，RGB彩色图像，并且带alpha通道\n\n注：这其中mono8和bgr8两种图像编码格式是大多数OpenCV的编码格式。\n\nOpenCV图像编码格式：\n\n```\n8UC[1-4]\n8SC[1-4]\n16UC[1-4]\n16SC[1-4]\n32SC[1-4]\n32FC[1-4]\n64FC[1-4]\n```\n\n### 补充\n\n使用`rosmsg show Header`命令查看消息详细信息：\n\n~~~shell\n[std_msgs/Header]:\nuint32 seq\ntime stamp  #ros::Time\nstring frame_id \n~~~\n\n## OpenCV图像转ROS Image message\n\n示例代码：\n\n```c++\n#include <cv_bridge/cv_bridge.h>\n\nint main()\n{\n    cv::Mat imRight;\n    sensor_msgs::ImagePtr msg;\n  \tstd_msgs::Header header;\n\timRight = cv::imread(\"image_path\",CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(\"time_stamp\");//不需要传时间戳就不用设置\n    if(imRight.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(\"image_path\") << endl;\n        return 1;\n    }\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"mono8\", imRight).toImageMsg();//如果不需要传时间戳，第一参数可以为std_msgs::Header()\n}\n```\n\n实现这个过程，重点是调用了CvImage类的toImageMsg()函数。\n\n~~~c++\nclass CvImage\n{\n  sensor_msgs::ImagePtr toImageMsg() const;\n\n  // Overload mainly intended for aggregate messages that contain\n  // a sensor_msgs::Image as a member.\n  void toImageMsg(sensor_msgs::Image& ros_image) const;\n};\n~~~\n\n\n\n## 参考资料\n\n1. http://docs.ros.org/hydro/api/cv_bridge/html/c++/namespacecv__bridge.html#aafa38a1d9be98d9efaefe45fd873133c\n2. https://www.cnblogs.com/li-yao7758258/p/6637079.html\n3. http://docs.ros.org/hydro/api/cv_bridge/html/c++/cv__bridge_8cpp.html","slug":"ROS学习之OpenCV图像、ROS Image转换接口cv_bridge","published":1,"updated":"2019-05-30T12:29:26.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbus001gqlcrozwo1eli","content":"<p>这篇文章是有关OpenCV图像与ROS Image转换接口ROS cv_bridge的学习内容。</p>\n<a id=\"more\"></a>\n<p>由于项目中需要使用ROS消息发布器、接收器分别发布和接收图像消息，一般情况下发布消息之前需要将<code>cv::Mat</code>格式的图像转化为ROS Image message，接收到消息后也需要再转化到<code>cv::Mat</code>格式。这个过程就需要使用ROS cv_bridge，即是一个ROS和OpenCV库之间提供接口的开发包。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/976394/201703/976394-20170329110339701-1788396407.png\" alt=\"img\"></p>\n<h2 id=\"ROS-Image-message转OpenCV图像\"><a href=\"#ROS-Image-message转OpenCV图像\" class=\"headerlink\" title=\"ROS Image message转OpenCV图像\"></a>ROS Image message转OpenCV图像</h2><p>示例代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">imageCallback</span><span class=\"params\">(<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr&amp; msg)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    cv_bridge::CvImageConstPtr cv_ptr_image;</span><br><span class=\"line\">    <span class=\"keyword\">try</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        cv_ptr_image = cv_bridge::toCvShare(msg, <span class=\"string\">\"mono8\"</span>);</span><br><span class=\"line\">        cv::Mat = cv_ptr_image-&gt;image;</span><br><span class=\"line\">        cv::waitKey(<span class=\"number\">30</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (cv_bridge::Exception&amp; e)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        ROS_ERROR(<span class=\"string\">\"cv_bridge exception: %s\"</span>, e.what());</span><br><span class=\"line\">        ROS_ERROR(<span class=\"string\">\"Could not convert from '%s' to 'bgr8'.\"</span>, msg-&gt;encoding.c_str());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"CvImage类\"><a href=\"#CvImage类\" class=\"headerlink\" title=\"CvImage类\"></a>CvImage类</h3><p>cvbridge定义了一个opencv图像CvImage的类型、包含了编码和ROS的信息头。CvImage包含准确的信息sensor_msgs /image，因此我们可以将两种数据类型进行转换。<code>cv_bridge::CvImage</code>类（<code>#include &lt;cv_bridge.h&gt;</code>）定义：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">namespace</span> cv_bridge &#123;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CvImage</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">//Public Attributes</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  std_msgs::Header header;\t<span class=\"comment\">// \tROS header. </span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> encoding;\t\t<span class=\"comment\">//\tImage encoding (\"mono8\", \"bgr8\", etc.)</span></span><br><span class=\"line\">  cv::Mat image;\t\t\t<span class=\"comment\">// \tImage data for use with OpenCV. </span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">typedef</span> boost::<span class=\"built_in\">shared_ptr</span>&lt;CvImage&gt; CvImagePtr;</span><br><span class=\"line\"><span class=\"keyword\">typedef</span> boost::<span class=\"built_in\">shared_ptr</span>&lt;CvImage <span class=\"keyword\">const</span>&gt; CvImageConstPtr;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"toCvShare-函数原型\"><a href=\"#toCvShare-函数原型\" class=\"headerlink\" title=\"toCvShare()函数原型\"></a>toCvShare()函数原型</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CvImageConstPtr cv_bridge::toCvShare(<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr &amp; source,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t <span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> &amp; encoding = <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>())</span><br></pre></td></tr></table></figure>\n<ul>\n<li>函数功能：将<code>sensor_msgs::Image</code>类型的message转化为与OpenCV兼容的<code>cv_bridge::CvImage</code>类型；</li>\n<li>输入：图像消息指针、可选的编码参数（编码是指CvImage的类型）；如果没有输入编码（或更确切地说，空字符串），则目标图像编码将与图像消息编码相同（即与消息发布器发布消息时转化图像时的图像编码）；</li>\n<li>输出：CvImageConstPtr智能指针，指向CvImage类型的数据。</li>\n</ul>\n<p>介绍几种cvbridge中常见的数据编码的形式，cv_bridge可以有选择的对颜色和深度信息进行转化。为了使用指定的特征编码，就有下面集中的编码形式：</p>\n<ul>\n<li>mono8:  CV_8UC1， 灰度图像</li>\n<li>mono16: CV_16UC1,16位灰度图像</li>\n<li>bgr8: CV_8UC3,带有颜色信息并且颜色的顺序是BGR顺序</li>\n<li>rgb8: CV_8UC3,带有颜色信息并且颜色的顺序是RGB顺序</li>\n<li>bgra8: CV_8UC4, BGR的彩色图像，并且带alpha通道</li>\n<li>rgba8: CV_8UC4,CV，RGB彩色图像，并且带alpha通道</li>\n</ul>\n<p>注：这其中mono8和bgr8两种图像编码格式是大多数OpenCV的编码格式。</p>\n<p>OpenCV图像编码格式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">8UC[1-4]</span><br><span class=\"line\">8SC[1-4]</span><br><span class=\"line\">16UC[1-4]</span><br><span class=\"line\">16SC[1-4]</span><br><span class=\"line\">32SC[1-4]</span><br><span class=\"line\">32FC[1-4]</span><br><span class=\"line\">64FC[1-4]</span><br></pre></td></tr></table></figure>\n<h3 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h3><p>使用<code>rosmsg show Header</code>命令查看消息详细信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[std_msgs/Header]:</span><br><span class=\"line\">uint32 seq</span><br><span class=\"line\">time stamp  #ros::Time</span><br><span class=\"line\">string frame_id</span><br></pre></td></tr></table></figure>\n<h2 id=\"OpenCV图像转ROS-Image-message\"><a href=\"#OpenCV图像转ROS-Image-message\" class=\"headerlink\" title=\"OpenCV图像转ROS Image message\"></a>OpenCV图像转ROS Image message</h2><p>示例代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    cv::Mat imRight;</span><br><span class=\"line\">    sensor_msgs::ImagePtr msg;</span><br><span class=\"line\">  \tstd_msgs::Header header;</span><br><span class=\"line\">\timRight = cv::imread(<span class=\"string\">\"image_path\"</span>,CV_LOAD_IMAGE_UNCHANGED);</span><br><span class=\"line\">    header.stamp = ros::Time(<span class=\"string\">\"time_stamp\"</span>);<span class=\"comment\">//不需要传时间戳就不用设置</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(imRight.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"built_in\">endl</span> &lt;&lt; <span class=\"string\">\"Failed to load image at: \"</span></span><br><span class=\"line\">             &lt;&lt; <span class=\"built_in\">string</span>(<span class=\"string\">\"image_path\"</span>) &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">30</span>);</span><br><span class=\"line\">    msg = cv_bridge::CvImage(header, <span class=\"string\">\"mono8\"</span>, imRight).toImageMsg();<span class=\"comment\">//如果不需要传时间戳，第一参数可以为std_msgs::Header()</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>实现这个过程，重点是调用了CvImage类的toImageMsg()函数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CvImage</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">  sensor_msgs::<span class=\"function\">ImagePtr <span class=\"title\">toImageMsg</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// Overload mainly intended for aggregate messages that contain</span></span><br><span class=\"line\">  <span class=\"comment\">// a sensor_msgs::Image as a member.</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">toImageMsg</span><span class=\"params\">(sensor_msgs::Image&amp; ros_image)</span> <span class=\"keyword\">const</span></span>;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://docs.ros.org/hydro/api/cv_bridge/html/c++/namespacecv__bridge.html#aafa38a1d9be98d9efaefe45fd873133c\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/hydro/api/cv_bridge/html/c++/namespacecv__bridge.html#aafa38a1d9be98d9efaefe45fd873133c</a></li>\n<li><a href=\"https://www.cnblogs.com/li-yao7758258/p/6637079.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/li-yao7758258/p/6637079.html</a></li>\n<li><a href=\"http://docs.ros.org/hydro/api/cv_bridge/html/c++/cv__bridge_8cpp.html\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/hydro/api/cv_bridge/html/c++/cv__bridge_8cpp.html</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>这篇文章是有关OpenCV图像与ROS Image转换接口ROS cv_bridge的学习内容。</p>","more":"<p>由于项目中需要使用ROS消息发布器、接收器分别发布和接收图像消息，一般情况下发布消息之前需要将<code>cv::Mat</code>格式的图像转化为ROS Image message，接收到消息后也需要再转化到<code>cv::Mat</code>格式。这个过程就需要使用ROS cv_bridge，即是一个ROS和OpenCV库之间提供接口的开发包。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/976394/201703/976394-20170329110339701-1788396407.png\" alt=\"img\"></p>\n<h2 id=\"ROS-Image-message转OpenCV图像\"><a href=\"#ROS-Image-message转OpenCV图像\" class=\"headerlink\" title=\"ROS Image message转OpenCV图像\"></a>ROS Image message转OpenCV图像</h2><p>示例代码：</p>\n<!--�35-->\n<h3 id=\"CvImage类\"><a href=\"#CvImage类\" class=\"headerlink\" title=\"CvImage类\"></a>CvImage类</h3><p>cvbridge定义了一个opencv图像CvImage的类型、包含了编码和ROS的信息头。CvImage包含准确的信息sensor_msgs /image，因此我们可以将两种数据类型进行转换。<code>cv_bridge::CvImage</code>类（<code>#include &lt;cv_bridge.h&gt;</code>）定义：</p>\n<!--�36-->\n<h3 id=\"toCvShare-函数原型\"><a href=\"#toCvShare-函数原型\" class=\"headerlink\" title=\"toCvShare()函数原型\"></a>toCvShare()函数原型</h3><!--�37-->\n<ul>\n<li>函数功能：将<code>sensor_msgs::Image</code>类型的message转化为与OpenCV兼容的<code>cv_bridge::CvImage</code>类型；</li>\n<li>输入：图像消息指针、可选的编码参数（编码是指CvImage的类型）；如果没有输入编码（或更确切地说，空字符串），则目标图像编码将与图像消息编码相同（即与消息发布器发布消息时转化图像时的图像编码）；</li>\n<li>输出：CvImageConstPtr智能指针，指向CvImage类型的数据。</li>\n</ul>\n<p>介绍几种cvbridge中常见的数据编码的形式，cv_bridge可以有选择的对颜色和深度信息进行转化。为了使用指定的特征编码，就有下面集中的编码形式：</p>\n<ul>\n<li>mono8:  CV_8UC1， 灰度图像</li>\n<li>mono16: CV_16UC1,16位灰度图像</li>\n<li>bgr8: CV_8UC3,带有颜色信息并且颜色的顺序是BGR顺序</li>\n<li>rgb8: CV_8UC3,带有颜色信息并且颜色的顺序是RGB顺序</li>\n<li>bgra8: CV_8UC4, BGR的彩色图像，并且带alpha通道</li>\n<li>rgba8: CV_8UC4,CV，RGB彩色图像，并且带alpha通道</li>\n</ul>\n<p>注：这其中mono8和bgr8两种图像编码格式是大多数OpenCV的编码格式。</p>\n<p>OpenCV图像编码格式：</p>\n<!--�38-->\n<h3 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h3><p>使用<code>rosmsg show Header</code>命令查看消息详细信息：</p>\n<!--�39-->\n<h2 id=\"OpenCV图像转ROS-Image-message\"><a href=\"#OpenCV图像转ROS-Image-message\" class=\"headerlink\" title=\"OpenCV图像转ROS Image message\"></a>OpenCV图像转ROS Image message</h2><p>示例代码：</p>\n<!--�40-->\n<p>实现这个过程，重点是调用了CvImage类的toImageMsg()函数。</p>\n<!--�41-->\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://docs.ros.org/hydro/api/cv_bridge/html/c++/namespacecv__bridge.html#aafa38a1d9be98d9efaefe45fd873133c\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/hydro/api/cv_bridge/html/c++/namespacecv__bridge.html#aafa38a1d9be98d9efaefe45fd873133c</a></li>\n<li><a href=\"https://www.cnblogs.com/li-yao7758258/p/6637079.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/li-yao7758258/p/6637079.html</a></li>\n<li><a href=\"http://docs.ros.org/hydro/api/cv_bridge/html/c++/cv__bridge_8cpp.html\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/hydro/api/cv_bridge/html/c++/cv__bridge_8cpp.html</a></li>\n</ol>"},{"title":"ROS学习之nodelet","date":"2018-04-04T02:37:16.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中nodelet使用的学习内容。\n\n<!--more--->\n\nnodelet包提供了一种可在同一进程中运行多个算法，并在算法之间进行零拷贝传输的方法。该包提供了实现nodelet所需的nodelet基类以及用于实例化nodelet的NodeletLoader类。\n\n#　Threading Model\n\n一个nodelet管理器有一个线程池，它在管理器中运行的所有节点上共享。在nodelet中运行的代码中有两种可能的线程API。 默认线程模型对所有回调都有一个线程。 还有一个多线程API。Nodelet将在NodeletManager内运行。 nodelet管理器是一个c ++程序，它被设置为监听ROS服务，并且将成为nodelet动态加载的可执行文件。 在这种情况下，我们将运行独立管理器，但在很多情况下，这些管理器将嵌入正在运行的节点中。","source":"_posts/ROS学习之nodelet.md","raw":"---\ntitle: ROS学习之nodelet\ndate: 2018-04-04 10:37:16\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中nodelet使用的学习内容。\n\n<!--more--->\n\nnodelet包提供了一种可在同一进程中运行多个算法，并在算法之间进行零拷贝传输的方法。该包提供了实现nodelet所需的nodelet基类以及用于实例化nodelet的NodeletLoader类。\n\n#　Threading Model\n\n一个nodelet管理器有一个线程池，它在管理器中运行的所有节点上共享。在nodelet中运行的代码中有两种可能的线程API。 默认线程模型对所有回调都有一个线程。 还有一个多线程API。Nodelet将在NodeletManager内运行。 nodelet管理器是一个c ++程序，它被设置为监听ROS服务，并且将成为nodelet动态加载的可执行文件。 在这种情况下，我们将运行独立管理器，但在很多情况下，这些管理器将嵌入正在运行的节点中。","slug":"ROS学习之nodelet","published":1,"updated":"2019-05-30T12:29:26.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbut001iqlcrfb1n1xow","content":"<hr>\n<p>这篇文章是有关ROS中nodelet使用的学习内容。</p>\n<a id=\"more\"></a>\n<p>nodelet包提供了一种可在同一进程中运行多个算法，并在算法之间进行零拷贝传输的方法。该包提供了实现nodelet所需的nodelet基类以及用于实例化nodelet的NodeletLoader类。</p>\n<h1 id=\"Threading-Model\"><a href=\"#Threading-Model\" class=\"headerlink\" title=\"　Threading Model\"></a>　Threading Model</h1><p>一个nodelet管理器有一个线程池，它在管理器中运行的所有节点上共享。在nodelet中运行的代码中有两种可能的线程API。 默认线程模型对所有回调都有一个线程。 还有一个多线程API。Nodelet将在NodeletManager内运行。 nodelet管理器是一个c ++程序，它被设置为监听ROS服务，并且将成为nodelet动态加载的可执行文件。 在这种情况下，我们将运行独立管理器，但在很多情况下，这些管理器将嵌入正在运行的节点中。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中nodelet使用的学习内容。</p>","more":"<p>nodelet包提供了一种可在同一进程中运行多个算法，并在算法之间进行零拷贝传输的方法。该包提供了实现nodelet所需的nodelet基类以及用于实例化nodelet的NodeletLoader类。</p>\n<h1 id=\"Threading-Model\"><a href=\"#Threading-Model\" class=\"headerlink\" title=\"　Threading Model\"></a>　Threading Model</h1><p>一个nodelet管理器有一个线程池，它在管理器中运行的所有节点上共享。在nodelet中运行的代码中有两种可能的线程API。 默认线程模型对所有回调都有一个线程。 还有一个多线程API。Nodelet将在NodeletManager内运行。 nodelet管理器是一个c ++程序，它被设置为监听ROS服务，并且将成为nodelet动态加载的可执行文件。 在这种情况下，我们将运行独立管理器，但在很多情况下，这些管理器将嵌入正在运行的节点中。</p>"},{"title":"ROS学习之基于arbotix和rviz进行简单的机器人仿真","date":"2018-03-27T10:36:25.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关ROS中基于arbotix和rviz进行简单的机器人仿真的内容。\n\n<!--more-->\n\n在学习古月居大神关于ROS的博客时，参考他安装模拟器arbotix的方式总是连接超时，找到了如下源码安装方式。\n\n### 本人的环境\n\nubuntu16.04+ROS(kinetic)\n\n### 首先安装rbx1\n\nrbx1是 *ROS by Example* 一书中的实例代码，该书是国外关于ROS出版的第一本书，主要针对Electric和Fuerte版本，使用机器人主要是TurtleBot。书中详细讲解了关于机器人的基本仿真、导航、路径规划、图像处理、语音识别等等，相关的代码基本都包含在`rbx１`中。rbx1源码安装方式：\n\n~~~shell\ncd ~/catkin_ws/src\ngit clone https://github.com/pirobot/rbx1.git \ncd ..\ncatkin_make\nsource ./devel/setup.bash\nrospack profile\n~~~\n\n### 安装arbotix模拟器\n\n~~~shell\ncd ~/catkin_ws/src\ngit clone  https://github.com/vanadiumlabs/arbotix_ros.git\n// 在arbotix_ros文件夹下新建文件夹src,将arbotix_ros目录下的所有文件剪切放到src文件夹下;\ncd ..\ncatkin_make\n~~~\n\n后续测试模拟器等操作可以参考：\n\nhttps://blog.csdn.net/lizilpl/article/details/46757683\n\n和http://www.guyuehome.com/237\n\n## rviz说明\n\n显示的类型：\n\n- Axes 显示坐标轴\n- Effort 显示一个物体的边缘化 \n- camera 提供一个窗口显示图像 \n- grid 显示2D或者3D的一个栅格 \n- Alpha 该参数表示透明度\n- Ｌine Style 该参数表示线性（Billboards、Lines）\n- grid cells 在一个网格中绘制八叉树地图\n- iamge 用图像创造一个窗口 \n- interactiveMake 允许用箭头来控制 \n- Laser Scan 使用激光雷达进行扫描 \n- Map 显示地图信息 \n- Maker 允许程序员用topic 来控制 \n- path 显示导航的路径 \n- point 绘制出一些小的球 \n- pose 绘制出位姿 \n- ploygon 绘制多边形的轮廓线 \n- Odometry 视觉里程计 \n- range 显示视觉里程及声呐的测距范围 \n- tf 显示tf变换的层次结构 \n- RobotModel 显示机器人\n\n### 动态修改参数\n\n~~~c++\nrosrun rqt_reconfigure rqt_reconfigure\n~~~\n\n该命令打开GUI中可以的动态调整ROS节点的参数，无需重新启动节点。","source":"_posts/ROS学习之基于arbotix和rviz进行简单的机器人仿真.md","raw":"---\ntitle: ROS学习之基于arbotix和rviz进行简单的机器人仿真\ndate: 2018-03-27 18:36:25\ntags:\n  - ROS\n  - rviz\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n---\n\n这篇文章是有关ROS中基于arbotix和rviz进行简单的机器人仿真的内容。\n\n<!--more-->\n\n在学习古月居大神关于ROS的博客时，参考他安装模拟器arbotix的方式总是连接超时，找到了如下源码安装方式。\n\n### 本人的环境\n\nubuntu16.04+ROS(kinetic)\n\n### 首先安装rbx1\n\nrbx1是 *ROS by Example* 一书中的实例代码，该书是国外关于ROS出版的第一本书，主要针对Electric和Fuerte版本，使用机器人主要是TurtleBot。书中详细讲解了关于机器人的基本仿真、导航、路径规划、图像处理、语音识别等等，相关的代码基本都包含在`rbx１`中。rbx1源码安装方式：\n\n~~~shell\ncd ~/catkin_ws/src\ngit clone https://github.com/pirobot/rbx1.git \ncd ..\ncatkin_make\nsource ./devel/setup.bash\nrospack profile\n~~~\n\n### 安装arbotix模拟器\n\n~~~shell\ncd ~/catkin_ws/src\ngit clone  https://github.com/vanadiumlabs/arbotix_ros.git\n// 在arbotix_ros文件夹下新建文件夹src,将arbotix_ros目录下的所有文件剪切放到src文件夹下;\ncd ..\ncatkin_make\n~~~\n\n后续测试模拟器等操作可以参考：\n\nhttps://blog.csdn.net/lizilpl/article/details/46757683\n\n和http://www.guyuehome.com/237\n\n## rviz说明\n\n显示的类型：\n\n- Axes 显示坐标轴\n- Effort 显示一个物体的边缘化 \n- camera 提供一个窗口显示图像 \n- grid 显示2D或者3D的一个栅格 \n- Alpha 该参数表示透明度\n- Ｌine Style 该参数表示线性（Billboards、Lines）\n- grid cells 在一个网格中绘制八叉树地图\n- iamge 用图像创造一个窗口 \n- interactiveMake 允许用箭头来控制 \n- Laser Scan 使用激光雷达进行扫描 \n- Map 显示地图信息 \n- Maker 允许程序员用topic 来控制 \n- path 显示导航的路径 \n- point 绘制出一些小的球 \n- pose 绘制出位姿 \n- ploygon 绘制多边形的轮廓线 \n- Odometry 视觉里程计 \n- range 显示视觉里程及声呐的测距范围 \n- tf 显示tf变换的层次结构 \n- RobotModel 显示机器人\n\n### 动态修改参数\n\n~~~c++\nrosrun rqt_reconfigure rqt_reconfigure\n~~~\n\n该命令打开GUI中可以的动态调整ROS节点的参数，无需重新启动节点。","slug":"ROS学习之基于arbotix和rviz进行简单的机器人仿真","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuu001lqlcrb9417eyv","content":"<hr>\n<p>这篇文章是有关ROS中基于arbotix和rviz进行简单的机器人仿真的内容。</p>\n<a id=\"more\"></a>\n<p>在学习古月居大神关于ROS的博客时，参考他安装模拟器arbotix的方式总是连接超时，找到了如下源码安装方式。</p>\n<h3 id=\"本人的环境\"><a href=\"#本人的环境\" class=\"headerlink\" title=\"本人的环境\"></a>本人的环境</h3><p>ubuntu16.04+ROS(kinetic)</p>\n<h3 id=\"首先安装rbx1\"><a href=\"#首先安装rbx1\" class=\"headerlink\" title=\"首先安装rbx1\"></a>首先安装rbx1</h3><p>rbx1是 <em>ROS by Example</em> 一书中的实例代码，该书是国外关于ROS出版的第一本书，主要针对Electric和Fuerte版本，使用机器人主要是TurtleBot。书中详细讲解了关于机器人的基本仿真、导航、路径规划、图像处理、语音识别等等，相关的代码基本都包含在<code>rbx１</code>中。rbx1源码安装方式：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/catkin_ws/src</span><br><span class=\"line\">git clone https://github.com/pirobot/rbx1.git </span><br><span class=\"line\">cd ..</span><br><span class=\"line\">catkin_make</span><br><span class=\"line\">source ./devel/setup.bash</span><br><span class=\"line\">rospack profile</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装arbotix模拟器\"><a href=\"#安装arbotix模拟器\" class=\"headerlink\" title=\"安装arbotix模拟器\"></a>安装arbotix模拟器</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/catkin_ws/src</span><br><span class=\"line\">git clone  https://github.com/vanadiumlabs/arbotix_ros.git</span><br><span class=\"line\">// 在arbotix_ros文件夹下新建文件夹src,将arbotix_ros目录下的所有文件剪切放到src文件夹下;</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">catkin_make</span><br></pre></td></tr></table></figure>\n<p>后续测试模拟器等操作可以参考：</p>\n<p><a href=\"https://blog.csdn.net/lizilpl/article/details/46757683\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lizilpl/article/details/46757683</a></p>\n<p>和<a href=\"http://www.guyuehome.com/237\" target=\"_blank\" rel=\"noopener\">http://www.guyuehome.com/237</a></p>\n<h2 id=\"rviz说明\"><a href=\"#rviz说明\" class=\"headerlink\" title=\"rviz说明\"></a>rviz说明</h2><p>显示的类型：</p>\n<ul>\n<li>Axes 显示坐标轴</li>\n<li>Effort 显示一个物体的边缘化 </li>\n<li>camera 提供一个窗口显示图像 </li>\n<li>grid 显示2D或者3D的一个栅格 </li>\n<li>Alpha 该参数表示透明度</li>\n<li>Ｌine Style 该参数表示线性（Billboards、Lines）</li>\n<li>grid cells 在一个网格中绘制八叉树地图</li>\n<li>iamge 用图像创造一个窗口 </li>\n<li>interactiveMake 允许用箭头来控制 </li>\n<li>Laser Scan 使用激光雷达进行扫描 </li>\n<li>Map 显示地图信息 </li>\n<li>Maker 允许程序员用topic 来控制 </li>\n<li>path 显示导航的路径 </li>\n<li>point 绘制出一些小的球 </li>\n<li>pose 绘制出位姿 </li>\n<li>ploygon 绘制多边形的轮廓线 </li>\n<li>Odometry 视觉里程计 </li>\n<li>range 显示视觉里程及声呐的测距范围 </li>\n<li>tf 显示tf变换的层次结构 </li>\n<li>RobotModel 显示机器人</li>\n</ul>\n<h3 id=\"动态修改参数\"><a href=\"#动态修改参数\" class=\"headerlink\" title=\"动态修改参数\"></a>动态修改参数</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun rqt_reconfigure rqt_reconfigure</span><br></pre></td></tr></table></figure>\n<p>该命令打开GUI中可以的动态调整ROS节点的参数，无需重新启动节点。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中基于arbotix和rviz进行简单的机器人仿真的内容。</p>","more":"<p>在学习古月居大神关于ROS的博客时，参考他安装模拟器arbotix的方式总是连接超时，找到了如下源码安装方式。</p>\n<h3 id=\"本人的环境\"><a href=\"#本人的环境\" class=\"headerlink\" title=\"本人的环境\"></a>本人的环境</h3><p>ubuntu16.04+ROS(kinetic)</p>\n<h3 id=\"首先安装rbx1\"><a href=\"#首先安装rbx1\" class=\"headerlink\" title=\"首先安装rbx1\"></a>首先安装rbx1</h3><p>rbx1是 <em>ROS by Example</em> 一书中的实例代码，该书是国外关于ROS出版的第一本书，主要针对Electric和Fuerte版本，使用机器人主要是TurtleBot。书中详细讲解了关于机器人的基本仿真、导航、路径规划、图像处理、语音识别等等，相关的代码基本都包含在<code>rbx１</code>中。rbx1源码安装方式：</p>\n<!--�42-->\n<h3 id=\"安装arbotix模拟器\"><a href=\"#安装arbotix模拟器\" class=\"headerlink\" title=\"安装arbotix模拟器\"></a>安装arbotix模拟器</h3><!--�43-->\n<p>后续测试模拟器等操作可以参考：</p>\n<p><a href=\"https://blog.csdn.net/lizilpl/article/details/46757683\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lizilpl/article/details/46757683</a></p>\n<p>和<a href=\"http://www.guyuehome.com/237\" target=\"_blank\" rel=\"noopener\">http://www.guyuehome.com/237</a></p>\n<h2 id=\"rviz说明\"><a href=\"#rviz说明\" class=\"headerlink\" title=\"rviz说明\"></a>rviz说明</h2><p>显示的类型：</p>\n<ul>\n<li>Axes 显示坐标轴</li>\n<li>Effort 显示一个物体的边缘化 </li>\n<li>camera 提供一个窗口显示图像 </li>\n<li>grid 显示2D或者3D的一个栅格 </li>\n<li>Alpha 该参数表示透明度</li>\n<li>Ｌine Style 该参数表示线性（Billboards、Lines）</li>\n<li>grid cells 在一个网格中绘制八叉树地图</li>\n<li>iamge 用图像创造一个窗口 </li>\n<li>interactiveMake 允许用箭头来控制 </li>\n<li>Laser Scan 使用激光雷达进行扫描 </li>\n<li>Map 显示地图信息 </li>\n<li>Maker 允许程序员用topic 来控制 </li>\n<li>path 显示导航的路径 </li>\n<li>point 绘制出一些小的球 </li>\n<li>pose 绘制出位姿 </li>\n<li>ploygon 绘制多边形的轮廓线 </li>\n<li>Odometry 视觉里程计 </li>\n<li>range 显示视觉里程及声呐的测距范围 </li>\n<li>tf 显示tf变换的层次结构 </li>\n<li>RobotModel 显示机器人</li>\n</ul>\n<h3 id=\"动态修改参数\"><a href=\"#动态修改参数\" class=\"headerlink\" title=\"动态修改参数\"></a>动态修改参数</h3><!--�44-->\n<p>该命令打开GUI中可以的动态调整ROS节点的参数，无需重新启动节点。</p>"},{"title":"ROS学习之tf","date":"2018-04-04T07:05:37.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是ROS tf有关的学习内容。\n\n<!--more-->\n\n## 概述\n\n一个机器人系统有很多三维的坐标系，随时都在发生变化。tf可以对所有的坐标系进行实时监控，以供查询坐标系以及坐标系与坐标系之间的关系和关系的变化情况。rf可以在分布式系统中操作，意味着一个机器人的所有的坐标信息都能提供给系统中的任何主机上面的所有ROS组件。\n\n- tf没有转换信息的中央服务器。\n- tf默认坐标系都是右手坐标系，x轴向前、y轴向左、z轴向上。\n\n任何用户使用tf基本上都会有两个任务，即监听变换和广播变换。\n\n1. 使用tf必须要监听变换\n\n   监听变换：接收并缓存系统中广播的所有坐标系，在坐标系中查找特定变换。\n\n2. 如果希望扩展机器人的能力，需要开启广播变换：\n\n   广播变换：发送坐标系的相关位姿到系统的其他部分。一个系统就可以有很多广播者，每一个都会提供机器人不同部位的信息。\n\n> translation：平移\n>\n> rotation：旋转\n>\n> Transform(ations)：变换\n\n## 数据类型\n\n|  **Type**  |      **tf**      |\n| :--------: | :--------------: |\n| Quaternion | `tf::Quaternion` |\n|   Vector   |  `tf::Vector3`   |\n|   Point    |   `tf::Point`    |\n|    Pose    |    `tf::Pose`    |\n| Transform  | `tf::Transform`  |\n\n其中四元数`tf::Quaternion`可以通过固定轴的Roll, Pitch and Yaw(滚动，俯仰和偏转)构造。\n\n## tf工具\n\n可以使用tf工具查看相关的信息。\n\n### view_frames\n\n`rosrun tf view_frames`：查看正在广播的坐标系的关系图，会生成`frames.pdf`，`evince frames.pdf`查看图。\n\n### rqt_tf_tree\n\n`rosrun rqt_tf_tree rqt_tf_tree`or`rqt &`：查看ROS中正在广播的坐标系的树形图。\n\n### tf_echo\n\n`rosrun tf tf_echo [reference_frame][target_frame]`：查看ROS中广播的任意两个坐标系之间的变换关系。\n\n\n\n## 参考资料\n\n1. [wiki官方文档](http://wiki.ros.org/tf)\n2. [wiki官方Tutorials](http://wiki.ros.org/tf/Tutorials)\n3. [ROS与C++入门教程](https://www.ncnynl.com/archives/201702/1308.html)\n4. [坐标系统-古月居](http://www.guyuehome.com/265)\n5. [关于TF转换信息(Transforms)的理解](https://blog.csdn.net/github_30605157/article/details/72081946)--推荐阅读","source":"_posts/ROS学习之tf.md","raw":"---\ntitle: ROS学习之tf\ndate: 2018-04-04 15:05:37\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是ROS tf有关的学习内容。\n\n<!--more-->\n\n## 概述\n\n一个机器人系统有很多三维的坐标系，随时都在发生变化。tf可以对所有的坐标系进行实时监控，以供查询坐标系以及坐标系与坐标系之间的关系和关系的变化情况。rf可以在分布式系统中操作，意味着一个机器人的所有的坐标信息都能提供给系统中的任何主机上面的所有ROS组件。\n\n- tf没有转换信息的中央服务器。\n- tf默认坐标系都是右手坐标系，x轴向前、y轴向左、z轴向上。\n\n任何用户使用tf基本上都会有两个任务，即监听变换和广播变换。\n\n1. 使用tf必须要监听变换\n\n   监听变换：接收并缓存系统中广播的所有坐标系，在坐标系中查找特定变换。\n\n2. 如果希望扩展机器人的能力，需要开启广播变换：\n\n   广播变换：发送坐标系的相关位姿到系统的其他部分。一个系统就可以有很多广播者，每一个都会提供机器人不同部位的信息。\n\n> translation：平移\n>\n> rotation：旋转\n>\n> Transform(ations)：变换\n\n## 数据类型\n\n|  **Type**  |      **tf**      |\n| :--------: | :--------------: |\n| Quaternion | `tf::Quaternion` |\n|   Vector   |  `tf::Vector3`   |\n|   Point    |   `tf::Point`    |\n|    Pose    |    `tf::Pose`    |\n| Transform  | `tf::Transform`  |\n\n其中四元数`tf::Quaternion`可以通过固定轴的Roll, Pitch and Yaw(滚动，俯仰和偏转)构造。\n\n## tf工具\n\n可以使用tf工具查看相关的信息。\n\n### view_frames\n\n`rosrun tf view_frames`：查看正在广播的坐标系的关系图，会生成`frames.pdf`，`evince frames.pdf`查看图。\n\n### rqt_tf_tree\n\n`rosrun rqt_tf_tree rqt_tf_tree`or`rqt &`：查看ROS中正在广播的坐标系的树形图。\n\n### tf_echo\n\n`rosrun tf tf_echo [reference_frame][target_frame]`：查看ROS中广播的任意两个坐标系之间的变换关系。\n\n\n\n## 参考资料\n\n1. [wiki官方文档](http://wiki.ros.org/tf)\n2. [wiki官方Tutorials](http://wiki.ros.org/tf/Tutorials)\n3. [ROS与C++入门教程](https://www.ncnynl.com/archives/201702/1308.html)\n4. [坐标系统-古月居](http://www.guyuehome.com/265)\n5. [关于TF转换信息(Transforms)的理解](https://blog.csdn.net/github_30605157/article/details/72081946)--推荐阅读","slug":"ROS学习之tf","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuw001oqlcrkow70gfo","content":"<hr>\n<p>这篇文章是ROS tf有关的学习内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>一个机器人系统有很多三维的坐标系，随时都在发生变化。tf可以对所有的坐标系进行实时监控，以供查询坐标系以及坐标系与坐标系之间的关系和关系的变化情况。rf可以在分布式系统中操作，意味着一个机器人的所有的坐标信息都能提供给系统中的任何主机上面的所有ROS组件。</p>\n<ul>\n<li>tf没有转换信息的中央服务器。</li>\n<li>tf默认坐标系都是右手坐标系，x轴向前、y轴向左、z轴向上。</li>\n</ul>\n<p>任何用户使用tf基本上都会有两个任务，即监听变换和广播变换。</p>\n<ol>\n<li><p>使用tf必须要监听变换</p>\n<p>监听变换：接收并缓存系统中广播的所有坐标系，在坐标系中查找特定变换。</p>\n</li>\n<li><p>如果希望扩展机器人的能力，需要开启广播变换：</p>\n<p>广播变换：发送坐标系的相关位姿到系统的其他部分。一个系统就可以有很多广播者，每一个都会提供机器人不同部位的信息。</p>\n</li>\n</ol>\n<blockquote>\n<p>translation：平移</p>\n<p>rotation：旋转</p>\n<p>Transform(ations)：变换</p>\n</blockquote>\n<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"><strong>Type</strong></th>\n<th style=\"text-align:center\"><strong>tf</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Quaternion</td>\n<td style=\"text-align:center\"><code>tf::Quaternion</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Vector</td>\n<td style=\"text-align:center\"><code>tf::Vector3</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point</td>\n<td style=\"text-align:center\"><code>tf::Point</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Pose</td>\n<td style=\"text-align:center\"><code>tf::Pose</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transform</td>\n<td style=\"text-align:center\"><code>tf::Transform</code></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>其中四元数<code>tf::Quaternion</code>可以通过固定轴的Roll, Pitch and Yaw(滚动，俯仰和偏转)构造。</p>\n<h2 id=\"tf工具\"><a href=\"#tf工具\" class=\"headerlink\" title=\"tf工具\"></a>tf工具</h2><p>可以使用tf工具查看相关的信息。</p>\n<h3 id=\"view-frames\"><a href=\"#view-frames\" class=\"headerlink\" title=\"view_frames\"></a>view_frames</h3><p><code>rosrun tf view_frames</code>：查看正在广播的坐标系的关系图，会生成<code>frames.pdf</code>，<code>evince frames.pdf</code>查看图。</p>\n<h3 id=\"rqt-tf-tree\"><a href=\"#rqt-tf-tree\" class=\"headerlink\" title=\"rqt_tf_tree\"></a>rqt_tf_tree</h3><p><code>rosrun rqt_tf_tree rqt_tf_tree</code>or<code>rqt &amp;</code>：查看ROS中正在广播的坐标系的树形图。</p>\n<h3 id=\"tf-echo\"><a href=\"#tf-echo\" class=\"headerlink\" title=\"tf_echo\"></a>tf_echo</h3><p><code>rosrun tf tf_echo [reference_frame][target_frame]</code>：查看ROS中广播的任意两个坐标系之间的变换关系。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://wiki.ros.org/tf\" target=\"_blank\" rel=\"noopener\">wiki官方文档</a></li>\n<li><a href=\"http://wiki.ros.org/tf/Tutorials\" target=\"_blank\" rel=\"noopener\">wiki官方Tutorials</a></li>\n<li><a href=\"https://www.ncnynl.com/archives/201702/1308.html\" target=\"_blank\" rel=\"noopener\">ROS与C++入门教程</a></li>\n<li><a href=\"http://www.guyuehome.com/265\" target=\"_blank\" rel=\"noopener\">坐标系统-古月居</a></li>\n<li><a href=\"https://blog.csdn.net/github_30605157/article/details/72081946\" target=\"_blank\" rel=\"noopener\">关于TF转换信息(Transforms)的理解</a>—推荐阅读</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是ROS tf有关的学习内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>一个机器人系统有很多三维的坐标系，随时都在发生变化。tf可以对所有的坐标系进行实时监控，以供查询坐标系以及坐标系与坐标系之间的关系和关系的变化情况。rf可以在分布式系统中操作，意味着一个机器人的所有的坐标信息都能提供给系统中的任何主机上面的所有ROS组件。</p>\n<ul>\n<li>tf没有转换信息的中央服务器。</li>\n<li>tf默认坐标系都是右手坐标系，x轴向前、y轴向左、z轴向上。</li>\n</ul>\n<p>任何用户使用tf基本上都会有两个任务，即监听变换和广播变换。</p>\n<ol>\n<li><p>使用tf必须要监听变换</p>\n<p>监听变换：接收并缓存系统中广播的所有坐标系，在坐标系中查找特定变换。</p>\n</li>\n<li><p>如果希望扩展机器人的能力，需要开启广播变换：</p>\n<p>广播变换：发送坐标系的相关位姿到系统的其他部分。一个系统就可以有很多广播者，每一个都会提供机器人不同部位的信息。</p>\n</li>\n</ol>\n<blockquote>\n<p>translation：平移</p>\n<p>rotation：旋转</p>\n<p>Transform(ations)：变换</p>\n</blockquote>\n<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"><strong>Type</strong></th>\n<th style=\"text-align:center\"><strong>tf</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Quaternion</td>\n<td style=\"text-align:center\"><code>tf::Quaternion</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Vector</td>\n<td style=\"text-align:center\"><code>tf::Vector3</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point</td>\n<td style=\"text-align:center\"><code>tf::Point</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Pose</td>\n<td style=\"text-align:center\"><code>tf::Pose</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transform</td>\n<td style=\"text-align:center\"><code>tf::Transform</code></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>其中四元数<code>tf::Quaternion</code>可以通过固定轴的Roll, Pitch and Yaw(滚动，俯仰和偏转)构造。</p>\n<h2 id=\"tf工具\"><a href=\"#tf工具\" class=\"headerlink\" title=\"tf工具\"></a>tf工具</h2><p>可以使用tf工具查看相关的信息。</p>\n<h3 id=\"view-frames\"><a href=\"#view-frames\" class=\"headerlink\" title=\"view_frames\"></a>view_frames</h3><p><code>rosrun tf view_frames</code>：查看正在广播的坐标系的关系图，会生成<code>frames.pdf</code>，<code>evince frames.pdf</code>查看图。</p>\n<h3 id=\"rqt-tf-tree\"><a href=\"#rqt-tf-tree\" class=\"headerlink\" title=\"rqt_tf_tree\"></a>rqt_tf_tree</h3><p><code>rosrun rqt_tf_tree rqt_tf_tree</code>or<code>rqt &amp;</code>：查看ROS中正在广播的坐标系的树形图。</p>\n<h3 id=\"tf-echo\"><a href=\"#tf-echo\" class=\"headerlink\" title=\"tf_echo\"></a>tf_echo</h3><p><code>rosrun tf tf_echo [reference_frame][target_frame]</code>：查看ROS中广播的任意两个坐标系之间的变换关系。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://wiki.ros.org/tf\" target=\"_blank\" rel=\"noopener\">wiki官方文档</a></li>\n<li><a href=\"http://wiki.ros.org/tf/Tutorials\" target=\"_blank\" rel=\"noopener\">wiki官方Tutorials</a></li>\n<li><a href=\"https://www.ncnynl.com/archives/201702/1308.html\" target=\"_blank\" rel=\"noopener\">ROS与C++入门教程</a></li>\n<li><a href=\"http://www.guyuehome.com/265\" target=\"_blank\" rel=\"noopener\">坐标系统-古月居</a></li>\n<li><a href=\"https://blog.csdn.net/github_30605157/article/details/72081946\" target=\"_blank\" rel=\"noopener\">关于TF转换信息(Transforms)的理解</a>—推荐阅读</li>\n</ol>"},{"title":"ROS学习之工作空间、软件包的创建和编译","date":"2018-05-10T13:42:22.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中工作空间、软件包创建以及编译的内容。\n\n<!--more--->\n\n## 创建工作空间\n\n~~~~~shell\nmkdir -p work_space/src\ncd work_space\ncatkin_make\nsource devel/setup.bash\necho $ROS_PACKAGE_PATH\t\n#查看环境变量包含内容：/home/.../work_space/src:/opt/ros/kinetic/share:/opt/ros/kinetic/stacks\n~~~~~\n\n## 创建程序包\n\n~~~~~shell\ncd work_space/src\ncatkin_create_pkg my_package std_msgs rospy roscpp\n~~~~~\n\n## 编译程序包\n\n~~~~shell\ncd work_space\nsource /opt/ros/kinetic/setup.bash\ncatkin_make\ncatkin_make install #可选\n~~~~\n\n**提示：**如果工作空间下包很多，每次都使用catkin_make的话效率十分低下，因为这种编译方法会编译工作空间下的所有的包，特别是在调试程序过程中会经常修改CMakeLists.txt文件里的内容，这样每次修改都要编译整个工作空间。所以可以使用ROS的catkin_make的功能编译一个或者多个包，具体的命令是：\n\n`catkin_make  -DCATKIN_WHITELIST_PACKAGES=\"package_name\")`\n\n例如：`catkin_make  -DCATKIN_WHITELIST_PACKAGES=\"ros_slam\"`\n\n如果需要编译两个或者多个只需要中间加分号即可：\n\n`catkin_make -DCATKIN_WHITELIST_PACKAGES=\"ros_slam;cv_bridge\"`","source":"_posts/ROS学习之创建工作空间、软件包.md","raw":"---\ntitle: ROS学习之工作空间、软件包的创建和编译\ndate: 2018-05-10 21:42:22\ntags:\n  - ROS \ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中工作空间、软件包创建以及编译的内容。\n\n<!--more--->\n\n## 创建工作空间\n\n~~~~~shell\nmkdir -p work_space/src\ncd work_space\ncatkin_make\nsource devel/setup.bash\necho $ROS_PACKAGE_PATH\t\n#查看环境变量包含内容：/home/.../work_space/src:/opt/ros/kinetic/share:/opt/ros/kinetic/stacks\n~~~~~\n\n## 创建程序包\n\n~~~~~shell\ncd work_space/src\ncatkin_create_pkg my_package std_msgs rospy roscpp\n~~~~~\n\n## 编译程序包\n\n~~~~shell\ncd work_space\nsource /opt/ros/kinetic/setup.bash\ncatkin_make\ncatkin_make install #可选\n~~~~\n\n**提示：**如果工作空间下包很多，每次都使用catkin_make的话效率十分低下，因为这种编译方法会编译工作空间下的所有的包，特别是在调试程序过程中会经常修改CMakeLists.txt文件里的内容，这样每次修改都要编译整个工作空间。所以可以使用ROS的catkin_make的功能编译一个或者多个包，具体的命令是：\n\n`catkin_make  -DCATKIN_WHITELIST_PACKAGES=\"package_name\")`\n\n例如：`catkin_make  -DCATKIN_WHITELIST_PACKAGES=\"ros_slam\"`\n\n如果需要编译两个或者多个只需要中间加分号即可：\n\n`catkin_make -DCATKIN_WHITELIST_PACKAGES=\"ros_slam;cv_bridge\"`","slug":"ROS学习之创建工作空间、软件包","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbux001rqlcrlrl97z21","content":"<hr>\n<p>这篇文章是有关ROS中工作空间、软件包创建以及编译的内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"创建工作空间\"><a href=\"#创建工作空间\" class=\"headerlink\" title=\"创建工作空间\"></a>创建工作空间</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p work_space/src</span><br><span class=\"line\">cd work_space</span><br><span class=\"line\">catkin_make</span><br><span class=\"line\">source devel/setup.bash</span><br><span class=\"line\">echo $ROS_PACKAGE_PATH\t</span><br><span class=\"line\"><span class=\"meta\">#</span>查看环境变量包含内容：/home/.../work_space/src:/opt/ros/kinetic/share:/opt/ros/kinetic/stacks</span><br></pre></td></tr></table></figure>\n<h2 id=\"创建程序包\"><a href=\"#创建程序包\" class=\"headerlink\" title=\"创建程序包\"></a>创建程序包</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd work_space/src</span><br><span class=\"line\">catkin_create_pkg my_package std_msgs rospy roscpp</span><br></pre></td></tr></table></figure>\n<h2 id=\"编译程序包\"><a href=\"#编译程序包\" class=\"headerlink\" title=\"编译程序包\"></a>编译程序包</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd work_space</span><br><span class=\"line\">source /opt/ros/kinetic/setup.bash</span><br><span class=\"line\">catkin_make</span><br><span class=\"line\">catkin_make install #可选</span><br></pre></td></tr></table></figure>\n<p><strong>提示：</strong>如果工作空间下包很多，每次都使用catkin_make的话效率十分低下，因为这种编译方法会编译工作空间下的所有的包，特别是在调试程序过程中会经常修改CMakeLists.txt文件里的内容，这样每次修改都要编译整个工作空间。所以可以使用ROS的catkin_make的功能编译一个或者多个包，具体的命令是：</p>\n<p><code>catkin_make  -DCATKIN_WHITELIST_PACKAGES=&quot;package_name&quot;)</code></p>\n<p>例如：<code>catkin_make  -DCATKIN_WHITELIST_PACKAGES=&quot;ros_slam&quot;</code></p>\n<p>如果需要编译两个或者多个只需要中间加分号即可：</p>\n<p><code>catkin_make -DCATKIN_WHITELIST_PACKAGES=&quot;ros_slam;cv_bridge&quot;</code></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中工作空间、软件包创建以及编译的内容。</p>","more":"<h2 id=\"创建工作空间\"><a href=\"#创建工作空间\" class=\"headerlink\" title=\"创建工作空间\"></a>创建工作空间</h2><!--�45-->\n<h2 id=\"创建程序包\"><a href=\"#创建程序包\" class=\"headerlink\" title=\"创建程序包\"></a>创建程序包</h2><!--�46-->\n<h2 id=\"编译程序包\"><a href=\"#编译程序包\" class=\"headerlink\" title=\"编译程序包\"></a>编译程序包</h2><!--�47-->\n<p><strong>提示：</strong>如果工作空间下包很多，每次都使用catkin_make的话效率十分低下，因为这种编译方法会编译工作空间下的所有的包，特别是在调试程序过程中会经常修改CMakeLists.txt文件里的内容，这样每次修改都要编译整个工作空间。所以可以使用ROS的catkin_make的功能编译一个或者多个包，具体的命令是：</p>\n<p><code>catkin_make  -DCATKIN_WHITELIST_PACKAGES=&quot;package_name&quot;)</code></p>\n<p>例如：<code>catkin_make  -DCATKIN_WHITELIST_PACKAGES=&quot;ros_slam&quot;</code></p>\n<p>如果需要编译两个或者多个只需要中间加分号即可：</p>\n<p><code>catkin_make -DCATKIN_WHITELIST_PACKAGES=&quot;ros_slam;cv_bridge&quot;</code></p>"},{"title":"ROS学习之消息过滤器messsage_filters","date":"2018-08-08T07:41:19.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中messsage_filters使用的学习内容。\n\n<!--more-->\n\n## 消息滤波器概述\n\n一组消息过滤器，它们接收消息并可以在之后根据过滤器需要满足的条件输出这些消息。\n\n`message_filters`是一个用于`roscpp`和`rospy`的实用程序库。 它集合了许多的常用的消息“过滤”算法。 消息过滤器message_filters类似一个消息缓存，当消息到达消息过滤器的时候，可能并不会立即输出，而是在稍后的时间点里满足一定条件下才输出。\n\n举个例子，比如时间同步器，它接收来自多个源的不同类型的消息，并且仅当它们在每个源上接收到具有相同时间戳的消息时才输出它们，也就是起到了一个消息同步输出的效果。\n\n## Subscriber 订阅者\n\n[C++ message_filters::Subscriber API docs](http://www.ros.org/doc/api/message_filters/html/c++/classmessage__filters_1_1Subscriber.html) \n\n订阅者过滤器是对ROS订阅的封装，为其他过滤器提供源（source）。订阅者过滤器无法将另一个过滤器的输出作为其输入，而是使用ROS话题作为其输入。即通过过订阅ROS话题，从订阅的话题中获取相关信息作为其输入。\n\n### 输入输出形式\n\n**输入** \n\n​    无输入连接 \n\n**输出** \n\n​         C++: `void callback(const boost::shared_ptr<M const>&)`\n\n### 例子（C++）\n\n~~~c++\nmessage_filters::Subscriber<std_msgs::UInt32> sub(nh, \"my_topic\", 1);\nsub.registerCallback(myCallback);\n~~~\n\n等同于\n\n~~~c++\nros::Subscriber sub = nh.subscribe(\"my_topic\", 1, myCallback);\n~~~\n\n## Policy-Based Synchronizer 基于策略的同步器 [ROS 1.1+]\n\nSynchronizer filter同步滤波器通过包含在其`header`中的时间戳来同步输入通道，并以单个回调的形式经过相同数量的通道输出它们。 C ++实现最多可以同步9个通道。\n\n> 关于header，以sensor_msgs/Image消息为例：\n>\n> ~~~\n> [sensor_msgs/Image]:\n> std_msgs/Header header\n>   uint32 seq\n>   time stamp\n>   string frame_id\n> uint32 height\n> uint32 width\n> string encoding\n> uint8 is_bigendian\n> uint32 step\n> uint8[] data\n> ~~~\n\nSynchronize滤波器在确定如何同步通道的策略上进行模板化。 \n\n有两种策略：ExactTime和ApproximateTime，理解为松同步与紧同步，紧同步是精确的同步，松同步是粗略的同步，分别对应`message_filters::sync_policies::ExactTime` 、`message_filters::sync_policies::ApproximateTime`。\n\nC++ Header: message_filters/synchronizer.h\n\n### 输入输出形式\n\n#### 输入\n\n**C ++：** 最多9个独立的过滤器，每个过滤器的形式为`void callback（const boost::shared_ptr <M const>＆）`。 支持的过滤器数量由类创建的模板参数的数量决定。  \n\n#### 输出\n\n**C ++：** 对于消息类型M0..M8，`void callback（const boost::shared_ptr <M0 const>＆，...，const boost::shared_ptr <M8 const>＆）`。 参数的数量由类创建的模板参数的数量决定。 \n\n### ExactTime策略\n\n`message_filters::sync_policies::ExactTime`策略要求消息具有完全相同的时间戳以便匹配。 只有在具有相同确切时间戳的所有指定通道上收到消息时，才会调用回调。 从所有消息的`header`域读取时间戳（这是该策略所必需的）。 \n\nC++头文件：message_filters/sync_policies/exact_time.h\n\n~~~c++\n#include <message_filters/subscriber.h>\n#include <message_filters/synchronizer.h>\n#include <message_filters/sync_policies/exact_time.h>\n#include <sensor_msgs/Image.h>\n#include <sensor_msgs/CameraInfo.h>\n\nusing namespace sensor_msgs;\nusing namespace message_filters;\n\nvoid callback(const ImageConstPtr& image, const CameraInfoConstPtr& cam_info)\n{\n  // Solve all of perception here...\n}\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"vision_node\");\n\n  ros::NodeHandle nh;\n  message_filters::Subscriber<sensor_msgs::Image> image_sub(nh, \"image\", 1);\n  message_filters::Subscriber<sensor_msgs::CameraInfo> info_sub(nh, \"camera_info\", 1);\n\n  typedef message_filters::sync_policies::ExactTime<sensor_msgs::Image, sensor_msgs::CameraInfo> MySyncPolicy;\n  // ExactTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n  message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image_sub, info_sub);\n  sync.registerCallback(boost::bind(&callback, _1, _2));\n\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n### ApproximateTime 策略\n\n`message_filters::sync_policies::ApproximateTime`策略使用自适应算法来匹配基于其时间戳的消息。 \n\n如果不是所有的消息都有一个标题字段，从中可以确定时间戳，请参见下面的解决方法。 \n\nC++头文件：message_filters/sync_policies/approximate_time.h \n\n例子(C++)：\n\n~~~c++\n#include <message_filters/subscriber.h>\n#include <message_filters/synchronizer.h>\n#include <message_filters/sync_policies/approximate_time.h>\n#include <sensor_msgs/Image.h>\n\nusing namespace sensor_msgs;\nusing namespace message_filters;\n\nvoid callback(const ImageConstPtr& image1, const ImageConstPtr& image2)\n{\n  // Solve all of perception here...\n}\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"vision_node\");\n\n  ros::NodeHandle nh;\n  message_filters::Subscriber<sensor_msgs::Image> image1_sub(nh, \"image1\", 1);\n  message_filters::Subscriber<sensor_msgs::Image> image2_sub(nh, \"image2\", 1);\n\n  typedef  message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n  // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n   message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n  sync.registerCallback(boost::bind(&callback, _1, _2));\n\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n如果某些消息的类型不包含`header`字段，则ApproximateTimeSynchronizer默认拒绝添加此类消息。 \n\n## 参考资料\n\n1. https://blog.csdn.net/Start_From_Scratch/article/details/52337689?locationNum=10&fps=1\n2. [ROS官网](http://wiki.ros.org/message_filters#Subscriber)\n3. https://blog.csdn.net/chishuideyu/article/details/77479758","source":"_posts/ROS学习之消息过滤器messsage-filters.md","raw":"---\ntitle: ROS学习之消息过滤器messsage_filters\ndate: 2018-08-08 15:41:19\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中messsage_filters使用的学习内容。\n\n<!--more-->\n\n## 消息滤波器概述\n\n一组消息过滤器，它们接收消息并可以在之后根据过滤器需要满足的条件输出这些消息。\n\n`message_filters`是一个用于`roscpp`和`rospy`的实用程序库。 它集合了许多的常用的消息“过滤”算法。 消息过滤器message_filters类似一个消息缓存，当消息到达消息过滤器的时候，可能并不会立即输出，而是在稍后的时间点里满足一定条件下才输出。\n\n举个例子，比如时间同步器，它接收来自多个源的不同类型的消息，并且仅当它们在每个源上接收到具有相同时间戳的消息时才输出它们，也就是起到了一个消息同步输出的效果。\n\n## Subscriber 订阅者\n\n[C++ message_filters::Subscriber API docs](http://www.ros.org/doc/api/message_filters/html/c++/classmessage__filters_1_1Subscriber.html) \n\n订阅者过滤器是对ROS订阅的封装，为其他过滤器提供源（source）。订阅者过滤器无法将另一个过滤器的输出作为其输入，而是使用ROS话题作为其输入。即通过过订阅ROS话题，从订阅的话题中获取相关信息作为其输入。\n\n### 输入输出形式\n\n**输入** \n\n​    无输入连接 \n\n**输出** \n\n​         C++: `void callback(const boost::shared_ptr<M const>&)`\n\n### 例子（C++）\n\n~~~c++\nmessage_filters::Subscriber<std_msgs::UInt32> sub(nh, \"my_topic\", 1);\nsub.registerCallback(myCallback);\n~~~\n\n等同于\n\n~~~c++\nros::Subscriber sub = nh.subscribe(\"my_topic\", 1, myCallback);\n~~~\n\n## Policy-Based Synchronizer 基于策略的同步器 [ROS 1.1+]\n\nSynchronizer filter同步滤波器通过包含在其`header`中的时间戳来同步输入通道，并以单个回调的形式经过相同数量的通道输出它们。 C ++实现最多可以同步9个通道。\n\n> 关于header，以sensor_msgs/Image消息为例：\n>\n> ~~~\n> [sensor_msgs/Image]:\n> std_msgs/Header header\n>   uint32 seq\n>   time stamp\n>   string frame_id\n> uint32 height\n> uint32 width\n> string encoding\n> uint8 is_bigendian\n> uint32 step\n> uint8[] data\n> ~~~\n\nSynchronize滤波器在确定如何同步通道的策略上进行模板化。 \n\n有两种策略：ExactTime和ApproximateTime，理解为松同步与紧同步，紧同步是精确的同步，松同步是粗略的同步，分别对应`message_filters::sync_policies::ExactTime` 、`message_filters::sync_policies::ApproximateTime`。\n\nC++ Header: message_filters/synchronizer.h\n\n### 输入输出形式\n\n#### 输入\n\n**C ++：** 最多9个独立的过滤器，每个过滤器的形式为`void callback（const boost::shared_ptr <M const>＆）`。 支持的过滤器数量由类创建的模板参数的数量决定。  \n\n#### 输出\n\n**C ++：** 对于消息类型M0..M8，`void callback（const boost::shared_ptr <M0 const>＆，...，const boost::shared_ptr <M8 const>＆）`。 参数的数量由类创建的模板参数的数量决定。 \n\n### ExactTime策略\n\n`message_filters::sync_policies::ExactTime`策略要求消息具有完全相同的时间戳以便匹配。 只有在具有相同确切时间戳的所有指定通道上收到消息时，才会调用回调。 从所有消息的`header`域读取时间戳（这是该策略所必需的）。 \n\nC++头文件：message_filters/sync_policies/exact_time.h\n\n~~~c++\n#include <message_filters/subscriber.h>\n#include <message_filters/synchronizer.h>\n#include <message_filters/sync_policies/exact_time.h>\n#include <sensor_msgs/Image.h>\n#include <sensor_msgs/CameraInfo.h>\n\nusing namespace sensor_msgs;\nusing namespace message_filters;\n\nvoid callback(const ImageConstPtr& image, const CameraInfoConstPtr& cam_info)\n{\n  // Solve all of perception here...\n}\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"vision_node\");\n\n  ros::NodeHandle nh;\n  message_filters::Subscriber<sensor_msgs::Image> image_sub(nh, \"image\", 1);\n  message_filters::Subscriber<sensor_msgs::CameraInfo> info_sub(nh, \"camera_info\", 1);\n\n  typedef message_filters::sync_policies::ExactTime<sensor_msgs::Image, sensor_msgs::CameraInfo> MySyncPolicy;\n  // ExactTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n  message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image_sub, info_sub);\n  sync.registerCallback(boost::bind(&callback, _1, _2));\n\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n### ApproximateTime 策略\n\n`message_filters::sync_policies::ApproximateTime`策略使用自适应算法来匹配基于其时间戳的消息。 \n\n如果不是所有的消息都有一个标题字段，从中可以确定时间戳，请参见下面的解决方法。 \n\nC++头文件：message_filters/sync_policies/approximate_time.h \n\n例子(C++)：\n\n~~~c++\n#include <message_filters/subscriber.h>\n#include <message_filters/synchronizer.h>\n#include <message_filters/sync_policies/approximate_time.h>\n#include <sensor_msgs/Image.h>\n\nusing namespace sensor_msgs;\nusing namespace message_filters;\n\nvoid callback(const ImageConstPtr& image1, const ImageConstPtr& image2)\n{\n  // Solve all of perception here...\n}\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"vision_node\");\n\n  ros::NodeHandle nh;\n  message_filters::Subscriber<sensor_msgs::Image> image1_sub(nh, \"image1\", 1);\n  message_filters::Subscriber<sensor_msgs::Image> image2_sub(nh, \"image2\", 1);\n\n  typedef  message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n  // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n   message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n  sync.registerCallback(boost::bind(&callback, _1, _2));\n\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n如果某些消息的类型不包含`header`字段，则ApproximateTimeSynchronizer默认拒绝添加此类消息。 \n\n## 参考资料\n\n1. https://blog.csdn.net/Start_From_Scratch/article/details/52337689?locationNum=10&fps=1\n2. [ROS官网](http://wiki.ros.org/message_filters#Subscriber)\n3. https://blog.csdn.net/chishuideyu/article/details/77479758","slug":"ROS学习之消息过滤器messsage-filters","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbuz001uqlcrzz3632oz","content":"<hr>\n<p>这篇文章是有关ROS中messsage_filters使用的学习内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"消息滤波器概述\"><a href=\"#消息滤波器概述\" class=\"headerlink\" title=\"消息滤波器概述\"></a>消息滤波器概述</h2><p>一组消息过滤器，它们接收消息并可以在之后根据过滤器需要满足的条件输出这些消息。</p>\n<p><code>message_filters</code>是一个用于<code>roscpp</code>和<code>rospy</code>的实用程序库。 它集合了许多的常用的消息“过滤”算法。 消息过滤器message_filters类似一个消息缓存，当消息到达消息过滤器的时候，可能并不会立即输出，而是在稍后的时间点里满足一定条件下才输出。</p>\n<p>举个例子，比如时间同步器，它接收来自多个源的不同类型的消息，并且仅当它们在每个源上接收到具有相同时间戳的消息时才输出它们，也就是起到了一个消息同步输出的效果。</p>\n<h2 id=\"Subscriber-订阅者\"><a href=\"#Subscriber-订阅者\" class=\"headerlink\" title=\"Subscriber 订阅者\"></a>Subscriber 订阅者</h2><p><a href=\"http://www.ros.org/doc/api/message_filters/html/c++/classmessage__filters_1_1Subscriber.html\" target=\"_blank\" rel=\"noopener\">C++ message_filters::Subscriber API docs</a> </p>\n<p>订阅者过滤器是对ROS订阅的封装，为其他过滤器提供源（source）。订阅者过滤器无法将另一个过滤器的输出作为其输入，而是使用ROS话题作为其输入。即通过过订阅ROS话题，从订阅的话题中获取相关信息作为其输入。</p>\n<h3 id=\"输入输出形式\"><a href=\"#输入输出形式\" class=\"headerlink\" title=\"输入输出形式\"></a>输入输出形式</h3><p><strong>输入</strong> </p>\n<p>​    无输入连接 </p>\n<p><strong>输出</strong> </p>\n<p>​         C++: <code>void callback(const boost::shared_ptr&lt;M const&gt;&amp;)</code></p>\n<h3 id=\"例子（C-）\"><a href=\"#例子（C-）\" class=\"headerlink\" title=\"例子（C++）\"></a>例子（C++）</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message_filters::Subscriber&lt;std_msgs::UInt32&gt; sub(nh, <span class=\"string\">\"my_topic\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">sub.registerCallback(myCallback);</span><br></pre></td></tr></table></figure>\n<p>等同于</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ros::Subscriber sub = nh.subscribe(<span class=\"string\">\"my_topic\"</span>, <span class=\"number\">1</span>, myCallback);</span><br></pre></td></tr></table></figure>\n<h2 id=\"Policy-Based-Synchronizer-基于策略的同步器-ROS-1-1\"><a href=\"#Policy-Based-Synchronizer-基于策略的同步器-ROS-1-1\" class=\"headerlink\" title=\"Policy-Based Synchronizer 基于策略的同步器 [ROS 1.1+]\"></a>Policy-Based Synchronizer 基于策略的同步器 [ROS 1.1+]</h2><p>Synchronizer filter同步滤波器通过包含在其<code>header</code>中的时间戳来同步输入通道，并以单个回调的形式经过相同数量的通道输出它们。 C ++实现最多可以同步9个通道。</p>\n<blockquote>\n<p>关于header，以sensor_msgs/Image消息为例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; [sensor_msgs/Image]:</span><br><span class=\"line\">&gt; std_msgs/Header header</span><br><span class=\"line\">&gt;   uint32 seq</span><br><span class=\"line\">&gt;   time stamp</span><br><span class=\"line\">&gt;   string frame_id</span><br><span class=\"line\">&gt; uint32 height</span><br><span class=\"line\">&gt; uint32 width</span><br><span class=\"line\">&gt; string encoding</span><br><span class=\"line\">&gt; uint8 is_bigendian</span><br><span class=\"line\">&gt; uint32 step</span><br><span class=\"line\">&gt; uint8[] data</span><br><span class=\"line\">&gt;</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>Synchronize滤波器在确定如何同步通道的策略上进行模板化。 </p>\n<p>有两种策略：ExactTime和ApproximateTime，理解为松同步与紧同步，紧同步是精确的同步，松同步是粗略的同步，分别对应<code>message_filters::sync_policies::ExactTime</code> 、<code>message_filters::sync_policies::ApproximateTime</code>。</p>\n<p>C++ Header: message_filters/synchronizer.h</p>\n<h3 id=\"输入输出形式-1\"><a href=\"#输入输出形式-1\" class=\"headerlink\" title=\"输入输出形式\"></a>输入输出形式</h3><h4 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h4><p><strong>C ++：</strong> 最多9个独立的过滤器，每个过滤器的形式为<code>void callback（const boost::shared_ptr &lt;M const&gt;＆）</code>。 支持的过滤器数量由类创建的模板参数的数量决定。  </p>\n<h4 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h4><p><strong>C ++：</strong> 对于消息类型M0..M8，<code>void callback（const boost::shared_ptr &lt;M0 const&gt;＆，...，const boost::shared_ptr &lt;M8 const&gt;＆）</code>。 参数的数量由类创建的模板参数的数量决定。 </p>\n<h3 id=\"ExactTime策略\"><a href=\"#ExactTime策略\" class=\"headerlink\" title=\"ExactTime策略\"></a>ExactTime策略</h3><p><code>message_filters::sync_policies::ExactTime</code>策略要求消息具有完全相同的时间戳以便匹配。 只有在具有相同确切时间戳的所有指定通道上收到消息时，才会调用回调。 从所有消息的<code>header</code>域读取时间戳（这是该策略所必需的）。 </p>\n<p>C++头文件：message_filters/sync_policies/exact_time.h</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/subscriber.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/synchronizer.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/sync_policies/exact_time.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sensor_msgs/Image.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sensor_msgs/CameraInfo.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> sensor_msgs;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> message_filters;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">callback</span><span class=\"params\">(<span class=\"keyword\">const</span> ImageConstPtr&amp; image, <span class=\"keyword\">const</span> CameraInfoConstPtr&amp; cam_info)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"comment\">// Solve all of perception here...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"vision_node\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  message_filters::Subscriber&lt;sensor_msgs::Image&gt; image_sub(nh, <span class=\"string\">\"image\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">  message_filters::Subscriber&lt;sensor_msgs::CameraInfo&gt; info_sub(nh, <span class=\"string\">\"camera_info\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">typedef</span> message_filters::sync_policies::ExactTime&lt;sensor_msgs::Image, sensor_msgs::CameraInfo&gt; MySyncPolicy;</span><br><span class=\"line\">  <span class=\"comment\">// ExactTime takes a queue size as its constructor argument, hence MySyncPolicy(10)</span></span><br><span class=\"line\">  message_filters::Synchronizer&lt;MySyncPolicy&gt; sync(MySyncPolicy(<span class=\"number\">10</span>), image_sub, info_sub);</span><br><span class=\"line\">  sync.registerCallback(boost::bind(&amp;callback, _1, _2));</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"ApproximateTime-策略\"><a href=\"#ApproximateTime-策略\" class=\"headerlink\" title=\"ApproximateTime 策略\"></a>ApproximateTime 策略</h3><p><code>message_filters::sync_policies::ApproximateTime</code>策略使用自适应算法来匹配基于其时间戳的消息。 </p>\n<p>如果不是所有的消息都有一个标题字段，从中可以确定时间戳，请参见下面的解决方法。 </p>\n<p>C++头文件：message_filters/sync_policies/approximate_time.h </p>\n<p>例子(C++)：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/subscriber.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/synchronizer.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/sync_policies/approximate_time.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sensor_msgs/Image.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> sensor_msgs;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> message_filters;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">callback</span><span class=\"params\">(<span class=\"keyword\">const</span> ImageConstPtr&amp; image1, <span class=\"keyword\">const</span> ImageConstPtr&amp; image2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"comment\">// Solve all of perception here...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"vision_node\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  message_filters::Subscriber&lt;sensor_msgs::Image&gt; image1_sub(nh, <span class=\"string\">\"image1\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">  message_filters::Subscriber&lt;sensor_msgs::Image&gt; image2_sub(nh, <span class=\"string\">\"image2\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">typedef</span>  message_filters::sync_policies::ApproximateTime&lt;sensor_msgs::Image, sensor_msgs::Image&gt; MySyncPolicy;</span><br><span class=\"line\">  <span class=\"comment\">// ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)</span></span><br><span class=\"line\">   message_filters::Synchronizer&lt;MySyncPolicy&gt; sync(MySyncPolicy(<span class=\"number\">10</span>), image1_sub, image2_sub);</span><br><span class=\"line\">  sync.registerCallback(boost::bind(&amp;callback, _1, _2));</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果某些消息的类型不包含<code>header</code>字段，则ApproximateTimeSynchronizer默认拒绝添加此类消息。 </p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/Start_From_Scratch/article/details/52337689?locationNum=10&amp;fps=1\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Start_From_Scratch/article/details/52337689?locationNum=10&amp;fps=1</a></li>\n<li><a href=\"http://wiki.ros.org/message_filters#Subscriber\" target=\"_blank\" rel=\"noopener\">ROS官网</a></li>\n<li><a href=\"https://blog.csdn.net/chishuideyu/article/details/77479758\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/chishuideyu/article/details/77479758</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中messsage_filters使用的学习内容。</p>","more":"<h2 id=\"消息滤波器概述\"><a href=\"#消息滤波器概述\" class=\"headerlink\" title=\"消息滤波器概述\"></a>消息滤波器概述</h2><p>一组消息过滤器，它们接收消息并可以在之后根据过滤器需要满足的条件输出这些消息。</p>\n<p><code>message_filters</code>是一个用于<code>roscpp</code>和<code>rospy</code>的实用程序库。 它集合了许多的常用的消息“过滤”算法。 消息过滤器message_filters类似一个消息缓存，当消息到达消息过滤器的时候，可能并不会立即输出，而是在稍后的时间点里满足一定条件下才输出。</p>\n<p>举个例子，比如时间同步器，它接收来自多个源的不同类型的消息，并且仅当它们在每个源上接收到具有相同时间戳的消息时才输出它们，也就是起到了一个消息同步输出的效果。</p>\n<h2 id=\"Subscriber-订阅者\"><a href=\"#Subscriber-订阅者\" class=\"headerlink\" title=\"Subscriber 订阅者\"></a>Subscriber 订阅者</h2><p><a href=\"http://www.ros.org/doc/api/message_filters/html/c++/classmessage__filters_1_1Subscriber.html\" target=\"_blank\" rel=\"noopener\">C++ message_filters::Subscriber API docs</a> </p>\n<p>订阅者过滤器是对ROS订阅的封装，为其他过滤器提供源（source）。订阅者过滤器无法将另一个过滤器的输出作为其输入，而是使用ROS话题作为其输入。即通过过订阅ROS话题，从订阅的话题中获取相关信息作为其输入。</p>\n<h3 id=\"输入输出形式\"><a href=\"#输入输出形式\" class=\"headerlink\" title=\"输入输出形式\"></a>输入输出形式</h3><p><strong>输入</strong> </p>\n<p>​    无输入连接 </p>\n<p><strong>输出</strong> </p>\n<p>​         C++: <code>void callback(const boost::shared_ptr&lt;M const&gt;&amp;)</code></p>\n<h3 id=\"例子（C-）\"><a href=\"#例子（C-）\" class=\"headerlink\" title=\"例子（C++）\"></a>例子（C++）</h3><!--�48-->\n<p>等同于</p>\n<!--�49-->\n<h2 id=\"Policy-Based-Synchronizer-基于策略的同步器-ROS-1-1\"><a href=\"#Policy-Based-Synchronizer-基于策略的同步器-ROS-1-1\" class=\"headerlink\" title=\"Policy-Based Synchronizer 基于策略的同步器 [ROS 1.1+]\"></a>Policy-Based Synchronizer 基于策略的同步器 [ROS 1.1+]</h2><p>Synchronizer filter同步滤波器通过包含在其<code>header</code>中的时间戳来同步输入通道，并以单个回调的形式经过相同数量的通道输出它们。 C ++实现最多可以同步9个通道。</p>\n<blockquote>\n<p>关于header，以sensor_msgs/Image消息为例：</p>\n<!--�50-->\n</blockquote>\n<p>Synchronize滤波器在确定如何同步通道的策略上进行模板化。 </p>\n<p>有两种策略：ExactTime和ApproximateTime，理解为松同步与紧同步，紧同步是精确的同步，松同步是粗略的同步，分别对应<code>message_filters::sync_policies::ExactTime</code> 、<code>message_filters::sync_policies::ApproximateTime</code>。</p>\n<p>C++ Header: message_filters/synchronizer.h</p>\n<h3 id=\"输入输出形式-1\"><a href=\"#输入输出形式-1\" class=\"headerlink\" title=\"输入输出形式\"></a>输入输出形式</h3><h4 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h4><p><strong>C ++：</strong> 最多9个独立的过滤器，每个过滤器的形式为<code>void callback（const boost::shared_ptr &lt;M const&gt;＆）</code>。 支持的过滤器数量由类创建的模板参数的数量决定。  </p>\n<h4 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h4><p><strong>C ++：</strong> 对于消息类型M0..M8，<code>void callback（const boost::shared_ptr &lt;M0 const&gt;＆，...，const boost::shared_ptr &lt;M8 const&gt;＆）</code>。 参数的数量由类创建的模板参数的数量决定。 </p>\n<h3 id=\"ExactTime策略\"><a href=\"#ExactTime策略\" class=\"headerlink\" title=\"ExactTime策略\"></a>ExactTime策略</h3><p><code>message_filters::sync_policies::ExactTime</code>策略要求消息具有完全相同的时间戳以便匹配。 只有在具有相同确切时间戳的所有指定通道上收到消息时，才会调用回调。 从所有消息的<code>header</code>域读取时间戳（这是该策略所必需的）。 </p>\n<p>C++头文件：message_filters/sync_policies/exact_time.h</p>\n<!--�51-->\n<h3 id=\"ApproximateTime-策略\"><a href=\"#ApproximateTime-策略\" class=\"headerlink\" title=\"ApproximateTime 策略\"></a>ApproximateTime 策略</h3><p><code>message_filters::sync_policies::ApproximateTime</code>策略使用自适应算法来匹配基于其时间戳的消息。 </p>\n<p>如果不是所有的消息都有一个标题字段，从中可以确定时间戳，请参见下面的解决方法。 </p>\n<p>C++头文件：message_filters/sync_policies/approximate_time.h </p>\n<p>例子(C++)：</p>\n<!--�52-->\n<p>如果某些消息的类型不包含<code>header</code>字段，则ApproximateTimeSynchronizer默认拒绝添加此类消息。 </p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/Start_From_Scratch/article/details/52337689?locationNum=10&amp;fps=1\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Start_From_Scratch/article/details/52337689?locationNum=10&amp;fps=1</a></li>\n<li><a href=\"http://wiki.ros.org/message_filters#Subscriber\" target=\"_blank\" rel=\"noopener\">ROS官网</a></li>\n<li><a href=\"https://blog.csdn.net/chishuideyu/article/details/77479758\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/chishuideyu/article/details/77479758</a></li>\n</ol>"},{"title":"ROS学习之编写简单的消息发布器和订阅器","date":"2018-03-28T12:57:12.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中消息发布器和订阅器的学习内容。\n\n<!--more--->\n\n# 创建完成该任务的程序包\n\n~~~shell\ncd ~/catkin_ws/src #工作空间catkin_ws\ncatkin_create_pkg beginner_tutorials std_msgs rospy roscpp #创建程序包\nmkdir -p beginner_tutorials/src　#放置所有源代码\n~~~\n\n<!--more--->\n\n# 创建消息发布器节点talker\n\n消息发布器节点`talker`将不断在ROS网络中广播消息。\n\n在`beginner_tutorials/src`文件夹下创建`talker.cpp`文件：\n\n~~~c++\n//ros.h引用了 ROS 系统中大部分常用的头文件\n#include \"ros/ros.h\"\n//引用std_msgs/String 消息, 它存放在 std_msgs package 里\n#include \"std_msgs/String.h\"\n#include <sstream>\n\nint main(int argc, char **argv)\n{\n  //初始化ros，定义节点名字\"talker\"\n  ros::init(argc, argv, \"talker\");\n  //为该进程的节点创建句柄，与ROS系统通信的主要接入点。第一个创建的 NodeHandle 会为节点进行初始化，最后一个销毁的 NodeHandle 则会释放该节点所占用的所有资源。 \n  ros::NodeHandle n;\n  //告知master，在话题\"chatter\"上发布<std_msgs::String>类型的数据，chatter_pub用于发布消息\n  ros::Publisher chatter_pub = n.advertise<std_msgs::String>(\"chatter\", 1000);\n  //指定自循环的频率，设为10hz\n  ros::Rate loop_rate(10);\n  //发送数据的次数计数\n  int count = 0;\n  \n  //SIGINT 被触发 (Ctrl-C) 时返回false\n  while (ros::ok()){\n    //消息对象\n    std_msgs::String msg;\n\n    std::stringstream ss;\n    ss << \"hello world \" << count;\n    msg.data = ss.str();\n\n    //终端输出消息\n    ROS_INFO(\"%s\", msg.data.c_str());\n    //发布消息\n    chatter_pub.publish(msg);\n    //这里不是必须的，当有回调时需要使用该函数，否则回调函数就不会被调用\n    ros::spinOnce();\n    //调用 ros::Rate 对象来休眠一段时间以使得发布频率为 10Hz\n    loop_rate.sleep();\n    \n    ++count;\n  }\n  return 0;\n}\n~~~\n\n总结流程：\n\n- 初始化 ROS 系统 \n- 在 ROS 网络内广播我们将要在 chatter 话题上发布`std_msgs/String`类型的消息 \n- 以每秒 10 次的频率在 chatter 上发布消息 \n\n# 创建消息订阅器节点\n\n在`beginner_tutorials/src`文件夹下创建`listener.cpp`文件：\n\n~~~c++\n#include \"ros/ros.h\"\n#include \"std_msgs/String.h\"\n//回调函数，接收到chatter话题时就会被调用\nvoid chatterCallback(const std_msgs::String::ConstPtr& msg)\n{\n  ROS_INFO(\"I heard: [%s]\", msg->data.c_str());\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"listener\");\n\n  ros::NodeHandle n;\n  //告知master订阅chatter话题的消息，当有消息发布到这个话题时，ROS 就会调用回调函数\n  ros::Subscriber sub = n.subscribe(\"chatter\", 1000, chatterCallback);\n  //进入循环，等待回调，所有的回调函数都会被调用，摁下Ctrl-C或者被master关闭时退出\n  ros::spin();\n  return 0;\n}\n~~~\n\n流程总结：\n\n- 初始化ROS系统 \n- 订阅 `chatter` 话题 \n- 进入自循环，等待消息的到达 \n- 当消息到达，调用 `chatterCallback()` 函数 \n\n# 编译节点\n\n在`CMakeList.txt`文件中添加：\n\n~~~cmake\ninclude_directories(include ${catkin_INCLUDE_DIRS})\n\nadd_executable(talker src/talker.cpp)\ntarget_link_libraries(talker ${catkin_LIBRARIES})\nadd_dependencies(talker beginner_tutorials_gencpp)　#不加这句也可以\n\nadd_executable(listener src/listener.cpp)\ntarget_link_libraries(listener ${catkin_LIBRARIES})\nadd_dependencies(listener beginner_tutorials_gencpp)　#不加这句也可以\n~~~\n\n\n\n在工作空间下执行：\n\n~~~shell\ncatkin_make\n~~~\n\n执行完编译命令就会生成两个可执行文件, `talker` 和 `listener`, 默认存储到 `devel space` 目录下，具体是在`~/工作空间/devel/lib/<package name>` 中。\n\n# 运行节点\n\n1. 启动ROS\n\n   ~~~shell\n   roscore\n   ~~~\n\n2. 启动发布器\n\n   ~~~shell\n   cd ~/catkin_ws　#catkin_ws为工作空间\n   source ./devel/setup.bash\n   rosrun beginner_tutorials talker\n   ~~~\n\n3. 启动订阅器\n\n   ~~~powershell\n   rosrun beginner_tutorials listener\n   ~~~\n\n这样在发布器终端和订阅器终端就会看到相应的输出信息。\n\n![](/home/eric/图片/ros消息发布与订阅.png)\n\n## 推荐阅读\n\nhttps://blog.csdn.net/weixin_28900531/article/details/79431155\n\nhttps://blog.csdn.net/u013453604/article/details/49102957","source":"_posts/ROS学习之编写简单的消息发布器和订阅器.md","raw":"---\ntitle: ROS学习之编写简单的消息发布器和订阅器\ndate: 2018-03-28 20:57:12\ntags: \n  - ROS \n  - C++\n  - catkin\n  - ROS消息发布器\n  - ROS消息订阅器\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中消息发布器和订阅器的学习内容。\n\n<!--more--->\n\n# 创建完成该任务的程序包\n\n~~~shell\ncd ~/catkin_ws/src #工作空间catkin_ws\ncatkin_create_pkg beginner_tutorials std_msgs rospy roscpp #创建程序包\nmkdir -p beginner_tutorials/src　#放置所有源代码\n~~~\n\n<!--more--->\n\n# 创建消息发布器节点talker\n\n消息发布器节点`talker`将不断在ROS网络中广播消息。\n\n在`beginner_tutorials/src`文件夹下创建`talker.cpp`文件：\n\n~~~c++\n//ros.h引用了 ROS 系统中大部分常用的头文件\n#include \"ros/ros.h\"\n//引用std_msgs/String 消息, 它存放在 std_msgs package 里\n#include \"std_msgs/String.h\"\n#include <sstream>\n\nint main(int argc, char **argv)\n{\n  //初始化ros，定义节点名字\"talker\"\n  ros::init(argc, argv, \"talker\");\n  //为该进程的节点创建句柄，与ROS系统通信的主要接入点。第一个创建的 NodeHandle 会为节点进行初始化，最后一个销毁的 NodeHandle 则会释放该节点所占用的所有资源。 \n  ros::NodeHandle n;\n  //告知master，在话题\"chatter\"上发布<std_msgs::String>类型的数据，chatter_pub用于发布消息\n  ros::Publisher chatter_pub = n.advertise<std_msgs::String>(\"chatter\", 1000);\n  //指定自循环的频率，设为10hz\n  ros::Rate loop_rate(10);\n  //发送数据的次数计数\n  int count = 0;\n  \n  //SIGINT 被触发 (Ctrl-C) 时返回false\n  while (ros::ok()){\n    //消息对象\n    std_msgs::String msg;\n\n    std::stringstream ss;\n    ss << \"hello world \" << count;\n    msg.data = ss.str();\n\n    //终端输出消息\n    ROS_INFO(\"%s\", msg.data.c_str());\n    //发布消息\n    chatter_pub.publish(msg);\n    //这里不是必须的，当有回调时需要使用该函数，否则回调函数就不会被调用\n    ros::spinOnce();\n    //调用 ros::Rate 对象来休眠一段时间以使得发布频率为 10Hz\n    loop_rate.sleep();\n    \n    ++count;\n  }\n  return 0;\n}\n~~~\n\n总结流程：\n\n- 初始化 ROS 系统 \n- 在 ROS 网络内广播我们将要在 chatter 话题上发布`std_msgs/String`类型的消息 \n- 以每秒 10 次的频率在 chatter 上发布消息 \n\n# 创建消息订阅器节点\n\n在`beginner_tutorials/src`文件夹下创建`listener.cpp`文件：\n\n~~~c++\n#include \"ros/ros.h\"\n#include \"std_msgs/String.h\"\n//回调函数，接收到chatter话题时就会被调用\nvoid chatterCallback(const std_msgs::String::ConstPtr& msg)\n{\n  ROS_INFO(\"I heard: [%s]\", msg->data.c_str());\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"listener\");\n\n  ros::NodeHandle n;\n  //告知master订阅chatter话题的消息，当有消息发布到这个话题时，ROS 就会调用回调函数\n  ros::Subscriber sub = n.subscribe(\"chatter\", 1000, chatterCallback);\n  //进入循环，等待回调，所有的回调函数都会被调用，摁下Ctrl-C或者被master关闭时退出\n  ros::spin();\n  return 0;\n}\n~~~\n\n流程总结：\n\n- 初始化ROS系统 \n- 订阅 `chatter` 话题 \n- 进入自循环，等待消息的到达 \n- 当消息到达，调用 `chatterCallback()` 函数 \n\n# 编译节点\n\n在`CMakeList.txt`文件中添加：\n\n~~~cmake\ninclude_directories(include ${catkin_INCLUDE_DIRS})\n\nadd_executable(talker src/talker.cpp)\ntarget_link_libraries(talker ${catkin_LIBRARIES})\nadd_dependencies(talker beginner_tutorials_gencpp)　#不加这句也可以\n\nadd_executable(listener src/listener.cpp)\ntarget_link_libraries(listener ${catkin_LIBRARIES})\nadd_dependencies(listener beginner_tutorials_gencpp)　#不加这句也可以\n~~~\n\n\n\n在工作空间下执行：\n\n~~~shell\ncatkin_make\n~~~\n\n执行完编译命令就会生成两个可执行文件, `talker` 和 `listener`, 默认存储到 `devel space` 目录下，具体是在`~/工作空间/devel/lib/<package name>` 中。\n\n# 运行节点\n\n1. 启动ROS\n\n   ~~~shell\n   roscore\n   ~~~\n\n2. 启动发布器\n\n   ~~~shell\n   cd ~/catkin_ws　#catkin_ws为工作空间\n   source ./devel/setup.bash\n   rosrun beginner_tutorials talker\n   ~~~\n\n3. 启动订阅器\n\n   ~~~powershell\n   rosrun beginner_tutorials listener\n   ~~~\n\n这样在发布器终端和订阅器终端就会看到相应的输出信息。\n\n![](/home/eric/图片/ros消息发布与订阅.png)\n\n## 推荐阅读\n\nhttps://blog.csdn.net/weixin_28900531/article/details/79431155\n\nhttps://blog.csdn.net/u013453604/article/details/49102957","slug":"ROS学习之编写简单的消息发布器和订阅器","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv0001xqlcr5mwxa4f4","content":"<hr>\n<p>这篇文章是有关ROS中消息发布器和订阅器的学习内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"创建完成该任务的程序包\"><a href=\"#创建完成该任务的程序包\" class=\"headerlink\" title=\"创建完成该任务的程序包\"></a>创建完成该任务的程序包</h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/catkin_ws/src #工作空间catkin_ws</span><br><span class=\"line\">catkin_create_pkg beginner_tutorials std_msgs rospy roscpp #创建程序包</span><br><span class=\"line\">mkdir -p beginner_tutorials/src　#放置所有源代码</span><br></pre></td></tr></table></figure>\n<!--more--->\n<h1 id=\"创建消息发布器节点talker\"><a href=\"#创建消息发布器节点talker\" class=\"headerlink\" title=\"创建消息发布器节点talker\"></a>创建消息发布器节点talker</h1><p>消息发布器节点<code>talker</code>将不断在ROS网络中广播消息。</p>\n<p>在<code>beginner_tutorials/src</code>文件夹下创建<code>talker.cpp</code>文件：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//ros.h引用了 ROS 系统中大部分常用的头文件</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"ros/ros.h\"</span></span></span><br><span class=\"line\"><span class=\"comment\">//引用std_msgs/String 消息, 它存放在 std_msgs package 里</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"std_msgs/String.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sstream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"comment\">//初始化ros，定义节点名字\"talker\"</span></span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"talker\"</span>);</span><br><span class=\"line\">  <span class=\"comment\">//为该进程的节点创建句柄，与ROS系统通信的主要接入点。第一个创建的 NodeHandle 会为节点进行初始化，最后一个销毁的 NodeHandle 则会释放该节点所占用的所有资源。 </span></span><br><span class=\"line\">  ros::NodeHandle n;</span><br><span class=\"line\">  <span class=\"comment\">//告知master，在话题\"chatter\"上发布&lt;std_msgs::String&gt;类型的数据，chatter_pub用于发布消息</span></span><br><span class=\"line\">  ros::Publisher chatter_pub = n.advertise&lt;std_msgs::String&gt;(<span class=\"string\">\"chatter\"</span>, <span class=\"number\">1000</span>);</span><br><span class=\"line\">  <span class=\"comment\">//指定自循环的频率，设为10hz</span></span><br><span class=\"line\">  ros::<span class=\"function\">Rate <span class=\"title\">loop_rate</span><span class=\"params\">(<span class=\"number\">10</span>)</span></span>;</span><br><span class=\"line\">  <span class=\"comment\">//发送数据的次数计数</span></span><br><span class=\"line\">  <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\">//SIGINT 被触发 (Ctrl-C) 时返回false</span></span><br><span class=\"line\">  <span class=\"keyword\">while</span> (ros::ok())&#123;</span><br><span class=\"line\">    <span class=\"comment\">//消息对象</span></span><br><span class=\"line\">    std_msgs::String msg;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">stringstream</span> ss;</span><br><span class=\"line\">    ss &lt;&lt; <span class=\"string\">\"hello world \"</span> &lt;&lt; count;</span><br><span class=\"line\">    msg.data = ss.str();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//终端输出消息</span></span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"%s\"</span>, msg.data.c_str());</span><br><span class=\"line\">    <span class=\"comment\">//发布消息</span></span><br><span class=\"line\">    chatter_pub.publish(msg);</span><br><span class=\"line\">    <span class=\"comment\">//这里不是必须的，当有回调时需要使用该函数，否则回调函数就不会被调用</span></span><br><span class=\"line\">    ros::spinOnce();</span><br><span class=\"line\">    <span class=\"comment\">//调用 ros::Rate 对象来休眠一段时间以使得发布频率为 10Hz</span></span><br><span class=\"line\">    loop_rate.sleep();</span><br><span class=\"line\">    </span><br><span class=\"line\">    ++count;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>总结流程：</p>\n<ul>\n<li>初始化 ROS 系统 </li>\n<li>在 ROS 网络内广播我们将要在 chatter 话题上发布<code>std_msgs/String</code>类型的消息 </li>\n<li>以每秒 10 次的频率在 chatter 上发布消息 </li>\n</ul>\n<h1 id=\"创建消息订阅器节点\"><a href=\"#创建消息订阅器节点\" class=\"headerlink\" title=\"创建消息订阅器节点\"></a>创建消息订阅器节点</h1><p>在<code>beginner_tutorials/src</code>文件夹下创建<code>listener.cpp</code>文件：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"ros/ros.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"std_msgs/String.h\"</span></span></span><br><span class=\"line\"><span class=\"comment\">//回调函数，接收到chatter话题时就会被调用</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">chatterCallback</span><span class=\"params\">(<span class=\"keyword\">const</span> std_msgs::String::ConstPtr&amp; msg)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"I heard: [%s]\"</span>, msg-&gt;data.c_str());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"listener\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle n;</span><br><span class=\"line\">  <span class=\"comment\">//告知master订阅chatter话题的消息，当有消息发布到这个话题时，ROS 就会调用回调函数</span></span><br><span class=\"line\">  ros::Subscriber sub = n.subscribe(<span class=\"string\">\"chatter\"</span>, <span class=\"number\">1000</span>, chatterCallback);</span><br><span class=\"line\">  <span class=\"comment\">//进入循环，等待回调，所有的回调函数都会被调用，摁下Ctrl-C或者被master关闭时退出</span></span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>流程总结：</p>\n<ul>\n<li>初始化ROS系统 </li>\n<li>订阅 <code>chatter</code> 话题 </li>\n<li>进入自循环，等待消息的到达 </li>\n<li>当消息到达，调用 <code>chatterCallback()</code> 函数 </li>\n</ul>\n<h1 id=\"编译节点\"><a href=\"#编译节点\" class=\"headerlink\" title=\"编译节点\"></a>编译节点</h1><p>在<code>CMakeList.txt</code>文件中添加：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"keyword\">include</span> <span class=\"variable\">$&#123;catkin_INCLUDE_DIRS&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(talker src/talker.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(talker <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(talker beginner_tutorials_gencpp)　<span class=\"comment\">#不加这句也可以</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(listener src/listener.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(listener <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(listener beginner_tutorials_gencpp)　<span class=\"comment\">#不加这句也可以</span></span><br></pre></td></tr></table></figure>\n<p>在工作空间下执行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_make</span><br></pre></td></tr></table></figure>\n<p>执行完编译命令就会生成两个可执行文件, <code>talker</code> 和 <code>listener</code>, 默认存储到 <code>devel space</code> 目录下，具体是在<code>~/工作空间/devel/lib/&lt;package name&gt;</code> 中。</p>\n<h1 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h1><ol>\n<li><p>启动ROS</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscore</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动发布器</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/catkin_ws　#catkin_ws为工作空间</span><br><span class=\"line\">source ./devel/setup.bash</span><br><span class=\"line\">rosrun beginner_tutorials talker</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动订阅器</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun beginner_tutorials listener</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>这样在发布器终端和订阅器终端就会看到相应的输出信息。</p>\n<p><img src=\"/home/eric/图片/ros消息发布与订阅.png\" alt></p>\n<h2 id=\"推荐阅读\"><a href=\"#推荐阅读\" class=\"headerlink\" title=\"推荐阅读\"></a>推荐阅读</h2><p><a href=\"https://blog.csdn.net/weixin_28900531/article/details/79431155\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_28900531/article/details/79431155</a></p>\n<p><a href=\"https://blog.csdn.net/u013453604/article/details/49102957\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013453604/article/details/49102957</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中消息发布器和订阅器的学习内容。</p>","more":"<h1 id=\"创建完成该任务的程序包\"><a href=\"#创建完成该任务的程序包\" class=\"headerlink\" title=\"创建完成该任务的程序包\"></a>创建完成该任务的程序包</h1><!--�53-->\n<!--more--->\n<h1 id=\"创建消息发布器节点talker\"><a href=\"#创建消息发布器节点talker\" class=\"headerlink\" title=\"创建消息发布器节点talker\"></a>创建消息发布器节点talker</h1><p>消息发布器节点<code>talker</code>将不断在ROS网络中广播消息。</p>\n<p>在<code>beginner_tutorials/src</code>文件夹下创建<code>talker.cpp</code>文件：</p>\n<!--�54-->\n<p>总结流程：</p>\n<ul>\n<li>初始化 ROS 系统 </li>\n<li>在 ROS 网络内广播我们将要在 chatter 话题上发布<code>std_msgs/String</code>类型的消息 </li>\n<li>以每秒 10 次的频率在 chatter 上发布消息 </li>\n</ul>\n<h1 id=\"创建消息订阅器节点\"><a href=\"#创建消息订阅器节点\" class=\"headerlink\" title=\"创建消息订阅器节点\"></a>创建消息订阅器节点</h1><p>在<code>beginner_tutorials/src</code>文件夹下创建<code>listener.cpp</code>文件：</p>\n<!--�55-->\n<p>流程总结：</p>\n<ul>\n<li>初始化ROS系统 </li>\n<li>订阅 <code>chatter</code> 话题 </li>\n<li>进入自循环，等待消息的到达 </li>\n<li>当消息到达，调用 <code>chatterCallback()</code> 函数 </li>\n</ul>\n<h1 id=\"编译节点\"><a href=\"#编译节点\" class=\"headerlink\" title=\"编译节点\"></a>编译节点</h1><p>在<code>CMakeList.txt</code>文件中添加：</p>\n<!--�56-->\n<p>在工作空间下执行：</p>\n<!--�57-->\n<p>执行完编译命令就会生成两个可执行文件, <code>talker</code> 和 <code>listener</code>, 默认存储到 <code>devel space</code> 目录下，具体是在<code>~/工作空间/devel/lib/&lt;package name&gt;</code> 中。</p>\n<h1 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h1><ol>\n<li><p>启动ROS</p>\n<!--�58-->\n</li>\n<li><p>启动发布器</p>\n<!--�59-->\n</li>\n<li><p>启动订阅器</p>\n<!--�60-->\n</li>\n</ol>\n<p>这样在发布器终端和订阅器终端就会看到相应的输出信息。</p>\n<p><img src=\"/home/eric/图片/ros消息发布与订阅.png\" alt></p>\n<h2 id=\"推荐阅读\"><a href=\"#推荐阅读\" class=\"headerlink\" title=\"推荐阅读\"></a>推荐阅读</h2><p><a href=\"https://blog.csdn.net/weixin_28900531/article/details/79431155\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_28900531/article/details/79431155</a></p>\n<p><a href=\"https://blog.csdn.net/u013453604/article/details/49102957\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013453604/article/details/49102957</a></p>"},{"title":"VSCode调试C++代码","date":"2019-04-29T10:01:15.000Z","copyright":true,"_content":"---\n\n简单记录下使用VSCode调试代码收集的一些内容。\n<!--more--->\n\n1. 对于一般的C++程序，可以参考[这里](https://medium.com/@LicHacker/debugging-c-with-vscode-and-gdb-a266eec287e3)或[这里](https://blog.csdn.net/weixin_43374723/article/details/84064644#5_129)配置相关文件，并调试代码。\n   - 其中比较重要的一步是在`launch.json`文件中添加可执行文件的路径；\n   - 如果不想用外部控制台进行调试，只在vscode内部显示相关信息，设置参数`“externalConsole”: false`即可。\n   - [GDB Quick Guide](https://www.tutorialspoint.com/gnu_debugger/gdb_quick_guide.htm)\n2. 对于采用CMake编译的情况，除了步骤1的配置外，还需注意：\n   - CMakeList.txt文件`set`命令中需要添加`-g`，表示允许调试，否则即使设置了断点，也不会在断点处暂停。例如：`set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11 -O3 -march=native -g\" )`。参考自[链接1](https://stackoverflow.com/questions/50306354/fail-to-hit-breakpoint-of-c-program-build-with-cmake-on-ubuntu)、[链接2](https://github.com/Microsoft/vscode-cpptools/issues/416)。\n3. 对于ROS程序，除了上述步骤1、2的配置外，还需注意：\n   - 项目`launch.json`文件中添加的可执行文件路径为：`/home/username/ros_work_space/devel/lib/ros_package_name/file_name`。\n   - 关于ROS下如何调试程序，可参见[这里](http://www.dataguru.cn/article-10359-1.html)。\n4. ROS程序，如果使用`roslaunch`命令启动节点\n   - 需要在`launch`文件中节点定义一行添加：`launch-prefix=\"xterm -e gdb --args\" `，例如：`<node name=\"x\" pkg=\"xx\" type=\"xxx\" output=\"screen\" launch-prefix=\"xterm -e gdb --args\" >`。\n   - [Roslaunch Nodes in valgrind or GDB](http://library.isr.ist.utl.pt/docs/roswiki/roslaunch(2f)Tutorials(2f)Roslaunch(20)Nodes(20)in(20)Valgrind(20)or(20)GDB.html)","source":"_posts/VSCode调试C-代码.md","raw":"---\ntitle: VSCode调试C++代码\ndate: 2019-04-29 18:01:15\ntags:\n  - ubuntu\n  - VSCode\n  - C++\n  - Debug\ncategories:\n  - 工具\n  - VSCode\ncopyright: true\n---\n---\n\n简单记录下使用VSCode调试代码收集的一些内容。\n<!--more--->\n\n1. 对于一般的C++程序，可以参考[这里](https://medium.com/@LicHacker/debugging-c-with-vscode-and-gdb-a266eec287e3)或[这里](https://blog.csdn.net/weixin_43374723/article/details/84064644#5_129)配置相关文件，并调试代码。\n   - 其中比较重要的一步是在`launch.json`文件中添加可执行文件的路径；\n   - 如果不想用外部控制台进行调试，只在vscode内部显示相关信息，设置参数`“externalConsole”: false`即可。\n   - [GDB Quick Guide](https://www.tutorialspoint.com/gnu_debugger/gdb_quick_guide.htm)\n2. 对于采用CMake编译的情况，除了步骤1的配置外，还需注意：\n   - CMakeList.txt文件`set`命令中需要添加`-g`，表示允许调试，否则即使设置了断点，也不会在断点处暂停。例如：`set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11 -O3 -march=native -g\" )`。参考自[链接1](https://stackoverflow.com/questions/50306354/fail-to-hit-breakpoint-of-c-program-build-with-cmake-on-ubuntu)、[链接2](https://github.com/Microsoft/vscode-cpptools/issues/416)。\n3. 对于ROS程序，除了上述步骤1、2的配置外，还需注意：\n   - 项目`launch.json`文件中添加的可执行文件路径为：`/home/username/ros_work_space/devel/lib/ros_package_name/file_name`。\n   - 关于ROS下如何调试程序，可参见[这里](http://www.dataguru.cn/article-10359-1.html)。\n4. ROS程序，如果使用`roslaunch`命令启动节点\n   - 需要在`launch`文件中节点定义一行添加：`launch-prefix=\"xterm -e gdb --args\" `，例如：`<node name=\"x\" pkg=\"xx\" type=\"xxx\" output=\"screen\" launch-prefix=\"xterm -e gdb --args\" >`。\n   - [Roslaunch Nodes in valgrind or GDB](http://library.isr.ist.utl.pt/docs/roswiki/roslaunch(2f)Tutorials(2f)Roslaunch(20)Nodes(20)in(20)Valgrind(20)or(20)GDB.html)","slug":"VSCode调试C-代码","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv2001zqlcralky9u3w","content":"<hr>\n<p>简单记录下使用VSCode调试代码收集的一些内容。<br><a id=\"more\"></a></p>\n<ol>\n<li>对于一般的C++程序，可以参考<a href=\"https://medium.com/@LicHacker/debugging-c-with-vscode-and-gdb-a266eec287e3\" target=\"_blank\" rel=\"noopener\">这里</a>或<a href=\"https://blog.csdn.net/weixin_43374723/article/details/84064644#5_129\" target=\"_blank\" rel=\"noopener\">这里</a>配置相关文件，并调试代码。<ul>\n<li>其中比较重要的一步是在<code>launch.json</code>文件中添加可执行文件的路径；</li>\n<li>如果不想用外部控制台进行调试，只在vscode内部显示相关信息，设置参数<code>“externalConsole”: false</code>即可。</li>\n<li><a href=\"https://www.tutorialspoint.com/gnu_debugger/gdb_quick_guide.htm\" target=\"_blank\" rel=\"noopener\">GDB Quick Guide</a></li>\n</ul>\n</li>\n<li>对于采用CMake编译的情况，除了步骤1的配置外，还需注意：<ul>\n<li>CMakeList.txt文件<code>set</code>命令中需要添加<code>-g</code>，表示允许调试，否则即使设置了断点，也不会在断点处暂停。例如：<code>set(CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -std=c++11 -O3 -march=native -g&quot; )</code>。参考自<a href=\"https://stackoverflow.com/questions/50306354/fail-to-hit-breakpoint-of-c-program-build-with-cmake-on-ubuntu\" target=\"_blank\" rel=\"noopener\">链接1</a>、<a href=\"https://github.com/Microsoft/vscode-cpptools/issues/416\" target=\"_blank\" rel=\"noopener\">链接2</a>。</li>\n</ul>\n</li>\n<li>对于ROS程序，除了上述步骤1、2的配置外，还需注意：<ul>\n<li>项目<code>launch.json</code>文件中添加的可执行文件路径为：<code>/home/username/ros_work_space/devel/lib/ros_package_name/file_name</code>。</li>\n<li>关于ROS下如何调试程序，可参见<a href=\"http://www.dataguru.cn/article-10359-1.html\" target=\"_blank\" rel=\"noopener\">这里</a>。</li>\n</ul>\n</li>\n<li>ROS程序，如果使用<code>roslaunch</code>命令启动节点<ul>\n<li>需要在<code>launch</code>文件中节点定义一行添加：<code>launch-prefix=&quot;xterm -e gdb --args&quot;</code>，例如：<code>&lt;node name=&quot;x&quot; pkg=&quot;xx&quot; type=&quot;xxx&quot; output=&quot;screen&quot; launch-prefix=&quot;xterm -e gdb --args&quot; &gt;</code>。</li>\n<li><a href=\"http://library.isr.ist.utl.pt/docs/roswiki/roslaunch(2f\" target=\"_blank\" rel=\"noopener\">Roslaunch Nodes in valgrind or GDB</a>Tutorials(2f)Roslaunch(20)Nodes(20)in(20)Valgrind(20)or(20)GDB.html)</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>简单记录下使用VSCode调试代码收集的一些内容。<br>","more":"</p>\n<ol>\n<li>对于一般的C++程序，可以参考<a href=\"https://medium.com/@LicHacker/debugging-c-with-vscode-and-gdb-a266eec287e3\" target=\"_blank\" rel=\"noopener\">这里</a>或<a href=\"https://blog.csdn.net/weixin_43374723/article/details/84064644#5_129\" target=\"_blank\" rel=\"noopener\">这里</a>配置相关文件，并调试代码。<ul>\n<li>其中比较重要的一步是在<code>launch.json</code>文件中添加可执行文件的路径；</li>\n<li>如果不想用外部控制台进行调试，只在vscode内部显示相关信息，设置参数<code>“externalConsole”: false</code>即可。</li>\n<li><a href=\"https://www.tutorialspoint.com/gnu_debugger/gdb_quick_guide.htm\" target=\"_blank\" rel=\"noopener\">GDB Quick Guide</a></li>\n</ul>\n</li>\n<li>对于采用CMake编译的情况，除了步骤1的配置外，还需注意：<ul>\n<li>CMakeList.txt文件<code>set</code>命令中需要添加<code>-g</code>，表示允许调试，否则即使设置了断点，也不会在断点处暂停。例如：<code>set(CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -std=c++11 -O3 -march=native -g&quot; )</code>。参考自<a href=\"https://stackoverflow.com/questions/50306354/fail-to-hit-breakpoint-of-c-program-build-with-cmake-on-ubuntu\" target=\"_blank\" rel=\"noopener\">链接1</a>、<a href=\"https://github.com/Microsoft/vscode-cpptools/issues/416\" target=\"_blank\" rel=\"noopener\">链接2</a>。</li>\n</ul>\n</li>\n<li>对于ROS程序，除了上述步骤1、2的配置外，还需注意：<ul>\n<li>项目<code>launch.json</code>文件中添加的可执行文件路径为：<code>/home/username/ros_work_space/devel/lib/ros_package_name/file_name</code>。</li>\n<li>关于ROS下如何调试程序，可参见<a href=\"http://www.dataguru.cn/article-10359-1.html\" target=\"_blank\" rel=\"noopener\">这里</a>。</li>\n</ul>\n</li>\n<li>ROS程序，如果使用<code>roslaunch</code>命令启动节点<ul>\n<li>需要在<code>launch</code>文件中节点定义一行添加：<code>launch-prefix=&quot;xterm -e gdb --args&quot;</code>，例如：<code>&lt;node name=&quot;x&quot; pkg=&quot;xx&quot; type=&quot;xxx&quot; output=&quot;screen&quot; launch-prefix=&quot;xterm -e gdb --args&quot; &gt;</code>。</li>\n<li><a href=\"http://library.isr.ist.utl.pt/docs/roswiki/roslaunch(2f\" target=\"_blank\" rel=\"noopener\">Roslaunch Nodes in valgrind or GDB</a>Tutorials(2f)Roslaunch(20)Nodes(20)in(20)Valgrind(20)or(20)GDB.html)</li>\n</ul>\n</li>\n</ol>"},{"title":"coding.net git","date":"2018-08-02T08:50:09.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关git相关指令的内容。\n\n<!--more--->\n\n# Git\n\n{% asset_img git.png  %}\n\n- Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。\n- WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。\n- .git：存放Git管理信息的目录，初始化仓库的时候自动创建。\n- Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。\n- Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。\n- Stash：是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。\n\n{% asset_img git2.png  %}\n\n## 命令\n\n~~~shell\ngit init \t\t\t\t\t  \t#创建本地仓库，自动产生'.git'隐藏文件\ngit status \t\t\t\t\t  \t#查看workspace状态\ngit add filename or git add . \t#将文件或更新放到暂存区\ngit commit -m \"message\"\t\t\t#提交更新，从暂存区到本地仓库，-m后是描述信息\ngit commit -a -m \"message\"\t\t#跳过git add步骤提交更新，修改某个文件后提交可以执行该命令\ngit diff \t\t\t\t\t  \t#显示workspace与暂存区的差异\ngit diff HEAD~n\t\t\t\t\t#显示workspace与本地仓库的差异\ngit remote\t\t\t\t\t\t#显示已经配置的远程仓库服务器\ngit remote -v \t\t\t\t\t#显示远程仓库服务器简写及对应的URL\ngit remote add shortname url\t#添加远程仓库\ngit push shortname branchname\t#推送数据到远程仓库\ngit log \t\t\t\t\t\t#查看提交历史\ngit log -p -2\t\t\t\t\t#-p显示每次提交的内容差异，-2显示最近两次提交\n~~~\n\n\n\nubuntu git远程仓库管理：https://blog.csdn.net/maclechan/article/details/44964439\n\n详细的git原理及使用 ：https://git-scm.com/book/zh/v2\n\n简易指南：http://www.bootcss.com/p/git-guide/","source":"_posts/coding-net-git.md","raw":"---\ntitle: coding.net git\ndate: 2018-08-02 16:50:09\ntags:\n   - Git\ncategories: 工具\ncopyright: true\n---\n\n-----\n\n这篇文章是有关git相关指令的内容。\n\n<!--more--->\n\n# Git\n\n{% asset_img git.png  %}\n\n- Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。\n- WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。\n- .git：存放Git管理信息的目录，初始化仓库的时候自动创建。\n- Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。\n- Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。\n- Stash：是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。\n\n{% asset_img git2.png  %}\n\n## 命令\n\n~~~shell\ngit init \t\t\t\t\t  \t#创建本地仓库，自动产生'.git'隐藏文件\ngit status \t\t\t\t\t  \t#查看workspace状态\ngit add filename or git add . \t#将文件或更新放到暂存区\ngit commit -m \"message\"\t\t\t#提交更新，从暂存区到本地仓库，-m后是描述信息\ngit commit -a -m \"message\"\t\t#跳过git add步骤提交更新，修改某个文件后提交可以执行该命令\ngit diff \t\t\t\t\t  \t#显示workspace与暂存区的差异\ngit diff HEAD~n\t\t\t\t\t#显示workspace与本地仓库的差异\ngit remote\t\t\t\t\t\t#显示已经配置的远程仓库服务器\ngit remote -v \t\t\t\t\t#显示远程仓库服务器简写及对应的URL\ngit remote add shortname url\t#添加远程仓库\ngit push shortname branchname\t#推送数据到远程仓库\ngit log \t\t\t\t\t\t#查看提交历史\ngit log -p -2\t\t\t\t\t#-p显示每次提交的内容差异，-2显示最近两次提交\n~~~\n\n\n\nubuntu git远程仓库管理：https://blog.csdn.net/maclechan/article/details/44964439\n\n详细的git原理及使用 ：https://git-scm.com/book/zh/v2\n\n简易指南：http://www.bootcss.com/p/git-guide/","slug":"coding-net-git","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv30021qlcrkj6lxdoh","content":"<hr>\n<p>这篇文章是有关git相关指令的内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1>\n<ul>\n<li>Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。</li>\n<li>WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。</li>\n<li>.git：存放Git管理信息的目录，初始化仓库的时候自动创建。</li>\n<li>Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。</li>\n<li>Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。</li>\n<li>Stash：是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。</li>\n</ul>\n\n<h2 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git init \t\t\t\t\t  \t#创建本地仓库，自动产生'.git'隐藏文件</span><br><span class=\"line\">git status \t\t\t\t\t  \t#查看workspace状态</span><br><span class=\"line\">git add filename or git add . \t#将文件或更新放到暂存区</span><br><span class=\"line\">git commit -m \"message\"\t\t\t#提交更新，从暂存区到本地仓库，-m后是描述信息</span><br><span class=\"line\">git commit -a -m \"message\"\t\t#跳过git add步骤提交更新，修改某个文件后提交可以执行该命令</span><br><span class=\"line\">git diff \t\t\t\t\t  \t#显示workspace与暂存区的差异</span><br><span class=\"line\">git diff HEAD~n\t\t\t\t\t#显示workspace与本地仓库的差异</span><br><span class=\"line\">git remote\t\t\t\t\t\t#显示已经配置的远程仓库服务器</span><br><span class=\"line\">git remote -v \t\t\t\t\t#显示远程仓库服务器简写及对应的URL</span><br><span class=\"line\">git remote add shortname url\t#添加远程仓库</span><br><span class=\"line\">git push shortname branchname\t#推送数据到远程仓库</span><br><span class=\"line\">git log \t\t\t\t\t\t#查看提交历史</span><br><span class=\"line\">git log -p -2\t\t\t\t\t#-p显示每次提交的内容差异，-2显示最近两次提交</span><br></pre></td></tr></table></figure>\n<p>ubuntu git远程仓库管理：<a href=\"https://blog.csdn.net/maclechan/article/details/44964439\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/maclechan/article/details/44964439</a></p>\n<p>详细的git原理及使用 ：<a href=\"https://git-scm.com/book/zh/v2\" target=\"_blank\" rel=\"noopener\">https://git-scm.com/book/zh/v2</a></p>\n<p>简易指南：<a href=\"http://www.bootcss.com/p/git-guide/\" target=\"_blank\" rel=\"noopener\">http://www.bootcss.com/p/git-guide/</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关git相关指令的内容。</p>","more":"<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1>\n<ul>\n<li>Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。</li>\n<li>WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。</li>\n<li>.git：存放Git管理信息的目录，初始化仓库的时候自动创建。</li>\n<li>Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。</li>\n<li>Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。</li>\n<li>Stash：是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。</li>\n</ul>\n\n<h2 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h2><!--�61-->\n<p>ubuntu git远程仓库管理：<a href=\"https://blog.csdn.net/maclechan/article/details/44964439\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/maclechan/article/details/44964439</a></p>\n<p>详细的git原理及使用 ：<a href=\"https://git-scm.com/book/zh/v2\" target=\"_blank\" rel=\"noopener\">https://git-scm.com/book/zh/v2</a></p>\n<p>简易指南：<a href=\"http://www.bootcss.com/p/git-guide/\" target=\"_blank\" rel=\"noopener\">http://www.bootcss.com/p/git-guide/</a></p>"},{"title":"Zotero基于坚果云实现多机同步","date":"2018-08-10T14:59:43.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关Zotero工具基于坚果云和webdav实现多机同步的内容。\n\n<!--more-->\n\n首先参考[该文章](http://www.sohu.com/a/145196470_241268)在Zotero中设置webdav连接到坚果云，其中输入的坚果云服务器地址为`https://dav.jianguoyun.com/dav/work`，需要提前在坚果云创建`work`文件夹。\n\n> 提示：输入的用户名为坚果云账号邮箱，密码为第三方应用管理中获取到的应用密码。\n\n## Ubuntu设置方法\n\n1. 我的zotero源文件开始是在ubuntu系统下，在上面的操作后，坚果云会提示在本地创建`work`目录，我设置在`/home/usrname/work/`；\n2. zotero安装在`/home/usrname/Zotero`目录下，将该目录下的storage目录剪切到`/home/usrname/work/zotero`目录下；\n3. 命令行执行：`ln -s /home/usrname/Zotero /home/usrname/work/zotero`，会在`Zotero`下面会出现软链接目录`storage`；\n4. 等待坚果云同步完成，再回到zotero里面点击同步按钮。\n\n> 提示：如果work目录已经创建好，里面同步了数据，这时候就可以直接将zotero下的storage删除，执行命令：\n>\n> `ln -s /home/eric/work/zotero/storage /home/eric/Zotero`创建软链接到zotero下即可。\n\n## win设置方法\n\n1. 由于前面在ubuntu系统已经设置过，进入windows后，坚果云会提示同步`work`目录（联网状态），这时选择同步到自己想要放置的磁盘，如`D:\\work`。zotero默认安装在C盘，`storage`目录地址是`C:\\User\\user\\Zotero\\storage`；\n2. 剪切`C:\\User\\user\\Zotero\\storage`目录到`D:\\work\\Zotero`目录下（这时zotero下面没有storage目录了）；\n3. 运行cmd输入：`mklink /j C:\\User\\user\\Zotero\\storage D:\\work\\Zotero`，现在zotero下面出现了软链接目录`storage`。\n\n参考：http://www.360doc.com/content/18/0506/18/46033958_751645308.shtml","source":"_posts/Zotero基于坚果云实现多机同步.md","raw":"---\ntitle: Zotero基于坚果云实现多机同步\ndate: 2018-08-10 22:59:43\ntags:\n  - Zotero\ncategories: 工具\ncopyright: true\n---\n\n-----\n\n这篇文章是有关Zotero工具基于坚果云和webdav实现多机同步的内容。\n\n<!--more-->\n\n首先参考[该文章](http://www.sohu.com/a/145196470_241268)在Zotero中设置webdav连接到坚果云，其中输入的坚果云服务器地址为`https://dav.jianguoyun.com/dav/work`，需要提前在坚果云创建`work`文件夹。\n\n> 提示：输入的用户名为坚果云账号邮箱，密码为第三方应用管理中获取到的应用密码。\n\n## Ubuntu设置方法\n\n1. 我的zotero源文件开始是在ubuntu系统下，在上面的操作后，坚果云会提示在本地创建`work`目录，我设置在`/home/usrname/work/`；\n2. zotero安装在`/home/usrname/Zotero`目录下，将该目录下的storage目录剪切到`/home/usrname/work/zotero`目录下；\n3. 命令行执行：`ln -s /home/usrname/Zotero /home/usrname/work/zotero`，会在`Zotero`下面会出现软链接目录`storage`；\n4. 等待坚果云同步完成，再回到zotero里面点击同步按钮。\n\n> 提示：如果work目录已经创建好，里面同步了数据，这时候就可以直接将zotero下的storage删除，执行命令：\n>\n> `ln -s /home/eric/work/zotero/storage /home/eric/Zotero`创建软链接到zotero下即可。\n\n## win设置方法\n\n1. 由于前面在ubuntu系统已经设置过，进入windows后，坚果云会提示同步`work`目录（联网状态），这时选择同步到自己想要放置的磁盘，如`D:\\work`。zotero默认安装在C盘，`storage`目录地址是`C:\\User\\user\\Zotero\\storage`；\n2. 剪切`C:\\User\\user\\Zotero\\storage`目录到`D:\\work\\Zotero`目录下（这时zotero下面没有storage目录了）；\n3. 运行cmd输入：`mklink /j C:\\User\\user\\Zotero\\storage D:\\work\\Zotero`，现在zotero下面出现了软链接目录`storage`。\n\n参考：http://www.360doc.com/content/18/0506/18/46033958_751645308.shtml","slug":"Zotero基于坚果云实现多机同步","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv50025qlcrbe04tu6e","content":"<hr>\n<p>这篇文章是有关Zotero工具基于坚果云和webdav实现多机同步的内容。</p>\n<a id=\"more\"></a>\n<p>首先参考<a href=\"http://www.sohu.com/a/145196470_241268\" target=\"_blank\" rel=\"noopener\">该文章</a>在Zotero中设置webdav连接到坚果云，其中输入的坚果云服务器地址为<code>https://dav.jianguoyun.com/dav/work</code>，需要提前在坚果云创建<code>work</code>文件夹。</p>\n<blockquote>\n<p>提示：输入的用户名为坚果云账号邮箱，密码为第三方应用管理中获取到的应用密码。</p>\n</blockquote>\n<h2 id=\"Ubuntu设置方法\"><a href=\"#Ubuntu设置方法\" class=\"headerlink\" title=\"Ubuntu设置方法\"></a>Ubuntu设置方法</h2><ol>\n<li>我的zotero源文件开始是在ubuntu系统下，在上面的操作后，坚果云会提示在本地创建<code>work</code>目录，我设置在<code>/home/usrname/work/</code>；</li>\n<li>zotero安装在<code>/home/usrname/Zotero</code>目录下，将该目录下的storage目录剪切到<code>/home/usrname/work/zotero</code>目录下；</li>\n<li>命令行执行：<code>ln -s /home/usrname/Zotero /home/usrname/work/zotero</code>，会在<code>Zotero</code>下面会出现软链接目录<code>storage</code>；</li>\n<li>等待坚果云同步完成，再回到zotero里面点击同步按钮。</li>\n</ol>\n<blockquote>\n<p>提示：如果work目录已经创建好，里面同步了数据，这时候就可以直接将zotero下的storage删除，执行命令：</p>\n<p><code>ln -s /home/eric/work/zotero/storage /home/eric/Zotero</code>创建软链接到zotero下即可。</p>\n</blockquote>\n<h2 id=\"win设置方法\"><a href=\"#win设置方法\" class=\"headerlink\" title=\"win设置方法\"></a>win设置方法</h2><ol>\n<li>由于前面在ubuntu系统已经设置过，进入windows后，坚果云会提示同步<code>work</code>目录（联网状态），这时选择同步到自己想要放置的磁盘，如<code>D:\\work</code>。zotero默认安装在C盘，<code>storage</code>目录地址是<code>C:\\User\\user\\Zotero\\storage</code>；</li>\n<li>剪切<code>C:\\User\\user\\Zotero\\storage</code>目录到<code>D:\\work\\Zotero</code>目录下（这时zotero下面没有storage目录了）；</li>\n<li>运行cmd输入：<code>mklink /j C:\\User\\user\\Zotero\\storage D:\\work\\Zotero</code>，现在zotero下面出现了软链接目录<code>storage</code>。</li>\n</ol>\n<p>参考：<a href=\"http://www.360doc.com/content/18/0506/18/46033958_751645308.shtml\" target=\"_blank\" rel=\"noopener\">http://www.360doc.com/content/18/0506/18/46033958_751645308.shtml</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关Zotero工具基于坚果云和webdav实现多机同步的内容。</p>","more":"<p>首先参考<a href=\"http://www.sohu.com/a/145196470_241268\" target=\"_blank\" rel=\"noopener\">该文章</a>在Zotero中设置webdav连接到坚果云，其中输入的坚果云服务器地址为<code>https://dav.jianguoyun.com/dav/work</code>，需要提前在坚果云创建<code>work</code>文件夹。</p>\n<blockquote>\n<p>提示：输入的用户名为坚果云账号邮箱，密码为第三方应用管理中获取到的应用密码。</p>\n</blockquote>\n<h2 id=\"Ubuntu设置方法\"><a href=\"#Ubuntu设置方法\" class=\"headerlink\" title=\"Ubuntu设置方法\"></a>Ubuntu设置方法</h2><ol>\n<li>我的zotero源文件开始是在ubuntu系统下，在上面的操作后，坚果云会提示在本地创建<code>work</code>目录，我设置在<code>/home/usrname/work/</code>；</li>\n<li>zotero安装在<code>/home/usrname/Zotero</code>目录下，将该目录下的storage目录剪切到<code>/home/usrname/work/zotero</code>目录下；</li>\n<li>命令行执行：<code>ln -s /home/usrname/Zotero /home/usrname/work/zotero</code>，会在<code>Zotero</code>下面会出现软链接目录<code>storage</code>；</li>\n<li>等待坚果云同步完成，再回到zotero里面点击同步按钮。</li>\n</ol>\n<blockquote>\n<p>提示：如果work目录已经创建好，里面同步了数据，这时候就可以直接将zotero下的storage删除，执行命令：</p>\n<p><code>ln -s /home/eric/work/zotero/storage /home/eric/Zotero</code>创建软链接到zotero下即可。</p>\n</blockquote>\n<h2 id=\"win设置方法\"><a href=\"#win设置方法\" class=\"headerlink\" title=\"win设置方法\"></a>win设置方法</h2><ol>\n<li>由于前面在ubuntu系统已经设置过，进入windows后，坚果云会提示同步<code>work</code>目录（联网状态），这时选择同步到自己想要放置的磁盘，如<code>D:\\work</code>。zotero默认安装在C盘，<code>storage</code>目录地址是<code>C:\\User\\user\\Zotero\\storage</code>；</li>\n<li>剪切<code>C:\\User\\user\\Zotero\\storage</code>目录到<code>D:\\work\\Zotero</code>目录下（这时zotero下面没有storage目录了）；</li>\n<li>运行cmd输入：<code>mklink /j C:\\User\\user\\Zotero\\storage D:\\work\\Zotero</code>，现在zotero下面出现了软链接目录<code>storage</code>。</li>\n</ol>\n<p>参考：<a href=\"http://www.360doc.com/content/18/0506/18/46033958_751645308.shtml\" target=\"_blank\" rel=\"noopener\">http://www.360doc.com/content/18/0506/18/46033958_751645308.shtml</a></p>"},{"title":"lightweight_mapping学习之MapDrawer","date":"2018-09-06T10:27:55.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录MapDrawer模块新增的内容。\n\n<!--more--->\n\n## 概述\n\nORB_SLAM2可视化的功能采用的Pangolin库，`MapDrawer`类是对地图可视化的实现，在可视化线程中被调用，类中各功能的实现都是基于Pangolin的，彼此之间过程类似，比较简单。lightwight_mapping项目在该类中新添了四个功能函数：\n\n1. `void DrawVertexes(bool flag);`\n2. `void DrawTetrahedra(bool flag, double y_base );`\n3. `void DrawSpace(bool flag);`\n4. `void DrawMesh(bool flag);`\n\n通过这四个功能函数访问LocalMeshing线程生成的三维空间顶点、三角形、边，并对实现这些信息的可视化，对应的文件为`MapDrawer.h`和`MapDrawer.cpp`。\n\n## 函数功能\n\n1. 该函数通过接口获取LocalMeshing线程生成的三维顶点，使用`GL_POINTS`类型，通过`glVertex3f()`函数将顶点可视化。\n2. 该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形（其实就是三个三维点组成的结构），使用`GL_TRIANGLES`类型，通过`glVertex3f()`函数将三角形可视化（这里很有意思，和可视化顶点用的是一个函数～），三角形的各顶点使用的不同颜色。\n3. 该函数通过接口获取LocalMeshing线程生成的三维空间中的边（其实就是两个三维点组成的结构），使用`GL_LINES`类型，通过`glVertex3f()`函数将三维边可视化，两个顶点使用的相同颜色。\n4. 该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形，使用`GL_LINES`类型，通过`glVertex3f()`函数将三角形可视化，这里三角形的三个顶点使用的同一种颜色。\n\n## 参考资料\n\n1. 无","source":"_posts/lightweight_mapping学习之MapDrawer.md","raw":"---\ntitle: lightweight_mapping学习之MapDrawer\ndate: 2018-09-06 18:27:55\ntags: \n  - lightweight_mapping\ncategories: \n  - 机器人\n  - SLAM\n  - navigation\ncopyright: true\n---\n\n---\n\n这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录MapDrawer模块新增的内容。\n\n<!--more--->\n\n## 概述\n\nORB_SLAM2可视化的功能采用的Pangolin库，`MapDrawer`类是对地图可视化的实现，在可视化线程中被调用，类中各功能的实现都是基于Pangolin的，彼此之间过程类似，比较简单。lightwight_mapping项目在该类中新添了四个功能函数：\n\n1. `void DrawVertexes(bool flag);`\n2. `void DrawTetrahedra(bool flag, double y_base );`\n3. `void DrawSpace(bool flag);`\n4. `void DrawMesh(bool flag);`\n\n通过这四个功能函数访问LocalMeshing线程生成的三维空间顶点、三角形、边，并对实现这些信息的可视化，对应的文件为`MapDrawer.h`和`MapDrawer.cpp`。\n\n## 函数功能\n\n1. 该函数通过接口获取LocalMeshing线程生成的三维顶点，使用`GL_POINTS`类型，通过`glVertex3f()`函数将顶点可视化。\n2. 该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形（其实就是三个三维点组成的结构），使用`GL_TRIANGLES`类型，通过`glVertex3f()`函数将三角形可视化（这里很有意思，和可视化顶点用的是一个函数～），三角形的各顶点使用的不同颜色。\n3. 该函数通过接口获取LocalMeshing线程生成的三维空间中的边（其实就是两个三维点组成的结构），使用`GL_LINES`类型，通过`glVertex3f()`函数将三维边可视化，两个顶点使用的相同颜色。\n4. 该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形，使用`GL_LINES`类型，通过`glVertex3f()`函数将三角形可视化，这里三角形的三个顶点使用的同一种颜色。\n\n## 参考资料\n\n1. 无","slug":"lightweight_mapping学习之MapDrawer","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv60026qlcrf55pwv32","content":"<hr>\n<p>这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录MapDrawer模块新增的内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>ORB_SLAM2可视化的功能采用的Pangolin库，<code>MapDrawer</code>类是对地图可视化的实现，在可视化线程中被调用，类中各功能的实现都是基于Pangolin的，彼此之间过程类似，比较简单。lightwight_mapping项目在该类中新添了四个功能函数：</p>\n<ol>\n<li><code>void DrawVertexes(bool flag);</code></li>\n<li><code>void DrawTetrahedra(bool flag, double y_base );</code></li>\n<li><code>void DrawSpace(bool flag);</code></li>\n<li><code>void DrawMesh(bool flag);</code></li>\n</ol>\n<p>通过这四个功能函数访问LocalMeshing线程生成的三维空间顶点、三角形、边，并对实现这些信息的可视化，对应的文件为<code>MapDrawer.h</code>和<code>MapDrawer.cpp</code>。</p>\n<h2 id=\"函数功能\"><a href=\"#函数功能\" class=\"headerlink\" title=\"函数功能\"></a>函数功能</h2><ol>\n<li>该函数通过接口获取LocalMeshing线程生成的三维顶点，使用<code>GL_POINTS</code>类型，通过<code>glVertex3f()</code>函数将顶点可视化。</li>\n<li>该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形（其实就是三个三维点组成的结构），使用<code>GL_TRIANGLES</code>类型，通过<code>glVertex3f()</code>函数将三角形可视化（这里很有意思，和可视化顶点用的是一个函数～），三角形的各顶点使用的不同颜色。</li>\n<li>该函数通过接口获取LocalMeshing线程生成的三维空间中的边（其实就是两个三维点组成的结构），使用<code>GL_LINES</code>类型，通过<code>glVertex3f()</code>函数将三维边可视化，两个顶点使用的相同颜色。</li>\n<li>该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形，使用<code>GL_LINES</code>类型，通过<code>glVertex3f()</code>函数将三角形可视化，这里三角形的三个顶点使用的同一种颜色。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>无</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录MapDrawer模块新增的内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>ORB_SLAM2可视化的功能采用的Pangolin库，<code>MapDrawer</code>类是对地图可视化的实现，在可视化线程中被调用，类中各功能的实现都是基于Pangolin的，彼此之间过程类似，比较简单。lightwight_mapping项目在该类中新添了四个功能函数：</p>\n<ol>\n<li><code>void DrawVertexes(bool flag);</code></li>\n<li><code>void DrawTetrahedra(bool flag, double y_base );</code></li>\n<li><code>void DrawSpace(bool flag);</code></li>\n<li><code>void DrawMesh(bool flag);</code></li>\n</ol>\n<p>通过这四个功能函数访问LocalMeshing线程生成的三维空间顶点、三角形、边，并对实现这些信息的可视化，对应的文件为<code>MapDrawer.h</code>和<code>MapDrawer.cpp</code>。</p>\n<h2 id=\"函数功能\"><a href=\"#函数功能\" class=\"headerlink\" title=\"函数功能\"></a>函数功能</h2><ol>\n<li>该函数通过接口获取LocalMeshing线程生成的三维顶点，使用<code>GL_POINTS</code>类型，通过<code>glVertex3f()</code>函数将顶点可视化。</li>\n<li>该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形（其实就是三个三维点组成的结构），使用<code>GL_TRIANGLES</code>类型，通过<code>glVertex3f()</code>函数将三角形可视化（这里很有意思，和可视化顶点用的是一个函数～），三角形的各顶点使用的不同颜色。</li>\n<li>该函数通过接口获取LocalMeshing线程生成的三维空间中的边（其实就是两个三维点组成的结构），使用<code>GL_LINES</code>类型，通过<code>glVertex3f()</code>函数将三维边可视化，两个顶点使用的相同颜色。</li>\n<li>该函数通过接口获取LocalMeshing线程生成的三维空间中的三角形，使用<code>GL_LINES</code>类型，通过<code>glVertex3f()</code>函数将三角形可视化，这里三角形的三个顶点使用的同一种颜色。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>无</li>\n</ol>"},{"title":"ROS学习之编写简单的服务器和客户端","date":"2018-03-28T14:11:20.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中服务器和客户端的学习内容。\n\n<!--more--->\n\n**写在篇头：**\n\nROS程序包中一般包含`msg`、`src`、`srv`、`scripts`目录，分别存放`msg`消息文件、C++源文件（`.cpp`）、`srv`服务文件、Python源文件（`.py`），执行`catkin_make`命令编译完成后，`.msg`文件、`srv`文件都会转换为ROS所支持的源代码，并生成C++可执行文件。\n\n1. C++\n\n   - `.msg`、`.srv`文件生成的C++头文件将放在`~/工作空间/devel/include/程序包名/`下\n   - 生成的可执行文件放在`~/工作空间/devel/lib/<package name>` 下\n\n2. Python\n\n   - `.msg`文件生成的Python`.py`脚本文件放在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg`下\n\n   - `.srv`文件生成的Python`.py`脚本文件放在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv`下\n\n   - 使用`chmod +x scripts/xxx.py`命令，使节点文件具有执行属性\n\n     <!--more--->\n\n# 消息(msg)和服务(srv)介绍\n\n- 消息(msg): msg文件就是一个描述ROS中所使用消息类型的简单文本，被存放在package的msg目录下。该文件会被用来生成不同语言的源代码，一般是C++、Python。 msg文件实际上就是每行声明一个数据类型和变量名，可以使用的数据类型如下： \n  - int8, int16, int32, int64 (plus uint*) \n  - float32, float64 \n  - string \n  - time, duration \n  - other msg files \n  - variable-length array[] and fixed-length array[C] \n\n\n- 服务(srv): 一个srv文件描述一项服务， srv文件被存放在srv目录下。 srv文件分为请求和响应两部分，由'---'分隔。下面是srv的一个样例： \n\n  ```\n  int64 A\n  int64 B\n  ---\n  int64 Sum\n  ```\n\n  其中 `A` 和 `B` 是请求, 而`Sum` 是响应。 \n\n# 创建完成该任务的程序包\n\n```shell\ncd ~/catkin_ws/src #工作空间catkin_ws\ncatkin_create_pkg beginner_tutorials std_msgs rospy roscpp #创建程序包\nmkdir -p beginner_tutorials/src　#放置所有源代码\n```\n\n# 创建msg\n\n1. 创建`msg`消息\n\n   ~~~shell\n   mkdir msg #在新创建的程序包目录下\n   echo \"int64 num\" > msg/Num.msg\n   ~~~\n\n\n2. 配置文件\n\n   - `package.xml`中添加：\n\n     ~~~xml\n     <build_depend>message_generation</build_depend\n     <run_depend>message_runtime</run_depend>\n     ~~~\n\n     ​\n\n   - `CMakeList.txt`添加信息的部分：\n\n     ~~~cmake\n     find_package(catkin REQUIRED COMPONENTS\n       roscpp\n       rospy\n       std_msgs\n       message_generation\n     )\n     add_message_files(\n       FILES\n       Num.msg\n     )\n     generate_messages(\n       DEPENDENCIES\n       std_msgs\n     )\n     catkin_package(\n      CATKIN_DEPENDS message_runtime\n     )\n     ~~~\n\n**注意：**执行`catkin_make`编译程序包后，某个程序包中的`.msg`文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在`~/工作空间/devel/include/程序包名/`下，本程序生成`Num.h`。Python脚本语言会在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg` 目录下创建。\n\n# 　创建srv\n\n1. 创建`srv`文件\n\n   ~~~shell\n   mkdir msg　#在新创建的程序包目录下\n   roscp rospy_tutorials AddTwoInts.srv srv/AddTwoInts.srv #从其他程序包中复制一个服务文件\n   ~~~\n\n\n2. 配置文件\n\n   `CMakeList.txt`添加信息的部分：\n\n   ```cmake\n   add_service_files(\n     FILES\n     AddTwoInts.srv\n   )\n   ```\n\n**注意：**执行`catkin_make`编译程序包后，某个程序包中的`.srv`文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在`~/工作空间/devel/include/程序包名/`下，这里生成的是`AddTwoInts.h`。Python脚本语言会在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv` 目录下创建。\n\n# 创建Service节点\n\n创建一个简单的service节点`add_two_ints_server`，该节点将接收到两个整形数字，并返回它们的和。 \n\n在程序包创建`src/add_two_ints_server.cpp`文件：\n\n~~~c++\n#include \"ros/ros.h\"\n//编译系统自动根据先前创建的srv文件生成的对应该srv文件的头文件\n#include \"beginner_tutorials/AddTwoInts.h\"\n\n//提供两个int值的求和服务，int值从request中获取，返回数据装入response，这些数据类型都定义在srv文件内部\nbool add(beginner_tutorials::AddTwoInts::Request  &req,\n         beginner_tutorials::AddTwoInts::Response &res)\n{\n  res.sum = req.a + req.b;\n  ROS_INFO(\"request: x=%ld, y=%ld\", (long int)req.a, (long int)req.b);\n  ROS_INFO(\"sending back response: [%ld]\", (long int)res.sum);\n  return true;\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"add_two_ints_server\");\n  ros::NodeHandle n;\n\n  //service已经建立起来，并在ROS内发布出来，参数add_two_ints与客户端创建client时的参数一致\n  ros::ServiceServer service = n.advertiseService(\"add_two_ints\", add);\n  ROS_INFO(\"Ready to add two ints.\");\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n# 创建Clinet节点\n\n在程序包创建`src/add_two_ints_client.cpp`文件：\n\n~~~c++\n#include \"ros/ros.h\"\n#include \"beginner_tutorials/AddTwoInts.h\"\n#include <cstdlib>\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"add_two_ints_client\");\n  if (argc != 3)\n  {\n    ROS_INFO(\"usage: add_two_ints_client X Y\");\n    return 1;\n  }\n\n  ros::NodeHandle n;\n  //为add_two_ints service创建一个client。ros::ServiceClient 对象会用来调用service\n  ros::ServiceClient client = \n      \t\t\t\t\t\tn.serviceClient<beginner_tutorials::AddTwoInts>(\"add_two_ints\");\n  beginner_tutorials::AddTwoInts srv;\n  srv.request.a = atoll(argv[1]);//long long int atoll ( const char * str );\n  srv.request.b = atoll(argv[2]);\n  \n  //调用service，该过程是模态过程（调用的时候占用进程阻止其他代码的执行），一旦调用完成，将返回调用结果。如果service调用成功，call()函数将返回true，srv.response里面的值将是合法的值。如果调用失败，call()函数将返回false，srv.response里面的值将是非法的。 \n  if (client.call(srv))\n  {\n    ROS_INFO(\"Sum: %ld\", (long int)srv.response.sum);\n  }\n  else\n  {\n    ROS_ERROR(\"Failed to call service add_two_ints\");\n    return 1;\n  }\n\n  return 0;\n}\n~~~\n\n# 编译节点\n\n在`CMakeList.txt`文件末尾添加：\n\n```cmake\nadd_executable(add_two_ints_server src/add_two_ints_server.cpp)\ntarget_link_libraries(add_two_ints_server ${catkin_LIBRARIES})\nadd_dependencies(add_two_ints_server beginner_tutorials_gencpp)　#不加这句也可以\n\nadd_executable(add_two_ints_client src/add_two_ints_client.cpp)\ntarget_link_libraries(add_two_ints_client ${catkin_LIBRARIES})\nadd_dependencies(add_two_ints_client beginner_tutorials_gencpp)　#不加这句也可以\n```\n\n工作空间下执行命令：\n\n~~~shell\ncatkin_make\n~~~\n\n执行结束将生成两个可执行程序`add_two_ints_server`和`add_two_ints_client`，默认放在`devel space`下的包目录下，即`~/工作空间/devel/lib/<package name>`。可以直接调用可执行程序，或者使用rosrun命令去调用。\n\n# 运行节点\n\n1. 启动ROS\n\n   ```shell\n   roscore\n   ```\n\n2. 启动服务端\n\n   ```shell\n   rosrun beginner_tutorials add_two_ints_server\n   ```\n\n3. 启动客户端（带参数）\n\n   ```powershell\n   rosrun beginner_tutorials add_two_ints_client 1 3\n   ```\n\n这样在服务端终端和客户端终端就会看到相应的输出信息。\n","source":"_posts/ROS学习之编写简单的服务器和客户端.md","raw":"---\ntitle: ROS学习之编写简单的服务器和客户端\ndate: 2018-03-28 22:11:20\ntags: \n  - C++\n  - catkin\n  - ROS服务器\n  - ROS客户端\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中服务器和客户端的学习内容。\n\n<!--more--->\n\n**写在篇头：**\n\nROS程序包中一般包含`msg`、`src`、`srv`、`scripts`目录，分别存放`msg`消息文件、C++源文件（`.cpp`）、`srv`服务文件、Python源文件（`.py`），执行`catkin_make`命令编译完成后，`.msg`文件、`srv`文件都会转换为ROS所支持的源代码，并生成C++可执行文件。\n\n1. C++\n\n   - `.msg`、`.srv`文件生成的C++头文件将放在`~/工作空间/devel/include/程序包名/`下\n   - 生成的可执行文件放在`~/工作空间/devel/lib/<package name>` 下\n\n2. Python\n\n   - `.msg`文件生成的Python`.py`脚本文件放在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg`下\n\n   - `.srv`文件生成的Python`.py`脚本文件放在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv`下\n\n   - 使用`chmod +x scripts/xxx.py`命令，使节点文件具有执行属性\n\n     <!--more--->\n\n# 消息(msg)和服务(srv)介绍\n\n- 消息(msg): msg文件就是一个描述ROS中所使用消息类型的简单文本，被存放在package的msg目录下。该文件会被用来生成不同语言的源代码，一般是C++、Python。 msg文件实际上就是每行声明一个数据类型和变量名，可以使用的数据类型如下： \n  - int8, int16, int32, int64 (plus uint*) \n  - float32, float64 \n  - string \n  - time, duration \n  - other msg files \n  - variable-length array[] and fixed-length array[C] \n\n\n- 服务(srv): 一个srv文件描述一项服务， srv文件被存放在srv目录下。 srv文件分为请求和响应两部分，由'---'分隔。下面是srv的一个样例： \n\n  ```\n  int64 A\n  int64 B\n  ---\n  int64 Sum\n  ```\n\n  其中 `A` 和 `B` 是请求, 而`Sum` 是响应。 \n\n# 创建完成该任务的程序包\n\n```shell\ncd ~/catkin_ws/src #工作空间catkin_ws\ncatkin_create_pkg beginner_tutorials std_msgs rospy roscpp #创建程序包\nmkdir -p beginner_tutorials/src　#放置所有源代码\n```\n\n# 创建msg\n\n1. 创建`msg`消息\n\n   ~~~shell\n   mkdir msg #在新创建的程序包目录下\n   echo \"int64 num\" > msg/Num.msg\n   ~~~\n\n\n2. 配置文件\n\n   - `package.xml`中添加：\n\n     ~~~xml\n     <build_depend>message_generation</build_depend\n     <run_depend>message_runtime</run_depend>\n     ~~~\n\n     ​\n\n   - `CMakeList.txt`添加信息的部分：\n\n     ~~~cmake\n     find_package(catkin REQUIRED COMPONENTS\n       roscpp\n       rospy\n       std_msgs\n       message_generation\n     )\n     add_message_files(\n       FILES\n       Num.msg\n     )\n     generate_messages(\n       DEPENDENCIES\n       std_msgs\n     )\n     catkin_package(\n      CATKIN_DEPENDS message_runtime\n     )\n     ~~~\n\n**注意：**执行`catkin_make`编译程序包后，某个程序包中的`.msg`文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在`~/工作空间/devel/include/程序包名/`下，本程序生成`Num.h`。Python脚本语言会在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg` 目录下创建。\n\n# 　创建srv\n\n1. 创建`srv`文件\n\n   ~~~shell\n   mkdir msg　#在新创建的程序包目录下\n   roscp rospy_tutorials AddTwoInts.srv srv/AddTwoInts.srv #从其他程序包中复制一个服务文件\n   ~~~\n\n\n2. 配置文件\n\n   `CMakeList.txt`添加信息的部分：\n\n   ```cmake\n   add_service_files(\n     FILES\n     AddTwoInts.srv\n   )\n   ```\n\n**注意：**执行`catkin_make`编译程序包后，某个程序包中的`.srv`文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在`~/工作空间/devel/include/程序包名/`下，这里生成的是`AddTwoInts.h`。Python脚本语言会在 `~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv` 目录下创建。\n\n# 创建Service节点\n\n创建一个简单的service节点`add_two_ints_server`，该节点将接收到两个整形数字，并返回它们的和。 \n\n在程序包创建`src/add_two_ints_server.cpp`文件：\n\n~~~c++\n#include \"ros/ros.h\"\n//编译系统自动根据先前创建的srv文件生成的对应该srv文件的头文件\n#include \"beginner_tutorials/AddTwoInts.h\"\n\n//提供两个int值的求和服务，int值从request中获取，返回数据装入response，这些数据类型都定义在srv文件内部\nbool add(beginner_tutorials::AddTwoInts::Request  &req,\n         beginner_tutorials::AddTwoInts::Response &res)\n{\n  res.sum = req.a + req.b;\n  ROS_INFO(\"request: x=%ld, y=%ld\", (long int)req.a, (long int)req.b);\n  ROS_INFO(\"sending back response: [%ld]\", (long int)res.sum);\n  return true;\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"add_two_ints_server\");\n  ros::NodeHandle n;\n\n  //service已经建立起来，并在ROS内发布出来，参数add_two_ints与客户端创建client时的参数一致\n  ros::ServiceServer service = n.advertiseService(\"add_two_ints\", add);\n  ROS_INFO(\"Ready to add two ints.\");\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n# 创建Clinet节点\n\n在程序包创建`src/add_two_ints_client.cpp`文件：\n\n~~~c++\n#include \"ros/ros.h\"\n#include \"beginner_tutorials/AddTwoInts.h\"\n#include <cstdlib>\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"add_two_ints_client\");\n  if (argc != 3)\n  {\n    ROS_INFO(\"usage: add_two_ints_client X Y\");\n    return 1;\n  }\n\n  ros::NodeHandle n;\n  //为add_two_ints service创建一个client。ros::ServiceClient 对象会用来调用service\n  ros::ServiceClient client = \n      \t\t\t\t\t\tn.serviceClient<beginner_tutorials::AddTwoInts>(\"add_two_ints\");\n  beginner_tutorials::AddTwoInts srv;\n  srv.request.a = atoll(argv[1]);//long long int atoll ( const char * str );\n  srv.request.b = atoll(argv[2]);\n  \n  //调用service，该过程是模态过程（调用的时候占用进程阻止其他代码的执行），一旦调用完成，将返回调用结果。如果service调用成功，call()函数将返回true，srv.response里面的值将是合法的值。如果调用失败，call()函数将返回false，srv.response里面的值将是非法的。 \n  if (client.call(srv))\n  {\n    ROS_INFO(\"Sum: %ld\", (long int)srv.response.sum);\n  }\n  else\n  {\n    ROS_ERROR(\"Failed to call service add_two_ints\");\n    return 1;\n  }\n\n  return 0;\n}\n~~~\n\n# 编译节点\n\n在`CMakeList.txt`文件末尾添加：\n\n```cmake\nadd_executable(add_two_ints_server src/add_two_ints_server.cpp)\ntarget_link_libraries(add_two_ints_server ${catkin_LIBRARIES})\nadd_dependencies(add_two_ints_server beginner_tutorials_gencpp)　#不加这句也可以\n\nadd_executable(add_two_ints_client src/add_two_ints_client.cpp)\ntarget_link_libraries(add_two_ints_client ${catkin_LIBRARIES})\nadd_dependencies(add_two_ints_client beginner_tutorials_gencpp)　#不加这句也可以\n```\n\n工作空间下执行命令：\n\n~~~shell\ncatkin_make\n~~~\n\n执行结束将生成两个可执行程序`add_two_ints_server`和`add_two_ints_client`，默认放在`devel space`下的包目录下，即`~/工作空间/devel/lib/<package name>`。可以直接调用可执行程序，或者使用rosrun命令去调用。\n\n# 运行节点\n\n1. 启动ROS\n\n   ```shell\n   roscore\n   ```\n\n2. 启动服务端\n\n   ```shell\n   rosrun beginner_tutorials add_two_ints_server\n   ```\n\n3. 启动客户端（带参数）\n\n   ```powershell\n   rosrun beginner_tutorials add_two_ints_client 1 3\n   ```\n\n这样在服务端终端和客户端终端就会看到相应的输出信息。\n","slug":"ROS学习之编写简单的服务器和客户端","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv80029qlcrfyykdafy","content":"<hr>\n<p>这篇文章是有关ROS中服务器和客户端的学习内容。</p>\n<a id=\"more\"></a>\n<p><strong>写在篇头：</strong></p>\n<p>ROS程序包中一般包含<code>msg</code>、<code>src</code>、<code>srv</code>、<code>scripts</code>目录，分别存放<code>msg</code>消息文件、C++源文件（<code>.cpp</code>）、<code>srv</code>服务文件、Python源文件（<code>.py</code>），执行<code>catkin_make</code>命令编译完成后，<code>.msg</code>文件、<code>srv</code>文件都会转换为ROS所支持的源代码，并生成C++可执行文件。</p>\n<ol>\n<li><p>C++</p>\n<ul>\n<li><code>.msg</code>、<code>.srv</code>文件生成的C++头文件将放在<code>~/工作空间/devel/include/程序包名/</code>下</li>\n<li>生成的可执行文件放在<code>~/工作空间/devel/lib/&lt;package name&gt;</code> 下</li>\n</ul>\n</li>\n<li><p>Python</p>\n<ul>\n<li><p><code>.msg</code>文件生成的Python<code>.py</code>脚本文件放在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg</code>下</p>\n</li>\n<li><p><code>.srv</code>文件生成的Python<code>.py</code>脚本文件放在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv</code>下</p>\n</li>\n<li><p>使用<code>chmod +x scripts/xxx.py</code>命令，使节点文件具有执行属性</p>\n<!--more--->\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"消息-msg-和服务-srv-介绍\"><a href=\"#消息-msg-和服务-srv-介绍\" class=\"headerlink\" title=\"消息(msg)和服务(srv)介绍\"></a>消息(msg)和服务(srv)介绍</h1><ul>\n<li>消息(msg): msg文件就是一个描述ROS中所使用消息类型的简单文本，被存放在package的msg目录下。该文件会被用来生成不同语言的源代码，一般是C++、Python。 msg文件实际上就是每行声明一个数据类型和变量名，可以使用的数据类型如下： <ul>\n<li>int8, int16, int32, int64 (plus uint*) </li>\n<li>float32, float64 </li>\n<li>string </li>\n<li>time, duration </li>\n<li>other msg files </li>\n<li>variable-length array[] and fixed-length array[C] </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>服务(srv): 一个srv文件描述一项服务， srv文件被存放在srv目录下。 srv文件分为请求和响应两部分，由’—-‘分隔。下面是srv的一个样例： </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int64 A</span><br><span class=\"line\">int64 B</span><br><span class=\"line\">---</span><br><span class=\"line\">int64 Sum</span><br></pre></td></tr></table></figure>\n<p>其中 <code>A</code> 和 <code>B</code> 是请求, 而<code>Sum</code> 是响应。 </p>\n</li>\n</ul>\n<h1 id=\"创建完成该任务的程序包\"><a href=\"#创建完成该任务的程序包\" class=\"headerlink\" title=\"创建完成该任务的程序包\"></a>创建完成该任务的程序包</h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/catkin_ws/src #工作空间catkin_ws</span><br><span class=\"line\">catkin_create_pkg beginner_tutorials std_msgs rospy roscpp #创建程序包</span><br><span class=\"line\">mkdir -p beginner_tutorials/src　#放置所有源代码</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建msg\"><a href=\"#创建msg\" class=\"headerlink\" title=\"创建msg\"></a>创建msg</h1><ol>\n<li><p>创建<code>msg</code>消息</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir msg #在新创建的程序包目录下</span><br><span class=\"line\">echo \"int64 num\" &gt; msg/Num.msg</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置文件</p>\n<ul>\n<li><p><code>package.xml</code>中添加：</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>message_generation<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span></span></span><br><span class=\"line\">&lt;run_depend&gt;message_runtime&lt;/run_depend&gt;</span><br></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p><code>CMakeList.txt</code>添加信息的部分：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">  message_generation</span><br><span class=\"line\">)</span><br><span class=\"line\">add_message_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  Num.msg</span><br><span class=\"line\">)</span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\"> CATKIN_DEPENDS message_runtime</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ol>\n<p><strong>注意：</strong>执行<code>catkin_make</code>编译程序包后，某个程序包中的<code>.msg</code>文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在<code>~/工作空间/devel/include/程序包名/</code>下，本程序生成<code>Num.h</code>。Python脚本语言会在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg</code> 目录下创建。</p>\n<h1 id=\"创建srv\"><a href=\"#创建srv\" class=\"headerlink\" title=\"　创建srv\"></a>　创建srv</h1><ol>\n<li><p>创建<code>srv</code>文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir msg　#在新创建的程序包目录下</span><br><span class=\"line\">roscp rospy_tutorials AddTwoInts.srv srv/AddTwoInts.srv #从其他程序包中复制一个服务文件</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置文件</p>\n<p><code>CMakeList.txt</code>添加信息的部分：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_service_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  AddTwoInts.srv</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><strong>注意：</strong>执行<code>catkin_make</code>编译程序包后，某个程序包中的<code>.srv</code>文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在<code>~/工作空间/devel/include/程序包名/</code>下，这里生成的是<code>AddTwoInts.h</code>。Python脚本语言会在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv</code> 目录下创建。</p>\n<h1 id=\"创建Service节点\"><a href=\"#创建Service节点\" class=\"headerlink\" title=\"创建Service节点\"></a>创建Service节点</h1><p>创建一个简单的service节点<code>add_two_ints_server</code>，该节点将接收到两个整形数字，并返回它们的和。 </p>\n<p>在程序包创建<code>src/add_two_ints_server.cpp</code>文件：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"ros/ros.h\"</span></span></span><br><span class=\"line\"><span class=\"comment\">//编译系统自动根据先前创建的srv文件生成的对应该srv文件的头文件</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"beginner_tutorials/AddTwoInts.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//提供两个int值的求和服务，int值从request中获取，返回数据装入response，这些数据类型都定义在srv文件内部</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">add</span><span class=\"params\">(beginner_tutorials::AddTwoInts::Request  &amp;req,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         beginner_tutorials::AddTwoInts::Response &amp;res)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  res.sum = req.a + req.b;</span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"request: x=%ld, y=%ld\"</span>, (<span class=\"keyword\">long</span> <span class=\"keyword\">int</span>)req.a, (<span class=\"keyword\">long</span> <span class=\"keyword\">int</span>)req.b);</span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"sending back response: [%ld]\"</span>, (<span class=\"keyword\">long</span> <span class=\"keyword\">int</span>)res.sum);</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"add_two_ints_server\"</span>);</span><br><span class=\"line\">  ros::NodeHandle n;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//service已经建立起来，并在ROS内发布出来，参数add_two_ints与客户端创建client时的参数一致</span></span><br><span class=\"line\">  ros::ServiceServer service = n.advertiseService(<span class=\"string\">\"add_two_ints\"</span>, add);</span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Ready to add two ints.\"</span>);</span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建Clinet节点\"><a href=\"#创建Clinet节点\" class=\"headerlink\" title=\"创建Clinet节点\"></a>创建Clinet节点</h1><p>在程序包创建<code>src/add_two_ints_client.cpp</code>文件：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"ros/ros.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"beginner_tutorials/AddTwoInts.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdlib&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"add_two_ints_client\"</span>);</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (argc != <span class=\"number\">3</span>)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"usage: add_two_ints_client X Y\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle n;</span><br><span class=\"line\">  <span class=\"comment\">//为add_two_ints service创建一个client。ros::ServiceClient 对象会用来调用service</span></span><br><span class=\"line\">  ros::ServiceClient client = </span><br><span class=\"line\">      \t\t\t\t\t\tn.serviceClient&lt;beginner_tutorials::AddTwoInts&gt;(<span class=\"string\">\"add_two_ints\"</span>);</span><br><span class=\"line\">  beginner_tutorials::AddTwoInts srv;</span><br><span class=\"line\">  srv.request.a = atoll(argv[<span class=\"number\">1</span>]);<span class=\"comment\">//long long int atoll ( const char * str );</span></span><br><span class=\"line\">  srv.request.b = atoll(argv[<span class=\"number\">2</span>]);</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\">//调用service，该过程是模态过程（调用的时候占用进程阻止其他代码的执行），一旦调用完成，将返回调用结果。如果service调用成功，call()函数将返回true，srv.response里面的值将是合法的值。如果调用失败，call()函数将返回false，srv.response里面的值将是非法的。 </span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (client.call(srv))</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Sum: %ld\"</span>, (<span class=\"keyword\">long</span> <span class=\"keyword\">int</span>)srv.response.sum);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">else</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    ROS_ERROR(<span class=\"string\">\"Failed to call service add_two_ints\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"编译节点\"><a href=\"#编译节点\" class=\"headerlink\" title=\"编译节点\"></a>编译节点</h1><p>在<code>CMakeList.txt</code>文件末尾添加：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(add_two_ints_server src/add_two_ints_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(add_two_ints_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(add_two_ints_server beginner_tutorials_gencpp)　<span class=\"comment\">#不加这句也可以</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(add_two_ints_client src/add_two_ints_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(add_two_ints_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(add_two_ints_client beginner_tutorials_gencpp)　<span class=\"comment\">#不加这句也可以</span></span><br></pre></td></tr></table></figure>\n<p>工作空间下执行命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_make</span><br></pre></td></tr></table></figure>\n<p>执行结束将生成两个可执行程序<code>add_two_ints_server</code>和<code>add_two_ints_client</code>，默认放在<code>devel space</code>下的包目录下，即<code>~/工作空间/devel/lib/&lt;package name&gt;</code>。可以直接调用可执行程序，或者使用rosrun命令去调用。</p>\n<h1 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h1><ol>\n<li><p>启动ROS</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscore</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动服务端</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun beginner_tutorials add_two_ints_server</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动客户端（带参数）</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun beginner_tutorials add_two_ints_client <span class=\"number\">1</span> <span class=\"number\">3</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>这样在服务端终端和客户端终端就会看到相应的输出信息。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中服务器和客户端的学习内容。</p>","more":"<p><strong>写在篇头：</strong></p>\n<p>ROS程序包中一般包含<code>msg</code>、<code>src</code>、<code>srv</code>、<code>scripts</code>目录，分别存放<code>msg</code>消息文件、C++源文件（<code>.cpp</code>）、<code>srv</code>服务文件、Python源文件（<code>.py</code>），执行<code>catkin_make</code>命令编译完成后，<code>.msg</code>文件、<code>srv</code>文件都会转换为ROS所支持的源代码，并生成C++可执行文件。</p>\n<ol>\n<li><p>C++</p>\n<ul>\n<li><code>.msg</code>、<code>.srv</code>文件生成的C++头文件将放在<code>~/工作空间/devel/include/程序包名/</code>下</li>\n<li>生成的可执行文件放在<code>~/工作空间/devel/lib/&lt;package name&gt;</code> 下</li>\n</ul>\n</li>\n<li><p>Python</p>\n<ul>\n<li><p><code>.msg</code>文件生成的Python<code>.py</code>脚本文件放在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg</code>下</p>\n</li>\n<li><p><code>.srv</code>文件生成的Python<code>.py</code>脚本文件放在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv</code>下</p>\n</li>\n<li><p>使用<code>chmod +x scripts/xxx.py</code>命令，使节点文件具有执行属性</p>\n<!--more--->\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"消息-msg-和服务-srv-介绍\"><a href=\"#消息-msg-和服务-srv-介绍\" class=\"headerlink\" title=\"消息(msg)和服务(srv)介绍\"></a>消息(msg)和服务(srv)介绍</h1><ul>\n<li>消息(msg): msg文件就是一个描述ROS中所使用消息类型的简单文本，被存放在package的msg目录下。该文件会被用来生成不同语言的源代码，一般是C++、Python。 msg文件实际上就是每行声明一个数据类型和变量名，可以使用的数据类型如下： <ul>\n<li>int8, int16, int32, int64 (plus uint*) </li>\n<li>float32, float64 </li>\n<li>string </li>\n<li>time, duration </li>\n<li>other msg files </li>\n<li>variable-length array[] and fixed-length array[C] </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>服务(srv): 一个srv文件描述一项服务， srv文件被存放在srv目录下。 srv文件分为请求和响应两部分，由’—-‘分隔。下面是srv的一个样例： </p>\n<!--�62-->\n<p>其中 <code>A</code> 和 <code>B</code> 是请求, 而<code>Sum</code> 是响应。 </p>\n</li>\n</ul>\n<h1 id=\"创建完成该任务的程序包\"><a href=\"#创建完成该任务的程序包\" class=\"headerlink\" title=\"创建完成该任务的程序包\"></a>创建完成该任务的程序包</h1><!--�63-->\n<h1 id=\"创建msg\"><a href=\"#创建msg\" class=\"headerlink\" title=\"创建msg\"></a>创建msg</h1><ol>\n<li><p>创建<code>msg</code>消息</p>\n<!--�64-->\n</li>\n<li><p>配置文件</p>\n<ul>\n<li><p><code>package.xml</code>中添加：</p>\n<!--�65-->\n<p>​</p>\n</li>\n<li><p><code>CMakeList.txt</code>添加信息的部分：</p>\n<!--�66-->\n</li>\n</ul>\n</li>\n</ol>\n<p><strong>注意：</strong>执行<code>catkin_make</code>编译程序包后，某个程序包中的<code>.msg</code>文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在<code>~/工作空间/devel/include/程序包名/</code>下，本程序生成<code>Num.h</code>。Python脚本语言会在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/msg</code> 目录下创建。</p>\n<h1 id=\"创建srv\"><a href=\"#创建srv\" class=\"headerlink\" title=\"　创建srv\"></a>　创建srv</h1><ol>\n<li><p>创建<code>srv</code>文件</p>\n<!--�67-->\n</li>\n<li><p>配置文件</p>\n<p><code>CMakeList.txt</code>添加信息的部分：</p>\n<!--�68-->\n</li>\n</ol>\n<p><strong>注意：</strong>执行<code>catkin_make</code>编译程序包后，某个程序包中的<code>.srv</code>文件都会转换为ROS所支持的源代码，生成的C++头文件将会放置在<code>~/工作空间/devel/include/程序包名/</code>下，这里生成的是<code>AddTwoInts.h</code>。Python脚本语言会在 <code>~/工作空间/devel/lib/python2.7/dist-packages/程序包名/srv</code> 目录下创建。</p>\n<h1 id=\"创建Service节点\"><a href=\"#创建Service节点\" class=\"headerlink\" title=\"创建Service节点\"></a>创建Service节点</h1><p>创建一个简单的service节点<code>add_two_ints_server</code>，该节点将接收到两个整形数字，并返回它们的和。 </p>\n<p>在程序包创建<code>src/add_two_ints_server.cpp</code>文件：</p>\n<!--�69-->\n<h1 id=\"创建Clinet节点\"><a href=\"#创建Clinet节点\" class=\"headerlink\" title=\"创建Clinet节点\"></a>创建Clinet节点</h1><p>在程序包创建<code>src/add_two_ints_client.cpp</code>文件：</p>\n<!--�70-->\n<h1 id=\"编译节点\"><a href=\"#编译节点\" class=\"headerlink\" title=\"编译节点\"></a>编译节点</h1><p>在<code>CMakeList.txt</code>文件末尾添加：</p>\n<!--�71-->\n<p>工作空间下执行命令：</p>\n<!--�72-->\n<p>执行结束将生成两个可执行程序<code>add_two_ints_server</code>和<code>add_two_ints_client</code>，默认放在<code>devel space</code>下的包目录下，即<code>~/工作空间/devel/lib/&lt;package name&gt;</code>。可以直接调用可执行程序，或者使用rosrun命令去调用。</p>\n<h1 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h1><ol>\n<li><p>启动ROS</p>\n<!--�73-->\n</li>\n<li><p>启动服务端</p>\n<!--�74-->\n</li>\n<li><p>启动客户端（带参数）</p>\n<!--�75-->\n</li>\n</ol>\n<p>这样在服务端终端和客户端终端就会看到相应的输出信息。</p>"},{"title":"python学习记录","date":"2019-06-03T15:02:49.000Z","copyright":true,"_content":"---\n\n-\n\n<!--more--->\n\n查看python的路径：\n\n```\nwhereis python\n```\n\nubuntu下切换python版本：\n\nhttps://blog.csdn.net/beijiu5854/article/details/77897767\n\nanaconda和ROS共存：\n\nhttps://www.jianshu.com/p/4e437e25480b\n\ntensorflow环境搭建过程：\n\n- 安装virtualenv：`sudo apt-get install python-virtualenv`\n- `mkdir envs`\n- `cd evns`\n- 创建虚拟环境：`virtualenv -p /usr/bin/python3 tensorflow`\n- 激活虚拟环境：`source ~/envs/tensorflow/bin/activate`\n- 安装tensorflow：`pip install tensorflow`\n\n在`~/.bashrc`文件中添加命令：\n\n`alias tensorflow=\"source ~/envs/tensorflow/bin/activate\"`\n\n这样就可以在shell中使用`tensorflow`命令激活虚拟环境。\n\n在tensorflow虚拟环境中搭建Jupyter Notebook环境：\n\n- 激活virtualenv：`tensorflow`\n- 执行：`sudo pip3 install jupyter ipython`\n- 执行：`sudo pip3 install ipykernel`\n- 将 Virtualenv 加入IPykernel中：`sudo python3 -m ipykernel install --user --name tf1 --display-name 'Python(tf1)'`，其中`--name your-name1`是给Jupter启动Kernel使用的名字，`--display-name 'your-name2'`是Jupyter notebook 菜单显示的名字。（不使用`sudo`可能会出现错误`/home/eric/envs/tensorflow/bin/python3: No module named ipykernel`）\n- 启动：`jupyter notebook`，shell中会有类似提示`本程序运行在: http://localhost:8888/?token=xxxxx`，点击在浏览器打开，并选择所需要的内核`Python(tf1)`，即`'your-name2'`。\n\n\n\n## 使用Anaconda搭建tensorflow环境\n\n```shell\nconda create -n EVSegNet python=2.7\npip install tensorflow-gpu==1.11.0\n```\n\n\n\n## GPU情况查看\n\n```shell\n# 查看GPU情况：（找一个空闲GPU→记录id）\nnvidia-smi\nnvidia-smi -l           # 自动刷新显示\nwatch -n 1 nvidia-smi   # 动态显示\n```\n\n","source":"_posts/python学习记录.md","raw":"---\ntitle: python学习记录\ndate: 2019-06-03 23:02:49\ntags:\n  - Python\ncategories: \n  - 语言\n  - Python\ncopyright: true\n---\n---\n\n-\n\n<!--more--->\n\n查看python的路径：\n\n```\nwhereis python\n```\n\nubuntu下切换python版本：\n\nhttps://blog.csdn.net/beijiu5854/article/details/77897767\n\nanaconda和ROS共存：\n\nhttps://www.jianshu.com/p/4e437e25480b\n\ntensorflow环境搭建过程：\n\n- 安装virtualenv：`sudo apt-get install python-virtualenv`\n- `mkdir envs`\n- `cd evns`\n- 创建虚拟环境：`virtualenv -p /usr/bin/python3 tensorflow`\n- 激活虚拟环境：`source ~/envs/tensorflow/bin/activate`\n- 安装tensorflow：`pip install tensorflow`\n\n在`~/.bashrc`文件中添加命令：\n\n`alias tensorflow=\"source ~/envs/tensorflow/bin/activate\"`\n\n这样就可以在shell中使用`tensorflow`命令激活虚拟环境。\n\n在tensorflow虚拟环境中搭建Jupyter Notebook环境：\n\n- 激活virtualenv：`tensorflow`\n- 执行：`sudo pip3 install jupyter ipython`\n- 执行：`sudo pip3 install ipykernel`\n- 将 Virtualenv 加入IPykernel中：`sudo python3 -m ipykernel install --user --name tf1 --display-name 'Python(tf1)'`，其中`--name your-name1`是给Jupter启动Kernel使用的名字，`--display-name 'your-name2'`是Jupyter notebook 菜单显示的名字。（不使用`sudo`可能会出现错误`/home/eric/envs/tensorflow/bin/python3: No module named ipykernel`）\n- 启动：`jupyter notebook`，shell中会有类似提示`本程序运行在: http://localhost:8888/?token=xxxxx`，点击在浏览器打开，并选择所需要的内核`Python(tf1)`，即`'your-name2'`。\n\n\n\n## 使用Anaconda搭建tensorflow环境\n\n```shell\nconda create -n EVSegNet python=2.7\npip install tensorflow-gpu==1.11.0\n```\n\n\n\n## GPU情况查看\n\n```shell\n# 查看GPU情况：（找一个空闲GPU→记录id）\nnvidia-smi\nnvidia-smi -l           # 自动刷新显示\nwatch -n 1 nvidia-smi   # 动态显示\n```\n\n","slug":"python学习记录","published":1,"updated":"2019-08-16T00:50:58.228Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbv9002cqlcrg9q9x1v8","content":"<hr>\n<p>-</p>\n<a id=\"more\"></a>\n<p>查看python的路径：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">whereis python</span><br></pre></td></tr></table></figure>\n<p>ubuntu下切换python版本：</p>\n<p><a href=\"https://blog.csdn.net/beijiu5854/article/details/77897767\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/beijiu5854/article/details/77897767</a></p>\n<p>anaconda和ROS共存：</p>\n<p><a href=\"https://www.jianshu.com/p/4e437e25480b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/4e437e25480b</a></p>\n<p>tensorflow环境搭建过程：</p>\n<ul>\n<li>安装virtualenv：<code>sudo apt-get install python-virtualenv</code></li>\n<li><code>mkdir envs</code></li>\n<li><code>cd evns</code></li>\n<li>创建虚拟环境：<code>virtualenv -p /usr/bin/python3 tensorflow</code></li>\n<li>激活虚拟环境：<code>source ~/envs/tensorflow/bin/activate</code></li>\n<li>安装tensorflow：<code>pip install tensorflow</code></li>\n</ul>\n<p>在<code>~/.bashrc</code>文件中添加命令：</p>\n<p><code>alias tensorflow=&quot;source ~/envs/tensorflow/bin/activate&quot;</code></p>\n<p>这样就可以在shell中使用<code>tensorflow</code>命令激活虚拟环境。</p>\n<p>在tensorflow虚拟环境中搭建Jupyter Notebook环境：</p>\n<ul>\n<li>激活virtualenv：<code>tensorflow</code></li>\n<li>执行：<code>sudo pip3 install jupyter ipython</code></li>\n<li>执行：<code>sudo pip3 install ipykernel</code></li>\n<li>将 Virtualenv 加入IPykernel中：<code>sudo python3 -m ipykernel install --user --name tf1 --display-name &#39;Python(tf1)&#39;</code>，其中<code>--name your-name1</code>是给Jupter启动Kernel使用的名字，<code>--display-name &#39;your-name2&#39;</code>是Jupyter notebook 菜单显示的名字。（不使用<code>sudo</code>可能会出现错误<code>/home/eric/envs/tensorflow/bin/python3: No module named ipykernel</code>）</li>\n<li>启动：<code>jupyter notebook</code>，shell中会有类似提示<code>本程序运行在: http://localhost:8888/?token=xxxxx</code>，点击在浏览器打开，并选择所需要的内核<code>Python(tf1)</code>，即<code>&#39;your-name2&#39;</code>。</li>\n</ul>\n<h2 id=\"使用Anaconda搭建tensorflow环境\"><a href=\"#使用Anaconda搭建tensorflow环境\" class=\"headerlink\" title=\"使用Anaconda搭建tensorflow环境\"></a>使用Anaconda搭建tensorflow环境</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n EVSegNet python=2.7</span><br><span class=\"line\">pip install tensorflow-gpu==1.11.0</span><br></pre></td></tr></table></figure>\n<h2 id=\"GPU情况查看\"><a href=\"#GPU情况查看\" class=\"headerlink\" title=\"GPU情况查看\"></a>GPU情况查看</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> 查看GPU情况：（找一个空闲GPU→记录id）</span><br><span class=\"line\">nvidia-smi</span><br><span class=\"line\">nvidia-smi -l           # 自动刷新显示</span><br><span class=\"line\">watch -n 1 nvidia-smi   # 动态显示</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<hr>\n<p>-</p>","more":"<p>查看python的路径：</p>\n<!--�76-->\n<p>ubuntu下切换python版本：</p>\n<p><a href=\"https://blog.csdn.net/beijiu5854/article/details/77897767\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/beijiu5854/article/details/77897767</a></p>\n<p>anaconda和ROS共存：</p>\n<p><a href=\"https://www.jianshu.com/p/4e437e25480b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/4e437e25480b</a></p>\n<p>tensorflow环境搭建过程：</p>\n<ul>\n<li>安装virtualenv：<code>sudo apt-get install python-virtualenv</code></li>\n<li><code>mkdir envs</code></li>\n<li><code>cd evns</code></li>\n<li>创建虚拟环境：<code>virtualenv -p /usr/bin/python3 tensorflow</code></li>\n<li>激活虚拟环境：<code>source ~/envs/tensorflow/bin/activate</code></li>\n<li>安装tensorflow：<code>pip install tensorflow</code></li>\n</ul>\n<p>在<code>~/.bashrc</code>文件中添加命令：</p>\n<p><code>alias tensorflow=&quot;source ~/envs/tensorflow/bin/activate&quot;</code></p>\n<p>这样就可以在shell中使用<code>tensorflow</code>命令激活虚拟环境。</p>\n<p>在tensorflow虚拟环境中搭建Jupyter Notebook环境：</p>\n<ul>\n<li>激活virtualenv：<code>tensorflow</code></li>\n<li>执行：<code>sudo pip3 install jupyter ipython</code></li>\n<li>执行：<code>sudo pip3 install ipykernel</code></li>\n<li>将 Virtualenv 加入IPykernel中：<code>sudo python3 -m ipykernel install --user --name tf1 --display-name &#39;Python(tf1)&#39;</code>，其中<code>--name your-name1</code>是给Jupter启动Kernel使用的名字，<code>--display-name &#39;your-name2&#39;</code>是Jupyter notebook 菜单显示的名字。（不使用<code>sudo</code>可能会出现错误<code>/home/eric/envs/tensorflow/bin/python3: No module named ipykernel</code>）</li>\n<li>启动：<code>jupyter notebook</code>，shell中会有类似提示<code>本程序运行在: http://localhost:8888/?token=xxxxx</code>，点击在浏览器打开，并选择所需要的内核<code>Python(tf1)</code>，即<code>&#39;your-name2&#39;</code>。</li>\n</ul>\n<h2 id=\"使用Anaconda搭建tensorflow环境\"><a href=\"#使用Anaconda搭建tensorflow环境\" class=\"headerlink\" title=\"使用Anaconda搭建tensorflow环境\"></a>使用Anaconda搭建tensorflow环境</h2><!--�77-->\n<h2 id=\"GPU情况查看\"><a href=\"#GPU情况查看\" class=\"headerlink\" title=\"GPU情况查看\"></a>GPU情况查看</h2><!--�78-->"},{"title":"ubuntu一些方便的命令","date":"2018-04-21T03:12:32.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ubuntu下一些常用命令行指令的内容。\n\n<!--more--->\n\n### 查看opencv的版本\n\n~~~shell\npkg-config --modversion opencv\n~~~\n\n### 查看显卡信息\n\n~~~shell\nlspci |grep VGA\n~~~\n\n### 显示设备信息\n\n~~~shell\nlspci\n~~~\n\n### 查看ubuntu系统版本\n\n~~~shell\nlsb_release -a\n~~~\n\n### 查看内核版本\n\n~~~shell\nuname -a\n~~~\n\n或\n\n~~~shell\ncat /proc/version\n~~~\n\n### 查看nvidia显卡信息\n\n~~~\nnvidia-smi\nnvidia-settings\n~~~\n\n","source":"_posts/ubuntu一些方便的命令.md","raw":"---\ntitle: ubuntu一些方便的命令\ndate: 2018-04-21 11:12:32\ntags:\n  - ubuntu\n  - cmake\n  - vscode\n  - debug\ncategories: \n  - 工具\n  - VSCode\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ubuntu下一些常用命令行指令的内容。\n\n<!--more--->\n\n### 查看opencv的版本\n\n~~~shell\npkg-config --modversion opencv\n~~~\n\n### 查看显卡信息\n\n~~~shell\nlspci |grep VGA\n~~~\n\n### 显示设备信息\n\n~~~shell\nlspci\n~~~\n\n### 查看ubuntu系统版本\n\n~~~shell\nlsb_release -a\n~~~\n\n### 查看内核版本\n\n~~~shell\nuname -a\n~~~\n\n或\n\n~~~shell\ncat /proc/version\n~~~\n\n### 查看nvidia显卡信息\n\n~~~\nnvidia-smi\nnvidia-settings\n~~~\n\n","slug":"ubuntu一些方便的命令","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvb002gqlcruy22yfcc","content":"<hr>\n<p>这篇文章是有关ubuntu下一些常用命令行指令的内容。</p>\n<a id=\"more\"></a>\n<h3 id=\"查看opencv的版本\"><a href=\"#查看opencv的版本\" class=\"headerlink\" title=\"查看opencv的版本\"></a>查看opencv的版本</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pkg-config --modversion opencv</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看显卡信息\"><a href=\"#查看显卡信息\" class=\"headerlink\" title=\"查看显卡信息\"></a>查看显卡信息</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lspci |grep VGA</span><br></pre></td></tr></table></figure>\n<h3 id=\"显示设备信息\"><a href=\"#显示设备信息\" class=\"headerlink\" title=\"显示设备信息\"></a>显示设备信息</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lspci</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看ubuntu系统版本\"><a href=\"#查看ubuntu系统版本\" class=\"headerlink\" title=\"查看ubuntu系统版本\"></a>查看ubuntu系统版本</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lsb_release -a</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看内核版本\"><a href=\"#查看内核版本\" class=\"headerlink\" title=\"查看内核版本\"></a>查看内核版本</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">uname -a</span><br></pre></td></tr></table></figure>\n<p>或</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/version</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看nvidia显卡信息\"><a href=\"#查看nvidia显卡信息\" class=\"headerlink\" title=\"查看nvidia显卡信息\"></a>查看nvidia显卡信息</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvidia-smi</span><br><span class=\"line\">nvidia-settings</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ubuntu下一些常用命令行指令的内容。</p>","more":"<h3 id=\"查看opencv的版本\"><a href=\"#查看opencv的版本\" class=\"headerlink\" title=\"查看opencv的版本\"></a>查看opencv的版本</h3><!--�79-->\n<h3 id=\"查看显卡信息\"><a href=\"#查看显卡信息\" class=\"headerlink\" title=\"查看显卡信息\"></a>查看显卡信息</h3><!--�80-->\n<h3 id=\"显示设备信息\"><a href=\"#显示设备信息\" class=\"headerlink\" title=\"显示设备信息\"></a>显示设备信息</h3><!--�81-->\n<h3 id=\"查看ubuntu系统版本\"><a href=\"#查看ubuntu系统版本\" class=\"headerlink\" title=\"查看ubuntu系统版本\"></a>查看ubuntu系统版本</h3><!--�82-->\n<h3 id=\"查看内核版本\"><a href=\"#查看内核版本\" class=\"headerlink\" title=\"查看内核版本\"></a>查看内核版本</h3><!--�83-->\n<p>或</p>\n<!--�84-->\n<h3 id=\"查看nvidia显卡信息\"><a href=\"#查看nvidia显卡信息\" class=\"headerlink\" title=\"查看nvidia显卡信息\"></a>查看nvidia显卡信息</h3><!--�85-->"},{"title":"Tensorflow学习笔记","date":"2019-06-13T05:55:22.000Z","mathjax":true,"copyright":true,"_content":"---\n\n记录学习Tensorflow过程中的一些重要内容。\n<!--more--->\n\n## 卷积神经网络\n\n\n\n## 图像数据处理\n\n虽然，复杂的预处理过程会减慢整个训练过程。但，通过对图像的预处理，可以尽量避免模型收到无关因素的影响。在大部分图像识别问题中，通过图像预处理过程可以提高模型的准确率。Tensorflow中的图像处理函数：\n\n- 图像解码处理：`tf.image.decode_jpeg`、`tf.image.decode_png`\n- 图像编码处理：`tf.image.encode_jpeg`、`tf.image.encode_png`\n- 图像大小调整：`tf.image.resize_images`，可以选择双线性插值、最近邻居法、双三插值法、面积插值法\n- 图像数据转化为实数类型：`tf.image.convert_image_dtype`\n- 图像裁剪或填充：`tf.image.resize_image_with_crop_or_pad`\n- 图像大小按比例调整：`tf.image.central_crop`\n- 图像翻转：`tf.image.flip_up_down`、`tf.image.flip_left_right`、`tf.image.random_flip_up_down`、`tf.image.random_flip_left_right`\n- 图像色彩调整：`tf.image.adjust_brightness`、`tf.image.random_brightness`\n- 图像对比度调整：`tf.image.adjust_contrast`、`tf.image.random_contrast`\n- 图像色相调整：`tf.image.adjust_hue`、`tf.image.random_hue`\n- 图像饱和度调整：`tf.image.adjust_saturation`、`tf.image.random_saturation`\n\n### 队列\n\nTensorflow提供`FIFOQueue`、`RandomShuffleQueue`两种队列，前者是先进先出队列，后者是随机队列，即每次出队列操作得到的是当前队列所有元素中随机选择的一个元素。队列的作用总结如下：\n\n- 一种数据结构\n- 也是异步计算张量取值的一个重要机制，如多线程可同时向一个队列中写元素，或同时读取一个队列中的元素。\n\n","source":"_posts/Tensorflow学习笔记.md","raw":"---\ntitle: Tensorflow学习笔记\ndate: 2019-06-13 13:55:22\ntags:\n  - Tensorflow\ncategories:\n  - 深度学习\n  - Tensorflow\nmathjax: true\ncopyright: true\n---\n---\n\n记录学习Tensorflow过程中的一些重要内容。\n<!--more--->\n\n## 卷积神经网络\n\n\n\n## 图像数据处理\n\n虽然，复杂的预处理过程会减慢整个训练过程。但，通过对图像的预处理，可以尽量避免模型收到无关因素的影响。在大部分图像识别问题中，通过图像预处理过程可以提高模型的准确率。Tensorflow中的图像处理函数：\n\n- 图像解码处理：`tf.image.decode_jpeg`、`tf.image.decode_png`\n- 图像编码处理：`tf.image.encode_jpeg`、`tf.image.encode_png`\n- 图像大小调整：`tf.image.resize_images`，可以选择双线性插值、最近邻居法、双三插值法、面积插值法\n- 图像数据转化为实数类型：`tf.image.convert_image_dtype`\n- 图像裁剪或填充：`tf.image.resize_image_with_crop_or_pad`\n- 图像大小按比例调整：`tf.image.central_crop`\n- 图像翻转：`tf.image.flip_up_down`、`tf.image.flip_left_right`、`tf.image.random_flip_up_down`、`tf.image.random_flip_left_right`\n- 图像色彩调整：`tf.image.adjust_brightness`、`tf.image.random_brightness`\n- 图像对比度调整：`tf.image.adjust_contrast`、`tf.image.random_contrast`\n- 图像色相调整：`tf.image.adjust_hue`、`tf.image.random_hue`\n- 图像饱和度调整：`tf.image.adjust_saturation`、`tf.image.random_saturation`\n\n### 队列\n\nTensorflow提供`FIFOQueue`、`RandomShuffleQueue`两种队列，前者是先进先出队列，后者是随机队列，即每次出队列操作得到的是当前队列所有元素中随机选择的一个元素。队列的作用总结如下：\n\n- 一种数据结构\n- 也是异步计算张量取值的一个重要机制，如多线程可同时向一个队列中写元素，或同时读取一个队列中的元素。\n\n","slug":"Tensorflow学习笔记","published":1,"updated":"2019-06-13T06:26:57.217Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvd002kqlcrwx05hmw2","content":"<hr>\n<p>记录学习Tensorflow过程中的一些重要内容。<br><a id=\"more\"></a></p>\n<h2 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h2><h2 id=\"图像数据处理\"><a href=\"#图像数据处理\" class=\"headerlink\" title=\"图像数据处理\"></a>图像数据处理</h2><p>虽然，复杂的预处理过程会减慢整个训练过程。但，通过对图像的预处理，可以尽量避免模型收到无关因素的影响。在大部分图像识别问题中，通过图像预处理过程可以提高模型的准确率。Tensorflow中的图像处理函数：</p>\n<ul>\n<li>图像解码处理：<code>tf.image.decode_jpeg</code>、<code>tf.image.decode_png</code></li>\n<li>图像编码处理：<code>tf.image.encode_jpeg</code>、<code>tf.image.encode_png</code></li>\n<li>图像大小调整：<code>tf.image.resize_images</code>，可以选择双线性插值、最近邻居法、双三插值法、面积插值法</li>\n<li>图像数据转化为实数类型：<code>tf.image.convert_image_dtype</code></li>\n<li>图像裁剪或填充：<code>tf.image.resize_image_with_crop_or_pad</code></li>\n<li>图像大小按比例调整：<code>tf.image.central_crop</code></li>\n<li>图像翻转：<code>tf.image.flip_up_down</code>、<code>tf.image.flip_left_right</code>、<code>tf.image.random_flip_up_down</code>、<code>tf.image.random_flip_left_right</code></li>\n<li>图像色彩调整：<code>tf.image.adjust_brightness</code>、<code>tf.image.random_brightness</code></li>\n<li>图像对比度调整：<code>tf.image.adjust_contrast</code>、<code>tf.image.random_contrast</code></li>\n<li>图像色相调整：<code>tf.image.adjust_hue</code>、<code>tf.image.random_hue</code></li>\n<li>图像饱和度调整：<code>tf.image.adjust_saturation</code>、<code>tf.image.random_saturation</code></li>\n</ul>\n<h3 id=\"队列\"><a href=\"#队列\" class=\"headerlink\" title=\"队列\"></a>队列</h3><p>Tensorflow提供<code>FIFOQueue</code>、<code>RandomShuffleQueue</code>两种队列，前者是先进先出队列，后者是随机队列，即每次出队列操作得到的是当前队列所有元素中随机选择的一个元素。队列的作用总结如下：</p>\n<ul>\n<li>一种数据结构</li>\n<li>也是异步计算张量取值的一个重要机制，如多线程可同时向一个队列中写元素，或同时读取一个队列中的元素。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<hr>\n<p>记录学习Tensorflow过程中的一些重要内容。<br>","more":"</p>\n<h2 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h2><h2 id=\"图像数据处理\"><a href=\"#图像数据处理\" class=\"headerlink\" title=\"图像数据处理\"></a>图像数据处理</h2><p>虽然，复杂的预处理过程会减慢整个训练过程。但，通过对图像的预处理，可以尽量避免模型收到无关因素的影响。在大部分图像识别问题中，通过图像预处理过程可以提高模型的准确率。Tensorflow中的图像处理函数：</p>\n<ul>\n<li>图像解码处理：<code>tf.image.decode_jpeg</code>、<code>tf.image.decode_png</code></li>\n<li>图像编码处理：<code>tf.image.encode_jpeg</code>、<code>tf.image.encode_png</code></li>\n<li>图像大小调整：<code>tf.image.resize_images</code>，可以选择双线性插值、最近邻居法、双三插值法、面积插值法</li>\n<li>图像数据转化为实数类型：<code>tf.image.convert_image_dtype</code></li>\n<li>图像裁剪或填充：<code>tf.image.resize_image_with_crop_or_pad</code></li>\n<li>图像大小按比例调整：<code>tf.image.central_crop</code></li>\n<li>图像翻转：<code>tf.image.flip_up_down</code>、<code>tf.image.flip_left_right</code>、<code>tf.image.random_flip_up_down</code>、<code>tf.image.random_flip_left_right</code></li>\n<li>图像色彩调整：<code>tf.image.adjust_brightness</code>、<code>tf.image.random_brightness</code></li>\n<li>图像对比度调整：<code>tf.image.adjust_contrast</code>、<code>tf.image.random_contrast</code></li>\n<li>图像色相调整：<code>tf.image.adjust_hue</code>、<code>tf.image.random_hue</code></li>\n<li>图像饱和度调整：<code>tf.image.adjust_saturation</code>、<code>tf.image.random_saturation</code></li>\n</ul>\n<h3 id=\"队列\"><a href=\"#队列\" class=\"headerlink\" title=\"队列\"></a>队列</h3><p>Tensorflow提供<code>FIFOQueue</code>、<code>RandomShuffleQueue</code>两种队列，前者是先进先出队列，后者是随机队列，即每次出队列操作得到的是当前队列所有元素中随机选择的一个元素。队列的作用总结如下：</p>\n<ul>\n<li>一种数据结构</li>\n<li>也是异步计算张量取值的一个重要机制，如多线程可同时向一个队列中写元素，或同时读取一个队列中的元素。</li>\n</ul>"},{"title":"ubuntu系统提示磁盘空间不足问题解决","date":"2018-09-19T13:38:23.000Z","copyright":true,"_content":"\n----\n\n系统经常会遇到提示磁盘空间不足的问题，记录下一种解决方案。\n\n<!--more--->\n\n如果系统有以下提示信息：\n\n{% asset_img 错误提示.png %}\n\n可以点击分析，查看使用空间比较多的文件夹，如下图所示：\n\n{%  asset_img 磁盘分析.png %}\n\n可以看到是`var\\log`目录占用的空间比较多，所以进入该目录，如果是以`.`开头的文件，需要在文件管理器中勾选“显示隐藏文件”。可以使用`df -h`命令查看文件系统空间占用情况，如下：\n\n{% asset_img 删除前.png %}\n\n`var\\log`目录下都是些系统的日志文件，可以选择删除比较大的某些日志文件，使用如下命令：\n\n`sudo rm -rf /var/log/xxx`\n\n删除文件后，查看文件系统空间占用情况，如下：\n\n{% asset_img 删除后.png %}\n\n成功解决。\n\n","source":"_posts/ubuntu系统提示磁盘空间不足问题解决.md","raw":"---\ntitle: ubuntu系统提示磁盘空间不足问题解决\ndate: 2018-09-19 21:38:23\ntags:\n  - ubuntu\ncategories: \n  - 系统\n  - ubuntu\ncopyright: true\n---\n\n----\n\n系统经常会遇到提示磁盘空间不足的问题，记录下一种解决方案。\n\n<!--more--->\n\n如果系统有以下提示信息：\n\n{% asset_img 错误提示.png %}\n\n可以点击分析，查看使用空间比较多的文件夹，如下图所示：\n\n{%  asset_img 磁盘分析.png %}\n\n可以看到是`var\\log`目录占用的空间比较多，所以进入该目录，如果是以`.`开头的文件，需要在文件管理器中勾选“显示隐藏文件”。可以使用`df -h`命令查看文件系统空间占用情况，如下：\n\n{% asset_img 删除前.png %}\n\n`var\\log`目录下都是些系统的日志文件，可以选择删除比较大的某些日志文件，使用如下命令：\n\n`sudo rm -rf /var/log/xxx`\n\n删除文件后，查看文件系统空间占用情况，如下：\n\n{% asset_img 删除后.png %}\n\n成功解决。\n\n","slug":"ubuntu系统提示磁盘空间不足问题解决","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvf002nqlcryqpdgnsa","content":"<hr>\n<p>系统经常会遇到提示磁盘空间不足的问题，记录下一种解决方案。</p>\n<a id=\"more\"></a>\n<p>如果系统有以下提示信息：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/错误提示.png\">\n<p>可以点击分析，查看使用空间比较多的文件夹，如下图所示：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/磁盘分析.png\">\n<p>可以看到是<code>var\\log</code>目录占用的空间比较多，所以进入该目录，如果是以<code>.</code>开头的文件，需要在文件管理器中勾选“显示隐藏文件”。可以使用<code>df -h</code>命令查看文件系统空间占用情况，如下：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/删除前.png\">\n<p><code>var\\log</code>目录下都是些系统的日志文件，可以选择删除比较大的某些日志文件，使用如下命令：</p>\n<p><code>sudo rm -rf /var/log/xxx</code></p>\n<p>删除文件后，查看文件系统空间占用情况，如下：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/删除后.png\">\n<p>成功解决。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>系统经常会遇到提示磁盘空间不足的问题，记录下一种解决方案。</p>","more":"<p>如果系统有以下提示信息：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/错误提示.png\">\n<p>可以点击分析，查看使用空间比较多的文件夹，如下图所示：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/磁盘分析.png\">\n<p>可以看到是<code>var\\log</code>目录占用的空间比较多，所以进入该目录，如果是以<code>.</code>开头的文件，需要在文件管理器中勾选“显示隐藏文件”。可以使用<code>df -h</code>命令查看文件系统空间占用情况，如下：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/删除前.png\">\n<p><code>var\\log</code>目录下都是些系统的日志文件，可以选择删除比较大的某些日志文件，使用如下命令：</p>\n<p><code>sudo rm -rf /var/log/xxx</code></p>\n<p>删除文件后，查看文件系统空间占用情况，如下：</p>\n<img src=\"/2018/09/19/ubuntu系统提示磁盘空间不足问题解决/删除后.png\">\n<p>成功解决。</p>"},{"title":"图像处理之基础知识","date":"2018-06-21T11:30:27.000Z","copyright":true,"_content":"\n----\n\n这篇文章是图像处理相关的基础知识学习记录。\n\n<!---more-->\n\n# 尺度空间\n\n对于一副图像，近距离观察和远距离观察效果是不同的，前者比较清晰、比较大，能看到图像的一些细节信息；后者比较模糊、比较小，能看到图像的一些轮廓的信息，这就是图像的尺度，图像的尺度是自然存在的，并不是人为创造的。图像不同的尺度在一起称为尺度空间，量化表示即（o，s），变量o是某一八度（octave），控制的是金字塔中尺寸这个尺度，s是该八度中的某一层，区分同一尺寸尺度下的图像，控制一个八度中不同的模糊程度。尺度是在二维图像的基础上得到的图像中自然存在的一个维度。因为高斯核是唯一的线性核，也就是说使用高斯核对图像模糊不会引入其他噪声，因此就选用了高斯核来构建图像的尺度。高斯卷积核是尺度变换的唯一的线性核。\n\n\n\n# 多尺度和多分辨率\n\n## 金字塔多分辨率\n金字塔是早期图像多尺度的表示形式，一个图像金字塔是一系列图像的集合，所有图像来源于同一张原始图像 ，通过对原始图像连续采样获得，直到达到某个终止条件才停止采样。\n\n有两种类型的图像金字塔常常出现在文献和应用中：\n\n- **高斯金字塔(Gaussian pyramid):** 用来向下采样，为一层一层的图像，层级越高，图像越小。\n- **拉普拉斯金字塔(Laplacian pyramid):** 用来从金字塔低层图像向上采样重建图像，高斯金字塔其逆形式。\n\n图像金字塔化一般包括两个步骤：使用低通滤波器平滑图像（高斯平滑/高斯核模糊？一个八度内进行不同的高斯核模糊？）；对平滑图像进行降采样（通常是水平，竖直方向1/2），从而得到一系列尺寸缩小的图像。对于二维图像，一个传统的金字塔中，每一层图像由上一层分辨率的长、宽各一半，也就是四分之一的像素组成。\n\n## 尺度空间表达和金字塔多分辨率表达之间最大的不同是：\n\n- 尺度空间表达是由不同高斯核平滑卷积得到，在所有尺度上有相同的分辨率；\n- 而金字塔多分辨率表达每层分辨率减少固定比率。\n\n所以，金字塔多分辨率生成较快，且占用存储空间少；而多尺度表达随着尺度参数的增加冗余信息也变多。\n\n多尺度表达的优点在于图像的局部特征可以用简单的形式在不同尺度上描述；而金字塔表达没有理论基础，难以分析图像局部特征。\n\n# 图像的上采样(up-sampling)和下采样(down-sampling)\n缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：\n\n- 使得图像符合显示区域的大小；\n\n- 生成对应图像的缩略图。\n\n放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像，从而可以显示在更高分辨率的显示设备上。对图像的缩放操作并不能带来更多关于该图像的信息，因此图像的质量将不可避免地受到影响。然而，确实有一些缩放方法能够增加图像的信息，从而使得缩放后的图像质量超过原图质量的。\n\n下采样原理：对于一幅图像I尺寸为M * N，对其进行s倍下采样，即得到(M/s) * (N/s)尺寸的得分辨率图像，当然s应该是M和N的公约数才行，如果考虑的是矩阵形式的图像，就是把原始图像s * s窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值。\n\n上采样原理：图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的元素。","source":"_posts/图像处理之基础知识.md","raw":"---\ntitle: 图像处理之基础知识\ndate: 2018-06-21 19:30:27\ntags:\n  - 图像处理\ncategories: 图像处理\ncopyright: true\n---\n\n----\n\n这篇文章是图像处理相关的基础知识学习记录。\n\n<!---more-->\n\n# 尺度空间\n\n对于一副图像，近距离观察和远距离观察效果是不同的，前者比较清晰、比较大，能看到图像的一些细节信息；后者比较模糊、比较小，能看到图像的一些轮廓的信息，这就是图像的尺度，图像的尺度是自然存在的，并不是人为创造的。图像不同的尺度在一起称为尺度空间，量化表示即（o，s），变量o是某一八度（octave），控制的是金字塔中尺寸这个尺度，s是该八度中的某一层，区分同一尺寸尺度下的图像，控制一个八度中不同的模糊程度。尺度是在二维图像的基础上得到的图像中自然存在的一个维度。因为高斯核是唯一的线性核，也就是说使用高斯核对图像模糊不会引入其他噪声，因此就选用了高斯核来构建图像的尺度。高斯卷积核是尺度变换的唯一的线性核。\n\n\n\n# 多尺度和多分辨率\n\n## 金字塔多分辨率\n金字塔是早期图像多尺度的表示形式，一个图像金字塔是一系列图像的集合，所有图像来源于同一张原始图像 ，通过对原始图像连续采样获得，直到达到某个终止条件才停止采样。\n\n有两种类型的图像金字塔常常出现在文献和应用中：\n\n- **高斯金字塔(Gaussian pyramid):** 用来向下采样，为一层一层的图像，层级越高，图像越小。\n- **拉普拉斯金字塔(Laplacian pyramid):** 用来从金字塔低层图像向上采样重建图像，高斯金字塔其逆形式。\n\n图像金字塔化一般包括两个步骤：使用低通滤波器平滑图像（高斯平滑/高斯核模糊？一个八度内进行不同的高斯核模糊？）；对平滑图像进行降采样（通常是水平，竖直方向1/2），从而得到一系列尺寸缩小的图像。对于二维图像，一个传统的金字塔中，每一层图像由上一层分辨率的长、宽各一半，也就是四分之一的像素组成。\n\n## 尺度空间表达和金字塔多分辨率表达之间最大的不同是：\n\n- 尺度空间表达是由不同高斯核平滑卷积得到，在所有尺度上有相同的分辨率；\n- 而金字塔多分辨率表达每层分辨率减少固定比率。\n\n所以，金字塔多分辨率生成较快，且占用存储空间少；而多尺度表达随着尺度参数的增加冗余信息也变多。\n\n多尺度表达的优点在于图像的局部特征可以用简单的形式在不同尺度上描述；而金字塔表达没有理论基础，难以分析图像局部特征。\n\n# 图像的上采样(up-sampling)和下采样(down-sampling)\n缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：\n\n- 使得图像符合显示区域的大小；\n\n- 生成对应图像的缩略图。\n\n放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像，从而可以显示在更高分辨率的显示设备上。对图像的缩放操作并不能带来更多关于该图像的信息，因此图像的质量将不可避免地受到影响。然而，确实有一些缩放方法能够增加图像的信息，从而使得缩放后的图像质量超过原图质量的。\n\n下采样原理：对于一幅图像I尺寸为M * N，对其进行s倍下采样，即得到(M/s) * (N/s)尺寸的得分辨率图像，当然s应该是M和N的公约数才行，如果考虑的是矩阵形式的图像，就是把原始图像s * s窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值。\n\n上采样原理：图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的元素。","slug":"图像处理之基础知识","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvg002pqlcr7cx8juc7","content":"<hr>\n<p>这篇文章是图像处理相关的基础知识学习记录。</p>\n<a id=\"more\"></a>\n<h1 id=\"尺度空间\"><a href=\"#尺度空间\" class=\"headerlink\" title=\"尺度空间\"></a>尺度空间</h1><p>对于一副图像，近距离观察和远距离观察效果是不同的，前者比较清晰、比较大，能看到图像的一些细节信息；后者比较模糊、比较小，能看到图像的一些轮廓的信息，这就是图像的尺度，图像的尺度是自然存在的，并不是人为创造的。图像不同的尺度在一起称为尺度空间，量化表示即（o，s），变量o是某一八度（octave），控制的是金字塔中尺寸这个尺度，s是该八度中的某一层，区分同一尺寸尺度下的图像，控制一个八度中不同的模糊程度。尺度是在二维图像的基础上得到的图像中自然存在的一个维度。因为高斯核是唯一的线性核，也就是说使用高斯核对图像模糊不会引入其他噪声，因此就选用了高斯核来构建图像的尺度。高斯卷积核是尺度变换的唯一的线性核。</p>\n<h1 id=\"多尺度和多分辨率\"><a href=\"#多尺度和多分辨率\" class=\"headerlink\" title=\"多尺度和多分辨率\"></a>多尺度和多分辨率</h1><h2 id=\"金字塔多分辨率\"><a href=\"#金字塔多分辨率\" class=\"headerlink\" title=\"金字塔多分辨率\"></a>金字塔多分辨率</h2><p>金字塔是早期图像多尺度的表示形式，一个图像金字塔是一系列图像的集合，所有图像来源于同一张原始图像 ，通过对原始图像连续采样获得，直到达到某个终止条件才停止采样。</p>\n<p>有两种类型的图像金字塔常常出现在文献和应用中：</p>\n<ul>\n<li><strong>高斯金字塔(Gaussian pyramid):</strong> 用来向下采样，为一层一层的图像，层级越高，图像越小。</li>\n<li><strong>拉普拉斯金字塔(Laplacian pyramid):</strong> 用来从金字塔低层图像向上采样重建图像，高斯金字塔其逆形式。</li>\n</ul>\n<p>图像金字塔化一般包括两个步骤：使用低通滤波器平滑图像（高斯平滑/高斯核模糊？一个八度内进行不同的高斯核模糊？）；对平滑图像进行降采样（通常是水平，竖直方向1/2），从而得到一系列尺寸缩小的图像。对于二维图像，一个传统的金字塔中，每一层图像由上一层分辨率的长、宽各一半，也就是四分之一的像素组成。</p>\n<h2 id=\"尺度空间表达和金字塔多分辨率表达之间最大的不同是：\"><a href=\"#尺度空间表达和金字塔多分辨率表达之间最大的不同是：\" class=\"headerlink\" title=\"尺度空间表达和金字塔多分辨率表达之间最大的不同是：\"></a>尺度空间表达和金字塔多分辨率表达之间最大的不同是：</h2><ul>\n<li>尺度空间表达是由不同高斯核平滑卷积得到，在所有尺度上有相同的分辨率；</li>\n<li>而金字塔多分辨率表达每层分辨率减少固定比率。</li>\n</ul>\n<p>所以，金字塔多分辨率生成较快，且占用存储空间少；而多尺度表达随着尺度参数的增加冗余信息也变多。</p>\n<p>多尺度表达的优点在于图像的局部特征可以用简单的形式在不同尺度上描述；而金字塔表达没有理论基础，难以分析图像局部特征。</p>\n<h1 id=\"图像的上采样-up-sampling-和下采样-down-sampling\"><a href=\"#图像的上采样-up-sampling-和下采样-down-sampling\" class=\"headerlink\" title=\"图像的上采样(up-sampling)和下采样(down-sampling)\"></a>图像的上采样(up-sampling)和下采样(down-sampling)</h1><p>缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：</p>\n<ul>\n<li><p>使得图像符合显示区域的大小；</p>\n</li>\n<li><p>生成对应图像的缩略图。</p>\n</li>\n</ul>\n<p>放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像，从而可以显示在更高分辨率的显示设备上。对图像的缩放操作并不能带来更多关于该图像的信息，因此图像的质量将不可避免地受到影响。然而，确实有一些缩放方法能够增加图像的信息，从而使得缩放后的图像质量超过原图质量的。</p>\n<p>下采样原理：对于一幅图像I尺寸为M <em> N，对其进行s倍下采样，即得到(M/s) </em> (N/s)尺寸的得分辨率图像，当然s应该是M和N的公约数才行，如果考虑的是矩阵形式的图像，就是把原始图像s * s窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值。</p>\n<p>上采样原理：图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的元素。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是图像处理相关的基础知识学习记录。</p>","more":"<h1 id=\"尺度空间\"><a href=\"#尺度空间\" class=\"headerlink\" title=\"尺度空间\"></a>尺度空间</h1><p>对于一副图像，近距离观察和远距离观察效果是不同的，前者比较清晰、比较大，能看到图像的一些细节信息；后者比较模糊、比较小，能看到图像的一些轮廓的信息，这就是图像的尺度，图像的尺度是自然存在的，并不是人为创造的。图像不同的尺度在一起称为尺度空间，量化表示即（o，s），变量o是某一八度（octave），控制的是金字塔中尺寸这个尺度，s是该八度中的某一层，区分同一尺寸尺度下的图像，控制一个八度中不同的模糊程度。尺度是在二维图像的基础上得到的图像中自然存在的一个维度。因为高斯核是唯一的线性核，也就是说使用高斯核对图像模糊不会引入其他噪声，因此就选用了高斯核来构建图像的尺度。高斯卷积核是尺度变换的唯一的线性核。</p>\n<h1 id=\"多尺度和多分辨率\"><a href=\"#多尺度和多分辨率\" class=\"headerlink\" title=\"多尺度和多分辨率\"></a>多尺度和多分辨率</h1><h2 id=\"金字塔多分辨率\"><a href=\"#金字塔多分辨率\" class=\"headerlink\" title=\"金字塔多分辨率\"></a>金字塔多分辨率</h2><p>金字塔是早期图像多尺度的表示形式，一个图像金字塔是一系列图像的集合，所有图像来源于同一张原始图像 ，通过对原始图像连续采样获得，直到达到某个终止条件才停止采样。</p>\n<p>有两种类型的图像金字塔常常出现在文献和应用中：</p>\n<ul>\n<li><strong>高斯金字塔(Gaussian pyramid):</strong> 用来向下采样，为一层一层的图像，层级越高，图像越小。</li>\n<li><strong>拉普拉斯金字塔(Laplacian pyramid):</strong> 用来从金字塔低层图像向上采样重建图像，高斯金字塔其逆形式。</li>\n</ul>\n<p>图像金字塔化一般包括两个步骤：使用低通滤波器平滑图像（高斯平滑/高斯核模糊？一个八度内进行不同的高斯核模糊？）；对平滑图像进行降采样（通常是水平，竖直方向1/2），从而得到一系列尺寸缩小的图像。对于二维图像，一个传统的金字塔中，每一层图像由上一层分辨率的长、宽各一半，也就是四分之一的像素组成。</p>\n<h2 id=\"尺度空间表达和金字塔多分辨率表达之间最大的不同是：\"><a href=\"#尺度空间表达和金字塔多分辨率表达之间最大的不同是：\" class=\"headerlink\" title=\"尺度空间表达和金字塔多分辨率表达之间最大的不同是：\"></a>尺度空间表达和金字塔多分辨率表达之间最大的不同是：</h2><ul>\n<li>尺度空间表达是由不同高斯核平滑卷积得到，在所有尺度上有相同的分辨率；</li>\n<li>而金字塔多分辨率表达每层分辨率减少固定比率。</li>\n</ul>\n<p>所以，金字塔多分辨率生成较快，且占用存储空间少；而多尺度表达随着尺度参数的增加冗余信息也变多。</p>\n<p>多尺度表达的优点在于图像的局部特征可以用简单的形式在不同尺度上描述；而金字塔表达没有理论基础，难以分析图像局部特征。</p>\n<h1 id=\"图像的上采样-up-sampling-和下采样-down-sampling\"><a href=\"#图像的上采样-up-sampling-和下采样-down-sampling\" class=\"headerlink\" title=\"图像的上采样(up-sampling)和下采样(down-sampling)\"></a>图像的上采样(up-sampling)和下采样(down-sampling)</h1><p>缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：</p>\n<ul>\n<li><p>使得图像符合显示区域的大小；</p>\n</li>\n<li><p>生成对应图像的缩略图。</p>\n</li>\n</ul>\n<p>放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像，从而可以显示在更高分辨率的显示设备上。对图像的缩放操作并不能带来更多关于该图像的信息，因此图像的质量将不可避免地受到影响。然而，确实有一些缩放方法能够增加图像的信息，从而使得缩放后的图像质量超过原图质量的。</p>\n<p>下采样原理：对于一幅图像I尺寸为M <em> N，对其进行s倍下采样，即得到(M/s) </em> (N/s)尺寸的得分辨率图像，当然s应该是M和N的公约数才行，如果考虑的是矩阵形式的图像，就是把原始图像s * s窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值。</p>\n<p>上采样原理：图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的元素。</p>"},{"title":"ubuntu学习之update和upgrade","date":"2018-03-27T04:07:48.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ubuntu下update和upgrade命令使用的内容。\n\n<!--more--->\n\n每个Linux的发行版，比如Ubuntu，都会维护一个自己的软件仓库，我们常用的几乎所有软件都在这里面。这里面的软件绝对安全，而且绝对的能正常安装。\n\n安装软件的方式：在Ubuntu下维护一个源列表，源列表里面都是一些网址信息，这每一条网址就是一个源，这个地址指向的数据标识着这台源服务器上有哪些软件可以安装使用。\n\n编辑源命令：`sudo gedit /etc/apt/sources.list`\n在这个文件里加入或者注释（加#）掉一些源后，保存。这时候，我们的源列表里指向的软件就会增加或减少一部分。\n\n接一下要做的就是：`sudo apt-get update`\n执行该命令，会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。我们在新立得软件包管理器里看到的软件列表，都是通过update命令更新的。\n\nupdate后，可能需要upgrade一下：`sudo apt-get upgrade`\n该命令会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示更新。如果软件都是最新版本，会提示：`升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。`\n\n总而言之，`update`是更新软件列表，`upgrade`是更新软件。\n\n**需要注意**，在源列表里面会有系统更新，执行upgrade命令可能会产生系统升级，如果将系统按照这种方式升级，升级前安装过的应用软件可能会有无法使用的问题。","source":"_posts/ubuntu学习之update和upgrade.md","raw":"---\ntitle: ubuntu学习之update和upgrade\ndate: 2018-03-27 12:07:48\ntags:\n  - ubuntu\ncategories: \n  - 系统\n  - ubuntu\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ubuntu下update和upgrade命令使用的内容。\n\n<!--more--->\n\n每个Linux的发行版，比如Ubuntu，都会维护一个自己的软件仓库，我们常用的几乎所有软件都在这里面。这里面的软件绝对安全，而且绝对的能正常安装。\n\n安装软件的方式：在Ubuntu下维护一个源列表，源列表里面都是一些网址信息，这每一条网址就是一个源，这个地址指向的数据标识着这台源服务器上有哪些软件可以安装使用。\n\n编辑源命令：`sudo gedit /etc/apt/sources.list`\n在这个文件里加入或者注释（加#）掉一些源后，保存。这时候，我们的源列表里指向的软件就会增加或减少一部分。\n\n接一下要做的就是：`sudo apt-get update`\n执行该命令，会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。我们在新立得软件包管理器里看到的软件列表，都是通过update命令更新的。\n\nupdate后，可能需要upgrade一下：`sudo apt-get upgrade`\n该命令会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示更新。如果软件都是最新版本，会提示：`升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。`\n\n总而言之，`update`是更新软件列表，`upgrade`是更新软件。\n\n**需要注意**，在源列表里面会有系统更新，执行upgrade命令可能会产生系统升级，如果将系统按照这种方式升级，升级前安装过的应用软件可能会有无法使用的问题。","slug":"ubuntu学习之update和upgrade","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvi002sqlcrb92jh2nt","content":"<hr>\n<p>这篇文章是有关ubuntu下update和upgrade命令使用的内容。</p>\n<a id=\"more\"></a>\n<p>每个Linux的发行版，比如Ubuntu，都会维护一个自己的软件仓库，我们常用的几乎所有软件都在这里面。这里面的软件绝对安全，而且绝对的能正常安装。</p>\n<p>安装软件的方式：在Ubuntu下维护一个源列表，源列表里面都是一些网址信息，这每一条网址就是一个源，这个地址指向的数据标识着这台源服务器上有哪些软件可以安装使用。</p>\n<p>编辑源命令：<code>sudo gedit /etc/apt/sources.list</code><br>在这个文件里加入或者注释（加#）掉一些源后，保存。这时候，我们的源列表里指向的软件就会增加或减少一部分。</p>\n<p>接一下要做的就是：<code>sudo apt-get update</code><br>执行该命令，会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。我们在新立得软件包管理器里看到的软件列表，都是通过update命令更新的。</p>\n<p>update后，可能需要upgrade一下：<code>sudo apt-get upgrade</code><br>该命令会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示更新。如果软件都是最新版本，会提示：<code>升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。</code></p>\n<p>总而言之，<code>update</code>是更新软件列表，<code>upgrade</code>是更新软件。</p>\n<p><strong>需要注意</strong>，在源列表里面会有系统更新，执行upgrade命令可能会产生系统升级，如果将系统按照这种方式升级，升级前安装过的应用软件可能会有无法使用的问题。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ubuntu下update和upgrade命令使用的内容。</p>","more":"<p>每个Linux的发行版，比如Ubuntu，都会维护一个自己的软件仓库，我们常用的几乎所有软件都在这里面。这里面的软件绝对安全，而且绝对的能正常安装。</p>\n<p>安装软件的方式：在Ubuntu下维护一个源列表，源列表里面都是一些网址信息，这每一条网址就是一个源，这个地址指向的数据标识着这台源服务器上有哪些软件可以安装使用。</p>\n<p>编辑源命令：<code>sudo gedit /etc/apt/sources.list</code><br>在这个文件里加入或者注释（加#）掉一些源后，保存。这时候，我们的源列表里指向的软件就会增加或减少一部分。</p>\n<p>接一下要做的就是：<code>sudo apt-get update</code><br>执行该命令，会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。我们在新立得软件包管理器里看到的软件列表，都是通过update命令更新的。</p>\n<p>update后，可能需要upgrade一下：<code>sudo apt-get upgrade</code><br>该命令会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示更新。如果软件都是最新版本，会提示：<code>升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。</code></p>\n<p>总而言之，<code>update</code>是更新软件列表，<code>upgrade</code>是更新软件。</p>\n<p><strong>需要注意</strong>，在源列表里面会有系统更新，执行upgrade命令可能会产生系统升级，如果将系统按照这种方式升级，升级前安装过的应用软件可能会有无法使用的问题。</p>"},{"title":"视觉SLAM十四讲阅读笔记七-双目相机模型","date":"2018-09-01T14:26:28.000Z","mathjax":true,"copyright":true,"_content":"\n---\n\n这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录双目相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。\n\n<!--more--->\n\n双目相机一般由左右两个相机水平放置组成，可以把两个相机都看作是针孔相机。水平放置的两个相机，意味着它们的光圈中心都位于x轴上。两者之间的距离成为双目相机的**基线**（Baseline，记做$b$）。双目相机的成像模型如下所示：\n\n{% asset_img 双目相机模型.png %}\n\n$O_L,O_r$为左右光圈中心，方框为成像平面，$f$为焦距。$u_L,u_R$为成像平面的坐标。\n\n考虑空间点$P$，它在左右相机各成一像，记做$P_L,P_R$。由于相机基线的存在，它们的成像位置是不同的。记左右侧坐标分别为$u_L,u_R$，根据三角形相似关系，有：\n\n$\\frac{z-f}z=\\frac{b-u_L+u_R}b$\n\n整理得：\n\n$z=\\frac{fb}d,\\quad d=u_L-u_R$\n\n其中，$d$为左右图横坐标之差，称为视差。根据视差，可以估计一个像素与相机之间的距离。视差与距离成反比：视差越大，距离越近。\n\n## 参考资料\n\n1. 视觉SLAM十四讲第5讲","source":"_posts/视觉SLAM十四讲阅读笔记七-双目相机模型.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记七-双目相机模型\ndate: 2018-09-01 22:26:28\ntags: \n  - SLAM基础\n  - 读书笔记\n  - 双目\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n---\n\n这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录双目相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。\n\n<!--more--->\n\n双目相机一般由左右两个相机水平放置组成，可以把两个相机都看作是针孔相机。水平放置的两个相机，意味着它们的光圈中心都位于x轴上。两者之间的距离成为双目相机的**基线**（Baseline，记做$b$）。双目相机的成像模型如下所示：\n\n{% asset_img 双目相机模型.png %}\n\n$O_L,O_r$为左右光圈中心，方框为成像平面，$f$为焦距。$u_L,u_R$为成像平面的坐标。\n\n考虑空间点$P$，它在左右相机各成一像，记做$P_L,P_R$。由于相机基线的存在，它们的成像位置是不同的。记左右侧坐标分别为$u_L,u_R$，根据三角形相似关系，有：\n\n$\\frac{z-f}z=\\frac{b-u_L+u_R}b$\n\n整理得：\n\n$z=\\frac{fb}d,\\quad d=u_L-u_R$\n\n其中，$d$为左右图横坐标之差，称为视差。根据视差，可以估计一个像素与相机之间的距离。视差与距离成反比：视差越大，距离越近。\n\n## 参考资料\n\n1. 视觉SLAM十四讲第5讲","slug":"视觉SLAM十四讲阅读笔记七-双目相机模型","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvj002uqlcr2js1alsv","content":"<hr>\n<p>这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录双目相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。</p>\n<a id=\"more\"></a>\n<p>双目相机一般由左右两个相机水平放置组成，可以把两个相机都看作是针孔相机。水平放置的两个相机，意味着它们的光圈中心都位于x轴上。两者之间的距离成为双目相机的<strong>基线</strong>（Baseline，记做$b$）。双目相机的成像模型如下所示：</p>\n\n<p>$O_L,O_r$为左右光圈中心，方框为成像平面，$f$为焦距。$u_L,u_R$为成像平面的坐标。</p>\n<p>考虑空间点$P$，它在左右相机各成一像，记做$P_L,P_R$。由于相机基线的存在，它们的成像位置是不同的。记左右侧坐标分别为$u_L,u_R$，根据三角形相似关系，有：</p>\n<p>$\\frac{z-f}z=\\frac{b-u_L+u_R}b$</p>\n<p>整理得：</p>\n<p>$z=\\frac{fb}d,\\quad d=u_L-u_R$</p>\n<p>其中，$d$为左右图横坐标之差，称为视差。根据视差，可以估计一个像素与相机之间的距离。视差与距离成反比：视差越大，距离越近。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉SLAM十四讲第5讲</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录双目相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。</p>","more":"<p>双目相机一般由左右两个相机水平放置组成，可以把两个相机都看作是针孔相机。水平放置的两个相机，意味着它们的光圈中心都位于x轴上。两者之间的距离成为双目相机的<strong>基线</strong>（Baseline，记做$b$）。双目相机的成像模型如下所示：</p>\n\n<p>$O_L,O_r$为左右光圈中心，方框为成像平面，$f$为焦距。$u_L,u_R$为成像平面的坐标。</p>\n<p>考虑空间点$P$，它在左右相机各成一像，记做$P_L,P_R$。由于相机基线的存在，它们的成像位置是不同的。记左右侧坐标分别为$u_L,u_R$，根据三角形相似关系，有：</p>\n<p>$\\frac{z-f}z=\\frac{b-u_L+u_R}b$</p>\n<p>整理得：</p>\n<p>$z=\\frac{fb}d,\\quad d=u_L-u_R$</p>\n<p>其中，$d$为左右图横坐标之差，称为视差。根据视差，可以估计一个像素与相机之间的距离。视差与距离成反比：视差越大，距离越近。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉SLAM十四讲第5讲</li>\n</ol>"},{"title":"test","date":"2019-05-30T12:42:50.000Z","copyright":true,"_content":"---\n\n-just for test\n<!--more--->\n","source":"_posts/test.md","raw":"---\ntitle: test\ndate: 2019-05-30 20:42:50\ntags: \n  - ubuntu16.04\n  - Hexo \n  - Github\n  - Typora\ncategories: 工具\ncopyright: true\n---\n---\n\n-just for test\n<!--more--->\n","slug":"test","published":1,"updated":"2019-05-30T12:43:38.939Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvl002xqlcrpqczn1qo","content":"<hr>\n<p>-just for test<br><a id=\"more\"></a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>-just for test<br>","more":"</p>"},{"title":"视觉SLAM十四讲阅读笔记五-图优化与g2o基础","date":"2018-08-31T02:17:36.000Z","mathjax":true,"copyright":true,"_content":"\n---\n\n这篇文章是阅读视觉SLAM十四讲第6讲非线性优化部分和高翔关于图优化与g2o库的博客过程中总结和记录的内容，属于SLAM系统优化的基础理论内容。\n\n<!--more-->\n\n## 概述\n\nSLAM问题的处理方法主要分为滤波和图优化两类。滤波的方法中常见的是扩展卡尔曼滤波、粒子滤波、信息滤波等，这种方法是递增的、实时的处理数据并矫正机器人位姿。比如基于粒子滤波的SLAM的处理思路是假设机器人知道当前时刻的位姿，利用编码器或者IMU之类的惯性导航又能够计算下一时刻的位姿，然而这类传感器有累计误差，所以再将每个粒子的激光传感器数据或者图像特征对比当前建立好的地图中的特征，挑选和地图特征匹配最好的粒子的位姿当做当前位姿，如此往复。当然在gmapping、hector_slam这类算法中，不会如此轻易的使用激光数据，激光测距这么准，当然不能只用来计算粒子权重，而是将激光数据与地图环境进行匹配（scan match）估计机器人位姿，比用编码器之流精度高出很多。\n\n目前SLAM主流研究热点几乎都是基于图优化的，对于处理视觉SLAM，如果用EKF，随着时间推移地图扩大，内存消耗，计算量都很大；而使用图优化计算在高建图精度的前提下效率更高。\n\n## 关于图优化\n\n> 阅读参考资料1，通过例子更直观地理解图优化的原理。\n\n图优化是目前视觉SLAM里主流的优化方式。其思想是把一个优化问题表达成图（Graph），以便我们理解、观察。一个图中有很多顶点，以及连接各顶点的边。当它们表示一个优化问题时，**顶点**是待优化的**变量**，而**边**是指**误差项**。我们把各个边的误差加到一起，就得到了整个优化问题的误差函数。\n\n图优化SLAM问题能够分解成两个任务：\n\n1. 构建图，机器人位姿当做顶点，位姿间关系当做边，这一步常常被成为前端（front-end），往往是传感器信息的堆积。\n2. 优化图，调整机器人位姿顶点尽量满足边的约束，这一步称为后端（back-end）。\n\n图优化过程：先堆积数据，机器人位姿为构建的顶点，边是位姿之间的关系，可以是编码器数据计算的位姿，也可以是通过ICP匹配计算出来的位姿，还可以是闭环检测的位姿关系。首先是构建图，得到原始未经优化的地图，构建完成地图后，调整顶点满足边的约束，最后得到优化后的地图。\n\n## 图的表达\n\n下面这些图都是不同的表达形式，前三个是ORB-SLAM2中用到图。（关于图优化和常用的优化库g2o还需要再深入学习）\n\n### Covisibility Graph\n\n共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。\n\n### Essential Graph\n\n为了在优化阶段减小计算量，ORB-SLAM2作者提出了**Essential Graph**的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。\n\n### Spanning Graph\n\n生成树\n\n### Pose Graph\n\n如果我们对特征点的空间位置并不关心，就可以构建只带有关键帧结点，以及它们之间的边这样的图。由于一个照片中常常有上千个特征点，这样做可以节省许多计算量。\n\n## 参考资料\n\n1. [graph slam tutorial : 从推导到应用1](https://blog.csdn.net/heyijia0327/article/details/47686523)\n2. [graph slam tutorial ：从推导到应用2](https://blog.csdn.net/heyijia0327/article/details/47731631)\n3. [graph slam tutorial ：从推导到应用3](https://blog.csdn.net/heyijia0327/article/details/47428553)\n4. [【SLAM】（二）Cartographer的原理探究——GraphSLAM理论基础](https://blog.csdn.net/jsgaobiao/article/details/65628918)\n5. [深入理解图优化与g2o：图优化篇](https://www.cnblogs.com/gaoxiang12/p/5244828.html)\n6. [知乎问题](https://www.zhihu.com/question/42050992)","source":"_posts/视觉SLAM十四讲阅读笔记五-图优化与g2o基础.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记五-图优化与g2o基础\ndate: 2018-08-31 10:17:36\ntags: \n  - SLAM基础\n  - 读书笔记\n  - 图优化\n  - g2o\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n---\n\n这篇文章是阅读视觉SLAM十四讲第6讲非线性优化部分和高翔关于图优化与g2o库的博客过程中总结和记录的内容，属于SLAM系统优化的基础理论内容。\n\n<!--more-->\n\n## 概述\n\nSLAM问题的处理方法主要分为滤波和图优化两类。滤波的方法中常见的是扩展卡尔曼滤波、粒子滤波、信息滤波等，这种方法是递增的、实时的处理数据并矫正机器人位姿。比如基于粒子滤波的SLAM的处理思路是假设机器人知道当前时刻的位姿，利用编码器或者IMU之类的惯性导航又能够计算下一时刻的位姿，然而这类传感器有累计误差，所以再将每个粒子的激光传感器数据或者图像特征对比当前建立好的地图中的特征，挑选和地图特征匹配最好的粒子的位姿当做当前位姿，如此往复。当然在gmapping、hector_slam这类算法中，不会如此轻易的使用激光数据，激光测距这么准，当然不能只用来计算粒子权重，而是将激光数据与地图环境进行匹配（scan match）估计机器人位姿，比用编码器之流精度高出很多。\n\n目前SLAM主流研究热点几乎都是基于图优化的，对于处理视觉SLAM，如果用EKF，随着时间推移地图扩大，内存消耗，计算量都很大；而使用图优化计算在高建图精度的前提下效率更高。\n\n## 关于图优化\n\n> 阅读参考资料1，通过例子更直观地理解图优化的原理。\n\n图优化是目前视觉SLAM里主流的优化方式。其思想是把一个优化问题表达成图（Graph），以便我们理解、观察。一个图中有很多顶点，以及连接各顶点的边。当它们表示一个优化问题时，**顶点**是待优化的**变量**，而**边**是指**误差项**。我们把各个边的误差加到一起，就得到了整个优化问题的误差函数。\n\n图优化SLAM问题能够分解成两个任务：\n\n1. 构建图，机器人位姿当做顶点，位姿间关系当做边，这一步常常被成为前端（front-end），往往是传感器信息的堆积。\n2. 优化图，调整机器人位姿顶点尽量满足边的约束，这一步称为后端（back-end）。\n\n图优化过程：先堆积数据，机器人位姿为构建的顶点，边是位姿之间的关系，可以是编码器数据计算的位姿，也可以是通过ICP匹配计算出来的位姿，还可以是闭环检测的位姿关系。首先是构建图，得到原始未经优化的地图，构建完成地图后，调整顶点满足边的约束，最后得到优化后的地图。\n\n## 图的表达\n\n下面这些图都是不同的表达形式，前三个是ORB-SLAM2中用到图。（关于图优化和常用的优化库g2o还需要再深入学习）\n\n### Covisibility Graph\n\n共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。\n\n### Essential Graph\n\n为了在优化阶段减小计算量，ORB-SLAM2作者提出了**Essential Graph**的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。\n\n### Spanning Graph\n\n生成树\n\n### Pose Graph\n\n如果我们对特征点的空间位置并不关心，就可以构建只带有关键帧结点，以及它们之间的边这样的图。由于一个照片中常常有上千个特征点，这样做可以节省许多计算量。\n\n## 参考资料\n\n1. [graph slam tutorial : 从推导到应用1](https://blog.csdn.net/heyijia0327/article/details/47686523)\n2. [graph slam tutorial ：从推导到应用2](https://blog.csdn.net/heyijia0327/article/details/47731631)\n3. [graph slam tutorial ：从推导到应用3](https://blog.csdn.net/heyijia0327/article/details/47428553)\n4. [【SLAM】（二）Cartographer的原理探究——GraphSLAM理论基础](https://blog.csdn.net/jsgaobiao/article/details/65628918)\n5. [深入理解图优化与g2o：图优化篇](https://www.cnblogs.com/gaoxiang12/p/5244828.html)\n6. [知乎问题](https://www.zhihu.com/question/42050992)","slug":"视觉SLAM十四讲阅读笔记五-图优化与g2o基础","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvm0030qlcrttrhc7dr","content":"<hr>\n<p>这篇文章是阅读视觉SLAM十四讲第6讲非线性优化部分和高翔关于图优化与g2o库的博客过程中总结和记录的内容，属于SLAM系统优化的基础理论内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>SLAM问题的处理方法主要分为滤波和图优化两类。滤波的方法中常见的是扩展卡尔曼滤波、粒子滤波、信息滤波等，这种方法是递增的、实时的处理数据并矫正机器人位姿。比如基于粒子滤波的SLAM的处理思路是假设机器人知道当前时刻的位姿，利用编码器或者IMU之类的惯性导航又能够计算下一时刻的位姿，然而这类传感器有累计误差，所以再将每个粒子的激光传感器数据或者图像特征对比当前建立好的地图中的特征，挑选和地图特征匹配最好的粒子的位姿当做当前位姿，如此往复。当然在gmapping、hector_slam这类算法中，不会如此轻易的使用激光数据，激光测距这么准，当然不能只用来计算粒子权重，而是将激光数据与地图环境进行匹配（scan match）估计机器人位姿，比用编码器之流精度高出很多。</p>\n<p>目前SLAM主流研究热点几乎都是基于图优化的，对于处理视觉SLAM，如果用EKF，随着时间推移地图扩大，内存消耗，计算量都很大；而使用图优化计算在高建图精度的前提下效率更高。</p>\n<h2 id=\"关于图优化\"><a href=\"#关于图优化\" class=\"headerlink\" title=\"关于图优化\"></a>关于图优化</h2><blockquote>\n<p>阅读参考资料1，通过例子更直观地理解图优化的原理。</p>\n</blockquote>\n<p>图优化是目前视觉SLAM里主流的优化方式。其思想是把一个优化问题表达成图（Graph），以便我们理解、观察。一个图中有很多顶点，以及连接各顶点的边。当它们表示一个优化问题时，<strong>顶点</strong>是待优化的<strong>变量</strong>，而<strong>边</strong>是指<strong>误差项</strong>。我们把各个边的误差加到一起，就得到了整个优化问题的误差函数。</p>\n<p>图优化SLAM问题能够分解成两个任务：</p>\n<ol>\n<li>构建图，机器人位姿当做顶点，位姿间关系当做边，这一步常常被成为前端（front-end），往往是传感器信息的堆积。</li>\n<li>优化图，调整机器人位姿顶点尽量满足边的约束，这一步称为后端（back-end）。</li>\n</ol>\n<p>图优化过程：先堆积数据，机器人位姿为构建的顶点，边是位姿之间的关系，可以是编码器数据计算的位姿，也可以是通过ICP匹配计算出来的位姿，还可以是闭环检测的位姿关系。首先是构建图，得到原始未经优化的地图，构建完成地图后，调整顶点满足边的约束，最后得到优化后的地图。</p>\n<h2 id=\"图的表达\"><a href=\"#图的表达\" class=\"headerlink\" title=\"图的表达\"></a>图的表达</h2><p>下面这些图都是不同的表达形式，前三个是ORB-SLAM2中用到图。（关于图优化和常用的优化库g2o还需要再深入学习）</p>\n<h3 id=\"Covisibility-Graph\"><a href=\"#Covisibility-Graph\" class=\"headerlink\" title=\"Covisibility Graph\"></a>Covisibility Graph</h3><p>共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。</p>\n<h3 id=\"Essential-Graph\"><a href=\"#Essential-Graph\" class=\"headerlink\" title=\"Essential Graph\"></a>Essential Graph</h3><p>为了在优化阶段减小计算量，ORB-SLAM2作者提出了<strong>Essential Graph</strong>的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。</p>\n<h3 id=\"Spanning-Graph\"><a href=\"#Spanning-Graph\" class=\"headerlink\" title=\"Spanning Graph\"></a>Spanning Graph</h3><p>生成树</p>\n<h3 id=\"Pose-Graph\"><a href=\"#Pose-Graph\" class=\"headerlink\" title=\"Pose Graph\"></a>Pose Graph</h3><p>如果我们对特征点的空间位置并不关心，就可以构建只带有关键帧结点，以及它们之间的边这样的图。由于一个照片中常常有上千个特征点，这样做可以节省许多计算量。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/47686523\" target=\"_blank\" rel=\"noopener\">graph slam tutorial : 从推导到应用1</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/47731631\" target=\"_blank\" rel=\"noopener\">graph slam tutorial ：从推导到应用2</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/47428553\" target=\"_blank\" rel=\"noopener\">graph slam tutorial ：从推导到应用3</a></li>\n<li><a href=\"https://blog.csdn.net/jsgaobiao/article/details/65628918\" target=\"_blank\" rel=\"noopener\">【SLAM】（二）Cartographer的原理探究——GraphSLAM理论基础</a></li>\n<li><a href=\"https://www.cnblogs.com/gaoxiang12/p/5244828.html\" target=\"_blank\" rel=\"noopener\">深入理解图优化与g2o：图优化篇</a></li>\n<li><a href=\"https://www.zhihu.com/question/42050992\" target=\"_blank\" rel=\"noopener\">知乎问题</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是阅读视觉SLAM十四讲第6讲非线性优化部分和高翔关于图优化与g2o库的博客过程中总结和记录的内容，属于SLAM系统优化的基础理论内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>SLAM问题的处理方法主要分为滤波和图优化两类。滤波的方法中常见的是扩展卡尔曼滤波、粒子滤波、信息滤波等，这种方法是递增的、实时的处理数据并矫正机器人位姿。比如基于粒子滤波的SLAM的处理思路是假设机器人知道当前时刻的位姿，利用编码器或者IMU之类的惯性导航又能够计算下一时刻的位姿，然而这类传感器有累计误差，所以再将每个粒子的激光传感器数据或者图像特征对比当前建立好的地图中的特征，挑选和地图特征匹配最好的粒子的位姿当做当前位姿，如此往复。当然在gmapping、hector_slam这类算法中，不会如此轻易的使用激光数据，激光测距这么准，当然不能只用来计算粒子权重，而是将激光数据与地图环境进行匹配（scan match）估计机器人位姿，比用编码器之流精度高出很多。</p>\n<p>目前SLAM主流研究热点几乎都是基于图优化的，对于处理视觉SLAM，如果用EKF，随着时间推移地图扩大，内存消耗，计算量都很大；而使用图优化计算在高建图精度的前提下效率更高。</p>\n<h2 id=\"关于图优化\"><a href=\"#关于图优化\" class=\"headerlink\" title=\"关于图优化\"></a>关于图优化</h2><blockquote>\n<p>阅读参考资料1，通过例子更直观地理解图优化的原理。</p>\n</blockquote>\n<p>图优化是目前视觉SLAM里主流的优化方式。其思想是把一个优化问题表达成图（Graph），以便我们理解、观察。一个图中有很多顶点，以及连接各顶点的边。当它们表示一个优化问题时，<strong>顶点</strong>是待优化的<strong>变量</strong>，而<strong>边</strong>是指<strong>误差项</strong>。我们把各个边的误差加到一起，就得到了整个优化问题的误差函数。</p>\n<p>图优化SLAM问题能够分解成两个任务：</p>\n<ol>\n<li>构建图，机器人位姿当做顶点，位姿间关系当做边，这一步常常被成为前端（front-end），往往是传感器信息的堆积。</li>\n<li>优化图，调整机器人位姿顶点尽量满足边的约束，这一步称为后端（back-end）。</li>\n</ol>\n<p>图优化过程：先堆积数据，机器人位姿为构建的顶点，边是位姿之间的关系，可以是编码器数据计算的位姿，也可以是通过ICP匹配计算出来的位姿，还可以是闭环检测的位姿关系。首先是构建图，得到原始未经优化的地图，构建完成地图后，调整顶点满足边的约束，最后得到优化后的地图。</p>\n<h2 id=\"图的表达\"><a href=\"#图的表达\" class=\"headerlink\" title=\"图的表达\"></a>图的表达</h2><p>下面这些图都是不同的表达形式，前三个是ORB-SLAM2中用到图。（关于图优化和常用的优化库g2o还需要再深入学习）</p>\n<h3 id=\"Covisibility-Graph\"><a href=\"#Covisibility-Graph\" class=\"headerlink\" title=\"Covisibility Graph\"></a>Covisibility Graph</h3><p>共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。</p>\n<h3 id=\"Essential-Graph\"><a href=\"#Essential-Graph\" class=\"headerlink\" title=\"Essential Graph\"></a>Essential Graph</h3><p>为了在优化阶段减小计算量，ORB-SLAM2作者提出了<strong>Essential Graph</strong>的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。</p>\n<h3 id=\"Spanning-Graph\"><a href=\"#Spanning-Graph\" class=\"headerlink\" title=\"Spanning Graph\"></a>Spanning Graph</h3><p>生成树</p>\n<h3 id=\"Pose-Graph\"><a href=\"#Pose-Graph\" class=\"headerlink\" title=\"Pose Graph\"></a>Pose Graph</h3><p>如果我们对特征点的空间位置并不关心，就可以构建只带有关键帧结点，以及它们之间的边这样的图。由于一个照片中常常有上千个特征点，这样做可以节省许多计算量。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/47686523\" target=\"_blank\" rel=\"noopener\">graph slam tutorial : 从推导到应用1</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/47731631\" target=\"_blank\" rel=\"noopener\">graph slam tutorial ：从推导到应用2</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/47428553\" target=\"_blank\" rel=\"noopener\">graph slam tutorial ：从推导到应用3</a></li>\n<li><a href=\"https://blog.csdn.net/jsgaobiao/article/details/65628918\" target=\"_blank\" rel=\"noopener\">【SLAM】（二）Cartographer的原理探究——GraphSLAM理论基础</a></li>\n<li><a href=\"https://www.cnblogs.com/gaoxiang12/p/5244828.html\" target=\"_blank\" rel=\"noopener\">深入理解图优化与g2o：图优化篇</a></li>\n<li><a href=\"https://www.zhihu.com/question/42050992\" target=\"_blank\" rel=\"noopener\">知乎问题</a></li>\n</ol>"},{"title":"视觉SLAM十四讲阅读笔记八-图像表示与存储","date":"2018-10-12T08:48:27.000Z","mathjax":true,"copyright":true,"_content":"\n---\n这篇文章记录十四讲中代码学习引出的一些内容，主要是计算机中图像的表示和存储相关的。\n\n<!--more-->\n\n## 引出\n\n在阅读十四讲第5讲的源码时，注意到下面这部分代码：\n\n~~~c++\nfor ( int v=0; v<color.rows; v++ )\n    for ( int u=0; u<color.cols; u++ )\n    {\n        //...\n        PointT p ;\n        p.x = pointWorld[0];\n        p.y = pointWorld[1];\n        p.z = pointWorld[2];\n        p.b = color.data[ v*color.step+u*color.channels() ];\n        p.g = color.data[ v*color.step+u*color.channels()+1 ];\n        p.r = color.data[ v*color.step+u*color.channels()+2 ];\n        pointCloud->points.push_back( p );\n    }\n~~~\n\n代码中`color`是彩色图像，9\\10\\11行从内存中读取像素[u,v]的三个通道值。如下图所示，图像在OpenCV中的表示和存储：\n\n{% asset_img 表示和存储.png %}\n\n其中`step`是行数据长度，即内存中保存图像的一行数据的空间长度。图像矩阵的像素数据按行存储在内存中，通常情况内存足够大的话图像的每一行是连续存放的，也就是在内存上图像的所有数据存放成一行，这种情况在访问时可以提供很大方便，例如上述代码。\n\n## 图像的表示\n\n{% asset_img 图像坐标示意图.png %}\n\n对于一个位于$x,y$处的像素，它在程序中的访问方式是：\n\n~~~c++\nunsigned char pixel = image[y][x];\n~~~\n\n它对应着灰度值$I(x,y)$的读数。注意$x$和$y$的顺序，如果顺序错误的话，编译器无法提供任何信息，会引起程序运行中的越界错误。\n\n## 参考资料\n\n1. 视觉slam十四讲第5讲\n2. [【OpenCV】访问Mat图像中每个像素的值](https://blog.csdn.net/xiaowei_cqu/article/details/7771760)","source":"_posts/视觉SLAM十四讲阅读笔记八-图像表示与存储.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记八-图像表示与存储\ndate: 2018-10-12 16:48:27\ntags: \n  - SLAM基础\n  - 读书笔记\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n---\n这篇文章记录十四讲中代码学习引出的一些内容，主要是计算机中图像的表示和存储相关的。\n\n<!--more-->\n\n## 引出\n\n在阅读十四讲第5讲的源码时，注意到下面这部分代码：\n\n~~~c++\nfor ( int v=0; v<color.rows; v++ )\n    for ( int u=0; u<color.cols; u++ )\n    {\n        //...\n        PointT p ;\n        p.x = pointWorld[0];\n        p.y = pointWorld[1];\n        p.z = pointWorld[2];\n        p.b = color.data[ v*color.step+u*color.channels() ];\n        p.g = color.data[ v*color.step+u*color.channels()+1 ];\n        p.r = color.data[ v*color.step+u*color.channels()+2 ];\n        pointCloud->points.push_back( p );\n    }\n~~~\n\n代码中`color`是彩色图像，9\\10\\11行从内存中读取像素[u,v]的三个通道值。如下图所示，图像在OpenCV中的表示和存储：\n\n{% asset_img 表示和存储.png %}\n\n其中`step`是行数据长度，即内存中保存图像的一行数据的空间长度。图像矩阵的像素数据按行存储在内存中，通常情况内存足够大的话图像的每一行是连续存放的，也就是在内存上图像的所有数据存放成一行，这种情况在访问时可以提供很大方便，例如上述代码。\n\n## 图像的表示\n\n{% asset_img 图像坐标示意图.png %}\n\n对于一个位于$x,y$处的像素，它在程序中的访问方式是：\n\n~~~c++\nunsigned char pixel = image[y][x];\n~~~\n\n它对应着灰度值$I(x,y)$的读数。注意$x$和$y$的顺序，如果顺序错误的话，编译器无法提供任何信息，会引起程序运行中的越界错误。\n\n## 参考资料\n\n1. 视觉slam十四讲第5讲\n2. [【OpenCV】访问Mat图像中每个像素的值](https://blog.csdn.net/xiaowei_cqu/article/details/7771760)","slug":"视觉SLAM十四讲阅读笔记八-图像表示与存储","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvo0033qlcr1wvlejsu","content":"<hr>\n<p>这篇文章记录十四讲中代码学习引出的一些内容，主要是计算机中图像的表示和存储相关的。</p>\n<a id=\"more\"></a>\n<h2 id=\"引出\"><a href=\"#引出\" class=\"headerlink\" title=\"引出\"></a>引出</h2><p>在阅读十四讲第5讲的源码时，注意到下面这部分代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> ( <span class=\"keyword\">int</span> v=<span class=\"number\">0</span>; v&lt;color.rows; v++ )</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ( <span class=\"keyword\">int</span> u=<span class=\"number\">0</span>; u&lt;color.cols; u++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//...</span></span><br><span class=\"line\">        PointT p ;</span><br><span class=\"line\">        p.x = pointWorld[<span class=\"number\">0</span>];</span><br><span class=\"line\">        p.y = pointWorld[<span class=\"number\">1</span>];</span><br><span class=\"line\">        p.z = pointWorld[<span class=\"number\">2</span>];</span><br><span class=\"line\">        p.b = color.data[ v*color.step+u*color.channels() ];</span><br><span class=\"line\">        p.g = color.data[ v*color.step+u*color.channels()+<span class=\"number\">1</span> ];</span><br><span class=\"line\">        p.r = color.data[ v*color.step+u*color.channels()+<span class=\"number\">2</span> ];</span><br><span class=\"line\">        pointCloud-&gt;points.push_back( p );</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>代码中<code>color</code>是彩色图像，9\\10\\11行从内存中读取像素[u,v]的三个通道值。如下图所示，图像在OpenCV中的表示和存储：</p>\n<img src=\"/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/表示和存储.png\">\n<p>其中<code>step</code>是行数据长度，即内存中保存图像的一行数据的空间长度。图像矩阵的像素数据按行存储在内存中，通常情况内存足够大的话图像的每一行是连续存放的，也就是在内存上图像的所有数据存放成一行，这种情况在访问时可以提供很大方便，例如上述代码。</p>\n<h2 id=\"图像的表示\"><a href=\"#图像的表示\" class=\"headerlink\" title=\"图像的表示\"></a>图像的表示</h2><img src=\"/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/图像坐标示意图.png\">\n<p>对于一个位于$x,y$处的像素，它在程序中的访问方式是：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> pixel = image[y][x];</span><br></pre></td></tr></table></figure>\n<p>它对应着灰度值$I(x,y)$的读数。注意$x$和$y$的顺序，如果顺序错误的话，编译器无法提供任何信息，会引起程序运行中的越界错误。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉slam十四讲第5讲</li>\n<li><a href=\"https://blog.csdn.net/xiaowei_cqu/article/details/7771760\" target=\"_blank\" rel=\"noopener\">【OpenCV】访问Mat图像中每个像素的值</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章记录十四讲中代码学习引出的一些内容，主要是计算机中图像的表示和存储相关的。</p>","more":"<h2 id=\"引出\"><a href=\"#引出\" class=\"headerlink\" title=\"引出\"></a>引出</h2><p>在阅读十四讲第5讲的源码时，注意到下面这部分代码：</p>\n<!--�86-->\n<p>代码中<code>color</code>是彩色图像，9\\10\\11行从内存中读取像素[u,v]的三个通道值。如下图所示，图像在OpenCV中的表示和存储：</p>\n<img src=\"/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/表示和存储.png\">\n<p>其中<code>step</code>是行数据长度，即内存中保存图像的一行数据的空间长度。图像矩阵的像素数据按行存储在内存中，通常情况内存足够大的话图像的每一行是连续存放的，也就是在内存上图像的所有数据存放成一行，这种情况在访问时可以提供很大方便，例如上述代码。</p>\n<h2 id=\"图像的表示\"><a href=\"#图像的表示\" class=\"headerlink\" title=\"图像的表示\"></a>图像的表示</h2><img src=\"/2018/10/12/视觉SLAM十四讲阅读笔记八-图像表示与存储/图像坐标示意图.png\">\n<p>对于一个位于$x,y$处的像素，它在程序中的访问方式是：</p>\n<!--�87-->\n<p>它对应着灰度值$I(x,y)$的读数。注意$x$和$y$的顺序，如果顺序错误的话，编译器无法提供任何信息，会引起程序运行中的越界错误。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉slam十四讲第5讲</li>\n<li><a href=\"https://blog.csdn.net/xiaowei_cqu/article/details/7771760\" target=\"_blank\" rel=\"noopener\">【OpenCV】访问Mat图像中每个像素的值</a></li>\n</ol>"},{"title":"视觉SLAM十四讲阅读笔记四-单目相机中的三角测量","date":"2018-08-29T14:47:39.000Z","mathjax":true,"copyright":true,"_content":"\n---\n\n这篇文章是视觉SLAM十四讲第7讲三角测量部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。\n\n<!--more-->\n\n## 概述\n\n三角测量/三角化（triangulation）就是估计地图点的深度值。在使用对极几何约束估计了相机运动之后，需要使用相机的运动估计特征点的空间位置。在单目SLAM中，由于我们无法通过单张图像获得相机的深度，因此我们通过三角测量的方法来估计地图点的深度。 三角测量是指：通过两处观察同一个点的夹角，来确定该点的距离。\n\n## 求解过程\n\n{% asset_img 三角测量.png %}\n\n如上图所示，考虑两幅图像中的特征点分别为$p_1$，$p_2$。理论上直线$O_1p_1$和$O_2p_2$在场景中会相交于一个点$P$，该点即是两个特征点所对应的地图点在三维场景中的位置。但是由于噪声的影响，两条直线往往无法相交。假设点$P$在相机坐标系下的坐标为$c_1$和$c_2$，根据针孔相机中的坐标变换公式可知：\n\n$s_1p_1=Kc_1$\n\n$s_2p_2=Kc_2$\n\n其中$s1$是$c1$在$Z$轴上的坐标，$s2$是$c2$在$Z$轴上的坐标，$K$是相机的内参矩阵。\n\n令：\n\n$p_1=Kx_1$ \n\n$p_2=Kx_2$\n\n其中$x1$,$x2$称为点$P$在相机坐标系下的归一化坐标。\n\n根据三维空间中的运动模型有：\n\n$c_2=Rc_1+t$\n\n$k^{−1}s_1p_1=Rk^{−1}s_2p_2+t$\n\n$s_1x_1=s_2Rx_2+t$\n\n我们已经知道了$R$，$t$，需要求解的就是两个特征点的深度值$s_1$，$s_2$。先同时左乘$x1$的反对称矩阵可得：\n\n$s_1x^\\wedge_1x_1=0=s_2x^\\wedge_1Rx_2+x^\\wedge_1t$\n\n上述等式的右边是个关于未知变量$s_2$的方程，求解此方程即可得到$s_2$。有了$s_2$，$s_1$也就迎刄而解了。\n\n但由于误差的存在，估计的$R$，$t$不一定精确到使上述方程成立，所以更常见的做法是求最小二乘解而不是零解。\n\n## 三角测量的矛盾\n\n三角化测量的前提是两幅图像之间存在平移。有平移才会由对极几何中的三角形，才谈得上三角化测量。\n要提高三角化的精度，其一是提高特征点的提取精度，即提高图像分辨率；其二是使平移量增大。如下图所示，当平移很小时，深度估计的不确定性会增大。因此要使深度的精确度增加，则需要增加平移，但是增加平移会导致图像的外观发生明显的变化，使得特征提取和匹配的难度增加，这称为三角测量的矛盾。\n\n{% asset_img 三角测量的矛盾.png %}\n\n## 参考资料\n\n1. 视觉slam十四讲第7讲\n2. [单目相机中的三角化测量](http://zhehangt.win/2017/03/06/SLAM/Triangularization/)\n3. [Monocular slam 中的理论基础(2)](https://blog.csdn.net/heyijia0327/article/details/50774104)","source":"_posts/视觉SLAM十四讲阅读笔记四-三角测量.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记四-单目相机中的三角测量\ndate: 2018-08-29 22:47:39\ntags: \n  - SLAM基础\n  - 读书笔记\n  - 单目SLAM\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n---\n\n这篇文章是视觉SLAM十四讲第7讲三角测量部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。\n\n<!--more-->\n\n## 概述\n\n三角测量/三角化（triangulation）就是估计地图点的深度值。在使用对极几何约束估计了相机运动之后，需要使用相机的运动估计特征点的空间位置。在单目SLAM中，由于我们无法通过单张图像获得相机的深度，因此我们通过三角测量的方法来估计地图点的深度。 三角测量是指：通过两处观察同一个点的夹角，来确定该点的距离。\n\n## 求解过程\n\n{% asset_img 三角测量.png %}\n\n如上图所示，考虑两幅图像中的特征点分别为$p_1$，$p_2$。理论上直线$O_1p_1$和$O_2p_2$在场景中会相交于一个点$P$，该点即是两个特征点所对应的地图点在三维场景中的位置。但是由于噪声的影响，两条直线往往无法相交。假设点$P$在相机坐标系下的坐标为$c_1$和$c_2$，根据针孔相机中的坐标变换公式可知：\n\n$s_1p_1=Kc_1$\n\n$s_2p_2=Kc_2$\n\n其中$s1$是$c1$在$Z$轴上的坐标，$s2$是$c2$在$Z$轴上的坐标，$K$是相机的内参矩阵。\n\n令：\n\n$p_1=Kx_1$ \n\n$p_2=Kx_2$\n\n其中$x1$,$x2$称为点$P$在相机坐标系下的归一化坐标。\n\n根据三维空间中的运动模型有：\n\n$c_2=Rc_1+t$\n\n$k^{−1}s_1p_1=Rk^{−1}s_2p_2+t$\n\n$s_1x_1=s_2Rx_2+t$\n\n我们已经知道了$R$，$t$，需要求解的就是两个特征点的深度值$s_1$，$s_2$。先同时左乘$x1$的反对称矩阵可得：\n\n$s_1x^\\wedge_1x_1=0=s_2x^\\wedge_1Rx_2+x^\\wedge_1t$\n\n上述等式的右边是个关于未知变量$s_2$的方程，求解此方程即可得到$s_2$。有了$s_2$，$s_1$也就迎刄而解了。\n\n但由于误差的存在，估计的$R$，$t$不一定精确到使上述方程成立，所以更常见的做法是求最小二乘解而不是零解。\n\n## 三角测量的矛盾\n\n三角化测量的前提是两幅图像之间存在平移。有平移才会由对极几何中的三角形，才谈得上三角化测量。\n要提高三角化的精度，其一是提高特征点的提取精度，即提高图像分辨率；其二是使平移量增大。如下图所示，当平移很小时，深度估计的不确定性会增大。因此要使深度的精确度增加，则需要增加平移，但是增加平移会导致图像的外观发生明显的变化，使得特征提取和匹配的难度增加，这称为三角测量的矛盾。\n\n{% asset_img 三角测量的矛盾.png %}\n\n## 参考资料\n\n1. 视觉slam十四讲第7讲\n2. [单目相机中的三角化测量](http://zhehangt.win/2017/03/06/SLAM/Triangularization/)\n3. [Monocular slam 中的理论基础(2)](https://blog.csdn.net/heyijia0327/article/details/50774104)","slug":"视觉SLAM十四讲阅读笔记四-三角测量","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvq0036qlcrfgtde0rb","content":"<hr>\n<p>这篇文章是视觉SLAM十四讲第7讲三角测量部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>三角测量/三角化（triangulation）就是估计地图点的深度值。在使用对极几何约束估计了相机运动之后，需要使用相机的运动估计特征点的空间位置。在单目SLAM中，由于我们无法通过单张图像获得相机的深度，因此我们通过三角测量的方法来估计地图点的深度。 三角测量是指：通过两处观察同一个点的夹角，来确定该点的距离。</p>\n<h2 id=\"求解过程\"><a href=\"#求解过程\" class=\"headerlink\" title=\"求解过程\"></a>求解过程</h2><img src=\"/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/三角测量.png\">\n<p>如上图所示，考虑两幅图像中的特征点分别为$p_1$，$p_2$。理论上直线$O_1p_1$和$O_2p_2$在场景中会相交于一个点$P$，该点即是两个特征点所对应的地图点在三维场景中的位置。但是由于噪声的影响，两条直线往往无法相交。假设点$P$在相机坐标系下的坐标为$c_1$和$c_2$，根据针孔相机中的坐标变换公式可知：</p>\n<p>$s_1p_1=Kc_1$</p>\n<p>$s_2p_2=Kc_2$</p>\n<p>其中$s1$是$c1$在$Z$轴上的坐标，$s2$是$c2$在$Z$轴上的坐标，$K$是相机的内参矩阵。</p>\n<p>令：</p>\n<p>$p_1=Kx_1$ </p>\n<p>$p_2=Kx_2$</p>\n<p>其中$x1$,$x2$称为点$P$在相机坐标系下的归一化坐标。</p>\n<p>根据三维空间中的运动模型有：</p>\n<p>$c_2=Rc_1+t$</p>\n<p>$k^{−1}s_1p_1=Rk^{−1}s_2p_2+t$</p>\n<p>$s_1x_1=s_2Rx_2+t$</p>\n<p>我们已经知道了$R$，$t$，需要求解的就是两个特征点的深度值$s_1$，$s_2$。先同时左乘$x1$的反对称矩阵可得：</p>\n<p>$s_1x^\\wedge_1x_1=0=s_2x^\\wedge_1Rx_2+x^\\wedge_1t$</p>\n<p>上述等式的右边是个关于未知变量$s_2$的方程，求解此方程即可得到$s_2$。有了$s_2$，$s_1$也就迎刄而解了。</p>\n<p>但由于误差的存在，估计的$R$，$t$不一定精确到使上述方程成立，所以更常见的做法是求最小二乘解而不是零解。</p>\n<h2 id=\"三角测量的矛盾\"><a href=\"#三角测量的矛盾\" class=\"headerlink\" title=\"三角测量的矛盾\"></a>三角测量的矛盾</h2><p>三角化测量的前提是两幅图像之间存在平移。有平移才会由对极几何中的三角形，才谈得上三角化测量。<br>要提高三角化的精度，其一是提高特征点的提取精度，即提高图像分辨率；其二是使平移量增大。如下图所示，当平移很小时，深度估计的不确定性会增大。因此要使深度的精确度增加，则需要增加平移，但是增加平移会导致图像的外观发生明显的变化，使得特征提取和匹配的难度增加，这称为三角测量的矛盾。</p>\n<img src=\"/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/三角测量的矛盾.png\">\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉slam十四讲第7讲</li>\n<li><a href=\"http://zhehangt.win/2017/03/06/SLAM/Triangularization/\" target=\"_blank\" rel=\"noopener\">单目相机中的三角化测量</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/50774104\" target=\"_blank\" rel=\"noopener\">Monocular slam 中的理论基础(2)</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是视觉SLAM十四讲第7讲三角测量部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>三角测量/三角化（triangulation）就是估计地图点的深度值。在使用对极几何约束估计了相机运动之后，需要使用相机的运动估计特征点的空间位置。在单目SLAM中，由于我们无法通过单张图像获得相机的深度，因此我们通过三角测量的方法来估计地图点的深度。 三角测量是指：通过两处观察同一个点的夹角，来确定该点的距离。</p>\n<h2 id=\"求解过程\"><a href=\"#求解过程\" class=\"headerlink\" title=\"求解过程\"></a>求解过程</h2><img src=\"/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/三角测量.png\">\n<p>如上图所示，考虑两幅图像中的特征点分别为$p_1$，$p_2$。理论上直线$O_1p_1$和$O_2p_2$在场景中会相交于一个点$P$，该点即是两个特征点所对应的地图点在三维场景中的位置。但是由于噪声的影响，两条直线往往无法相交。假设点$P$在相机坐标系下的坐标为$c_1$和$c_2$，根据针孔相机中的坐标变换公式可知：</p>\n<p>$s_1p_1=Kc_1$</p>\n<p>$s_2p_2=Kc_2$</p>\n<p>其中$s1$是$c1$在$Z$轴上的坐标，$s2$是$c2$在$Z$轴上的坐标，$K$是相机的内参矩阵。</p>\n<p>令：</p>\n<p>$p_1=Kx_1$ </p>\n<p>$p_2=Kx_2$</p>\n<p>其中$x1$,$x2$称为点$P$在相机坐标系下的归一化坐标。</p>\n<p>根据三维空间中的运动模型有：</p>\n<p>$c_2=Rc_1+t$</p>\n<p>$k^{−1}s_1p_1=Rk^{−1}s_2p_2+t$</p>\n<p>$s_1x_1=s_2Rx_2+t$</p>\n<p>我们已经知道了$R$，$t$，需要求解的就是两个特征点的深度值$s_1$，$s_2$。先同时左乘$x1$的反对称矩阵可得：</p>\n<p>$s_1x^\\wedge_1x_1=0=s_2x^\\wedge_1Rx_2+x^\\wedge_1t$</p>\n<p>上述等式的右边是个关于未知变量$s_2$的方程，求解此方程即可得到$s_2$。有了$s_2$，$s_1$也就迎刄而解了。</p>\n<p>但由于误差的存在，估计的$R$，$t$不一定精确到使上述方程成立，所以更常见的做法是求最小二乘解而不是零解。</p>\n<h2 id=\"三角测量的矛盾\"><a href=\"#三角测量的矛盾\" class=\"headerlink\" title=\"三角测量的矛盾\"></a>三角测量的矛盾</h2><p>三角化测量的前提是两幅图像之间存在平移。有平移才会由对极几何中的三角形，才谈得上三角化测量。<br>要提高三角化的精度，其一是提高特征点的提取精度，即提高图像分辨率；其二是使平移量增大。如下图所示，当平移很小时，深度估计的不确定性会增大。因此要使深度的精确度增加，则需要增加平移，但是增加平移会导致图像的外观发生明显的变化，使得特征提取和匹配的难度增加，这称为三角测量的矛盾。</p>\n<img src=\"/2018/08/29/视觉SLAM十四讲阅读笔记四-三角测量/三角测量的矛盾.png\">\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉slam十四讲第7讲</li>\n<li><a href=\"http://zhehangt.win/2017/03/06/SLAM/Triangularization/\" target=\"_blank\" rel=\"noopener\">单目相机中的三角化测量</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/50774104\" target=\"_blank\" rel=\"noopener\">Monocular slam 中的理论基础(2)</a></li>\n</ol>"},{"title":"论文阅读之《DTAM Dense Tracking and Mapping in Real-Time》","date":"2019-05-24T01:28:19.000Z","mathjax":true,"copyright":true,"_content":"---\n\n终于有时间读论文了，DTAM——视觉SLAM直接法鼻祖。\n<!--more--->\n\nDTAM基于稠密的像素匹配方法，而不是特征提取方法，能够进行实时相机追踪和建图。\n\n静态场景下移动RGB相机，系统估计详细的纹理深度地图。\n\n基于关键帧的机制\n\n基于非凸优化框架，最小化全局空间正则化能量函数\n\n基于针对整个稠密模型的帧速率全图像对齐，精确追踪相机的6自由度位姿\n\n使用GPU\n\nDTAM (Dense tracking andmapping) 的目标函数中包含了多种数据关联的误差。包括图像空间的匹配误差(2D-2D)和3D 空间的位置误差(3D-3D)。当帧间运动较小，成功匹配的3D点较多时，使用3D-3D匹配估计位姿矩阵；当帧间运动较大，匹配2D点较多时，使用2d-2d匹配估计基础矩阵。\n\nDTAM的direct method在默认环境亮度不变（brightness consistancy assumption）的前提下，  对每一个像素的深度数据进行inverse depth的提取和不断优化来建立稠密地图并实现稳定的位置跟踪。\n\n## Mapping\n\n> 构建稠密的3D表面模型\n\n本模块的分析详见参考资料2。\n\n构建**代价体素（Cost Volume）**。\n\n## Tracking\n\n> 基于3D模型进行稠密的相机位姿追踪，即全局的图像配准\n\n## 参考资料\n\n1. https://github.com/Ewenwan/MVision/tree/master/vSLAM/DTAM\n2. 墙裂推荐：https://zhuanlan.zhihu.com/p/42137963\n3. slides：https://wenku.baidu.com/view/3774d70c326c1eb91a37f111f18583d049640f04.html\n4. 关于帧间相机旋转估计：http://campar.in.tum.de/twiki/pub/ISMAR08IAR/WebHome/pres.pdf","source":"_posts/论文阅读之《DTAM-Dense-Tracking-and-Mapping-in-Real-Time》.md","raw":"---\ntitle: 论文阅读之《DTAM Dense Tracking and Mapping in Real-Time》\ndate: 2019-05-24 09:28:19\ntags: \n  - SLAM\n  - PTAM\n  - 直接法SLAM\ncategories: \n  - 机器人\n  - SLAM\n  - 论文阅读\nmathjax: true\ncopyright: true\n---\n---\n\n终于有时间读论文了，DTAM——视觉SLAM直接法鼻祖。\n<!--more--->\n\nDTAM基于稠密的像素匹配方法，而不是特征提取方法，能够进行实时相机追踪和建图。\n\n静态场景下移动RGB相机，系统估计详细的纹理深度地图。\n\n基于关键帧的机制\n\n基于非凸优化框架，最小化全局空间正则化能量函数\n\n基于针对整个稠密模型的帧速率全图像对齐，精确追踪相机的6自由度位姿\n\n使用GPU\n\nDTAM (Dense tracking andmapping) 的目标函数中包含了多种数据关联的误差。包括图像空间的匹配误差(2D-2D)和3D 空间的位置误差(3D-3D)。当帧间运动较小，成功匹配的3D点较多时，使用3D-3D匹配估计位姿矩阵；当帧间运动较大，匹配2D点较多时，使用2d-2d匹配估计基础矩阵。\n\nDTAM的direct method在默认环境亮度不变（brightness consistancy assumption）的前提下，  对每一个像素的深度数据进行inverse depth的提取和不断优化来建立稠密地图并实现稳定的位置跟踪。\n\n## Mapping\n\n> 构建稠密的3D表面模型\n\n本模块的分析详见参考资料2。\n\n构建**代价体素（Cost Volume）**。\n\n## Tracking\n\n> 基于3D模型进行稠密的相机位姿追踪，即全局的图像配准\n\n## 参考资料\n\n1. https://github.com/Ewenwan/MVision/tree/master/vSLAM/DTAM\n2. 墙裂推荐：https://zhuanlan.zhihu.com/p/42137963\n3. slides：https://wenku.baidu.com/view/3774d70c326c1eb91a37f111f18583d049640f04.html\n4. 关于帧间相机旋转估计：http://campar.in.tum.de/twiki/pub/ISMAR08IAR/WebHome/pres.pdf","slug":"论文阅读之《DTAM-Dense-Tracking-and-Mapping-in-Real-Time》","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvs003aqlcrfkd1sl8i","content":"<hr>\n<p>终于有时间读论文了，DTAM——视觉SLAM直接法鼻祖。<br><a id=\"more\"></a></p>\n<p>DTAM基于稠密的像素匹配方法，而不是特征提取方法，能够进行实时相机追踪和建图。</p>\n<p>静态场景下移动RGB相机，系统估计详细的纹理深度地图。</p>\n<p>基于关键帧的机制</p>\n<p>基于非凸优化框架，最小化全局空间正则化能量函数</p>\n<p>基于针对整个稠密模型的帧速率全图像对齐，精确追踪相机的6自由度位姿</p>\n<p>使用GPU</p>\n<p>DTAM (Dense tracking andmapping) 的目标函数中包含了多种数据关联的误差。包括图像空间的匹配误差(2D-2D)和3D 空间的位置误差(3D-3D)。当帧间运动较小，成功匹配的3D点较多时，使用3D-3D匹配估计位姿矩阵；当帧间运动较大，匹配2D点较多时，使用2d-2d匹配估计基础矩阵。</p>\n<p>DTAM的direct method在默认环境亮度不变（brightness consistancy assumption）的前提下，  对每一个像素的深度数据进行inverse depth的提取和不断优化来建立稠密地图并实现稳定的位置跟踪。</p>\n<h2 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h2><blockquote>\n<p>构建稠密的3D表面模型</p>\n</blockquote>\n<p>本模块的分析详见参考资料2。</p>\n<p>构建<strong>代价体素（Cost Volume）</strong>。</p>\n<h2 id=\"Tracking\"><a href=\"#Tracking\" class=\"headerlink\" title=\"Tracking\"></a>Tracking</h2><blockquote>\n<p>基于3D模型进行稠密的相机位姿追踪，即全局的图像配准</p>\n</blockquote>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://github.com/Ewenwan/MVision/tree/master/vSLAM/DTAM\" target=\"_blank\" rel=\"noopener\">https://github.com/Ewenwan/MVision/tree/master/vSLAM/DTAM</a></li>\n<li>墙裂推荐：<a href=\"https://zhuanlan.zhihu.com/p/42137963\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/42137963</a></li>\n<li>slides：<a href=\"https://wenku.baidu.com/view/3774d70c326c1eb91a37f111f18583d049640f04.html\" target=\"_blank\" rel=\"noopener\">https://wenku.baidu.com/view/3774d70c326c1eb91a37f111f18583d049640f04.html</a></li>\n<li>关于帧间相机旋转估计：<a href=\"http://campar.in.tum.de/twiki/pub/ISMAR08IAR/WebHome/pres.pdf\" target=\"_blank\" rel=\"noopener\">http://campar.in.tum.de/twiki/pub/ISMAR08IAR/WebHome/pres.pdf</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>终于有时间读论文了，DTAM——视觉SLAM直接法鼻祖。<br>","more":"</p>\n<p>DTAM基于稠密的像素匹配方法，而不是特征提取方法，能够进行实时相机追踪和建图。</p>\n<p>静态场景下移动RGB相机，系统估计详细的纹理深度地图。</p>\n<p>基于关键帧的机制</p>\n<p>基于非凸优化框架，最小化全局空间正则化能量函数</p>\n<p>基于针对整个稠密模型的帧速率全图像对齐，精确追踪相机的6自由度位姿</p>\n<p>使用GPU</p>\n<p>DTAM (Dense tracking andmapping) 的目标函数中包含了多种数据关联的误差。包括图像空间的匹配误差(2D-2D)和3D 空间的位置误差(3D-3D)。当帧间运动较小，成功匹配的3D点较多时，使用3D-3D匹配估计位姿矩阵；当帧间运动较大，匹配2D点较多时，使用2d-2d匹配估计基础矩阵。</p>\n<p>DTAM的direct method在默认环境亮度不变（brightness consistancy assumption）的前提下，  对每一个像素的深度数据进行inverse depth的提取和不断优化来建立稠密地图并实现稳定的位置跟踪。</p>\n<h2 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h2><blockquote>\n<p>构建稠密的3D表面模型</p>\n</blockquote>\n<p>本模块的分析详见参考资料2。</p>\n<p>构建<strong>代价体素（Cost Volume）</strong>。</p>\n<h2 id=\"Tracking\"><a href=\"#Tracking\" class=\"headerlink\" title=\"Tracking\"></a>Tracking</h2><blockquote>\n<p>基于3D模型进行稠密的相机位姿追踪，即全局的图像配准</p>\n</blockquote>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://github.com/Ewenwan/MVision/tree/master/vSLAM/DTAM\" target=\"_blank\" rel=\"noopener\">https://github.com/Ewenwan/MVision/tree/master/vSLAM/DTAM</a></li>\n<li>墙裂推荐：<a href=\"https://zhuanlan.zhihu.com/p/42137963\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/42137963</a></li>\n<li>slides：<a href=\"https://wenku.baidu.com/view/3774d70c326c1eb91a37f111f18583d049640f04.html\" target=\"_blank\" rel=\"noopener\">https://wenku.baidu.com/view/3774d70c326c1eb91a37f111f18583d049640f04.html</a></li>\n<li>关于帧间相机旋转估计：<a href=\"http://campar.in.tum.de/twiki/pub/ISMAR08IAR/WebHome/pres.pdf\" target=\"_blank\" rel=\"noopener\">http://campar.in.tum.de/twiki/pub/ISMAR08IAR/WebHome/pres.pdf</a></li>\n</ol>"},{"title":"视觉SLAM基础学习之非线性最小二乘问题求解方法","date":"2019-05-27T08:57:57.000Z","mathjax":true,"copyright":true,"_content":"---\n\n《Methods for Non-linear Least Squares Problems》学习记录。\n<!--more--->\n\n## Introduction and Definitions\n\n最小二乘问题的目标是找到局部极小解，是全局最优化问题（求目标函数/代价函数的全局最小值）的一个特例。由于全局最优化问题很难求解，习惯上将其简化为查找一个局部的最小解，即找到一个自变量向量，使得目标函数在确定区域内具有极小值。\n\n#### 定义 1.1. 最小二成问题\n\n$f(\\mathbf{x})=(f_1(\\mathbf{x}),f_2(\\mathbf{x}),...,f_m(\\mathbf{x}))$\n\n$f_i(\\mathbf{x})=f_i(x_1,x_2,...,x_n)=y_i,\\quad\\mathcal{R}^n\\mapsto\\mathcal{R},\\mathbf{x}\\in\\mathcal{R}^n,y_i\\in\\mathcal{R}$\n\n$f(\\mathbf{x})$是向量值函数，其自变量处于$n$维空间，值域属于$m$维向量空间，即$f(\\mathbf{x})$的值是向量。\n\n$f_i(\\mathbf{x})$是分量函数，其自变量是$n$维向量，值域属于实数集。\n\n## 2.1 梯度下降法\n\n梯度下降法是通过梯度方向和步长，直接求解目标函数的最小值时的参数。\n\n越接近最优值时，步长应该不断减小，否则会在最优值附近来回震荡。\n\n## 2.2 牛顿法\n\n牛顿法是求解函数值为0时的自变量取值的方法。\n\n利用牛顿法求解目标函数的最小值其实是转化为求使目标函数的一阶导数为0的参数值。这一转换的理论依据是，函数的极值点处的一阶导数为0。\n\n其迭代过程是在当前位置$x_0​$求该函数的切线，该切线和x轴的角点为$x_1​$，作为新的$x_0​$，重复这个过程，直到角点和函数的零点重合。此时的参数值就是使得目标函数取得极值的参数值。其迭代过程如下图所示。\n\n迭代公式：$x_{k+1}:=x_k+h_n=x_k-H^{-1}\\cdot F'(x)=x_k-\\frac{F'(x)}{F''(x)}$\n\n$H$为海森矩阵，其实就是目标函数对参数$x​$的二阶导数。\n\n### 总结\n\n牛顿法是通过求解目标函数的一阶导数为0时的参数，进而求出目标函数最小值时的参数。\n\n收敛速度快。\n\n海森矩阵的逆在迭代过程中不断减少，可以起到逐步减少步长的效果。\n\n缺点：海森矩阵的逆计算复杂，代价比较大，因此有了拟牛顿法。\n\n{% asset_img newton.png %}\n\n## 2.3 线性搜索\n\n该方法确定下降搜索的步长（step length）。\n\n文中的图2.1是代价函数随步长变化而变化的情况，横坐标是步长，其值大于0。\n\n## 参考资料\n\n1. 推荐中文解析：https://blog.csdn.net/zhangjunhit/article/details/88883459\n2. 梯度下降法和牛顿法比较：https://www.cnblogs.com/lyr2015/p/9010532.html \n3. 文献原文：\n\nhttp://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf","source":"_posts/视觉SLAM基础学习之非线性最小二乘问题求解方法.md","raw":"---\ntitle: 视觉SLAM基础学习之非线性最小二乘问题求解方法\ndate: 2019-05-27 16:57:57\ntags: \n  - SLAM\n  - 最小二乘\ncategories: \n  - 机器人\n  - SLAM\n  - 基础学习\nmathjax: true\ncopyright: true\n---\n---\n\n《Methods for Non-linear Least Squares Problems》学习记录。\n<!--more--->\n\n## Introduction and Definitions\n\n最小二乘问题的目标是找到局部极小解，是全局最优化问题（求目标函数/代价函数的全局最小值）的一个特例。由于全局最优化问题很难求解，习惯上将其简化为查找一个局部的最小解，即找到一个自变量向量，使得目标函数在确定区域内具有极小值。\n\n#### 定义 1.1. 最小二成问题\n\n$f(\\mathbf{x})=(f_1(\\mathbf{x}),f_2(\\mathbf{x}),...,f_m(\\mathbf{x}))$\n\n$f_i(\\mathbf{x})=f_i(x_1,x_2,...,x_n)=y_i,\\quad\\mathcal{R}^n\\mapsto\\mathcal{R},\\mathbf{x}\\in\\mathcal{R}^n,y_i\\in\\mathcal{R}$\n\n$f(\\mathbf{x})$是向量值函数，其自变量处于$n$维空间，值域属于$m$维向量空间，即$f(\\mathbf{x})$的值是向量。\n\n$f_i(\\mathbf{x})$是分量函数，其自变量是$n$维向量，值域属于实数集。\n\n## 2.1 梯度下降法\n\n梯度下降法是通过梯度方向和步长，直接求解目标函数的最小值时的参数。\n\n越接近最优值时，步长应该不断减小，否则会在最优值附近来回震荡。\n\n## 2.2 牛顿法\n\n牛顿法是求解函数值为0时的自变量取值的方法。\n\n利用牛顿法求解目标函数的最小值其实是转化为求使目标函数的一阶导数为0的参数值。这一转换的理论依据是，函数的极值点处的一阶导数为0。\n\n其迭代过程是在当前位置$x_0​$求该函数的切线，该切线和x轴的角点为$x_1​$，作为新的$x_0​$，重复这个过程，直到角点和函数的零点重合。此时的参数值就是使得目标函数取得极值的参数值。其迭代过程如下图所示。\n\n迭代公式：$x_{k+1}:=x_k+h_n=x_k-H^{-1}\\cdot F'(x)=x_k-\\frac{F'(x)}{F''(x)}$\n\n$H$为海森矩阵，其实就是目标函数对参数$x​$的二阶导数。\n\n### 总结\n\n牛顿法是通过求解目标函数的一阶导数为0时的参数，进而求出目标函数最小值时的参数。\n\n收敛速度快。\n\n海森矩阵的逆在迭代过程中不断减少，可以起到逐步减少步长的效果。\n\n缺点：海森矩阵的逆计算复杂，代价比较大，因此有了拟牛顿法。\n\n{% asset_img newton.png %}\n\n## 2.3 线性搜索\n\n该方法确定下降搜索的步长（step length）。\n\n文中的图2.1是代价函数随步长变化而变化的情况，横坐标是步长，其值大于0。\n\n## 参考资料\n\n1. 推荐中文解析：https://blog.csdn.net/zhangjunhit/article/details/88883459\n2. 梯度下降法和牛顿法比较：https://www.cnblogs.com/lyr2015/p/9010532.html \n3. 文献原文：\n\nhttp://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf","slug":"视觉SLAM基础学习之非线性最小二乘问题求解方法","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvu003cqlcr49wb6pc9","content":"<hr>\n<p>《Methods for Non-linear Least Squares Problems》学习记录。<br><a id=\"more\"></a></p>\n<h2 id=\"Introduction-and-Definitions\"><a href=\"#Introduction-and-Definitions\" class=\"headerlink\" title=\"Introduction and Definitions\"></a>Introduction and Definitions</h2><p>最小二乘问题的目标是找到局部极小解，是全局最优化问题（求目标函数/代价函数的全局最小值）的一个特例。由于全局最优化问题很难求解，习惯上将其简化为查找一个局部的最小解，即找到一个自变量向量，使得目标函数在确定区域内具有极小值。</p>\n<h4 id=\"定义-1-1-最小二成问题\"><a href=\"#定义-1-1-最小二成问题\" class=\"headerlink\" title=\"定义 1.1. 最小二成问题\"></a>定义 1.1. 最小二成问题</h4><p>$f(\\mathbf{x})=(f_1(\\mathbf{x}),f_2(\\mathbf{x}),…,f_m(\\mathbf{x}))$</p>\n<p>$f_i(\\mathbf{x})=f_i(x_1,x_2,…,x_n)=y_i,\\quad\\mathcal{R}^n\\mapsto\\mathcal{R},\\mathbf{x}\\in\\mathcal{R}^n,y_i\\in\\mathcal{R}$</p>\n<p>$f(\\mathbf{x})$是向量值函数，其自变量处于$n$维空间，值域属于$m$维向量空间，即$f(\\mathbf{x})$的值是向量。</p>\n<p>$f_i(\\mathbf{x})$是分量函数，其自变量是$n$维向量，值域属于实数集。</p>\n<h2 id=\"2-1-梯度下降法\"><a href=\"#2-1-梯度下降法\" class=\"headerlink\" title=\"2.1 梯度下降法\"></a>2.1 梯度下降法</h2><p>梯度下降法是通过梯度方向和步长，直接求解目标函数的最小值时的参数。</p>\n<p>越接近最优值时，步长应该不断减小，否则会在最优值附近来回震荡。</p>\n<h2 id=\"2-2-牛顿法\"><a href=\"#2-2-牛顿法\" class=\"headerlink\" title=\"2.2 牛顿法\"></a>2.2 牛顿法</h2><p>牛顿法是求解函数值为0时的自变量取值的方法。</p>\n<p>利用牛顿法求解目标函数的最小值其实是转化为求使目标函数的一阶导数为0的参数值。这一转换的理论依据是，函数的极值点处的一阶导数为0。</p>\n<p>其迭代过程是在当前位置$x_0​$求该函数的切线，该切线和x轴的角点为$x_1​$，作为新的$x_0​$，重复这个过程，直到角点和函数的零点重合。此时的参数值就是使得目标函数取得极值的参数值。其迭代过程如下图所示。</p>\n<p>迭代公式：$x_{k+1}:=x_k+h_n=x_k-H^{-1}\\cdot F’(x)=x_k-\\frac{F’(x)}{F’’(x)}$</p>\n<p>$H$为海森矩阵，其实就是目标函数对参数$x​$的二阶导数。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>牛顿法是通过求解目标函数的一阶导数为0时的参数，进而求出目标函数最小值时的参数。</p>\n<p>收敛速度快。</p>\n<p>海森矩阵的逆在迭代过程中不断减少，可以起到逐步减少步长的效果。</p>\n<p>缺点：海森矩阵的逆计算复杂，代价比较大，因此有了拟牛顿法。</p>\n<img src=\"/2019/05/27/视觉SLAM基础学习之非线性最小二乘问题求解方法/newton.png\">\n<h2 id=\"2-3-线性搜索\"><a href=\"#2-3-线性搜索\" class=\"headerlink\" title=\"2.3 线性搜索\"></a>2.3 线性搜索</h2><p>该方法确定下降搜索的步长（step length）。</p>\n<p>文中的图2.1是代价函数随步长变化而变化的情况，横坐标是步长，其值大于0。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>推荐中文解析：<a href=\"https://blog.csdn.net/zhangjunhit/article/details/88883459\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhangjunhit/article/details/88883459</a></li>\n<li>梯度下降法和牛顿法比较：<a href=\"https://www.cnblogs.com/lyr2015/p/9010532.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lyr2015/p/9010532.html</a> </li>\n<li>文献原文：</li>\n</ol>\n<p><a href=\"http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf\" target=\"_blank\" rel=\"noopener\">http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>《Methods for Non-linear Least Squares Problems》学习记录。<br>","more":"</p>\n<h2 id=\"Introduction-and-Definitions\"><a href=\"#Introduction-and-Definitions\" class=\"headerlink\" title=\"Introduction and Definitions\"></a>Introduction and Definitions</h2><p>最小二乘问题的目标是找到局部极小解，是全局最优化问题（求目标函数/代价函数的全局最小值）的一个特例。由于全局最优化问题很难求解，习惯上将其简化为查找一个局部的最小解，即找到一个自变量向量，使得目标函数在确定区域内具有极小值。</p>\n<h4 id=\"定义-1-1-最小二成问题\"><a href=\"#定义-1-1-最小二成问题\" class=\"headerlink\" title=\"定义 1.1. 最小二成问题\"></a>定义 1.1. 最小二成问题</h4><p>$f(\\mathbf{x})=(f_1(\\mathbf{x}),f_2(\\mathbf{x}),…,f_m(\\mathbf{x}))$</p>\n<p>$f_i(\\mathbf{x})=f_i(x_1,x_2,…,x_n)=y_i,\\quad\\mathcal{R}^n\\mapsto\\mathcal{R},\\mathbf{x}\\in\\mathcal{R}^n,y_i\\in\\mathcal{R}$</p>\n<p>$f(\\mathbf{x})$是向量值函数，其自变量处于$n$维空间，值域属于$m$维向量空间，即$f(\\mathbf{x})$的值是向量。</p>\n<p>$f_i(\\mathbf{x})$是分量函数，其自变量是$n$维向量，值域属于实数集。</p>\n<h2 id=\"2-1-梯度下降法\"><a href=\"#2-1-梯度下降法\" class=\"headerlink\" title=\"2.1 梯度下降法\"></a>2.1 梯度下降法</h2><p>梯度下降法是通过梯度方向和步长，直接求解目标函数的最小值时的参数。</p>\n<p>越接近最优值时，步长应该不断减小，否则会在最优值附近来回震荡。</p>\n<h2 id=\"2-2-牛顿法\"><a href=\"#2-2-牛顿法\" class=\"headerlink\" title=\"2.2 牛顿法\"></a>2.2 牛顿法</h2><p>牛顿法是求解函数值为0时的自变量取值的方法。</p>\n<p>利用牛顿法求解目标函数的最小值其实是转化为求使目标函数的一阶导数为0的参数值。这一转换的理论依据是，函数的极值点处的一阶导数为0。</p>\n<p>其迭代过程是在当前位置$x_0​$求该函数的切线，该切线和x轴的角点为$x_1​$，作为新的$x_0​$，重复这个过程，直到角点和函数的零点重合。此时的参数值就是使得目标函数取得极值的参数值。其迭代过程如下图所示。</p>\n<p>迭代公式：$x_{k+1}:=x_k+h_n=x_k-H^{-1}\\cdot F’(x)=x_k-\\frac{F’(x)}{F’’(x)}$</p>\n<p>$H$为海森矩阵，其实就是目标函数对参数$x​$的二阶导数。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>牛顿法是通过求解目标函数的一阶导数为0时的参数，进而求出目标函数最小值时的参数。</p>\n<p>收敛速度快。</p>\n<p>海森矩阵的逆在迭代过程中不断减少，可以起到逐步减少步长的效果。</p>\n<p>缺点：海森矩阵的逆计算复杂，代价比较大，因此有了拟牛顿法。</p>\n<img src=\"/2019/05/27/视觉SLAM基础学习之非线性最小二乘问题求解方法/newton.png\">\n<h2 id=\"2-3-线性搜索\"><a href=\"#2-3-线性搜索\" class=\"headerlink\" title=\"2.3 线性搜索\"></a>2.3 线性搜索</h2><p>该方法确定下降搜索的步长（step length）。</p>\n<p>文中的图2.1是代价函数随步长变化而变化的情况，横坐标是步长，其值大于0。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>推荐中文解析：<a href=\"https://blog.csdn.net/zhangjunhit/article/details/88883459\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhangjunhit/article/details/88883459</a></li>\n<li>梯度下降法和牛顿法比较：<a href=\"https://www.cnblogs.com/lyr2015/p/9010532.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lyr2015/p/9010532.html</a> </li>\n<li>文献原文：</li>\n</ol>\n<p><a href=\"http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf\" target=\"_blank\" rel=\"noopener\">http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf</a></p>"},{"title":"跨平台可视化库Pangolin","date":"2018-09-05T11:30:48.000Z","copyright":true,"_content":"\n---\n\n这篇文章记录SLAM中常用的一种跨平台可视化库的简单使用，包括点、线、面的绘制等。\n\n<!--more-->\n\n## 概述\n\nPangolin是SLAM系统中常用于可视化的跨平台库，它是对OpenGL进行封装的轻量级的OpenGL输入/输出和视频显示的库。可以用于3D视觉和3D导航的视觉图，可以输入各种类型的视频、并且可以保留视频和输入数据用于debug。其他的可视化库还有MRPT、OpenCV等，都是跨平台的库。Pangolin库中的各种数据类型`人如其名`，很容易理解。下面学习一些平时常用的内容，实例程序可以参考参考资料1。\n\n## 点 \n\n在Pangolin中，点是一切的基础。OpenGL提供了一系列函数指定一个点，它们都以glVertex开头，后面跟一个数字和1~2个字母。例如：`glVertex2d`、`glVertex2f`、`glVertex3f`、`glVertex3fv`等等。其中数字表示参数的个数，字母表示参数的类型：\n\n- s表示16位整数（OpenGL中将这个类型定义为GLshort）\n- i表示32位整数（OpenGL中将这个类型定义为GLint和GLsizei）\n- f表示32位浮点数（OpenGL中将这个类型定义为GLfloat和GLclampf）\n- d表示64位浮点数（OpenGL中将这个类型定义为GLdouble和GLclampd）\n- v表示传递的几个参数将使用指针的方式\n\n这些函数除了参数的类型和个数不同以外，功能是相同的。OpenGL的很多函数都是采用类似的形式。   \n\nOpenGL中描述一个面（线、点），采用`glBegin`+`glEnd`命令组的形式：  \n\n~~~c++\nglBegin(形状);  　　\n\tglVertex(顶点1);  　　\n\tglVertex(顶点2);  　　\n\t//……  \nglEnd();   \n~~~\n\n形状可以设为：\n\n- `GL_POINTS`：点\n- `GL_LINES`：线\n- `GL_LINE_STRIP`：折线\n- `GL_LINE_LOOP`：封闭折线\n- GL_TRIANGLES：三角形\n- `GL_POLYGON`：多边形\n\n`void glPointSize(GLfloat size);`，该函数用于设定点的大小，size必须大于0.0f，默认值为1.0f，单位为“像素”。 \n\n**注意**：对于具体的OpenGL实现，点的大小都有个限度的，如果设置的size超过最大值，则设置可能会有问题。 \n\n## 线\n\n`void glLineWidth(GLfloat width); `，该函数用于设定直线的宽度，其用法跟`glPointSize`类似。画线的形式和画点函数十分类似，不同在于`glBegin()`中的符号常量。使用图元常量`GL_LINES`可连接每一对相邻顶点而得到一组直线段。\n\n## 三角形\n\n画三角形以不同顶点的连接有三种方式，但都是**内部填充**的方式 。\n\n- `GL_TRIANGLES`：如同`GL_LINES`一样，第一个三角形的点是V0,V1,V2，第二个则是V3,V4,V5，即是一个3的倍数。不然最后的一个或两个点不显示。 \n- `GL_TRIANGLE_STRIP`：填充方式犹如放弃前一个顶点，如第一个三角形V0,V1,V2，第二个则是V1,V2,V3(舍弃V0)。 \n- `GL_TRIANGLE_FAN`：填充方式将永远以V0为起始点，如第一个三角形为V0,V1,V2，第二个则是V0,V2,V3 。\n\n{% asset_img 三角形.png %}\n\n## 其他函数\n\n### `glColor3f`\n\n颜色设置函数，有三个float类型的参数，参数值的范围是[0.0, 1.0]。具体的有：\n\n```c++\nglColor3f(0.0, 0.0, 0.0);  //--> 黑色  \nglColor3f(1.0, 0.0, 0.0);  //--> 红色  \nglColor3f(0.0, 1.0, 0.0);  //--> 绿色  \nglColor3f(0.0, 0.0, 1.0);  //--> 蓝色  \nglColor3f(1.0, 1.0, 0.0);  //--> 黄色  \nglColor3f(1.0, 0.0, 1.0);  //--> 品红色  \nglColor3f(0.0, 1.0, 1.0);  //--> 青色  \nglColor3f(1.0, 1.0, 1.0);  //--> 白色\n```\n\n需要注意的是，如果在`glBegin()`与`glEnd()`函数之间多次连续调用颜色函数，那么只会显示出最后一次调用对应的颜色。例如：\n\n```c++\nglBegin(GL_POINTS)  \n    glColor3f(0.0, 1.0,  0.0);  //绿色  \n    glColor3f(1.0, 1.0,  0.0);  //黄色  \n    glVertex(0.25, 0.75, 0.0);  \nglEnd();\n```\n\n画出来的线是黄色的。\n\n### `glBegin()`\n\n`glBegin()`和`glEnd()`之间可调用的函数：\n\n- `glVertex()`设置顶点坐标 \n- `glColor()`设置当前颜色 \n- `glIndex()`设置当前颜色表 \n- `glNormal()`设置法向坐标\n- `glEvalCoord()`产生坐标 \n- `glCallList()`,`glCallLists()`执行显示列表 \n- `glTexCoord()`设置纹理坐标 \n- `glEdgeFlag()`控制边界绘制 \n- `glMaterial()`设置材质 \n\n## 参考资料\n\n1. [OpenGL（三）之基础绘制篇](http://www.mamicode.com/info-detail-1139707.html)\n2. [OpenGL之glColor3f函数](https://www.jianshu.com/p/de161a954130)\n3. [Pangolin学习](https://www.cnblogs.com/shhu1993/p/6814714.html)","source":"_posts/跨平台可视化库Pangolin.md","raw":"---\ntitle: 跨平台可视化库Pangolin\ndate: 2018-09-05 19:30:48\ntags: \n  - Pangolin\ncategories: \n  - 机器人\n  - SLAM\n  - 可视化库\ncopyright: true\n---\n\n---\n\n这篇文章记录SLAM中常用的一种跨平台可视化库的简单使用，包括点、线、面的绘制等。\n\n<!--more-->\n\n## 概述\n\nPangolin是SLAM系统中常用于可视化的跨平台库，它是对OpenGL进行封装的轻量级的OpenGL输入/输出和视频显示的库。可以用于3D视觉和3D导航的视觉图，可以输入各种类型的视频、并且可以保留视频和输入数据用于debug。其他的可视化库还有MRPT、OpenCV等，都是跨平台的库。Pangolin库中的各种数据类型`人如其名`，很容易理解。下面学习一些平时常用的内容，实例程序可以参考参考资料1。\n\n## 点 \n\n在Pangolin中，点是一切的基础。OpenGL提供了一系列函数指定一个点，它们都以glVertex开头，后面跟一个数字和1~2个字母。例如：`glVertex2d`、`glVertex2f`、`glVertex3f`、`glVertex3fv`等等。其中数字表示参数的个数，字母表示参数的类型：\n\n- s表示16位整数（OpenGL中将这个类型定义为GLshort）\n- i表示32位整数（OpenGL中将这个类型定义为GLint和GLsizei）\n- f表示32位浮点数（OpenGL中将这个类型定义为GLfloat和GLclampf）\n- d表示64位浮点数（OpenGL中将这个类型定义为GLdouble和GLclampd）\n- v表示传递的几个参数将使用指针的方式\n\n这些函数除了参数的类型和个数不同以外，功能是相同的。OpenGL的很多函数都是采用类似的形式。   \n\nOpenGL中描述一个面（线、点），采用`glBegin`+`glEnd`命令组的形式：  \n\n~~~c++\nglBegin(形状);  　　\n\tglVertex(顶点1);  　　\n\tglVertex(顶点2);  　　\n\t//……  \nglEnd();   \n~~~\n\n形状可以设为：\n\n- `GL_POINTS`：点\n- `GL_LINES`：线\n- `GL_LINE_STRIP`：折线\n- `GL_LINE_LOOP`：封闭折线\n- GL_TRIANGLES：三角形\n- `GL_POLYGON`：多边形\n\n`void glPointSize(GLfloat size);`，该函数用于设定点的大小，size必须大于0.0f，默认值为1.0f，单位为“像素”。 \n\n**注意**：对于具体的OpenGL实现，点的大小都有个限度的，如果设置的size超过最大值，则设置可能会有问题。 \n\n## 线\n\n`void glLineWidth(GLfloat width); `，该函数用于设定直线的宽度，其用法跟`glPointSize`类似。画线的形式和画点函数十分类似，不同在于`glBegin()`中的符号常量。使用图元常量`GL_LINES`可连接每一对相邻顶点而得到一组直线段。\n\n## 三角形\n\n画三角形以不同顶点的连接有三种方式，但都是**内部填充**的方式 。\n\n- `GL_TRIANGLES`：如同`GL_LINES`一样，第一个三角形的点是V0,V1,V2，第二个则是V3,V4,V5，即是一个3的倍数。不然最后的一个或两个点不显示。 \n- `GL_TRIANGLE_STRIP`：填充方式犹如放弃前一个顶点，如第一个三角形V0,V1,V2，第二个则是V1,V2,V3(舍弃V0)。 \n- `GL_TRIANGLE_FAN`：填充方式将永远以V0为起始点，如第一个三角形为V0,V1,V2，第二个则是V0,V2,V3 。\n\n{% asset_img 三角形.png %}\n\n## 其他函数\n\n### `glColor3f`\n\n颜色设置函数，有三个float类型的参数，参数值的范围是[0.0, 1.0]。具体的有：\n\n```c++\nglColor3f(0.0, 0.0, 0.0);  //--> 黑色  \nglColor3f(1.0, 0.0, 0.0);  //--> 红色  \nglColor3f(0.0, 1.0, 0.0);  //--> 绿色  \nglColor3f(0.0, 0.0, 1.0);  //--> 蓝色  \nglColor3f(1.0, 1.0, 0.0);  //--> 黄色  \nglColor3f(1.0, 0.0, 1.0);  //--> 品红色  \nglColor3f(0.0, 1.0, 1.0);  //--> 青色  \nglColor3f(1.0, 1.0, 1.0);  //--> 白色\n```\n\n需要注意的是，如果在`glBegin()`与`glEnd()`函数之间多次连续调用颜色函数，那么只会显示出最后一次调用对应的颜色。例如：\n\n```c++\nglBegin(GL_POINTS)  \n    glColor3f(0.0, 1.0,  0.0);  //绿色  \n    glColor3f(1.0, 1.0,  0.0);  //黄色  \n    glVertex(0.25, 0.75, 0.0);  \nglEnd();\n```\n\n画出来的线是黄色的。\n\n### `glBegin()`\n\n`glBegin()`和`glEnd()`之间可调用的函数：\n\n- `glVertex()`设置顶点坐标 \n- `glColor()`设置当前颜色 \n- `glIndex()`设置当前颜色表 \n- `glNormal()`设置法向坐标\n- `glEvalCoord()`产生坐标 \n- `glCallList()`,`glCallLists()`执行显示列表 \n- `glTexCoord()`设置纹理坐标 \n- `glEdgeFlag()`控制边界绘制 \n- `glMaterial()`设置材质 \n\n## 参考资料\n\n1. [OpenGL（三）之基础绘制篇](http://www.mamicode.com/info-detail-1139707.html)\n2. [OpenGL之glColor3f函数](https://www.jianshu.com/p/de161a954130)\n3. [Pangolin学习](https://www.cnblogs.com/shhu1993/p/6814714.html)","slug":"跨平台可视化库Pangolin","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvx003fqlcrst97z8gc","content":"<hr>\n<p>这篇文章记录SLAM中常用的一种跨平台可视化库的简单使用，包括点、线、面的绘制等。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Pangolin是SLAM系统中常用于可视化的跨平台库，它是对OpenGL进行封装的轻量级的OpenGL输入/输出和视频显示的库。可以用于3D视觉和3D导航的视觉图，可以输入各种类型的视频、并且可以保留视频和输入数据用于debug。其他的可视化库还有MRPT、OpenCV等，都是跨平台的库。Pangolin库中的各种数据类型<code>人如其名</code>，很容易理解。下面学习一些平时常用的内容，实例程序可以参考参考资料1。</p>\n<h2 id=\"点\"><a href=\"#点\" class=\"headerlink\" title=\"点\"></a>点</h2><p>在Pangolin中，点是一切的基础。OpenGL提供了一系列函数指定一个点，它们都以glVertex开头，后面跟一个数字和1~2个字母。例如：<code>glVertex2d</code>、<code>glVertex2f</code>、<code>glVertex3f</code>、<code>glVertex3fv</code>等等。其中数字表示参数的个数，字母表示参数的类型：</p>\n<ul>\n<li>s表示16位整数（OpenGL中将这个类型定义为GLshort）</li>\n<li>i表示32位整数（OpenGL中将这个类型定义为GLint和GLsizei）</li>\n<li>f表示32位浮点数（OpenGL中将这个类型定义为GLfloat和GLclampf）</li>\n<li>d表示64位浮点数（OpenGL中将这个类型定义为GLdouble和GLclampd）</li>\n<li>v表示传递的几个参数将使用指针的方式</li>\n</ul>\n<p>这些函数除了参数的类型和个数不同以外，功能是相同的。OpenGL的很多函数都是采用类似的形式。   </p>\n<p>OpenGL中描述一个面（线、点），采用<code>glBegin</code>+<code>glEnd</code>命令组的形式：  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">glBegin(形状);  　　</span><br><span class=\"line\">\tglVertex(顶点<span class=\"number\">1</span>);  　　</span><br><span class=\"line\">\tglVertex(顶点<span class=\"number\">2</span>);  　　</span><br><span class=\"line\">\t<span class=\"comment\">//……  </span></span><br><span class=\"line\">glEnd();</span><br></pre></td></tr></table></figure>\n<p>形状可以设为：</p>\n<ul>\n<li><code>GL_POINTS</code>：点</li>\n<li><code>GL_LINES</code>：线</li>\n<li><code>GL_LINE_STRIP</code>：折线</li>\n<li><code>GL_LINE_LOOP</code>：封闭折线</li>\n<li>GL_TRIANGLES：三角形</li>\n<li><code>GL_POLYGON</code>：多边形</li>\n</ul>\n<p><code>void glPointSize(GLfloat size);</code>，该函数用于设定点的大小，size必须大于0.0f，默认值为1.0f，单位为“像素”。 </p>\n<p><strong>注意</strong>：对于具体的OpenGL实现，点的大小都有个限度的，如果设置的size超过最大值，则设置可能会有问题。 </p>\n<h2 id=\"线\"><a href=\"#线\" class=\"headerlink\" title=\"线\"></a>线</h2><p><code>void glLineWidth(GLfloat width);</code>，该函数用于设定直线的宽度，其用法跟<code>glPointSize</code>类似。画线的形式和画点函数十分类似，不同在于<code>glBegin()</code>中的符号常量。使用图元常量<code>GL_LINES</code>可连接每一对相邻顶点而得到一组直线段。</p>\n<h2 id=\"三角形\"><a href=\"#三角形\" class=\"headerlink\" title=\"三角形\"></a>三角形</h2><p>画三角形以不同顶点的连接有三种方式，但都是<strong>内部填充</strong>的方式 。</p>\n<ul>\n<li><code>GL_TRIANGLES</code>：如同<code>GL_LINES</code>一样，第一个三角形的点是V0,V1,V2，第二个则是V3,V4,V5，即是一个3的倍数。不然最后的一个或两个点不显示。 </li>\n<li><code>GL_TRIANGLE_STRIP</code>：填充方式犹如放弃前一个顶点，如第一个三角形V0,V1,V2，第二个则是V1,V2,V3(舍弃V0)。 </li>\n<li><code>GL_TRIANGLE_FAN</code>：填充方式将永远以V0为起始点，如第一个三角形为V0,V1,V2，第二个则是V0,V2,V3 。</li>\n</ul>\n<img src=\"/2018/09/05/跨平台可视化库Pangolin/三角形.png\">\n<h2 id=\"其他函数\"><a href=\"#其他函数\" class=\"headerlink\" title=\"其他函数\"></a>其他函数</h2><h3 id=\"glColor3f\"><a href=\"#glColor3f\" class=\"headerlink\" title=\"glColor3f\"></a><code>glColor3f</code></h3><p>颜色设置函数，有三个float类型的参数，参数值的范围是[0.0, 1.0]。具体的有：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">glColor3f(<span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>);  <span class=\"comment\">//--&gt; 黑色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">1.0</span>, <span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>);  <span class=\"comment\">//--&gt; 红色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">0.0</span>);  <span class=\"comment\">//--&gt; 绿色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>);  <span class=\"comment\">//--&gt; 蓝色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">1.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">0.0</span>);  <span class=\"comment\">//--&gt; 黄色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">1.0</span>, <span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>);  <span class=\"comment\">//--&gt; 品红色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">1.0</span>);  <span class=\"comment\">//--&gt; 青色  </span></span><br><span class=\"line\">glColor3f(<span class=\"number\">1.0</span>, <span class=\"number\">1.0</span>, <span class=\"number\">1.0</span>);  <span class=\"comment\">//--&gt; 白色</span></span><br></pre></td></tr></table></figure>\n<p>需要注意的是，如果在<code>glBegin()</code>与<code>glEnd()</code>函数之间多次连续调用颜色函数，那么只会显示出最后一次调用对应的颜色。例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">glBegin(GL_POINTS)  </span><br><span class=\"line\">    glColor3f(<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>,  <span class=\"number\">0.0</span>);  <span class=\"comment\">//绿色  </span></span><br><span class=\"line\">    glColor3f(<span class=\"number\">1.0</span>, <span class=\"number\">1.0</span>,  <span class=\"number\">0.0</span>);  <span class=\"comment\">//黄色  </span></span><br><span class=\"line\">    glVertex(<span class=\"number\">0.25</span>, <span class=\"number\">0.75</span>, <span class=\"number\">0.0</span>);  </span><br><span class=\"line\">glEnd();</span><br></pre></td></tr></table></figure>\n<p>画出来的线是黄色的。</p>\n<h3 id=\"glBegin\"><a href=\"#glBegin\" class=\"headerlink\" title=\"glBegin()\"></a><code>glBegin()</code></h3><p><code>glBegin()</code>和<code>glEnd()</code>之间可调用的函数：</p>\n<ul>\n<li><code>glVertex()</code>设置顶点坐标 </li>\n<li><code>glColor()</code>设置当前颜色 </li>\n<li><code>glIndex()</code>设置当前颜色表 </li>\n<li><code>glNormal()</code>设置法向坐标</li>\n<li><code>glEvalCoord()</code>产生坐标 </li>\n<li><code>glCallList()</code>,<code>glCallLists()</code>执行显示列表 </li>\n<li><code>glTexCoord()</code>设置纹理坐标 </li>\n<li><code>glEdgeFlag()</code>控制边界绘制 </li>\n<li><code>glMaterial()</code>设置材质 </li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://www.mamicode.com/info-detail-1139707.html\" target=\"_blank\" rel=\"noopener\">OpenGL（三）之基础绘制篇</a></li>\n<li><a href=\"https://www.jianshu.com/p/de161a954130\" target=\"_blank\" rel=\"noopener\">OpenGL之glColor3f函数</a></li>\n<li><a href=\"https://www.cnblogs.com/shhu1993/p/6814714.html\" target=\"_blank\" rel=\"noopener\">Pangolin学习</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章记录SLAM中常用的一种跨平台可视化库的简单使用，包括点、线、面的绘制等。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Pangolin是SLAM系统中常用于可视化的跨平台库，它是对OpenGL进行封装的轻量级的OpenGL输入/输出和视频显示的库。可以用于3D视觉和3D导航的视觉图，可以输入各种类型的视频、并且可以保留视频和输入数据用于debug。其他的可视化库还有MRPT、OpenCV等，都是跨平台的库。Pangolin库中的各种数据类型<code>人如其名</code>，很容易理解。下面学习一些平时常用的内容，实例程序可以参考参考资料1。</p>\n<h2 id=\"点\"><a href=\"#点\" class=\"headerlink\" title=\"点\"></a>点</h2><p>在Pangolin中，点是一切的基础。OpenGL提供了一系列函数指定一个点，它们都以glVertex开头，后面跟一个数字和1~2个字母。例如：<code>glVertex2d</code>、<code>glVertex2f</code>、<code>glVertex3f</code>、<code>glVertex3fv</code>等等。其中数字表示参数的个数，字母表示参数的类型：</p>\n<ul>\n<li>s表示16位整数（OpenGL中将这个类型定义为GLshort）</li>\n<li>i表示32位整数（OpenGL中将这个类型定义为GLint和GLsizei）</li>\n<li>f表示32位浮点数（OpenGL中将这个类型定义为GLfloat和GLclampf）</li>\n<li>d表示64位浮点数（OpenGL中将这个类型定义为GLdouble和GLclampd）</li>\n<li>v表示传递的几个参数将使用指针的方式</li>\n</ul>\n<p>这些函数除了参数的类型和个数不同以外，功能是相同的。OpenGL的很多函数都是采用类似的形式。   </p>\n<p>OpenGL中描述一个面（线、点），采用<code>glBegin</code>+<code>glEnd</code>命令组的形式：  </p>\n<!--�88-->\n<p>形状可以设为：</p>\n<ul>\n<li><code>GL_POINTS</code>：点</li>\n<li><code>GL_LINES</code>：线</li>\n<li><code>GL_LINE_STRIP</code>：折线</li>\n<li><code>GL_LINE_LOOP</code>：封闭折线</li>\n<li>GL_TRIANGLES：三角形</li>\n<li><code>GL_POLYGON</code>：多边形</li>\n</ul>\n<p><code>void glPointSize(GLfloat size);</code>，该函数用于设定点的大小，size必须大于0.0f，默认值为1.0f，单位为“像素”。 </p>\n<p><strong>注意</strong>：对于具体的OpenGL实现，点的大小都有个限度的，如果设置的size超过最大值，则设置可能会有问题。 </p>\n<h2 id=\"线\"><a href=\"#线\" class=\"headerlink\" title=\"线\"></a>线</h2><p><code>void glLineWidth(GLfloat width);</code>，该函数用于设定直线的宽度，其用法跟<code>glPointSize</code>类似。画线的形式和画点函数十分类似，不同在于<code>glBegin()</code>中的符号常量。使用图元常量<code>GL_LINES</code>可连接每一对相邻顶点而得到一组直线段。</p>\n<h2 id=\"三角形\"><a href=\"#三角形\" class=\"headerlink\" title=\"三角形\"></a>三角形</h2><p>画三角形以不同顶点的连接有三种方式，但都是<strong>内部填充</strong>的方式 。</p>\n<ul>\n<li><code>GL_TRIANGLES</code>：如同<code>GL_LINES</code>一样，第一个三角形的点是V0,V1,V2，第二个则是V3,V4,V5，即是一个3的倍数。不然最后的一个或两个点不显示。 </li>\n<li><code>GL_TRIANGLE_STRIP</code>：填充方式犹如放弃前一个顶点，如第一个三角形V0,V1,V2，第二个则是V1,V2,V3(舍弃V0)。 </li>\n<li><code>GL_TRIANGLE_FAN</code>：填充方式将永远以V0为起始点，如第一个三角形为V0,V1,V2，第二个则是V0,V2,V3 。</li>\n</ul>\n<img src=\"/2018/09/05/跨平台可视化库Pangolin/三角形.png\">\n<h2 id=\"其他函数\"><a href=\"#其他函数\" class=\"headerlink\" title=\"其他函数\"></a>其他函数</h2><h3 id=\"glColor3f\"><a href=\"#glColor3f\" class=\"headerlink\" title=\"glColor3f\"></a><code>glColor3f</code></h3><p>颜色设置函数，有三个float类型的参数，参数值的范围是[0.0, 1.0]。具体的有：</p>\n<!--�89-->\n<p>需要注意的是，如果在<code>glBegin()</code>与<code>glEnd()</code>函数之间多次连续调用颜色函数，那么只会显示出最后一次调用对应的颜色。例如：</p>\n<!--�90-->\n<p>画出来的线是黄色的。</p>\n<h3 id=\"glBegin\"><a href=\"#glBegin\" class=\"headerlink\" title=\"glBegin()\"></a><code>glBegin()</code></h3><p><code>glBegin()</code>和<code>glEnd()</code>之间可调用的函数：</p>\n<ul>\n<li><code>glVertex()</code>设置顶点坐标 </li>\n<li><code>glColor()</code>设置当前颜色 </li>\n<li><code>glIndex()</code>设置当前颜色表 </li>\n<li><code>glNormal()</code>设置法向坐标</li>\n<li><code>glEvalCoord()</code>产生坐标 </li>\n<li><code>glCallList()</code>,<code>glCallLists()</code>执行显示列表 </li>\n<li><code>glTexCoord()</code>设置纹理坐标 </li>\n<li><code>glEdgeFlag()</code>控制边界绘制 </li>\n<li><code>glMaterial()</code>设置材质 </li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://www.mamicode.com/info-detail-1139707.html\" target=\"_blank\" rel=\"noopener\">OpenGL（三）之基础绘制篇</a></li>\n<li><a href=\"https://www.jianshu.com/p/de161a954130\" target=\"_blank\" rel=\"noopener\">OpenGL之glColor3f函数</a></li>\n<li><a href=\"https://www.cnblogs.com/shhu1993/p/6814714.html\" target=\"_blank\" rel=\"noopener\">Pangolin学习</a></li>\n</ol>"},{"title":"论文阅读之主流VSLAM算法初始化总结","date":"2019-05-23T04:17:29.000Z","mathjax":true,"copyright":true,"_content":"---\n\n本文记录主流VSLAM系统初始化过程整理。\n<!--more--->\n\nMonoSLAM：初始化过程需要将相机放置在一个距离已知的平面场景下。\n\nPTAM：初始化过程，假设一个平面场景，计算**单应矩阵**，分解出旋转平移矩阵，作为相机初始位姿。\n\nDTAM：\n\nSVO：系统启动，获取两帧关键帧的位姿；使用最开始的两帧关键帧，采用三角化方法初始化地图；与PTAM相同，初始化时假设一个平面场景，通过估计单应矩阵估算初始位姿。\n\n","source":"_posts/论文阅读之主流VSLAM算法初始化总结.md","raw":"---\ntitle: 论文阅读之主流VSLAM算法初始化总结\ndate: 2019-05-23 12:17:29\ntags: \n  - SLAM\ncategories: \n  - 机器人\n  - SLAM\n  - 论文阅读\nmathjax: true\ncopyright: true\n---\n---\n\n本文记录主流VSLAM系统初始化过程整理。\n<!--more--->\n\nMonoSLAM：初始化过程需要将相机放置在一个距离已知的平面场景下。\n\nPTAM：初始化过程，假设一个平面场景，计算**单应矩阵**，分解出旋转平移矩阵，作为相机初始位姿。\n\nDTAM：\n\nSVO：系统启动，获取两帧关键帧的位姿；使用最开始的两帧关键帧，采用三角化方法初始化地图；与PTAM相同，初始化时假设一个平面场景，通过估计单应矩阵估算初始位姿。\n\n","slug":"论文阅读之主流VSLAM算法初始化总结","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbvy003hqlcrjpjbj762","content":"<hr>\n<p>本文记录主流VSLAM系统初始化过程整理。<br><a id=\"more\"></a></p>\n<p>MonoSLAM：初始化过程需要将相机放置在一个距离已知的平面场景下。</p>\n<p>PTAM：初始化过程，假设一个平面场景，计算<strong>单应矩阵</strong>，分解出旋转平移矩阵，作为相机初始位姿。</p>\n<p>DTAM：</p>\n<p>SVO：系统启动，获取两帧关键帧的位姿；使用最开始的两帧关键帧，采用三角化方法初始化地图；与PTAM相同，初始化时假设一个平面场景，通过估计单应矩阵估算初始位姿。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本文记录主流VSLAM系统初始化过程整理。<br>","more":"</p>\n<p>MonoSLAM：初始化过程需要将相机放置在一个距离已知的平面场景下。</p>\n<p>PTAM：初始化过程，假设一个平面场景，计算<strong>单应矩阵</strong>，分解出旋转平移矩阵，作为相机初始位姿。</p>\n<p>DTAM：</p>\n<p>SVO：系统启动，获取两帧关键帧的位姿；使用最开始的两帧关键帧，采用三角化方法初始化地图；与PTAM相同，初始化时假设一个平面场景，通过估计单应矩阵估算初始位姿。</p>"},{"title":"论文阅读之《SVO Fast Semi-Direct Monocular Visual Odometry》","date":"2019-05-25T01:51:05.000Z","mathjax":true,"copyright":true,"_content":"---\n\n本文介绍半直接法单目视觉里程计：Semi-direct Visual Odometry，即SVO。\n<!--more--->\n\n- 半稠密单目视觉里程计算法SVO (Semi-direct Visual Odometry)：直接使用像素强度值\n- 概率建图方法、异常点剔除策略：Bayesian滤波器用于估计特征点的深度，只有相关的深度滤波器满足收敛条件，三维地图点才被插入地图，因此地图点需要多次测量\n- 可部署至无人机设备，在此之前，应用于无人机的单目视觉里程计都是基于特征法的\n- 结合特征法（追踪特征、并行追踪与建图、关键帧机制）和直接法（低纹理、相机失焦、运动模糊场景更鲁棒）\n- 采用特征匹配关联方法，特征提取只发生在关键帧被用于初始化新的三维地图点时（避免在每帧图像进行特征提取，使得速度得以提升；亚像素特征关联提升了精确性）\n- 基于模型的稀疏图像对齐算法（与之相关的是基于模型的稠密图像对齐算法），用于运动位姿估计\n\n{% asset_img SVO追踪与建图.png %}\n\n如上图所示，系统采用并行的追踪、建图线程。\n\n- **运动估计线程**实现了半直接法完成相机位姿估计，主要步骤：\n  - 基于粗略运动估计完成位姿初始化。初始化位姿使用当前帧和上一帧图像，首先将相同三维点投影至两帧图像，通过最小化投影点的光度误差估计相机初始位姿；\n  - 关联特征Patch对齐，细化投影点的像素坐标；\n  - 运动估计，即细化位姿和三维结构。该过程采用上述的最小化重投影误差方法。\n- **建图线程**基于深度滤波器更新三维点深度信息，主要步骤：\n  - 判断新到达的图像帧是否为关键帧；新的关键帧将会提取特征，非关键帧图像则用于更新深度滤波器；\n  - 在新的关键帧中提取特征后，为关键帧中的每个2D特征，初始化一个概率深度滤波器，用于估计与其对应的三维点。初始的深度滤波器具有很大的深度不确定性，随着新的图像帧的加入，逐步更新2D特征点对应的三维地图点的深度值，直到深度不确定性足够小，深度滤波收敛，插入新的地图点，地图点用于追踪线程的运动估计过程。\n\n## Motion Estimation\n\n### Sparse Model-based Image Alignment\n\n将当前关键帧与上一相邻图像帧（注意不是关键帧）对齐，即**最小化光度误差**Photometric Error（特征点局部Patch的光度误差，Patch的大小为4×4），**优化两帧之间的相对位姿**（初始化为上一帧的位姿或单位矩阵），即图像帧对齐。\n\n$\\mathbf{T}_{k,k-1}=\\mathop{\\arg\\min}\\limits_{\\mathbf{T}_{k,k-1}}\\frac{1}{2}\\sum\\limits_{i\\in\\mathcal{\\overline{R}}}{\\parallel\\delta \\mathbf{I}(\\mathbf{T}_{k,k-1},\\mathbf{u}_i)\\parallel^2}$\n\n其中，$\\delta\\mathbf{I}(\\mathbf{T},\\mathbf{u})=I_k(\\pi(\\mathbf{T}\\cdot\\pi^{-1}(\\mathbf{u},d_{\\mathbf{u}}))-I_{k-1}(\\mathbf{u}),\\quad\\forall\\mathbf{u}\\in\\mathcal{\\overline{R}}$，表示上一帧中的特征点反投影至其相机坐标系下，再变换到当前帧相机坐标系下，重投影得到像素坐标值。\n\n具体过程：\n\n- **准备工作。**通过之前多帧之间的特征检测和深度估计，已确定第$I_{k-1}$帧中特征点位置和深度值，即图中$u_1,u_2,u_3$的坐标即深度值；假设相邻帧$I_{k-1}$和$I_{k}$之间位姿$T_{k,k-1}$已知，一般初始化为上一相邻时刻的位姿或者假设为单位矩阵；\n- **重投影。**将第$I_{k-1}$帧中特征点$u_i$投影到三维空间，得到该帧相机坐标系下的三维点$p^{k-1}_i$；再使用$T_{k,k-1}$将$p^{k-1}_i$变换至当前帧相机坐标系下，得到$p^{k}_i$；再使用相机内参重投影至当前帧图像，得到特征点的像素坐标$u'_i$；\n- **迭代优化更新位姿。**相邻两帧的变化比较小，相同特征点的亮度值变化不大，但由于相对位姿$T_{k,k-1}$是假设值，投影点$u'_i$的位置不准确，导致投影前后的亮度值不相等，有一个差值。因此，通过迭代优化相对位姿，减小这个差值，得到优化后的位姿$T_{k,k-1}$。\n\n{% asset_img a.png %}\n\n### Relaxation Through Feature Alignment\n\n由于上一步估计的相对位姿是不准确的，导致重投影预测的特征点位置$u'_i$并不是真正的特征点位置。下图$I_k$中灰色特征块为假设的真实位置，目前是未知的；蓝色特征块为预测的特征点位置，利用它们之间的偏差构建残差目标函数，和上述直接法类似，即**最小化光度误差**（同样是针对特征点的局部Patch）。但这一步加入了放射变换（因为关键帧与关键帧之间的距离可能比较远，特征点局部Patch也扩大为8×8），而且优化变量不再是相机位姿，而是**特征点预测位置$u'_i$**，通过迭代对特征块的预测位置进行优化，即特征对齐。\n\n$\\mathbf{u'}_i=\\mathop{\\arg\\min}\\limits_{\\mathbf{u'}_i}\\frac{1}{2}{\\parallel \\mathbf{I}_k(\\mathbf{u'}_i)-\\mathbf{A}_{i}\\cdot\\mathbf{I}_r(\\mathbf{u}_i)\\parallel^2},\\quad\\forall i$\n\n{% asset_img b.png %}\n\n### Pose and Structure Refinement\n\n上一步优化的特征点预测位置与第一步预测的特征点位置（即地图点通过第一步估计的位姿重投影的特征点位置）之间有偏差，利用该偏差构造新的优化目标函数，即**最小化重投影特征点位置误差**（不是像素值的差异），**优化当前关键帧相机位姿以及地图点位置**。\n\n> 这一步其实是Bundler Adjustment，包括Motion-only Bundler Adjustment和Structure-only Bundler Adjustment，前者是优化当前帧位姿（如下优化目标函数），后者是优化当前帧关联的地图点位置（优化目标函数与下式相似，只不过优化变量为三维地图点$_{w}\\mathbf{p}_i$位置）。\n\n$\\mathbf{T}_{k,w}=\\mathop{\\arg\\min}\\limits_{\\mathbf{T}_{k,w}}\\frac{1}{2}\\sum\\limits_{i}{\\parallel\\mathbf{u}_i-\\mathbf{\\pi}(\\mathbf{T}_{k,w},_{w}\\mathbf{p}_i)\\parallel^2}$\n\n{% asset_img c.png %}\n\n## Mapping\n\n对于已知位姿的当前帧，Mapping线程估计图像中2D特征（它们关联的三维地图点还未知）的深度值。深度值估计过程采用概率分布模型，每一组观测$\\{I_k,\\mathbf{T}_{k,w}\\}$，都会被用于更新Bayesian框架分布。当分布的变化收敛到足够小时，估计的深度将用于生成三维地图点$_{k}\\mathbf{p}=\\pi^{-1}(\\mathbf{u},d_{\\mathbf{u}})​$，新生成的地图点被加入到地图中，并立即用于运动估计。\n\n每个关键帧与一个深度滤波器关联。\n\n## 参考资料\n\n1. https://github.com/Ewenwan/MVision/tree/master/vSLAM/svo_slam","source":"_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》.md","raw":"---\ntitle: 论文阅读之《SVO Fast Semi-Direct Monocular Visual Odometry》\ndate: 2019-05-25 09:51:05\ntags: \n  - SLAM\n  - SVO\n  - 半直接法SLAM\ncategories: \n  - 机器人\n  - SLAM\n  - 论文阅读\nmathjax: true\ncopyright: true\n---\n---\n\n本文介绍半直接法单目视觉里程计：Semi-direct Visual Odometry，即SVO。\n<!--more--->\n\n- 半稠密单目视觉里程计算法SVO (Semi-direct Visual Odometry)：直接使用像素强度值\n- 概率建图方法、异常点剔除策略：Bayesian滤波器用于估计特征点的深度，只有相关的深度滤波器满足收敛条件，三维地图点才被插入地图，因此地图点需要多次测量\n- 可部署至无人机设备，在此之前，应用于无人机的单目视觉里程计都是基于特征法的\n- 结合特征法（追踪特征、并行追踪与建图、关键帧机制）和直接法（低纹理、相机失焦、运动模糊场景更鲁棒）\n- 采用特征匹配关联方法，特征提取只发生在关键帧被用于初始化新的三维地图点时（避免在每帧图像进行特征提取，使得速度得以提升；亚像素特征关联提升了精确性）\n- 基于模型的稀疏图像对齐算法（与之相关的是基于模型的稠密图像对齐算法），用于运动位姿估计\n\n{% asset_img SVO追踪与建图.png %}\n\n如上图所示，系统采用并行的追踪、建图线程。\n\n- **运动估计线程**实现了半直接法完成相机位姿估计，主要步骤：\n  - 基于粗略运动估计完成位姿初始化。初始化位姿使用当前帧和上一帧图像，首先将相同三维点投影至两帧图像，通过最小化投影点的光度误差估计相机初始位姿；\n  - 关联特征Patch对齐，细化投影点的像素坐标；\n  - 运动估计，即细化位姿和三维结构。该过程采用上述的最小化重投影误差方法。\n- **建图线程**基于深度滤波器更新三维点深度信息，主要步骤：\n  - 判断新到达的图像帧是否为关键帧；新的关键帧将会提取特征，非关键帧图像则用于更新深度滤波器；\n  - 在新的关键帧中提取特征后，为关键帧中的每个2D特征，初始化一个概率深度滤波器，用于估计与其对应的三维点。初始的深度滤波器具有很大的深度不确定性，随着新的图像帧的加入，逐步更新2D特征点对应的三维地图点的深度值，直到深度不确定性足够小，深度滤波收敛，插入新的地图点，地图点用于追踪线程的运动估计过程。\n\n## Motion Estimation\n\n### Sparse Model-based Image Alignment\n\n将当前关键帧与上一相邻图像帧（注意不是关键帧）对齐，即**最小化光度误差**Photometric Error（特征点局部Patch的光度误差，Patch的大小为4×4），**优化两帧之间的相对位姿**（初始化为上一帧的位姿或单位矩阵），即图像帧对齐。\n\n$\\mathbf{T}_{k,k-1}=\\mathop{\\arg\\min}\\limits_{\\mathbf{T}_{k,k-1}}\\frac{1}{2}\\sum\\limits_{i\\in\\mathcal{\\overline{R}}}{\\parallel\\delta \\mathbf{I}(\\mathbf{T}_{k,k-1},\\mathbf{u}_i)\\parallel^2}$\n\n其中，$\\delta\\mathbf{I}(\\mathbf{T},\\mathbf{u})=I_k(\\pi(\\mathbf{T}\\cdot\\pi^{-1}(\\mathbf{u},d_{\\mathbf{u}}))-I_{k-1}(\\mathbf{u}),\\quad\\forall\\mathbf{u}\\in\\mathcal{\\overline{R}}$，表示上一帧中的特征点反投影至其相机坐标系下，再变换到当前帧相机坐标系下，重投影得到像素坐标值。\n\n具体过程：\n\n- **准备工作。**通过之前多帧之间的特征检测和深度估计，已确定第$I_{k-1}$帧中特征点位置和深度值，即图中$u_1,u_2,u_3$的坐标即深度值；假设相邻帧$I_{k-1}$和$I_{k}$之间位姿$T_{k,k-1}$已知，一般初始化为上一相邻时刻的位姿或者假设为单位矩阵；\n- **重投影。**将第$I_{k-1}$帧中特征点$u_i$投影到三维空间，得到该帧相机坐标系下的三维点$p^{k-1}_i$；再使用$T_{k,k-1}$将$p^{k-1}_i$变换至当前帧相机坐标系下，得到$p^{k}_i$；再使用相机内参重投影至当前帧图像，得到特征点的像素坐标$u'_i$；\n- **迭代优化更新位姿。**相邻两帧的变化比较小，相同特征点的亮度值变化不大，但由于相对位姿$T_{k,k-1}$是假设值，投影点$u'_i$的位置不准确，导致投影前后的亮度值不相等，有一个差值。因此，通过迭代优化相对位姿，减小这个差值，得到优化后的位姿$T_{k,k-1}$。\n\n{% asset_img a.png %}\n\n### Relaxation Through Feature Alignment\n\n由于上一步估计的相对位姿是不准确的，导致重投影预测的特征点位置$u'_i$并不是真正的特征点位置。下图$I_k$中灰色特征块为假设的真实位置，目前是未知的；蓝色特征块为预测的特征点位置，利用它们之间的偏差构建残差目标函数，和上述直接法类似，即**最小化光度误差**（同样是针对特征点的局部Patch）。但这一步加入了放射变换（因为关键帧与关键帧之间的距离可能比较远，特征点局部Patch也扩大为8×8），而且优化变量不再是相机位姿，而是**特征点预测位置$u'_i$**，通过迭代对特征块的预测位置进行优化，即特征对齐。\n\n$\\mathbf{u'}_i=\\mathop{\\arg\\min}\\limits_{\\mathbf{u'}_i}\\frac{1}{2}{\\parallel \\mathbf{I}_k(\\mathbf{u'}_i)-\\mathbf{A}_{i}\\cdot\\mathbf{I}_r(\\mathbf{u}_i)\\parallel^2},\\quad\\forall i$\n\n{% asset_img b.png %}\n\n### Pose and Structure Refinement\n\n上一步优化的特征点预测位置与第一步预测的特征点位置（即地图点通过第一步估计的位姿重投影的特征点位置）之间有偏差，利用该偏差构造新的优化目标函数，即**最小化重投影特征点位置误差**（不是像素值的差异），**优化当前关键帧相机位姿以及地图点位置**。\n\n> 这一步其实是Bundler Adjustment，包括Motion-only Bundler Adjustment和Structure-only Bundler Adjustment，前者是优化当前帧位姿（如下优化目标函数），后者是优化当前帧关联的地图点位置（优化目标函数与下式相似，只不过优化变量为三维地图点$_{w}\\mathbf{p}_i$位置）。\n\n$\\mathbf{T}_{k,w}=\\mathop{\\arg\\min}\\limits_{\\mathbf{T}_{k,w}}\\frac{1}{2}\\sum\\limits_{i}{\\parallel\\mathbf{u}_i-\\mathbf{\\pi}(\\mathbf{T}_{k,w},_{w}\\mathbf{p}_i)\\parallel^2}$\n\n{% asset_img c.png %}\n\n## Mapping\n\n对于已知位姿的当前帧，Mapping线程估计图像中2D特征（它们关联的三维地图点还未知）的深度值。深度值估计过程采用概率分布模型，每一组观测$\\{I_k,\\mathbf{T}_{k,w}\\}$，都会被用于更新Bayesian框架分布。当分布的变化收敛到足够小时，估计的深度将用于生成三维地图点$_{k}\\mathbf{p}=\\pi^{-1}(\\mathbf{u},d_{\\mathbf{u}})​$，新生成的地图点被加入到地图中，并立即用于运动估计。\n\n每个关键帧与一个深度滤波器关联。\n\n## 参考资料\n\n1. https://github.com/Ewenwan/MVision/tree/master/vSLAM/svo_slam","slug":"论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyi00arqlcrqu4ltoyh","content":"<hr>\n<p>本文介绍半直接法单目视觉里程计：Semi-direct Visual Odometry，即SVO。<br><a id=\"more\"></a></p>\n<ul>\n<li>半稠密单目视觉里程计算法SVO (Semi-direct Visual Odometry)：直接使用像素强度值</li>\n<li>概率建图方法、异常点剔除策略：Bayesian滤波器用于估计特征点的深度，只有相关的深度滤波器满足收敛条件，三维地图点才被插入地图，因此地图点需要多次测量</li>\n<li>可部署至无人机设备，在此之前，应用于无人机的单目视觉里程计都是基于特征法的</li>\n<li>结合特征法（追踪特征、并行追踪与建图、关键帧机制）和直接法（低纹理、相机失焦、运动模糊场景更鲁棒）</li>\n<li>采用特征匹配关联方法，特征提取只发生在关键帧被用于初始化新的三维地图点时（避免在每帧图像进行特征提取，使得速度得以提升；亚像素特征关联提升了精确性）</li>\n<li>基于模型的稀疏图像对齐算法（与之相关的是基于模型的稠密图像对齐算法），用于运动位姿估计</li>\n</ul>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/SVO追踪与建图.png\">\n<p>如上图所示，系统采用并行的追踪、建图线程。</p>\n<ul>\n<li><strong>运动估计线程</strong>实现了半直接法完成相机位姿估计，主要步骤：<ul>\n<li>基于粗略运动估计完成位姿初始化。初始化位姿使用当前帧和上一帧图像，首先将相同三维点投影至两帧图像，通过最小化投影点的光度误差估计相机初始位姿；</li>\n<li>关联特征Patch对齐，细化投影点的像素坐标；</li>\n<li>运动估计，即细化位姿和三维结构。该过程采用上述的最小化重投影误差方法。</li>\n</ul>\n</li>\n<li><strong>建图线程</strong>基于深度滤波器更新三维点深度信息，主要步骤：<ul>\n<li>判断新到达的图像帧是否为关键帧；新的关键帧将会提取特征，非关键帧图像则用于更新深度滤波器；</li>\n<li>在新的关键帧中提取特征后，为关键帧中的每个2D特征，初始化一个概率深度滤波器，用于估计与其对应的三维点。初始的深度滤波器具有很大的深度不确定性，随着新的图像帧的加入，逐步更新2D特征点对应的三维地图点的深度值，直到深度不确定性足够小，深度滤波收敛，插入新的地图点，地图点用于追踪线程的运动估计过程。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Motion-Estimation\"><a href=\"#Motion-Estimation\" class=\"headerlink\" title=\"Motion Estimation\"></a>Motion Estimation</h2><h3 id=\"Sparse-Model-based-Image-Alignment\"><a href=\"#Sparse-Model-based-Image-Alignment\" class=\"headerlink\" title=\"Sparse Model-based Image Alignment\"></a>Sparse Model-based Image Alignment</h3><p>将当前关键帧与上一相邻图像帧（注意不是关键帧）对齐，即<strong>最小化光度误差</strong>Photometric Error（特征点局部Patch的光度误差，Patch的大小为4×4），<strong>优化两帧之间的相对位姿</strong>（初始化为上一帧的位姿或单位矩阵），即图像帧对齐。</p>\n<p>$\\mathbf{T}<em>{k,k-1}=\\mathop{\\arg\\min}\\limits</em>{\\mathbf{T}<em>{k,k-1}}\\frac{1}{2}\\sum\\limits</em>{i\\in\\mathcal{\\overline{R}}}{\\parallel\\delta \\mathbf{I}(\\mathbf{T}_{k,k-1},\\mathbf{u}_i)\\parallel^2}$</p>\n<p>其中，$\\delta\\mathbf{I}(\\mathbf{T},\\mathbf{u})=I<em>k(\\pi(\\mathbf{T}\\cdot\\pi^{-1}(\\mathbf{u},d</em>{\\mathbf{u}}))-I_{k-1}(\\mathbf{u}),\\quad\\forall\\mathbf{u}\\in\\mathcal{\\overline{R}}$，表示上一帧中的特征点反投影至其相机坐标系下，再变换到当前帧相机坐标系下，重投影得到像素坐标值。</p>\n<p>具体过程：</p>\n<ul>\n<li><strong>准备工作。</strong>通过之前多帧之间的特征检测和深度估计，已确定第$I<em>{k-1}$帧中特征点位置和深度值，即图中$u_1,u_2,u_3$的坐标即深度值；假设相邻帧$I</em>{k-1}$和$I<em>{k}$之间位姿$T</em>{k,k-1}$已知，一般初始化为上一相邻时刻的位姿或者假设为单位矩阵；</li>\n<li><strong>重投影。</strong>将第$I<em>{k-1}$帧中特征点$u_i$投影到三维空间，得到该帧相机坐标系下的三维点$p^{k-1}_i$；再使用$T</em>{k,k-1}$将$p^{k-1}_i$变换至当前帧相机坐标系下，得到$p^{k}_i$；再使用相机内参重投影至当前帧图像，得到特征点的像素坐标$u’_i$；</li>\n<li><strong>迭代优化更新位姿。</strong>相邻两帧的变化比较小，相同特征点的亮度值变化不大，但由于相对位姿$T<em>{k,k-1}$是假设值，投影点$u’_i$的位置不准确，导致投影前后的亮度值不相等，有一个差值。因此，通过迭代优化相对位姿，减小这个差值，得到优化后的位姿$T</em>{k,k-1}$。</li>\n</ul>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/a.png\">\n<h3 id=\"Relaxation-Through-Feature-Alignment\"><a href=\"#Relaxation-Through-Feature-Alignment\" class=\"headerlink\" title=\"Relaxation Through Feature Alignment\"></a>Relaxation Through Feature Alignment</h3><p>由于上一步估计的相对位姿是不准确的，导致重投影预测的特征点位置$u’_i$并不是真正的特征点位置。下图$I_k$中灰色特征块为假设的真实位置，目前是未知的；蓝色特征块为预测的特征点位置，利用它们之间的偏差构建残差目标函数，和上述直接法类似，即<strong>最小化光度误差</strong>（同样是针对特征点的局部Patch）。但这一步加入了放射变换（因为关键帧与关键帧之间的距离可能比较远，特征点局部Patch也扩大为8×8），而且优化变量不再是相机位姿，而是<strong>特征点预测位置$u’_i$</strong>，通过迭代对特征块的预测位置进行优化，即特征对齐。</p>\n<p>$\\mathbf{u’}<em>i=\\mathop{\\arg\\min}\\limits</em>{\\mathbf{u’}<em>i}\\frac{1}{2}{\\parallel \\mathbf{I}_k(\\mathbf{u’}_i)-\\mathbf{A}</em>{i}\\cdot\\mathbf{I}_r(\\mathbf{u}_i)\\parallel^2},\\quad\\forall i$</p>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/b.png\">\n<h3 id=\"Pose-and-Structure-Refinement\"><a href=\"#Pose-and-Structure-Refinement\" class=\"headerlink\" title=\"Pose and Structure Refinement\"></a>Pose and Structure Refinement</h3><p>上一步优化的特征点预测位置与第一步预测的特征点位置（即地图点通过第一步估计的位姿重投影的特征点位置）之间有偏差，利用该偏差构造新的优化目标函数，即<strong>最小化重投影特征点位置误差</strong>（不是像素值的差异），<strong>优化当前关键帧相机位姿以及地图点位置</strong>。</p>\n<blockquote>\n<p>这一步其实是Bundler Adjustment，包括Motion-only Bundler Adjustment和Structure-only Bundler Adjustment，前者是优化当前帧位姿（如下优化目标函数），后者是优化当前帧关联的地图点位置（优化目标函数与下式相似，只不过优化变量为三维地图点$_{w}\\mathbf{p}_i$位置）。</p>\n</blockquote>\n<p>$\\mathbf{T}<em>{k,w}=\\mathop{\\arg\\min}\\limits</em>{\\mathbf{T}<em>{k,w}}\\frac{1}{2}\\sum\\limits</em>{i}{\\parallel\\mathbf{u}<em>i-\\mathbf{\\pi}(\\mathbf{T}</em>{k,w},_{w}\\mathbf{p}_i)\\parallel^2}$</p>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/c.png\">\n<h2 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h2><p>对于已知位姿的当前帧，Mapping线程估计图像中2D特征（它们关联的三维地图点还未知）的深度值。深度值估计过程采用概率分布模型，每一组观测${I<em>k,\\mathbf{T}</em>{k,w}}$，都会被用于更新Bayesian框架分布。当分布的变化收敛到足够小时，估计的深度将用于生成三维地图点$<em>{k}\\mathbf{p}=\\pi^{-1}(\\mathbf{u},d</em>{\\mathbf{u}})​$，新生成的地图点被加入到地图中，并立即用于运动估计。</p>\n<p>每个关键帧与一个深度滤波器关联。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://github.com/Ewenwan/MVision/tree/master/vSLAM/svo_slam\" target=\"_blank\" rel=\"noopener\">https://github.com/Ewenwan/MVision/tree/master/vSLAM/svo_slam</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本文介绍半直接法单目视觉里程计：Semi-direct Visual Odometry，即SVO。<br>","more":"</p>\n<ul>\n<li>半稠密单目视觉里程计算法SVO (Semi-direct Visual Odometry)：直接使用像素强度值</li>\n<li>概率建图方法、异常点剔除策略：Bayesian滤波器用于估计特征点的深度，只有相关的深度滤波器满足收敛条件，三维地图点才被插入地图，因此地图点需要多次测量</li>\n<li>可部署至无人机设备，在此之前，应用于无人机的单目视觉里程计都是基于特征法的</li>\n<li>结合特征法（追踪特征、并行追踪与建图、关键帧机制）和直接法（低纹理、相机失焦、运动模糊场景更鲁棒）</li>\n<li>采用特征匹配关联方法，特征提取只发生在关键帧被用于初始化新的三维地图点时（避免在每帧图像进行特征提取，使得速度得以提升；亚像素特征关联提升了精确性）</li>\n<li>基于模型的稀疏图像对齐算法（与之相关的是基于模型的稠密图像对齐算法），用于运动位姿估计</li>\n</ul>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/SVO追踪与建图.png\">\n<p>如上图所示，系统采用并行的追踪、建图线程。</p>\n<ul>\n<li><strong>运动估计线程</strong>实现了半直接法完成相机位姿估计，主要步骤：<ul>\n<li>基于粗略运动估计完成位姿初始化。初始化位姿使用当前帧和上一帧图像，首先将相同三维点投影至两帧图像，通过最小化投影点的光度误差估计相机初始位姿；</li>\n<li>关联特征Patch对齐，细化投影点的像素坐标；</li>\n<li>运动估计，即细化位姿和三维结构。该过程采用上述的最小化重投影误差方法。</li>\n</ul>\n</li>\n<li><strong>建图线程</strong>基于深度滤波器更新三维点深度信息，主要步骤：<ul>\n<li>判断新到达的图像帧是否为关键帧；新的关键帧将会提取特征，非关键帧图像则用于更新深度滤波器；</li>\n<li>在新的关键帧中提取特征后，为关键帧中的每个2D特征，初始化一个概率深度滤波器，用于估计与其对应的三维点。初始的深度滤波器具有很大的深度不确定性，随着新的图像帧的加入，逐步更新2D特征点对应的三维地图点的深度值，直到深度不确定性足够小，深度滤波收敛，插入新的地图点，地图点用于追踪线程的运动估计过程。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Motion-Estimation\"><a href=\"#Motion-Estimation\" class=\"headerlink\" title=\"Motion Estimation\"></a>Motion Estimation</h2><h3 id=\"Sparse-Model-based-Image-Alignment\"><a href=\"#Sparse-Model-based-Image-Alignment\" class=\"headerlink\" title=\"Sparse Model-based Image Alignment\"></a>Sparse Model-based Image Alignment</h3><p>将当前关键帧与上一相邻图像帧（注意不是关键帧）对齐，即<strong>最小化光度误差</strong>Photometric Error（特征点局部Patch的光度误差，Patch的大小为4×4），<strong>优化两帧之间的相对位姿</strong>（初始化为上一帧的位姿或单位矩阵），即图像帧对齐。</p>\n<p>$\\mathbf{T}<em>{k,k-1}=\\mathop{\\arg\\min}\\limits</em>{\\mathbf{T}<em>{k,k-1}}\\frac{1}{2}\\sum\\limits</em>{i\\in\\mathcal{\\overline{R}}}{\\parallel\\delta \\mathbf{I}(\\mathbf{T}_{k,k-1},\\mathbf{u}_i)\\parallel^2}$</p>\n<p>其中，$\\delta\\mathbf{I}(\\mathbf{T},\\mathbf{u})=I<em>k(\\pi(\\mathbf{T}\\cdot\\pi^{-1}(\\mathbf{u},d</em>{\\mathbf{u}}))-I_{k-1}(\\mathbf{u}),\\quad\\forall\\mathbf{u}\\in\\mathcal{\\overline{R}}$，表示上一帧中的特征点反投影至其相机坐标系下，再变换到当前帧相机坐标系下，重投影得到像素坐标值。</p>\n<p>具体过程：</p>\n<ul>\n<li><strong>准备工作。</strong>通过之前多帧之间的特征检测和深度估计，已确定第$I<em>{k-1}$帧中特征点位置和深度值，即图中$u_1,u_2,u_3$的坐标即深度值；假设相邻帧$I</em>{k-1}$和$I<em>{k}$之间位姿$T</em>{k,k-1}$已知，一般初始化为上一相邻时刻的位姿或者假设为单位矩阵；</li>\n<li><strong>重投影。</strong>将第$I<em>{k-1}$帧中特征点$u_i$投影到三维空间，得到该帧相机坐标系下的三维点$p^{k-1}_i$；再使用$T</em>{k,k-1}$将$p^{k-1}_i$变换至当前帧相机坐标系下，得到$p^{k}_i$；再使用相机内参重投影至当前帧图像，得到特征点的像素坐标$u’_i$；</li>\n<li><strong>迭代优化更新位姿。</strong>相邻两帧的变化比较小，相同特征点的亮度值变化不大，但由于相对位姿$T<em>{k,k-1}$是假设值，投影点$u’_i$的位置不准确，导致投影前后的亮度值不相等，有一个差值。因此，通过迭代优化相对位姿，减小这个差值，得到优化后的位姿$T</em>{k,k-1}$。</li>\n</ul>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/a.png\">\n<h3 id=\"Relaxation-Through-Feature-Alignment\"><a href=\"#Relaxation-Through-Feature-Alignment\" class=\"headerlink\" title=\"Relaxation Through Feature Alignment\"></a>Relaxation Through Feature Alignment</h3><p>由于上一步估计的相对位姿是不准确的，导致重投影预测的特征点位置$u’_i$并不是真正的特征点位置。下图$I_k$中灰色特征块为假设的真实位置，目前是未知的；蓝色特征块为预测的特征点位置，利用它们之间的偏差构建残差目标函数，和上述直接法类似，即<strong>最小化光度误差</strong>（同样是针对特征点的局部Patch）。但这一步加入了放射变换（因为关键帧与关键帧之间的距离可能比较远，特征点局部Patch也扩大为8×8），而且优化变量不再是相机位姿，而是<strong>特征点预测位置$u’_i$</strong>，通过迭代对特征块的预测位置进行优化，即特征对齐。</p>\n<p>$\\mathbf{u’}<em>i=\\mathop{\\arg\\min}\\limits</em>{\\mathbf{u’}<em>i}\\frac{1}{2}{\\parallel \\mathbf{I}_k(\\mathbf{u’}_i)-\\mathbf{A}</em>{i}\\cdot\\mathbf{I}_r(\\mathbf{u}_i)\\parallel^2},\\quad\\forall i$</p>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/b.png\">\n<h3 id=\"Pose-and-Structure-Refinement\"><a href=\"#Pose-and-Structure-Refinement\" class=\"headerlink\" title=\"Pose and Structure Refinement\"></a>Pose and Structure Refinement</h3><p>上一步优化的特征点预测位置与第一步预测的特征点位置（即地图点通过第一步估计的位姿重投影的特征点位置）之间有偏差，利用该偏差构造新的优化目标函数，即<strong>最小化重投影特征点位置误差</strong>（不是像素值的差异），<strong>优化当前关键帧相机位姿以及地图点位置</strong>。</p>\n<blockquote>\n<p>这一步其实是Bundler Adjustment，包括Motion-only Bundler Adjustment和Structure-only Bundler Adjustment，前者是优化当前帧位姿（如下优化目标函数），后者是优化当前帧关联的地图点位置（优化目标函数与下式相似，只不过优化变量为三维地图点$_{w}\\mathbf{p}_i$位置）。</p>\n</blockquote>\n<p>$\\mathbf{T}<em>{k,w}=\\mathop{\\arg\\min}\\limits</em>{\\mathbf{T}<em>{k,w}}\\frac{1}{2}\\sum\\limits</em>{i}{\\parallel\\mathbf{u}<em>i-\\mathbf{\\pi}(\\mathbf{T}</em>{k,w},_{w}\\mathbf{p}_i)\\parallel^2}$</p>\n<img src=\"/2019/05/25/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/c.png\">\n<h2 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h2><p>对于已知位姿的当前帧，Mapping线程估计图像中2D特征（它们关联的三维地图点还未知）的深度值。深度值估计过程采用概率分布模型，每一组观测${I<em>k,\\mathbf{T}</em>{k,w}}$，都会被用于更新Bayesian框架分布。当分布的变化收敛到足够小时，估计的深度将用于生成三维地图点$<em>{k}\\mathbf{p}=\\pi^{-1}(\\mathbf{u},d</em>{\\mathbf{u}})​$，新生成的地图点被加入到地图中，并立即用于运动估计。</p>\n<p>每个关键帧与一个深度滤波器关联。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://github.com/Ewenwan/MVision/tree/master/vSLAM/svo_slam\" target=\"_blank\" rel=\"noopener\">https://github.com/Ewenwan/MVision/tree/master/vSLAM/svo_slam</a></li>\n</ol>"},{"title":"C++学习之const关键字","date":"2018-03-23T13:39:43.000Z","copyright":true,"_content":"\n------\n\n这篇文章是有关C++ const关键字的学习内容。\n\n<!--more--->\n\n# const介绍与分类\n\n`const`是constant的简写，只要一个变量前面用`const`来修饰，就意味着该变量里的数据可以被访问，不能被修改。也就是说const意味着“只读”readonly。\n\n采用符号常量写出的代码更容易维护；指针常常是边读边移动，而不是边写边移动；许多函数参数是只读不写的。const最常见用途是作为数组的界和switch分情况标号(也可以用枚举符代替)，const的使用分类如下：\n\n- 常变量：  **const 类型说明符 变量名**\n- 常引用：  **const 类型说明符 &引用名**\n- 常对象：  **类名 const 对象名**\n- 常成员函数：  **类名::fun(形参) const**\n- 常数组：  **类型说明符 const 数组名[大小]**    \n- 常指针：\n  - **const 类型说明符\\* 指针名 ** (指针称为指针常量，指针指向是一个常量)\n  - **类型说明符* const 指针名**  (指针称为常量指针，指针本身是一个常量)\n\n注意：在常变量、常引用、常对象、常数组，const 与 “类型说明符”或“类名”（其实类名是一种自定义的类型说明符）的位置可以互换，但在常指针中不能互换，这一点在下面的内容也会提到。\n\n# const的作用\n\n1. 如果想阻止一个变量被改变，可以使用`const`关键字。在定义该const变量时，通常需要对它进行初始化，因为以后就没有机会再去改变它了；例如`const int a = 3; const int & b = a;`必须向上面的方式写进行初始化，但`const int * p; int a = 3; p = &a; `，这样也是可以的，当然最好将指针常量初始化为`Null`。\n\n2. 对指针来说，可以指定指针本身为`const`，也可以指定指针所指的数据为`const`，或二者同时指定为`const`；\n\n   例如：\n\n   ~~~c++\n   int b = 500;\n   const int * a = &b;       //1\n   int const * a = &b;       //2\n   int * const a = &b;       //3\n   const int * const a = &b; //4\n   ~~~\n\n   分析：\n\n   - `const`位于`*`左侧，`const`修饰指针所指向的变量，即指针指向常量，不能修改指针指向的内容，p称为指针常量；\n   - `const`位于`*`右侧，`const`修饰指针本身，即指针本身是常量，不能对指针本身进行更改操作，p是常量指针。\n\n   因此，1和2的情况相同，都是指针所指向的内容为常量（`const`放在变量声明符的位置无关），这种情况下不允许对内容进行更改操作，如不能`*a = 3` ；\n\n   3表示指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如`a++`是错误的；\n\n   4为指针本身和指向的内容均为常量。\n\n3. 在一个函数声明中，`const`可以修饰形参，表明它是一个输入参数，在函数内部不能改变其值；\n\n   例如：\n\n   ~~~c++\n   void fun0(const A * a );\n   void fun1(const A & a); \n   ~~~\n\n   调用函数的时候，用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，如形参为｀`const A* a`，则不能对传递进来的指针的内容进行改变，保护了原指针所指向的内容；如形参为`const A& a` ，则不能对传递进来的引用对象进行改变，保护了原对象的属性。\n\n   注意：参数`const` 通常用于参数为指针或引用的情况。\n\n   ​\n\n4. 对于类的成员函数，若指定其为`const`类型，则表明其是一个常函数，不能修改类的成员变量；`const` 一般放在函数体后，形如：`void fun() const;`。 如果一个成员函数的不会修改数据成员，最好将其声明为`const`，因为`const`成员函数中不允许对数据成员进行修改，如果修改，编译器将报错，这大大提高了程序的健壮性。\n\n   **知识扩展：**如果有在`const`函数中修改成员变量值的需求，可以把成员变量声明为`mutable`类型，声明为`mutable`类型的成员变量可以在常函数中被修改。`mutable`是为了突破const的限制而设置的，被`mutable`修饰的变量，将永远处于可变的状态，即使在一个const函数中。可以[参考博客](https://blog.csdn.net/starlee/article/details/1430387)　理解。\n\n5. 对于类的成员函数，有时候必须指定其返回值为`const`类型，以使得其返回值不为\"左值”。\n\n   例如：\n\n   `const classA operator*(const classA & a1, const classA & a2);`\n\n   `operator*`的返回结果必须是一个`const`对象。需要注意，如果返回值不是`const`对象也不会编译出错。\n\n   ```c++\n   classA a, b, c;\n   (a * b) = c; // 对a*b的结果赋值\n   ```\n\n   操作`(a * b) = c`显然不符合编程者的初衷，也没有任何意义。\n\n   ​\n\n   **注意：**\n\n   - `const` 返回类型只有在修饰指针或引用是才有用。\n\n   - `const`对象只能调用类的`const`函数，因为常量对象的状态不允许被修改，调用常量对象的非常量函数会出错\n\n   - 在类中只有`const`函数时，非`const`对象可以调用`cosnt`函数，但有非`const`函数时，非`const`对象不能调用`const`函数。\n\n   - 非`const`函数、`const`函数同时存在时，非常对象将调用非常函数，常对象调用常函数。\n\n     例如：\n\n     ~~~c++\n     #include <iostream>\n     using namespace std;\n\n     class A\n     {\n         public:\n             A(int v): val(v) {}\n             \n             void print_val() { cout << \"not const:\" << val << endl;}\n             void print_val() const { val++; cout << \"const print_val:\" << val << endl;}\n             \n         private:\n             mutable int val;//注意体会mutable的作用\n     };\n\n     int main(int argc ,char **argv)\n     {\n         A b(45);\n         b.print_val();\n\n         const A a(12);\n         a.print_val();\n     }\n     ~~~\n\n     输出结果为：\n\n     ~~~\n     not const:45\n     const print_val:13\n     ~~~\n\n6. 类的成员变量为`const`类型时，类的const成员变量的初始化，必须在构造函数的初始化列表中进行。初始化列表是先于构造函数的函数体执行，并且成员初始化列表中的变量初始化顺序与成员在类中的声明顺序相同。\n\n   **注意：**\n\n   - `const`修饰的局部变量在栈上分配内存空间，`const`修饰的全局变量在只读存储区分配内储存空间。\n   - **类的static　const成员变量可以在类的内部声明时初始化**\n\n# const的初始化\n\n1. 非指针`const`常量初始化\n\n   ~~~c++\n   classA b;\n   const classA a = b;\n   ~~~\n\n2. 指针(引用)const常量初始化\n\n   - 指针\n\n   ```c++\n   classA * d = new classA();\n   const classA * c = d;\n   ```\n\n   或\n\n   ```c++\n   const classA * c = new classA();\n   ```\n\n   - 引用\n\n   ```c++\n   classA f;\n   const classA　& e = f; //这种方式，e只能访问声明为const的成员函数，不能访问一般的成员函数\n\n   ```\n\n3. 类的const成员变量初始化\n\n   ~~~c++\n   class A  \n   {  \n   public:   \n          A():Size(0){}//必须在构造函数的初始化列表初始化\n          \n   private:\n         const int Size;\n   }  \n   ~~~\n\n# 思考题\n\n1. 以下的这种赋值方法正确吗？\n\n    ```c++\n       const classA * c = new classA();\n       classA * e = c; \n    ```\n\n\n2. 以下的这种赋值方法正确吗？\n\n   ```c++\n   classA * const c = new classA();\n   classA * b = c;\n   ```\n\n3. 这样定义赋值操作符重载函数可以吗？\n\n    ~~~c++\n      const classA & operator = (const classA & a);\n    ~~~\n\n[思考题答案]\n\n1. 不正确。因为声明指针的目的是为了对其指向的内容进行改变，而声明的指针`e`指向的是一个常量，所以不正确。\n\n2. 正确。因为声明指针所指向的内容可变。\n\n3. 不正确。在`const A::operator=(const A& a)`中，参数列表中的`const`的用法正确，而当这样连续赋值的时侯，问题就出现了：\n\n   ~~~c++\n   A a,b,c:\n   (a = b) = c;\n   ~~~\n\n   因为`a.operator = (b)`的返回值是对`a`的`const`引用，不能再将`c`赋值给`const`常量。","source":"_posts/C++学习之const关键字.md","raw":"---\ntitle: C++学习之const关键字\ndate: 2018-03-23 21:39:43\ntags:\n  - C++\n  - 面试\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n------\n\n这篇文章是有关C++ const关键字的学习内容。\n\n<!--more--->\n\n# const介绍与分类\n\n`const`是constant的简写，只要一个变量前面用`const`来修饰，就意味着该变量里的数据可以被访问，不能被修改。也就是说const意味着“只读”readonly。\n\n采用符号常量写出的代码更容易维护；指针常常是边读边移动，而不是边写边移动；许多函数参数是只读不写的。const最常见用途是作为数组的界和switch分情况标号(也可以用枚举符代替)，const的使用分类如下：\n\n- 常变量：  **const 类型说明符 变量名**\n- 常引用：  **const 类型说明符 &引用名**\n- 常对象：  **类名 const 对象名**\n- 常成员函数：  **类名::fun(形参) const**\n- 常数组：  **类型说明符 const 数组名[大小]**    \n- 常指针：\n  - **const 类型说明符\\* 指针名 ** (指针称为指针常量，指针指向是一个常量)\n  - **类型说明符* const 指针名**  (指针称为常量指针，指针本身是一个常量)\n\n注意：在常变量、常引用、常对象、常数组，const 与 “类型说明符”或“类名”（其实类名是一种自定义的类型说明符）的位置可以互换，但在常指针中不能互换，这一点在下面的内容也会提到。\n\n# const的作用\n\n1. 如果想阻止一个变量被改变，可以使用`const`关键字。在定义该const变量时，通常需要对它进行初始化，因为以后就没有机会再去改变它了；例如`const int a = 3; const int & b = a;`必须向上面的方式写进行初始化，但`const int * p; int a = 3; p = &a; `，这样也是可以的，当然最好将指针常量初始化为`Null`。\n\n2. 对指针来说，可以指定指针本身为`const`，也可以指定指针所指的数据为`const`，或二者同时指定为`const`；\n\n   例如：\n\n   ~~~c++\n   int b = 500;\n   const int * a = &b;       //1\n   int const * a = &b;       //2\n   int * const a = &b;       //3\n   const int * const a = &b; //4\n   ~~~\n\n   分析：\n\n   - `const`位于`*`左侧，`const`修饰指针所指向的变量，即指针指向常量，不能修改指针指向的内容，p称为指针常量；\n   - `const`位于`*`右侧，`const`修饰指针本身，即指针本身是常量，不能对指针本身进行更改操作，p是常量指针。\n\n   因此，1和2的情况相同，都是指针所指向的内容为常量（`const`放在变量声明符的位置无关），这种情况下不允许对内容进行更改操作，如不能`*a = 3` ；\n\n   3表示指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如`a++`是错误的；\n\n   4为指针本身和指向的内容均为常量。\n\n3. 在一个函数声明中，`const`可以修饰形参，表明它是一个输入参数，在函数内部不能改变其值；\n\n   例如：\n\n   ~~~c++\n   void fun0(const A * a );\n   void fun1(const A & a); \n   ~~~\n\n   调用函数的时候，用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，如形参为｀`const A* a`，则不能对传递进来的指针的内容进行改变，保护了原指针所指向的内容；如形参为`const A& a` ，则不能对传递进来的引用对象进行改变，保护了原对象的属性。\n\n   注意：参数`const` 通常用于参数为指针或引用的情况。\n\n   ​\n\n4. 对于类的成员函数，若指定其为`const`类型，则表明其是一个常函数，不能修改类的成员变量；`const` 一般放在函数体后，形如：`void fun() const;`。 如果一个成员函数的不会修改数据成员，最好将其声明为`const`，因为`const`成员函数中不允许对数据成员进行修改，如果修改，编译器将报错，这大大提高了程序的健壮性。\n\n   **知识扩展：**如果有在`const`函数中修改成员变量值的需求，可以把成员变量声明为`mutable`类型，声明为`mutable`类型的成员变量可以在常函数中被修改。`mutable`是为了突破const的限制而设置的，被`mutable`修饰的变量，将永远处于可变的状态，即使在一个const函数中。可以[参考博客](https://blog.csdn.net/starlee/article/details/1430387)　理解。\n\n5. 对于类的成员函数，有时候必须指定其返回值为`const`类型，以使得其返回值不为\"左值”。\n\n   例如：\n\n   `const classA operator*(const classA & a1, const classA & a2);`\n\n   `operator*`的返回结果必须是一个`const`对象。需要注意，如果返回值不是`const`对象也不会编译出错。\n\n   ```c++\n   classA a, b, c;\n   (a * b) = c; // 对a*b的结果赋值\n   ```\n\n   操作`(a * b) = c`显然不符合编程者的初衷，也没有任何意义。\n\n   ​\n\n   **注意：**\n\n   - `const` 返回类型只有在修饰指针或引用是才有用。\n\n   - `const`对象只能调用类的`const`函数，因为常量对象的状态不允许被修改，调用常量对象的非常量函数会出错\n\n   - 在类中只有`const`函数时，非`const`对象可以调用`cosnt`函数，但有非`const`函数时，非`const`对象不能调用`const`函数。\n\n   - 非`const`函数、`const`函数同时存在时，非常对象将调用非常函数，常对象调用常函数。\n\n     例如：\n\n     ~~~c++\n     #include <iostream>\n     using namespace std;\n\n     class A\n     {\n         public:\n             A(int v): val(v) {}\n             \n             void print_val() { cout << \"not const:\" << val << endl;}\n             void print_val() const { val++; cout << \"const print_val:\" << val << endl;}\n             \n         private:\n             mutable int val;//注意体会mutable的作用\n     };\n\n     int main(int argc ,char **argv)\n     {\n         A b(45);\n         b.print_val();\n\n         const A a(12);\n         a.print_val();\n     }\n     ~~~\n\n     输出结果为：\n\n     ~~~\n     not const:45\n     const print_val:13\n     ~~~\n\n6. 类的成员变量为`const`类型时，类的const成员变量的初始化，必须在构造函数的初始化列表中进行。初始化列表是先于构造函数的函数体执行，并且成员初始化列表中的变量初始化顺序与成员在类中的声明顺序相同。\n\n   **注意：**\n\n   - `const`修饰的局部变量在栈上分配内存空间，`const`修饰的全局变量在只读存储区分配内储存空间。\n   - **类的static　const成员变量可以在类的内部声明时初始化**\n\n# const的初始化\n\n1. 非指针`const`常量初始化\n\n   ~~~c++\n   classA b;\n   const classA a = b;\n   ~~~\n\n2. 指针(引用)const常量初始化\n\n   - 指针\n\n   ```c++\n   classA * d = new classA();\n   const classA * c = d;\n   ```\n\n   或\n\n   ```c++\n   const classA * c = new classA();\n   ```\n\n   - 引用\n\n   ```c++\n   classA f;\n   const classA　& e = f; //这种方式，e只能访问声明为const的成员函数，不能访问一般的成员函数\n\n   ```\n\n3. 类的const成员变量初始化\n\n   ~~~c++\n   class A  \n   {  \n   public:   \n          A():Size(0){}//必须在构造函数的初始化列表初始化\n          \n   private:\n         const int Size;\n   }  \n   ~~~\n\n# 思考题\n\n1. 以下的这种赋值方法正确吗？\n\n    ```c++\n       const classA * c = new classA();\n       classA * e = c; \n    ```\n\n\n2. 以下的这种赋值方法正确吗？\n\n   ```c++\n   classA * const c = new classA();\n   classA * b = c;\n   ```\n\n3. 这样定义赋值操作符重载函数可以吗？\n\n    ~~~c++\n      const classA & operator = (const classA & a);\n    ~~~\n\n[思考题答案]\n\n1. 不正确。因为声明指针的目的是为了对其指向的内容进行改变，而声明的指针`e`指向的是一个常量，所以不正确。\n\n2. 正确。因为声明指针所指向的内容可变。\n\n3. 不正确。在`const A::operator=(const A& a)`中，参数列表中的`const`的用法正确，而当这样连续赋值的时侯，问题就出现了：\n\n   ~~~c++\n   A a,b,c:\n   (a = b) = c;\n   ~~~\n\n   因为`a.operator = (b)`的返回值是对`a`的`const`引用，不能再将`c`赋值给`const`常量。","slug":"C++学习之const关键字","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyj00atqlcronu7u4dv","content":"<hr>\n<p>这篇文章是有关C++ const关键字的学习内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"const介绍与分类\"><a href=\"#const介绍与分类\" class=\"headerlink\" title=\"const介绍与分类\"></a>const介绍与分类</h1><p><code>const</code>是constant的简写，只要一个变量前面用<code>const</code>来修饰，就意味着该变量里的数据可以被访问，不能被修改。也就是说const意味着“只读”readonly。</p>\n<p>采用符号常量写出的代码更容易维护；指针常常是边读边移动，而不是边写边移动；许多函数参数是只读不写的。const最常见用途是作为数组的界和switch分情况标号(也可以用枚举符代替)，const的使用分类如下：</p>\n<ul>\n<li>常变量：  <strong>const 类型说明符 变量名</strong></li>\n<li>常引用：  <strong>const 类型说明符 &amp;引用名</strong></li>\n<li>常对象：  <strong>类名 const 对象名</strong></li>\n<li>常成员函数：  <strong>类名::fun(形参) const</strong></li>\n<li>常数组：  <strong>类型说明符 const 数组名[大小]</strong>    </li>\n<li>常指针：<ul>\n<li><strong>const 类型说明符* 指针名 </strong> (指针称为指针常量，指针指向是一个常量)</li>\n<li><strong>类型说明符* const 指针名</strong>  (指针称为常量指针，指针本身是一个常量)</li>\n</ul>\n</li>\n</ul>\n<p>注意：在常变量、常引用、常对象、常数组，const 与 “类型说明符”或“类名”（其实类名是一种自定义的类型说明符）的位置可以互换，但在常指针中不能互换，这一点在下面的内容也会提到。</p>\n<h1 id=\"const的作用\"><a href=\"#const的作用\" class=\"headerlink\" title=\"const的作用\"></a>const的作用</h1><ol>\n<li><p>如果想阻止一个变量被改变，可以使用<code>const</code>关键字。在定义该const变量时，通常需要对它进行初始化，因为以后就没有机会再去改变它了；例如<code>const int a = 3; const int &amp; b = a;</code>必须向上面的方式写进行初始化，但<code>const int * p; int a = 3; p = &amp;a;</code>，这样也是可以的，当然最好将指针常量初始化为<code>Null</code>。</p>\n</li>\n<li><p>对指针来说，可以指定指针本身为<code>const</code>，也可以指定指针所指的数据为<code>const</code>，或二者同时指定为<code>const</code>；</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> b = <span class=\"number\">500</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> * a = &amp;b;       <span class=\"comment\">//1</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> * a = &amp;b;       <span class=\"comment\">//2</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> a = &amp;b;       <span class=\"comment\">//3</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> * <span class=\"keyword\">const</span> a = &amp;b; <span class=\"comment\">//4</span></span><br></pre></td></tr></table></figure>\n<p>分析：</p>\n<ul>\n<li><code>const</code>位于<code>*</code>左侧，<code>const</code>修饰指针所指向的变量，即指针指向常量，不能修改指针指向的内容，p称为指针常量；</li>\n<li><code>const</code>位于<code>*</code>右侧，<code>const</code>修饰指针本身，即指针本身是常量，不能对指针本身进行更改操作，p是常量指针。</li>\n</ul>\n<p>因此，1和2的情况相同，都是指针所指向的内容为常量（<code>const</code>放在变量声明符的位置无关），这种情况下不允许对内容进行更改操作，如不能<code>*a = 3</code> ；</p>\n<p>3表示指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如<code>a++</code>是错误的；</p>\n<p>4为指针本身和指向的内容均为常量。</p>\n</li>\n<li><p>在一个函数声明中，<code>const</code>可以修饰形参，表明它是一个输入参数，在函数内部不能改变其值；</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun0</span><span class=\"params\">(<span class=\"keyword\">const</span> A * a )</span></span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun1</span><span class=\"params\">(<span class=\"keyword\">const</span> A &amp; a)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>调用函数的时候，用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，如形参为｀<code>const A* a</code>，则不能对传递进来的指针的内容进行改变，保护了原指针所指向的内容；如形参为<code>const A&amp; a</code> ，则不能对传递进来的引用对象进行改变，保护了原对象的属性。</p>\n<p>注意：参数<code>const</code> 通常用于参数为指针或引用的情况。</p>\n<p>​</p>\n</li>\n<li><p>对于类的成员函数，若指定其为<code>const</code>类型，则表明其是一个常函数，不能修改类的成员变量；<code>const</code> 一般放在函数体后，形如：<code>void fun() const;</code>。 如果一个成员函数的不会修改数据成员，最好将其声明为<code>const</code>，因为<code>const</code>成员函数中不允许对数据成员进行修改，如果修改，编译器将报错，这大大提高了程序的健壮性。</p>\n<p><strong>知识扩展：</strong>如果有在<code>const</code>函数中修改成员变量值的需求，可以把成员变量声明为<code>mutable</code>类型，声明为<code>mutable</code>类型的成员变量可以在常函数中被修改。<code>mutable</code>是为了突破const的限制而设置的，被<code>mutable</code>修饰的变量，将永远处于可变的状态，即使在一个const函数中。可以<a href=\"https://blog.csdn.net/starlee/article/details/1430387\" target=\"_blank\" rel=\"noopener\">参考博客</a>　理解。</p>\n</li>\n<li><p>对于类的成员函数，有时候必须指定其返回值为<code>const</code>类型，以使得其返回值不为”左值”。</p>\n<p>例如：</p>\n<p><code>const classA operator*(const classA &amp; a1, const classA &amp; a2);</code></p>\n<p><code>operator*</code>的返回结果必须是一个<code>const</code>对象。需要注意，如果返回值不是<code>const</code>对象也不会编译出错。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classA a, b, c;</span><br><span class=\"line\">(a * b) = c; <span class=\"comment\">// 对a*b的结果赋值</span></span><br></pre></td></tr></table></figure>\n<p>操作<code>(a * b) = c</code>显然不符合编程者的初衷，也没有任何意义。</p>\n<p>​</p>\n<p><strong>注意：</strong></p>\n<ul>\n<li><p><code>const</code> 返回类型只有在修饰指针或引用是才有用。</p>\n</li>\n<li><p><code>const</code>对象只能调用类的<code>const</code>函数，因为常量对象的状态不允许被修改，调用常量对象的非常量函数会出错</p>\n</li>\n<li><p>在类中只有<code>const</code>函数时，非<code>const</code>对象可以调用<code>cosnt</code>函数，但有非<code>const</code>函数时，非<code>const</code>对象不能调用<code>const</code>函数。</p>\n</li>\n<li><p>非<code>const</code>函数、<code>const</code>函数同时存在时，非常对象将调用非常函数，常对象调用常函数。</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">        A(<span class=\"keyword\">int</span> v): val(v) &#123;&#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_val</span><span class=\"params\">()</span> </span>&#123; <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"not const:\"</span> &lt;&lt; val &lt;&lt; <span class=\"built_in\">endl</span>;&#125;</span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_val</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; val++; <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"const print_val:\"</span> &lt;&lt; val &lt;&lt; <span class=\"built_in\">endl</span>;&#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">private</span>:</span><br><span class=\"line\">        <span class=\"keyword\">mutable</span> <span class=\"keyword\">int</span> val;<span class=\"comment\">//注意体会mutable的作用</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc ,<span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">A <span class=\"title\">b</span><span class=\"params\">(<span class=\"number\">45</span>)</span></span>;</span><br><span class=\"line\">    b.print_val();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">const</span> A <span class=\"title\">a</span><span class=\"params\">(<span class=\"number\">12</span>)</span></span>;</span><br><span class=\"line\">    a.print_val();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>输出结果为：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">not const:45</span><br><span class=\"line\">const print_val:13</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>类的成员变量为<code>const</code>类型时，类的const成员变量的初始化，必须在构造函数的初始化列表中进行。初始化列表是先于构造函数的函数体执行，并且成员初始化列表中的变量初始化顺序与成员在类中的声明顺序相同。</p>\n<p><strong>注意：</strong></p>\n<ul>\n<li><code>const</code>修饰的局部变量在栈上分配内存空间，<code>const</code>修饰的全局变量在只读存储区分配内储存空间。</li>\n<li><strong>类的static　const成员变量可以在类的内部声明时初始化</strong></li>\n</ul>\n</li>\n</ol>\n<h1 id=\"const的初始化\"><a href=\"#const的初始化\" class=\"headerlink\" title=\"const的初始化\"></a>const的初始化</h1><ol>\n<li><p>非指针<code>const</code>常量初始化</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classA b;</span><br><span class=\"line\"><span class=\"keyword\">const</span> classA a = b;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指针(引用)const常量初始化</p>\n<ul>\n<li>指针</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classA * d = <span class=\"keyword\">new</span> classA();</span><br><span class=\"line\"><span class=\"keyword\">const</span> classA * c = d;</span><br></pre></td></tr></table></figure>\n<p>或</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> classA * c = <span class=\"keyword\">new</span> classA();</span><br></pre></td></tr></table></figure>\n<ul>\n<li>引用</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classA f;</span><br><span class=\"line\"><span class=\"keyword\">const</span> classA　&amp; e = f; <span class=\"comment\">//这种方式，e只能访问声明为const的成员函数，不能访问一般的成员函数</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>类的const成员变量初始化</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span>  </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span>  </span><br><span class=\"line\"><span class=\"keyword\">public</span>:   </span><br><span class=\"line\">       A():Size(<span class=\"number\">0</span>)&#123;&#125;<span class=\"comment\">//必须在构造函数的初始化列表初始化</span></span><br><span class=\"line\">       </span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">      <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> Size;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h1 id=\"思考题\"><a href=\"#思考题\" class=\"headerlink\" title=\"思考题\"></a>思考题</h1><ol>\n<li><p>以下的这种赋值方法正确吗？</p>\n <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> classA * c = <span class=\"keyword\">new</span> classA();</span><br><span class=\"line\">classA * e = c;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>以下的这种赋值方法正确吗？</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">classA * <span class=\"keyword\">const</span> c = <span class=\"keyword\">new</span> classA();</span><br><span class=\"line\">classA * b = c;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>这样定义赋值操作符重载函数可以吗？</p>\n <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> classA &amp; <span class=\"keyword\">operator</span> = (<span class=\"keyword\">const</span> classA &amp; a);</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>[思考题答案]</p>\n<ol>\n<li><p>不正确。因为声明指针的目的是为了对其指向的内容进行改变，而声明的指针<code>e</code>指向的是一个常量，所以不正确。</p>\n</li>\n<li><p>正确。因为声明指针所指向的内容可变。</p>\n</li>\n<li><p>不正确。在<code>const A::operator=(const A&amp; a)</code>中，参数列表中的<code>const</code>的用法正确，而当这样连续赋值的时侯，问题就出现了：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A a,b,c:</span><br><span class=\"line\">(a = b) = c;</span><br></pre></td></tr></table></figure>\n<p>因为<code>a.operator = (b)</code>的返回值是对<code>a</code>的<code>const</code>引用，不能再将<code>c</code>赋值给<code>const</code>常量。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++ const关键字的学习内容。</p>","more":"<h1 id=\"const介绍与分类\"><a href=\"#const介绍与分类\" class=\"headerlink\" title=\"const介绍与分类\"></a>const介绍与分类</h1><p><code>const</code>是constant的简写，只要一个变量前面用<code>const</code>来修饰，就意味着该变量里的数据可以被访问，不能被修改。也就是说const意味着“只读”readonly。</p>\n<p>采用符号常量写出的代码更容易维护；指针常常是边读边移动，而不是边写边移动；许多函数参数是只读不写的。const最常见用途是作为数组的界和switch分情况标号(也可以用枚举符代替)，const的使用分类如下：</p>\n<ul>\n<li>常变量：  <strong>const 类型说明符 变量名</strong></li>\n<li>常引用：  <strong>const 类型说明符 &amp;引用名</strong></li>\n<li>常对象：  <strong>类名 const 对象名</strong></li>\n<li>常成员函数：  <strong>类名::fun(形参) const</strong></li>\n<li>常数组：  <strong>类型说明符 const 数组名[大小]</strong>    </li>\n<li>常指针：<ul>\n<li><strong>const 类型说明符* 指针名 </strong> (指针称为指针常量，指针指向是一个常量)</li>\n<li><strong>类型说明符* const 指针名</strong>  (指针称为常量指针，指针本身是一个常量)</li>\n</ul>\n</li>\n</ul>\n<p>注意：在常变量、常引用、常对象、常数组，const 与 “类型说明符”或“类名”（其实类名是一种自定义的类型说明符）的位置可以互换，但在常指针中不能互换，这一点在下面的内容也会提到。</p>\n<h1 id=\"const的作用\"><a href=\"#const的作用\" class=\"headerlink\" title=\"const的作用\"></a>const的作用</h1><ol>\n<li><p>如果想阻止一个变量被改变，可以使用<code>const</code>关键字。在定义该const变量时，通常需要对它进行初始化，因为以后就没有机会再去改变它了；例如<code>const int a = 3; const int &amp; b = a;</code>必须向上面的方式写进行初始化，但<code>const int * p; int a = 3; p = &amp;a;</code>，这样也是可以的，当然最好将指针常量初始化为<code>Null</code>。</p>\n</li>\n<li><p>对指针来说，可以指定指针本身为<code>const</code>，也可以指定指针所指的数据为<code>const</code>，或二者同时指定为<code>const</code>；</p>\n<p>例如：</p>\n<!--�91-->\n<p>分析：</p>\n<ul>\n<li><code>const</code>位于<code>*</code>左侧，<code>const</code>修饰指针所指向的变量，即指针指向常量，不能修改指针指向的内容，p称为指针常量；</li>\n<li><code>const</code>位于<code>*</code>右侧，<code>const</code>修饰指针本身，即指针本身是常量，不能对指针本身进行更改操作，p是常量指针。</li>\n</ul>\n<p>因此，1和2的情况相同，都是指针所指向的内容为常量（<code>const</code>放在变量声明符的位置无关），这种情况下不允许对内容进行更改操作，如不能<code>*a = 3</code> ；</p>\n<p>3表示指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如<code>a++</code>是错误的；</p>\n<p>4为指针本身和指向的内容均为常量。</p>\n</li>\n<li><p>在一个函数声明中，<code>const</code>可以修饰形参，表明它是一个输入参数，在函数内部不能改变其值；</p>\n<p>例如：</p>\n<!--�92-->\n<p>调用函数的时候，用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，如形参为｀<code>const A* a</code>，则不能对传递进来的指针的内容进行改变，保护了原指针所指向的内容；如形参为<code>const A&amp; a</code> ，则不能对传递进来的引用对象进行改变，保护了原对象的属性。</p>\n<p>注意：参数<code>const</code> 通常用于参数为指针或引用的情况。</p>\n<p>​</p>\n</li>\n<li><p>对于类的成员函数，若指定其为<code>const</code>类型，则表明其是一个常函数，不能修改类的成员变量；<code>const</code> 一般放在函数体后，形如：<code>void fun() const;</code>。 如果一个成员函数的不会修改数据成员，最好将其声明为<code>const</code>，因为<code>const</code>成员函数中不允许对数据成员进行修改，如果修改，编译器将报错，这大大提高了程序的健壮性。</p>\n<p><strong>知识扩展：</strong>如果有在<code>const</code>函数中修改成员变量值的需求，可以把成员变量声明为<code>mutable</code>类型，声明为<code>mutable</code>类型的成员变量可以在常函数中被修改。<code>mutable</code>是为了突破const的限制而设置的，被<code>mutable</code>修饰的变量，将永远处于可变的状态，即使在一个const函数中。可以<a href=\"https://blog.csdn.net/starlee/article/details/1430387\" target=\"_blank\" rel=\"noopener\">参考博客</a>　理解。</p>\n</li>\n<li><p>对于类的成员函数，有时候必须指定其返回值为<code>const</code>类型，以使得其返回值不为”左值”。</p>\n<p>例如：</p>\n<p><code>const classA operator*(const classA &amp; a1, const classA &amp; a2);</code></p>\n<p><code>operator*</code>的返回结果必须是一个<code>const</code>对象。需要注意，如果返回值不是<code>const</code>对象也不会编译出错。</p>\n<!--�93-->\n<p>操作<code>(a * b) = c</code>显然不符合编程者的初衷，也没有任何意义。</p>\n<p>​</p>\n<p><strong>注意：</strong></p>\n<ul>\n<li><p><code>const</code> 返回类型只有在修饰指针或引用是才有用。</p>\n</li>\n<li><p><code>const</code>对象只能调用类的<code>const</code>函数，因为常量对象的状态不允许被修改，调用常量对象的非常量函数会出错</p>\n</li>\n<li><p>在类中只有<code>const</code>函数时，非<code>const</code>对象可以调用<code>cosnt</code>函数，但有非<code>const</code>函数时，非<code>const</code>对象不能调用<code>const</code>函数。</p>\n</li>\n<li><p>非<code>const</code>函数、<code>const</code>函数同时存在时，非常对象将调用非常函数，常对象调用常函数。</p>\n<p>例如：</p>\n<!--�94-->\n<p>输出结果为：</p>\n<!--�95-->\n</li>\n</ul>\n</li>\n<li><p>类的成员变量为<code>const</code>类型时，类的const成员变量的初始化，必须在构造函数的初始化列表中进行。初始化列表是先于构造函数的函数体执行，并且成员初始化列表中的变量初始化顺序与成员在类中的声明顺序相同。</p>\n<p><strong>注意：</strong></p>\n<ul>\n<li><code>const</code>修饰的局部变量在栈上分配内存空间，<code>const</code>修饰的全局变量在只读存储区分配内储存空间。</li>\n<li><strong>类的static　const成员变量可以在类的内部声明时初始化</strong></li>\n</ul>\n</li>\n</ol>\n<h1 id=\"const的初始化\"><a href=\"#const的初始化\" class=\"headerlink\" title=\"const的初始化\"></a>const的初始化</h1><ol>\n<li><p>非指针<code>const</code>常量初始化</p>\n<!--�96-->\n</li>\n<li><p>指针(引用)const常量初始化</p>\n<ul>\n<li>指针</li>\n</ul>\n<!--�97-->\n<p>或</p>\n<!--�98-->\n<ul>\n<li>引用</li>\n</ul>\n<!--�99-->\n</li>\n<li><p>类的const成员变量初始化</p>\n<!--�100-->\n</li>\n</ol>\n<h1 id=\"思考题\"><a href=\"#思考题\" class=\"headerlink\" title=\"思考题\"></a>思考题</h1><ol>\n<li><p>以下的这种赋值方法正确吗？</p>\n <!--�101-->\n</li>\n<li><p>以下的这种赋值方法正确吗？</p>\n<!--�102-->\n</li>\n<li><p>这样定义赋值操作符重载函数可以吗？</p>\n <!--�103-->\n</li>\n</ol>\n<p>[思考题答案]</p>\n<ol>\n<li><p>不正确。因为声明指针的目的是为了对其指向的内容进行改变，而声明的指针<code>e</code>指向的是一个常量，所以不正确。</p>\n</li>\n<li><p>正确。因为声明指针所指向的内容可变。</p>\n</li>\n<li><p>不正确。在<code>const A::operator=(const A&amp; a)</code>中，参数列表中的<code>const</code>的用法正确，而当这样连续赋值的时侯，问题就出现了：</p>\n<!--�104-->\n<p>因为<code>a.operator = (b)</code>的返回值是对<code>a</code>的<code>const</code>引用，不能再将<code>c</code>赋值给<code>const</code>常量。</p>\n</li>\n</ol>"},{"title":"C++中使用YAML语言","date":"2018-05-23T01:20:12.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++中使用YAML语言的基础，以及在结合ROS和OpenCV使用的学习内容。\n\n<!--more--->\n\n## YAML语言使用基础\n\nYAML语言在C++中，可以用于应用程序相关配置文件的保存，可读性、可修改性比较好。直接贴代码。\n\n测试代码：\n\n~~~c++\n#include <fstream>\n#include <iostream>\n#include <string>\n#include <assert.h>\n#include \"yaml-cpp/yaml.h\"\n\nusing namespace std;\n\n//=============================================================================\nvoid test1()\n{\n    YAML::Node config = YAML::LoadFile(\"site.yaml\");\n \n    std::cout<<\"here test1!!\"<<endl;\n    YAML::Node config_systemLog = config[\"systemLog\"];\n    \n    if ( config_systemLog[\"path\"] )\n        std::cout << config_systemLog[\"path\"] << std::endl;//输出c:\\data\\log\\mongod.log\n \n    std::ofstream fout( \"test1.yaml\" );\n    fout << config;\n}\n \n//=============================================================================\nvoid test2()\n{\n    YAML::Node node;\n    node[\"username\"] = \"glimix\";\n    node[\"password\"] = \"111222\";\n \n    std::ofstream fout( \"test2.yaml\" );\n    fout << node;\n}\n \n//=============================================================================\nvoid test3()\n{    \n    try\n    {\n        YAML::Node doc = YAML::LoadFile( \"Night.jpg.meta\" );\n        std::cout << doc << \"\\n\";\n    }\n    catch( const YAML::Exception &e )\n    {\n        std::cerr << e.what() << \"\\n\";//读取文件异常\n    }\n}\n \n//=============================================================================\nvoid test4()\n{\n    YAML::Node node;\n    node.push_back( \"glimix\" );\n    node.push_back( 123 );\n    node.push_back( 3.1415926 );\n    node[\"char\"].push_back( 'a' );\n    node[\"bool\"].push_back( true );\n \n    std::ofstream fout( \"test4.yaml\" );\n    fout << node;\n}\n \n//=============================================================================\nvoid test5()\n{\n    class Vector3\n    {\n    public:\n        float x, y, z;\n \n        void encode( YAML::Node &node )\n        {\n            node.push_back( x );\n            node.push_back( y );\n            node.push_back( z );\n        }\n \n        bool decode( YAML::Node &node )\n        {\n            if ( !node.IsSequence() || node.size() != 3 )\n                return false;\n \n            x = node[0].as<float>();\n            y = node[1].as<float>();\n            z = node[2].as<float>();\n \n            return true;\n        }\n    };\n \n    Vector3 pos;\n    pos.x = 100.0f; pos.y = -45.0f; pos.z = 50.0f;\n     \n    YAML::Node node;\n    pos.encode( node );\n \n    std::ofstream fout( \"test5.yaml\" );\n    fout << node;\n \n    Vector3 pos2;\n    pos2.decode( node );\n}\n \n//=============================================================================\nvoid test6()\n{\n    YAML::Node node;\n    node[\"name\"] = \"John Smith\";\n    node[\"age\"] = 37;\n     \n    YAML::Node node2;\n    node2[\"name\"] = \"Jane Smith\";\n    node2[\"age\"] = 25;\n     \n    YAML::Node node3;\n    node3[\"name\"] = \"Jimmy Smith\";\n    node3[\"age\"] = 15;\n    \n    YAML::Node node4;\n    node4[\"name\"] = \"Jenny Smith\";\n    node4[\"age\"] = 12;\n \n    node[\"spouse\"] = node2;\n    node[\"children\"].push_back( node3 );\n    node[\"children\"].push_back( node4 );\n \n    node[\"children\"].push_back( \"{name: Alex Smith, age: 14}\" );\n    node[\"children\"].push_back( \"name: Alex Smith, age: 14\" );\n    node[\"children\"].push_back( YAML::Load( \"{name: Alex Smith, age: 14}\" ) );\n    YAML::Node node5 = YAML::Load( \"{name: Alex Smith, age: 14}\" );\n    node[\"children\"].push_back( node5 );\n \n    std::ofstream fout( \"test6.yaml\" );\n    fout << node;\n}\n \n//=============================================================================\nvoid test7()\n{\n    YAML::Node node;  // starts out as null\n    node[\"key\"] = \"value\";  // it now is a map node\n    node[\"seq\"].push_back(\"first element\");  // node[\"seq\"] automatically becomes a sequence\n    node[\"seq\"].push_back(\"second element\");\n \n    node[\"mirror\"] = node[\"seq\"][0]; // this creates an alias\n    node[\"seq\"][0] = \"1st element\";  // this also changes node[\"mirror\"]\n    node[\"mirror\"] = \"element #1\";   // and this changes node[\"seq\"][0] - they're really the \"same\" node\n \n    node[\"self\"] = node;  // you can even create self-aliases\n    node[node[\"mirror\"]] = node[\"seq\"];  // and strange loops 🙂\n \n     \n    std::ofstream fout( \"test7.yaml\" );\n    fout << node;\n}\n\n//=============================================================================\nvoid test8()\n{\n  YAML::Node primes = YAML::Load(\"[2, 3, 5, 7, 11]\");\n  for (std::size_t i=0;i<primes.size();i++) \n  {\n   std::cout << primes[i].as<int>() << \"\\n\";\n  }\n  // or:\n//   for (YAML::const_iterator it=primes.begin();it!=primes.end();++it) \n//   {\n//     std::cout << it->as<int>() << \"\\n\";\n//   }\n\n  primes.push_back(13);\n  assert(primes.size() == 6);\n  std::ofstream fout(\"test8.yaml\");\n  fout << primes;\n}\n\n//=============================================================================\nvoid test9()\n{\n YAML::Node lineup = YAML::Load(\"{1B: Prince Fielder, 2B: Rickie Weeks, LF: Ryan Braun}\");\n for(YAML::const_iterator it = lineup.begin(); it != lineup.end(); ++it) \n {\n   std::cout << \"Playing at \" << it->first.as<std::string>() << \" is \" << it->second.as<std::string>() << \"\\n\";\n }\n\n lineup[\"RF\"] = \"Corey Hart\";\n lineup[\"C\"] = \"Jonathan Lucroy\";\n assert(lineup.size() == 2);//assert(表达式)保证满足特定条件，即表达式为真，否则整个程序退出并输出一条错误信息。\n \n std::ofstream fout(\"test9.yaml\");\n  fout << lineup;\n}\n\n//=============================================================================\nvoid test10()\n{\n YAML::Node node = YAML::Load(\"{name: Brewers, city: Milwaukee}\");\n\n if (node[\"name\"]) {\n   std::cout << node[\"name\"].as<std::string>() << \"\\n\";\n }\n if (node[\"mascot\"]) {//无输出\n   std::cout << node[\"mascot\"].as<std::string>() << \"\\n\";\n }\n assert(node.size() == 2); // the previous call didn't create a node\n}\n\n//=============================================================================\nvoid test11()\n{\n  YAML::Node node1 = YAML::Load(\"[1, 2, 3]\");//序列结构\n  assert(node1.Type() == YAML::NodeType::Sequence);\n  assert(node1.IsSequence());  // a shortcut!\n  \n  YAML::Node node2 = YAML::Load(\"{name: Brewers, city: Milwaukee}\");//散列/map结构\n  switch (node2.Type()) \n  {\n   case YAML::NodeType::Null: cout<<\"NodeType:NULL\"<<endl; break;\n   case YAML::NodeType::Scalar: cout<<\"NodeType:Scalar\"<<endl; break;\n   case YAML::NodeType::Sequence: cout<<\"NodeType:Sequence\"<<endl; break;\n   case YAML::NodeType::Map: cout<<\"NodeType:Map\"<<endl; break;//输出为Map\n   case YAML::NodeType::Undefined: cout<<\"NodeType:Undefined\"<<endl; break;\n  }\n}\n\n//=============================================================================\nint main(int argc ,char **argv)\n{\n  test11(); \n  return 0;  \n}\n~~~\n\n测试输出文件：\n\n~~~yaml\n#test1\nsystemLog:\n  destination: file\n  path: c:\\data\\log\\mongod.log\nstorage:\n  dbPath: c:\\data\\db\nsecurity:\n  authorization: enabled\nnet:\n  bindIp: 127.0.0.1\n  port: 27017\n  \n#test2\nusername: glimix\npassword: 111222\n\n#test4\n0: glimix\n1: 123\n2: 3.1415926\nchar:\n  - a\nbool:\n  - true\n  \n#test5\n- 100\n- -45\n- 50\n\n#test6\nname: John Smith\nage: 37\nspouse:\n  name: Jane Smith\n  age: 25\nchildren:\n  - name: Jimmy Smith\n    age: 15\n  - name: Jenny Smith\n    age: 12\n  - \"{name: Alex Smith, age: 14}\"\n  - \"name: Alex Smith, age: 14\"\n  - {name: Alex Smith, age: 14}\n  - {name: Alex Smith, age: 14}\n\n#test7\n&1\nkey: value\nseq: &2\n  - &3 \"element #1\"\n  - second element\nmirror: *3\nself: *1\n*3: *2\n\n#test8\n[2, 3, 5, 7, 11, 13]\n\n#test9\n{1B: Prince Fielder, 2B: Rickie Weeks, LF: Ryan Braun, RF: Corey Hart, C: Jonathan Lucroy}\n~~~\n\n\n\nsite.yaml文件（*注意：冒号和其后内容之间有一空格*）：\n\n~~~yaml\nsystemLog:\n    destination: file\n    path: c:\\data\\log\\mongod.log\nstorage:\n    dbPath: c:\\data\\db\nsecurity:\n     authorization: enabled\nnet:\n    bindIp: 127.0.0.1\n    port: 27017\n~~~\n\nCMakeLists.txt文件：\n\n~~~cmake\n# 使用c++11编译\nadd_compile_options(-std=c++11)\ncmake_minimum_required(VERSION 2.6)\nproject(test)\n\nfind_package(yaml-cpp REQUIRED)\n\nMessage(\"YAML_INCLUDE:${YAML_CPP_INCLUDE_DIR}\")\n\ninclude_directories(${PROJECT_SOURCE_DIR} ${YAML_CPP_INCLUDE_DIR})\nset(LIBS ${YAML_CPP_LIBRARIES})\nadd_executable(test main.cpp)\ntarget_link_libraries(test ${LIBS})\n~~~\n\n## 结合ROS+OpenCV的使用\n\n在许多ROS项目中使用YAML文件作为配置文件可以简化程序、提高代码的可读性和可修改性，在结合OpenCV的一些API，可以很方便地对配置信息进行修改，而不需要修改程序。下面是结合ROS+OpenCV读取YAML文件的一小段示例代码（未运行）。\n\n~~~c++\n#include <ros/ros.h>\n#include <ros/package.h> \t\t//ros::packgae\n#include <opencv2/opencv.hpp> \t//cv::FileStorage\n\nint main(int argc, char** argv)\n{\n    ros::init(argc, argv, \"node_name\");\n    string packagePath = ros::package::getPath(\"package_name\");\t\t//使用ROS包名读取包的地址\n    string configPath = packagePath + \"//config//config_name.yaml\";\t//YAML文件\n    cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\t//cv::FileStorage适用于XML/YAML/JSON文件\n    if(!fsSettings.isOpened())\n    {\n        cerr << \"ERROR: Wrong path to settings\" << endl;\n        return -1;\n    }\n    string config_variable_name = fsSettings[\"config_variable_name\"];\n    //...\n\treturn 0;\n}\n~~~\n\nYAML文件：\n\n~~~yaml\nconfig_variable_name: value\nstr_name: \"value\"\n...\n~~~\n\n## 参考资料\n\nhttps://github.com/jbeder/yaml-cpp/wiki/Tutorial\n\nhttp://www.glimix.com/archives/1570\n\nhttp://yaml.org/\n\n","source":"_posts/C++中使用YAML语言.md","raw":"---\ntitle: C++中使用YAML语言\ndate: 2018-05-23 09:20:12\ntags:\n  - C++\n  - YAML\n  - ROS\n  - OpenCV\ncategories: \n  - 语言\n  - YAML\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++中使用YAML语言的基础，以及在结合ROS和OpenCV使用的学习内容。\n\n<!--more--->\n\n## YAML语言使用基础\n\nYAML语言在C++中，可以用于应用程序相关配置文件的保存，可读性、可修改性比较好。直接贴代码。\n\n测试代码：\n\n~~~c++\n#include <fstream>\n#include <iostream>\n#include <string>\n#include <assert.h>\n#include \"yaml-cpp/yaml.h\"\n\nusing namespace std;\n\n//=============================================================================\nvoid test1()\n{\n    YAML::Node config = YAML::LoadFile(\"site.yaml\");\n \n    std::cout<<\"here test1!!\"<<endl;\n    YAML::Node config_systemLog = config[\"systemLog\"];\n    \n    if ( config_systemLog[\"path\"] )\n        std::cout << config_systemLog[\"path\"] << std::endl;//输出c:\\data\\log\\mongod.log\n \n    std::ofstream fout( \"test1.yaml\" );\n    fout << config;\n}\n \n//=============================================================================\nvoid test2()\n{\n    YAML::Node node;\n    node[\"username\"] = \"glimix\";\n    node[\"password\"] = \"111222\";\n \n    std::ofstream fout( \"test2.yaml\" );\n    fout << node;\n}\n \n//=============================================================================\nvoid test3()\n{    \n    try\n    {\n        YAML::Node doc = YAML::LoadFile( \"Night.jpg.meta\" );\n        std::cout << doc << \"\\n\";\n    }\n    catch( const YAML::Exception &e )\n    {\n        std::cerr << e.what() << \"\\n\";//读取文件异常\n    }\n}\n \n//=============================================================================\nvoid test4()\n{\n    YAML::Node node;\n    node.push_back( \"glimix\" );\n    node.push_back( 123 );\n    node.push_back( 3.1415926 );\n    node[\"char\"].push_back( 'a' );\n    node[\"bool\"].push_back( true );\n \n    std::ofstream fout( \"test4.yaml\" );\n    fout << node;\n}\n \n//=============================================================================\nvoid test5()\n{\n    class Vector3\n    {\n    public:\n        float x, y, z;\n \n        void encode( YAML::Node &node )\n        {\n            node.push_back( x );\n            node.push_back( y );\n            node.push_back( z );\n        }\n \n        bool decode( YAML::Node &node )\n        {\n            if ( !node.IsSequence() || node.size() != 3 )\n                return false;\n \n            x = node[0].as<float>();\n            y = node[1].as<float>();\n            z = node[2].as<float>();\n \n            return true;\n        }\n    };\n \n    Vector3 pos;\n    pos.x = 100.0f; pos.y = -45.0f; pos.z = 50.0f;\n     \n    YAML::Node node;\n    pos.encode( node );\n \n    std::ofstream fout( \"test5.yaml\" );\n    fout << node;\n \n    Vector3 pos2;\n    pos2.decode( node );\n}\n \n//=============================================================================\nvoid test6()\n{\n    YAML::Node node;\n    node[\"name\"] = \"John Smith\";\n    node[\"age\"] = 37;\n     \n    YAML::Node node2;\n    node2[\"name\"] = \"Jane Smith\";\n    node2[\"age\"] = 25;\n     \n    YAML::Node node3;\n    node3[\"name\"] = \"Jimmy Smith\";\n    node3[\"age\"] = 15;\n    \n    YAML::Node node4;\n    node4[\"name\"] = \"Jenny Smith\";\n    node4[\"age\"] = 12;\n \n    node[\"spouse\"] = node2;\n    node[\"children\"].push_back( node3 );\n    node[\"children\"].push_back( node4 );\n \n    node[\"children\"].push_back( \"{name: Alex Smith, age: 14}\" );\n    node[\"children\"].push_back( \"name: Alex Smith, age: 14\" );\n    node[\"children\"].push_back( YAML::Load( \"{name: Alex Smith, age: 14}\" ) );\n    YAML::Node node5 = YAML::Load( \"{name: Alex Smith, age: 14}\" );\n    node[\"children\"].push_back( node5 );\n \n    std::ofstream fout( \"test6.yaml\" );\n    fout << node;\n}\n \n//=============================================================================\nvoid test7()\n{\n    YAML::Node node;  // starts out as null\n    node[\"key\"] = \"value\";  // it now is a map node\n    node[\"seq\"].push_back(\"first element\");  // node[\"seq\"] automatically becomes a sequence\n    node[\"seq\"].push_back(\"second element\");\n \n    node[\"mirror\"] = node[\"seq\"][0]; // this creates an alias\n    node[\"seq\"][0] = \"1st element\";  // this also changes node[\"mirror\"]\n    node[\"mirror\"] = \"element #1\";   // and this changes node[\"seq\"][0] - they're really the \"same\" node\n \n    node[\"self\"] = node;  // you can even create self-aliases\n    node[node[\"mirror\"]] = node[\"seq\"];  // and strange loops 🙂\n \n     \n    std::ofstream fout( \"test7.yaml\" );\n    fout << node;\n}\n\n//=============================================================================\nvoid test8()\n{\n  YAML::Node primes = YAML::Load(\"[2, 3, 5, 7, 11]\");\n  for (std::size_t i=0;i<primes.size();i++) \n  {\n   std::cout << primes[i].as<int>() << \"\\n\";\n  }\n  // or:\n//   for (YAML::const_iterator it=primes.begin();it!=primes.end();++it) \n//   {\n//     std::cout << it->as<int>() << \"\\n\";\n//   }\n\n  primes.push_back(13);\n  assert(primes.size() == 6);\n  std::ofstream fout(\"test8.yaml\");\n  fout << primes;\n}\n\n//=============================================================================\nvoid test9()\n{\n YAML::Node lineup = YAML::Load(\"{1B: Prince Fielder, 2B: Rickie Weeks, LF: Ryan Braun}\");\n for(YAML::const_iterator it = lineup.begin(); it != lineup.end(); ++it) \n {\n   std::cout << \"Playing at \" << it->first.as<std::string>() << \" is \" << it->second.as<std::string>() << \"\\n\";\n }\n\n lineup[\"RF\"] = \"Corey Hart\";\n lineup[\"C\"] = \"Jonathan Lucroy\";\n assert(lineup.size() == 2);//assert(表达式)保证满足特定条件，即表达式为真，否则整个程序退出并输出一条错误信息。\n \n std::ofstream fout(\"test9.yaml\");\n  fout << lineup;\n}\n\n//=============================================================================\nvoid test10()\n{\n YAML::Node node = YAML::Load(\"{name: Brewers, city: Milwaukee}\");\n\n if (node[\"name\"]) {\n   std::cout << node[\"name\"].as<std::string>() << \"\\n\";\n }\n if (node[\"mascot\"]) {//无输出\n   std::cout << node[\"mascot\"].as<std::string>() << \"\\n\";\n }\n assert(node.size() == 2); // the previous call didn't create a node\n}\n\n//=============================================================================\nvoid test11()\n{\n  YAML::Node node1 = YAML::Load(\"[1, 2, 3]\");//序列结构\n  assert(node1.Type() == YAML::NodeType::Sequence);\n  assert(node1.IsSequence());  // a shortcut!\n  \n  YAML::Node node2 = YAML::Load(\"{name: Brewers, city: Milwaukee}\");//散列/map结构\n  switch (node2.Type()) \n  {\n   case YAML::NodeType::Null: cout<<\"NodeType:NULL\"<<endl; break;\n   case YAML::NodeType::Scalar: cout<<\"NodeType:Scalar\"<<endl; break;\n   case YAML::NodeType::Sequence: cout<<\"NodeType:Sequence\"<<endl; break;\n   case YAML::NodeType::Map: cout<<\"NodeType:Map\"<<endl; break;//输出为Map\n   case YAML::NodeType::Undefined: cout<<\"NodeType:Undefined\"<<endl; break;\n  }\n}\n\n//=============================================================================\nint main(int argc ,char **argv)\n{\n  test11(); \n  return 0;  \n}\n~~~\n\n测试输出文件：\n\n~~~yaml\n#test1\nsystemLog:\n  destination: file\n  path: c:\\data\\log\\mongod.log\nstorage:\n  dbPath: c:\\data\\db\nsecurity:\n  authorization: enabled\nnet:\n  bindIp: 127.0.0.1\n  port: 27017\n  \n#test2\nusername: glimix\npassword: 111222\n\n#test4\n0: glimix\n1: 123\n2: 3.1415926\nchar:\n  - a\nbool:\n  - true\n  \n#test5\n- 100\n- -45\n- 50\n\n#test6\nname: John Smith\nage: 37\nspouse:\n  name: Jane Smith\n  age: 25\nchildren:\n  - name: Jimmy Smith\n    age: 15\n  - name: Jenny Smith\n    age: 12\n  - \"{name: Alex Smith, age: 14}\"\n  - \"name: Alex Smith, age: 14\"\n  - {name: Alex Smith, age: 14}\n  - {name: Alex Smith, age: 14}\n\n#test7\n&1\nkey: value\nseq: &2\n  - &3 \"element #1\"\n  - second element\nmirror: *3\nself: *1\n*3: *2\n\n#test8\n[2, 3, 5, 7, 11, 13]\n\n#test9\n{1B: Prince Fielder, 2B: Rickie Weeks, LF: Ryan Braun, RF: Corey Hart, C: Jonathan Lucroy}\n~~~\n\n\n\nsite.yaml文件（*注意：冒号和其后内容之间有一空格*）：\n\n~~~yaml\nsystemLog:\n    destination: file\n    path: c:\\data\\log\\mongod.log\nstorage:\n    dbPath: c:\\data\\db\nsecurity:\n     authorization: enabled\nnet:\n    bindIp: 127.0.0.1\n    port: 27017\n~~~\n\nCMakeLists.txt文件：\n\n~~~cmake\n# 使用c++11编译\nadd_compile_options(-std=c++11)\ncmake_minimum_required(VERSION 2.6)\nproject(test)\n\nfind_package(yaml-cpp REQUIRED)\n\nMessage(\"YAML_INCLUDE:${YAML_CPP_INCLUDE_DIR}\")\n\ninclude_directories(${PROJECT_SOURCE_DIR} ${YAML_CPP_INCLUDE_DIR})\nset(LIBS ${YAML_CPP_LIBRARIES})\nadd_executable(test main.cpp)\ntarget_link_libraries(test ${LIBS})\n~~~\n\n## 结合ROS+OpenCV的使用\n\n在许多ROS项目中使用YAML文件作为配置文件可以简化程序、提高代码的可读性和可修改性，在结合OpenCV的一些API，可以很方便地对配置信息进行修改，而不需要修改程序。下面是结合ROS+OpenCV读取YAML文件的一小段示例代码（未运行）。\n\n~~~c++\n#include <ros/ros.h>\n#include <ros/package.h> \t\t//ros::packgae\n#include <opencv2/opencv.hpp> \t//cv::FileStorage\n\nint main(int argc, char** argv)\n{\n    ros::init(argc, argv, \"node_name\");\n    string packagePath = ros::package::getPath(\"package_name\");\t\t//使用ROS包名读取包的地址\n    string configPath = packagePath + \"//config//config_name.yaml\";\t//YAML文件\n    cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\t//cv::FileStorage适用于XML/YAML/JSON文件\n    if(!fsSettings.isOpened())\n    {\n        cerr << \"ERROR: Wrong path to settings\" << endl;\n        return -1;\n    }\n    string config_variable_name = fsSettings[\"config_variable_name\"];\n    //...\n\treturn 0;\n}\n~~~\n\nYAML文件：\n\n~~~yaml\nconfig_variable_name: value\nstr_name: \"value\"\n...\n~~~\n\n## 参考资料\n\nhttps://github.com/jbeder/yaml-cpp/wiki/Tutorial\n\nhttp://www.glimix.com/archives/1570\n\nhttp://yaml.org/\n\n","slug":"C++中使用YAML语言","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyl00awqlcr4iq6gct1","content":"<hr>\n<p>这篇文章是有关C++中使用YAML语言的基础，以及在结合ROS和OpenCV使用的学习内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"YAML语言使用基础\"><a href=\"#YAML语言使用基础\" class=\"headerlink\" title=\"YAML语言使用基础\"></a>YAML语言使用基础</h2><p>YAML语言在C++中，可以用于应用程序相关配置文件的保存，可读性、可修改性比较好。直接贴代码。</p>\n<p>测试代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;fstream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;assert.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"yaml-cpp/yaml.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    YAML::Node config = YAML::LoadFile(<span class=\"string\">\"site.yaml\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"here test1!!\"</span>&lt;&lt;<span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    YAML::Node config_systemLog = config[<span class=\"string\">\"systemLog\"</span>];</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">if</span> ( config_systemLog[<span class=\"string\">\"path\"</span>] )</span><br><span class=\"line\">        <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; config_systemLog[<span class=\"string\">\"path\"</span>] &lt;&lt; <span class=\"built_in\">std</span>::<span class=\"built_in\">endl</span>;<span class=\"comment\">//输出c:\\data\\log\\mongod.log</span></span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">( <span class=\"string\">\"test1.yaml\"</span> )</span></span>;</span><br><span class=\"line\">    fout &lt;&lt; config;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    YAML::Node node;</span><br><span class=\"line\">    node[<span class=\"string\">\"username\"</span>] = <span class=\"string\">\"glimix\"</span>;</span><br><span class=\"line\">    node[<span class=\"string\">\"password\"</span>] = <span class=\"string\">\"111222\"</span>;</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">( <span class=\"string\">\"test2.yaml\"</span> )</span></span>;</span><br><span class=\"line\">    fout &lt;&lt; node;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test3</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;    </span><br><span class=\"line\">    <span class=\"keyword\">try</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        YAML::Node doc = YAML::LoadFile( <span class=\"string\">\"Night.jpg.meta\"</span> );</span><br><span class=\"line\">        <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; doc &lt;&lt; <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span>( <span class=\"keyword\">const</span> YAML::Exception &amp;e )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">std</span>::<span class=\"built_in\">cerr</span> &lt;&lt; e.what() &lt;&lt; <span class=\"string\">\"\\n\"</span>;<span class=\"comment\">//读取文件异常</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test4</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    YAML::Node node;</span><br><span class=\"line\">    node.push_back( <span class=\"string\">\"glimix\"</span> );</span><br><span class=\"line\">    node.push_back( <span class=\"number\">123</span> );</span><br><span class=\"line\">    node.push_back( <span class=\"number\">3.1415926</span> );</span><br><span class=\"line\">    node[<span class=\"string\">\"char\"</span>].push_back( <span class=\"string\">'a'</span> );</span><br><span class=\"line\">    node[<span class=\"string\">\"bool\"</span>].push_back( <span class=\"literal\">true</span> );</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">( <span class=\"string\">\"test4.yaml\"</span> )</span></span>;</span><br><span class=\"line\">    fout &lt;&lt; node;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test5</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Vector3</span></span></span><br><span class=\"line\"><span class=\"class\">    &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">        <span class=\"keyword\">float</span> x, y, z;</span><br><span class=\"line\"> </span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">encode</span><span class=\"params\">( YAML::Node &amp;node )</span></span></span><br><span class=\"line\"><span class=\"function\">        </span>&#123;</span><br><span class=\"line\">            node.push_back( x );</span><br><span class=\"line\">            node.push_back( y );</span><br><span class=\"line\">            node.push_back( z );</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">decode</span><span class=\"params\">( YAML::Node &amp;node )</span></span></span><br><span class=\"line\"><span class=\"function\">        </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> ( !node.IsSequence() || node.size() != <span class=\"number\">3</span> )</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\"> </span><br><span class=\"line\">            x = node[<span class=\"number\">0</span>].as&lt;<span class=\"keyword\">float</span>&gt;();</span><br><span class=\"line\">            y = node[<span class=\"number\">1</span>].as&lt;<span class=\"keyword\">float</span>&gt;();</span><br><span class=\"line\">            z = node[<span class=\"number\">2</span>].as&lt;<span class=\"keyword\">float</span>&gt;();</span><br><span class=\"line\"> </span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\"> </span><br><span class=\"line\">    Vector3 pos;</span><br><span class=\"line\">    pos.x = <span class=\"number\">100.0f</span>; pos.y = <span class=\"number\">-45.0f</span>; pos.z = <span class=\"number\">50.0f</span>;</span><br><span class=\"line\">     </span><br><span class=\"line\">    YAML::Node node;</span><br><span class=\"line\">    pos.encode( node );</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">( <span class=\"string\">\"test5.yaml\"</span> )</span></span>;</span><br><span class=\"line\">    fout &lt;&lt; node;</span><br><span class=\"line\"> </span><br><span class=\"line\">    Vector3 pos2;</span><br><span class=\"line\">    pos2.decode( node );</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test6</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    YAML::Node node;</span><br><span class=\"line\">    node[<span class=\"string\">\"name\"</span>] = <span class=\"string\">\"John Smith\"</span>;</span><br><span class=\"line\">    node[<span class=\"string\">\"age\"</span>] = <span class=\"number\">37</span>;</span><br><span class=\"line\">     </span><br><span class=\"line\">    YAML::Node node2;</span><br><span class=\"line\">    node2[<span class=\"string\">\"name\"</span>] = <span class=\"string\">\"Jane Smith\"</span>;</span><br><span class=\"line\">    node2[<span class=\"string\">\"age\"</span>] = <span class=\"number\">25</span>;</span><br><span class=\"line\">     </span><br><span class=\"line\">    YAML::Node node3;</span><br><span class=\"line\">    node3[<span class=\"string\">\"name\"</span>] = <span class=\"string\">\"Jimmy Smith\"</span>;</span><br><span class=\"line\">    node3[<span class=\"string\">\"age\"</span>] = <span class=\"number\">15</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    YAML::Node node4;</span><br><span class=\"line\">    node4[<span class=\"string\">\"name\"</span>] = <span class=\"string\">\"Jenny Smith\"</span>;</span><br><span class=\"line\">    node4[<span class=\"string\">\"age\"</span>] = <span class=\"number\">12</span>;</span><br><span class=\"line\"> </span><br><span class=\"line\">    node[<span class=\"string\">\"spouse\"</span>] = node2;</span><br><span class=\"line\">    node[<span class=\"string\">\"children\"</span>].push_back( node3 );</span><br><span class=\"line\">    node[<span class=\"string\">\"children\"</span>].push_back( node4 );</span><br><span class=\"line\"> </span><br><span class=\"line\">    node[<span class=\"string\">\"children\"</span>].push_back( <span class=\"string\">\"&#123;name: Alex Smith, age: 14&#125;\"</span> );</span><br><span class=\"line\">    node[<span class=\"string\">\"children\"</span>].push_back( <span class=\"string\">\"name: Alex Smith, age: 14\"</span> );</span><br><span class=\"line\">    node[<span class=\"string\">\"children\"</span>].push_back( YAML::Load( <span class=\"string\">\"&#123;name: Alex Smith, age: 14&#125;\"</span> ) );</span><br><span class=\"line\">    YAML::Node node5 = YAML::Load( <span class=\"string\">\"&#123;name: Alex Smith, age: 14&#125;\"</span> );</span><br><span class=\"line\">    node[<span class=\"string\">\"children\"</span>].push_back( node5 );</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">( <span class=\"string\">\"test6.yaml\"</span> )</span></span>;</span><br><span class=\"line\">    fout &lt;&lt; node;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test7</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    YAML::Node node;  <span class=\"comment\">// starts out as null</span></span><br><span class=\"line\">    node[<span class=\"string\">\"key\"</span>] = <span class=\"string\">\"value\"</span>;  <span class=\"comment\">// it now is a map node</span></span><br><span class=\"line\">    node[<span class=\"string\">\"seq\"</span>].push_back(<span class=\"string\">\"first element\"</span>);  <span class=\"comment\">// node[\"seq\"] automatically becomes a sequence</span></span><br><span class=\"line\">    node[<span class=\"string\">\"seq\"</span>].push_back(<span class=\"string\">\"second element\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">    node[<span class=\"string\">\"mirror\"</span>] = node[<span class=\"string\">\"seq\"</span>][<span class=\"number\">0</span>]; <span class=\"comment\">// this creates an alias</span></span><br><span class=\"line\">    node[<span class=\"string\">\"seq\"</span>][<span class=\"number\">0</span>] = <span class=\"string\">\"1st element\"</span>;  <span class=\"comment\">// this also changes node[\"mirror\"]</span></span><br><span class=\"line\">    node[<span class=\"string\">\"mirror\"</span>] = <span class=\"string\">\"element #1\"</span>;   <span class=\"comment\">// and this changes node[\"seq\"][0] - they're really the \"same\" node</span></span><br><span class=\"line\"> </span><br><span class=\"line\">    node[<span class=\"string\">\"self\"</span>] = node;  <span class=\"comment\">// you can even create self-aliases</span></span><br><span class=\"line\">    node[node[<span class=\"string\">\"mirror\"</span>]] = node[<span class=\"string\">\"seq\"</span>];  <span class=\"comment\">// and strange loops 🙂</span></span><br><span class=\"line\"> </span><br><span class=\"line\">     </span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">( <span class=\"string\">\"test7.yaml\"</span> )</span></span>;</span><br><span class=\"line\">    fout &lt;&lt; node;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test8</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  YAML::Node primes = YAML::Load(<span class=\"string\">\"[2, 3, 5, 7, 11]\"</span>);</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> i=<span class=\"number\">0</span>;i&lt;primes.size();i++) </span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">   <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; primes[i].as&lt;<span class=\"keyword\">int</span>&gt;() &lt;&lt; <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"comment\">// or:</span></span><br><span class=\"line\"><span class=\"comment\">//   for (YAML::const_iterator it=primes.begin();it!=primes.end();++it) </span></span><br><span class=\"line\"><span class=\"comment\">//   &#123;</span></span><br><span class=\"line\"><span class=\"comment\">//     std::cout &lt;&lt; it-&gt;as&lt;int&gt;() &lt;&lt; \"\\n\";</span></span><br><span class=\"line\"><span class=\"comment\">//   &#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  primes.push_back(<span class=\"number\">13</span>);</span><br><span class=\"line\">  assert(primes.size() == <span class=\"number\">6</span>);</span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">(<span class=\"string\">\"test8.yaml\"</span>)</span></span>;</span><br><span class=\"line\">  fout &lt;&lt; primes;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test9</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"> YAML::Node lineup = YAML::Load(<span class=\"string\">\"&#123;1B: Prince Fielder, 2B: Rickie Weeks, LF: Ryan Braun&#125;\"</span>);</span><br><span class=\"line\"> <span class=\"keyword\">for</span>(YAML::const_iterator it = lineup.begin(); it != lineup.end(); ++it) </span><br><span class=\"line\"> &#123;</span><br><span class=\"line\">   <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"Playing at \"</span> &lt;&lt; it-&gt;first.as&lt;<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&gt;() &lt;&lt; <span class=\"string\">\" is \"</span> &lt;&lt; it-&gt;second.as&lt;<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&gt;() &lt;&lt; <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> lineup[<span class=\"string\">\"RF\"</span>] = <span class=\"string\">\"Corey Hart\"</span>;</span><br><span class=\"line\"> lineup[<span class=\"string\">\"C\"</span>] = <span class=\"string\">\"Jonathan Lucroy\"</span>;</span><br><span class=\"line\"> assert(lineup.size() == <span class=\"number\">2</span>);<span class=\"comment\">//assert(表达式)保证满足特定条件，即表达式为真，否则整个程序退出并输出一条错误信息。</span></span><br><span class=\"line\"> </span><br><span class=\"line\"> <span class=\"built_in\">std</span>::<span class=\"function\">ofstream <span class=\"title\">fout</span><span class=\"params\">(<span class=\"string\">\"test9.yaml\"</span>)</span></span>;</span><br><span class=\"line\">  fout &lt;&lt; lineup;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test10</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"> YAML::Node node = YAML::Load(<span class=\"string\">\"&#123;name: Brewers, city: Milwaukee&#125;\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"keyword\">if</span> (node[<span class=\"string\">\"name\"</span>]) &#123;</span><br><span class=\"line\">   <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; node[<span class=\"string\">\"name\"</span>].as&lt;<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&gt;() &lt;&lt; <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> <span class=\"keyword\">if</span> (node[<span class=\"string\">\"mascot\"</span>]) &#123;<span class=\"comment\">//无输出</span></span><br><span class=\"line\">   <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; node[<span class=\"string\">\"mascot\"</span>].as&lt;<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&gt;() &lt;&lt; <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"> assert(node.size() == <span class=\"number\">2</span>); <span class=\"comment\">// the previous call didn't create a node</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test11</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  YAML::Node node1 = YAML::Load(<span class=\"string\">\"[1, 2, 3]\"</span>);<span class=\"comment\">//序列结构</span></span><br><span class=\"line\">  assert(node1.Type() == YAML::NodeType::Sequence);</span><br><span class=\"line\">  assert(node1.IsSequence());  <span class=\"comment\">// a shortcut!</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  YAML::Node node2 = YAML::Load(<span class=\"string\">\"&#123;name: Brewers, city: Milwaukee&#125;\"</span>);<span class=\"comment\">//散列/map结构</span></span><br><span class=\"line\">  <span class=\"keyword\">switch</span> (node2.Type()) </span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">   <span class=\"keyword\">case</span> YAML::NodeType::Null: <span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"NodeType:NULL\"</span>&lt;&lt;<span class=\"built_in\">endl</span>; <span class=\"keyword\">break</span>;</span><br><span class=\"line\">   <span class=\"keyword\">case</span> YAML::NodeType::Scalar: <span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"NodeType:Scalar\"</span>&lt;&lt;<span class=\"built_in\">endl</span>; <span class=\"keyword\">break</span>;</span><br><span class=\"line\">   <span class=\"keyword\">case</span> YAML::NodeType::Sequence: <span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"NodeType:Sequence\"</span>&lt;&lt;<span class=\"built_in\">endl</span>; <span class=\"keyword\">break</span>;</span><br><span class=\"line\">   <span class=\"keyword\">case</span> YAML::NodeType::Map: <span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"NodeType:Map\"</span>&lt;&lt;<span class=\"built_in\">endl</span>; <span class=\"keyword\">break</span>;<span class=\"comment\">//输出为Map</span></span><br><span class=\"line\">   <span class=\"keyword\">case</span> YAML::NodeType::Undefined: <span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"NodeType:Undefined\"</span>&lt;&lt;<span class=\"built_in\">endl</span>; <span class=\"keyword\">break</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//=============================================================================</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc ,<span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  test11(); </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试输出文件：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#test1</span></span><br><span class=\"line\"><span class=\"attr\">systemLog:</span></span><br><span class=\"line\"><span class=\"attr\">  destination:</span> <span class=\"string\">file</span></span><br><span class=\"line\"><span class=\"attr\">  path:</span> <span class=\"attr\">c:\\data\\log\\mongod.log</span></span><br><span class=\"line\"><span class=\"attr\">storage:</span></span><br><span class=\"line\"><span class=\"attr\">  dbPath:</span> <span class=\"attr\">c:\\data\\db</span></span><br><span class=\"line\"><span class=\"attr\">security:</span></span><br><span class=\"line\"><span class=\"attr\">  authorization:</span> <span class=\"string\">enabled</span></span><br><span class=\"line\"><span class=\"attr\">net:</span></span><br><span class=\"line\"><span class=\"attr\">  bindIp:</span> <span class=\"number\">127.0</span><span class=\"number\">.0</span><span class=\"number\">.1</span></span><br><span class=\"line\"><span class=\"attr\">  port:</span> <span class=\"number\">27017</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\">#test2</span></span><br><span class=\"line\"><span class=\"attr\">username:</span> <span class=\"string\">glimix</span></span><br><span class=\"line\"><span class=\"attr\">password:</span> <span class=\"number\">111222</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test4</span></span><br><span class=\"line\"><span class=\"number\">0</span><span class=\"string\">:</span> <span class=\"string\">glimix</span></span><br><span class=\"line\"><span class=\"number\">1</span><span class=\"string\">:</span> <span class=\"number\">123</span></span><br><span class=\"line\"><span class=\"number\">2</span><span class=\"string\">:</span> <span class=\"number\">3.1415926</span></span><br><span class=\"line\"><span class=\"attr\">char:</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">a</span></span><br><span class=\"line\"><span class=\"attr\">bool:</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\">#test5</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"number\">100</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"bullet\">-45</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"number\">50</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test6</span></span><br><span class=\"line\"><span class=\"attr\">name:</span> <span class=\"string\">John</span> <span class=\"string\">Smith</span></span><br><span class=\"line\"><span class=\"attr\">age:</span> <span class=\"number\">37</span></span><br><span class=\"line\"><span class=\"attr\">spouse:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">Jane</span> <span class=\"string\">Smith</span></span><br><span class=\"line\"><span class=\"attr\">  age:</span> <span class=\"number\">25</span></span><br><span class=\"line\"><span class=\"attr\">children:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">Jimmy</span> <span class=\"string\">Smith</span></span><br><span class=\"line\"><span class=\"attr\">    age:</span> <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">Jenny</span> <span class=\"string\">Smith</span></span><br><span class=\"line\"><span class=\"attr\">    age:</span> <span class=\"number\">12</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">\"&#123;name: Alex Smith, age: 14&#125;\"</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">\"name: Alex Smith, age: 14\"</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">&#123;name:</span> <span class=\"string\">Alex</span> <span class=\"string\">Smith,</span> <span class=\"attr\">age:</span> <span class=\"number\">14</span><span class=\"string\">&#125;</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">&#123;name:</span> <span class=\"string\">Alex</span> <span class=\"string\">Smith,</span> <span class=\"attr\">age:</span> <span class=\"number\">14</span><span class=\"string\">&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test7</span></span><br><span class=\"line\"><span class=\"string\">&amp;1</span></span><br><span class=\"line\"><span class=\"attr\">key:</span> <span class=\"string\">value</span></span><br><span class=\"line\"><span class=\"attr\">seq:</span> <span class=\"string\">&amp;2</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">&amp;3</span> <span class=\"string\">\"element #1\"</span></span><br><span class=\"line\"><span class=\"bullet\">  -</span> <span class=\"string\">second</span> <span class=\"string\">element</span></span><br><span class=\"line\"><span class=\"attr\">mirror:</span> <span class=\"string\">*3</span></span><br><span class=\"line\"><span class=\"attr\">self:</span> <span class=\"string\">*1</span></span><br><span class=\"line\"><span class=\"string\">*3:</span> <span class=\"string\">*2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test8</span></span><br><span class=\"line\"><span class=\"string\">[2,</span> <span class=\"number\">3</span><span class=\"string\">,</span> <span class=\"number\">5</span><span class=\"string\">,</span> <span class=\"number\">7</span><span class=\"string\">,</span> <span class=\"number\">11</span><span class=\"string\">,</span> <span class=\"number\">13</span><span class=\"string\">]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#test9</span></span><br><span class=\"line\"><span class=\"string\">&#123;1B:</span> <span class=\"string\">Prince</span> <span class=\"string\">Fielder,</span> <span class=\"number\">2</span><span class=\"attr\">B:</span> <span class=\"string\">Rickie</span> <span class=\"string\">Weeks,</span> <span class=\"attr\">LF:</span> <span class=\"string\">Ryan</span> <span class=\"string\">Braun,</span> <span class=\"attr\">RF:</span> <span class=\"string\">Corey</span> <span class=\"string\">Hart,</span> <span class=\"attr\">C:</span> <span class=\"string\">Jonathan</span> <span class=\"string\">Lucroy&#125;</span></span><br></pre></td></tr></table></figure>\n<p>site.yaml文件（<em>注意：冒号和其后内容之间有一空格</em>）：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">systemLog:</span></span><br><span class=\"line\"><span class=\"attr\">    destination:</span> <span class=\"string\">file</span></span><br><span class=\"line\"><span class=\"attr\">    path:</span> <span class=\"attr\">c:\\data\\log\\mongod.log</span></span><br><span class=\"line\"><span class=\"attr\">storage:</span></span><br><span class=\"line\"><span class=\"attr\">    dbPath:</span> <span class=\"attr\">c:\\data\\db</span></span><br><span class=\"line\"><span class=\"attr\">security:</span></span><br><span class=\"line\"><span class=\"attr\">     authorization:</span> <span class=\"string\">enabled</span></span><br><span class=\"line\"><span class=\"attr\">net:</span></span><br><span class=\"line\"><span class=\"attr\">    bindIp:</span> <span class=\"number\">127.0</span><span class=\"number\">.0</span><span class=\"number\">.1</span></span><br><span class=\"line\"><span class=\"attr\">    port:</span> <span class=\"number\">27017</span></span><br></pre></td></tr></table></figure>\n<p>CMakeLists.txt文件：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用c++11编译</span></span><br><span class=\"line\">add_compile_options(-std=c++<span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.6</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(test)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(yaml-cpp REQUIRED)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">Message</span>(<span class=\"string\">\"YAML_INCLUDE:$&#123;YAML_CPP_INCLUDE_DIR&#125;\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"variable\">$&#123;PROJECT_SOURCE_DIR&#125;</span> <span class=\"variable\">$&#123;YAML_CPP_INCLUDE_DIR&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(LIBS <span class=\"variable\">$&#123;YAML_CPP_LIBRARIES&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(test main.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(test <span class=\"variable\">$&#123;LIBS&#125;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"结合ROS-OpenCV的使用\"><a href=\"#结合ROS-OpenCV的使用\" class=\"headerlink\" title=\"结合ROS+OpenCV的使用\"></a>结合ROS+OpenCV的使用</h2><p>在许多ROS项目中使用YAML文件作为配置文件可以简化程序、提高代码的可读性和可修改性，在结合OpenCV的一些API，可以很方便地对配置信息进行修改，而不需要修改程序。下面是结合ROS+OpenCV读取YAML文件的一小段示例代码（未运行）。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/package.h&gt; \t\t//ros::packgae</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;opencv2/opencv.hpp&gt; \t//cv::FileStorage</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ros::init(argc, argv, <span class=\"string\">\"node_name\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">string</span> packagePath = ros::package::getPath(<span class=\"string\">\"package_name\"</span>);\t\t<span class=\"comment\">//使用ROS包名读取包的地址</span></span><br><span class=\"line\">    <span class=\"built_in\">string</span> configPath = packagePath + <span class=\"string\">\"//config//config_name.yaml\"</span>;\t<span class=\"comment\">//YAML文件</span></span><br><span class=\"line\">    cv::<span class=\"function\">FileStorage <span class=\"title\">fsSettings</span><span class=\"params\">(configPath, cv::FileStorage::READ)</span></span>;\t<span class=\"comment\">//cv::FileStorage适用于XML/YAML/JSON文件</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!fsSettings.isOpened())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"string\">\"ERROR: Wrong path to settings\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">string</span> config_variable_name = fsSettings[<span class=\"string\">\"config_variable_name\"</span>];</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>YAML文件：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">config_variable_name:</span> <span class=\"string\">value</span></span><br><span class=\"line\"><span class=\"attr\">str_name:</span> <span class=\"string\">\"value\"</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://github.com/jbeder/yaml-cpp/wiki/Tutorial\" target=\"_blank\" rel=\"noopener\">https://github.com/jbeder/yaml-cpp/wiki/Tutorial</a></p>\n<p><a href=\"http://www.glimix.com/archives/1570\" target=\"_blank\" rel=\"noopener\">http://www.glimix.com/archives/1570</a></p>\n<p><a href=\"http://yaml.org/\" target=\"_blank\" rel=\"noopener\">http://yaml.org/</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++中使用YAML语言的基础，以及在结合ROS和OpenCV使用的学习内容。</p>","more":"<h2 id=\"YAML语言使用基础\"><a href=\"#YAML语言使用基础\" class=\"headerlink\" title=\"YAML语言使用基础\"></a>YAML语言使用基础</h2><p>YAML语言在C++中，可以用于应用程序相关配置文件的保存，可读性、可修改性比较好。直接贴代码。</p>\n<p>测试代码：</p>\n<!--�105-->\n<p>测试输出文件：</p>\n<!--�106-->\n<p>site.yaml文件（<em>注意：冒号和其后内容之间有一空格</em>）：</p>\n<!--�107-->\n<p>CMakeLists.txt文件：</p>\n<!--�108-->\n<h2 id=\"结合ROS-OpenCV的使用\"><a href=\"#结合ROS-OpenCV的使用\" class=\"headerlink\" title=\"结合ROS+OpenCV的使用\"></a>结合ROS+OpenCV的使用</h2><p>在许多ROS项目中使用YAML文件作为配置文件可以简化程序、提高代码的可读性和可修改性，在结合OpenCV的一些API，可以很方便地对配置信息进行修改，而不需要修改程序。下面是结合ROS+OpenCV读取YAML文件的一小段示例代码（未运行）。</p>\n<!--�109-->\n<p>YAML文件：</p>\n<!--�110-->\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://github.com/jbeder/yaml-cpp/wiki/Tutorial\" target=\"_blank\" rel=\"noopener\">https://github.com/jbeder/yaml-cpp/wiki/Tutorial</a></p>\n<p><a href=\"http://www.glimix.com/archives/1570\" target=\"_blank\" rel=\"noopener\">http://www.glimix.com/archives/1570</a></p>\n<p><a href=\"http://yaml.org/\" target=\"_blank\" rel=\"noopener\">http://yaml.org/</a></p>"},{"title":"Caffe的GPU模式安装","date":"2018-09-08T04:47:11.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关Caffe GPU模式安装的内容。\n\n<!--more--->\n\n暑假终于入手了一台属于自己的可以称之为高配置的笔记本，实验室的台式机显卡太渣，不想耗费时间和精力再配置台式机，自己的笔记本随时随地方便使用，鼓捣好自己的笔记本环境配置才是王道。\n\n## 笔记本配置\n\n- CPU-Intel七代i7\n- 内存-16G 显存6G\n- 双显卡-GeForce GTX 1060 + Intel\n- 双系统Win10+Ubuntu16.04 \n\n## 相关链接\n\n1. [查看自己的GPU是否支持CUDA](<https://developer.nvidia.com/cuda-gpus>)\n2. [下载匹配自己显卡的驱动](https://www.nvidia.cn/Download/index.aspx?lang=cn)(apt方法安装则不需要)\n3. [CUDA下载](https://developer.nvidia.com/cuda-toolkit-archive) 选择合适的版本，选择下载runfile文件\n4. [下载cuDNN library](https://developer.nvidia.com/rdp/cudnn-archive) 需要注册帐号\n5. [NVIDIA CUDA Installation Guide for Linux](http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4dMB1vD9s)\n6. [Caffe1官网](http://caffe.berkeleyvision.org/)\n7. [Caffe源码](https://github.com/BVLC/caffe)\n\n## 具体过程\n\n- 安装Nvidia显卡驱动\n- 安装CUDA9\n- 安装cuDNN\n- 安装Caffe\n\n### 安装Nvidia显卡驱动\n\n1. 从[相关链接2](https://www.nvidia.cn/Download/index.aspx?lang=cn)查询到自己系统对应的版本\n\n2. 安装驱动\n\n   ~~~shell\n   sudo add-apt-repository ppa:graphics-drivers/ppa  \n   sudo apt-get update  \n   sudo apt-get install nvidia-390 #此处要根据上面查询到的版本适当更改\n   sudo apt-get install mesa-common-dev  \n   sudo apt-get install freeglut3-dev\n   ~~~\n\n   之后重启系统让GTX1060显卡驱动生效。\n\n3. 测试。终端输入`nvidia-smi`，会显示显卡相关的信息，说明安装驱动成功。\n\n   {% asset_img nvidia安装成功.png %}\n\n4. 可以打开Nvidia x server setting切换双显卡。\n\n> ### 可能遇到的问题\n>\n> 执行`sudo apt-get install nvidia-390`命令时可能会产生依赖包冲突的问题。\n>\n> 解决方法：\n>\n> 使用aptitude安装，首先安装apitude`sudo apt-get install aptitude`，使用apitude进行安装的命令`sudo aptitude install xxxx`。根据提示选Y/N/Q，通常选N直到出现对版本做降级处理，点Y即可解决。\n\n### 安装CUDA9.0\n\n1. 从[相关链接3](https://developer.nvidia.com/cuda-toolkit-archive)下载CUDA9.0，选择funfile（下载好的文件名：cuda_9.0.176_384.81_linux.run）\n\n   {% asset_img CUDA.png %}\n\n   > **注意：**CUDA要和显卡驱动对应，如下图。[参考链接](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html)。\n   >\n   > {% asset_img CUDA和驱动版本对应.png %}\n\n2. 执行命令`sudo ./cuda_9.0.176_384.81_linux.run`启动安装程序，一直按空格到最后，输入accept接受条款。\n\n   - 输入n不安装nvidia图像驱动\n   - 输入y安装cuda 9.0工具\n   - 回车确认cuda默认安装路径：/usr/local/cuda-9.0\n   - 输入y或者n安装或者不安装指向/usr/local/cuda的符号链接\n   - 输入y安装CUDA 9.0 Samples，以便后面测试\n   - 回车确认CUDA 9.0 Samples默认安装路径：/home/eric（eric是我的用户名），该安装路径测试完可以删除\n   - 安装完显示如下图 \n\n   {% asset_img CUDA9安装.png %}\n\n   > 如果需要卸载CUDA：\n   >\n   > To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin\n\n3. 添加环境变量\n\n   执行命令`sudo gedit /etc/profile`编辑文件，在最后添加：\n\n   ~~~\n   export PATH=/usr/local/cuda-9.0/bin:$PATH\n   export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:$LD_LIBRARY_PATH\n   ~~~\n\n   重启系统！\n\n4. 测试CUDA Toolkit安装是否正确：`nvcc --version`，输出以下信息说明安装正确：\n\n   {% asset_img CUDA测试.png %}\n\n5. 编译CUDA Samples，默认路径为`~/NVIDIA_CUDA-9.0_Samples`\n\n   ```\n   make\n   ```\n\n   生成可执行文件在`~/NVIDIA_CUDA-9.0_Samples/bin/x84_64/linux/release`\n\n   ```\n   ./deviceQuery\n   ```\n\n   会有如下输出：\n\n   {% asset_img samples.png %}\n\n   > 如果在第一步下载的CUDA和显卡驱动不对应的话，会提示：\n   >\n   > ~~~\n   >  CUDA driver version is insufficient for CUDA runtime version\n   > ~~~\n\n### 安装cuDNN\n\ncuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络（Deep Neural Networks）中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。\n\n1. 从[相关链接4](https://developer.nvidia.com/rdp/cudnn-archive)下载合适版本的cuDNN（下载好的文件名：cuda_9.0.176_384.81_linux.run）\n\n   {% asset_img cuDNN.png %}\n\n2. 解压cuda_9.0.176_384.81_linux.run\n\n   ~~~shell\n   tar -xvzf cuda_9.0.176_384.81_linux.run\n   sudo cp cuda/include/cudnn.h /usr/local/cuda/include\n   sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\n   sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\n   ~~~\n\n3. 更新软链接（应该不需要这一步）\n\n   ~~~shell\n   cd /usr/local/cuda/lib64/\n   sudo rm -rf libcudnn.so libcudnn.so.5\n   sudo ln –s libcudnn.so.5.1.10 libcudnn.so.5\n   sudo ln –s libcudnn.so.5 libcudnn.so\n   ~~~\n\n\n### 安装Caffe\n\n1. 安装依赖包\n\n   ~~~shell\n   sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n   sudo apt-get install --no-install-recommends libboost-all-dev\n   sudo apt-get install libatlas-base-dev\n   sudo apt-get install build-essential\n   sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n   ~~~\n\n2. 安装python的pip和easy_install，方便安装软件包\n\n   ~~~shell\n   cd\n   wget --no-check-certificate https://bootstrap.pypa.io/ez_setup.py\n   sudo python ez_setup.py --insecure\n   wget https://bootstrap.pypa.io/get-pip.py\n   sudo python get-pip.py\n   ~~~\n\n3. 安装科学计算和python所需的部分库\n\n   ~~~shell\n   sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran python-numpy\n   ~~~\n\n4. 安装python依赖\n\n   ~~~shell\n   sudo apt-get install python-pip #安装pip\n   ~~~\n\n5. 编译Caffe\n\n   ##### 终端输入\n\n   ~~~shell\n   cd /home/eric/caffe\n   cp Makefile.config.example Makefile.config\n   gedit Makefile.config\n   ~~~\n\n   - 将`USE_CUDNN := 1`取消注释\n   - `INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include`后面打上一个空格 然后添加`/usr/include/hdf5/serial`如果没有这一句可能会报一个找不到hdf5.h的错误\n\n   ##### 终端输入 \n\n   ~~~shell\n   make\n   ~~~\n\n   > #### make过程中出现找不到lhdf5_hl和lhdf5的错误\n   >\n   > 解决方案：在计算机中搜索`libhdf5_serial.so.10.1.0`，找到后右键点击打开项目位置。该目录下空白处右键点击在终端打开，打开新终端输入   `sudo ln libhdf5_serial.so.10.1.0 libhdf5.so`   `sudo ln libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so` 。最后在终端输入`sudo ldconfig`使链接生效，原终端中输入`make clean`清除第一次编译结果，再重新编译。\n   >\n   > #### 出现`nvcc fatal   : Unsupported gpu architecture 'compute_20'`的错误\n   >\n   > 将Makefile.config文件中`CUDA_ARCH :=`包含`compute_20`的两项删除即可。\n\n   ##### 终端输入：\n\n   ~~~shell\n   make test -j4\n   make runtest -j4\n   make pycaffe -j4\n   make distribute\n   ~~~\n\n   生成发布安装包\n\n   ##### 测试python，终端输入:\n\n   ~~~shell\n   cd /home/erci/install/caffe/python\n   python\n   import caffe\n   ~~~\n\n   如果不报错就说明编译成功。\n\n   > #### 提示\n   >\n   > 如果执行`import caffe`，出现错误`ImportError: No module named skimage.io`，可以进行如下操作：\n   >\n   > - `sudo apt-get install python-skimage`\n   > - `sudo apt-get install python-numpy python-scipy python-matplotlib python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-nose python-pandas python-glags ipython`\n   > - `sudo apt-get update`\n   > - caffe目录下：`make pycaffe`\n\n## 参考资料\n\n1. [[专业亲测]Ubuntu16.04安装Nvidia显卡驱动（cuda）--解决你的所有困惑](https://blog.csdn.net/ghw15221836342/article/details/79571559)\n2. [ubuntu16.04+gtx1060+cuda8.0+caffe安装、测试经历](https://blog.csdn.net/wopawn/article/details/52302164)\n3. [Ubuntu16.04+GTX1050+CUDA8.0配置深度学习环境](https://blog.csdn.net/sikao_luwei/article/details/69375126)\n4. [ubuntu16.04下软件依赖冲突的解决方案](https://blog.csdn.net/qq_36511757/article/details/79795013)\n5. [cuDNN安装官网教程](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux)","source":"_posts/Caffe的GPU模式安装.md","raw":"---\ntitle: Caffe的GPU模式安装\ndate: 2018-09-08 12:47:11\ntags:\n  - Caffe\ncategories: \n  - 深度学习\n  - Caffe\ncopyright: true\n---\n\n---\n\n这篇文章是有关Caffe GPU模式安装的内容。\n\n<!--more--->\n\n暑假终于入手了一台属于自己的可以称之为高配置的笔记本，实验室的台式机显卡太渣，不想耗费时间和精力再配置台式机，自己的笔记本随时随地方便使用，鼓捣好自己的笔记本环境配置才是王道。\n\n## 笔记本配置\n\n- CPU-Intel七代i7\n- 内存-16G 显存6G\n- 双显卡-GeForce GTX 1060 + Intel\n- 双系统Win10+Ubuntu16.04 \n\n## 相关链接\n\n1. [查看自己的GPU是否支持CUDA](<https://developer.nvidia.com/cuda-gpus>)\n2. [下载匹配自己显卡的驱动](https://www.nvidia.cn/Download/index.aspx?lang=cn)(apt方法安装则不需要)\n3. [CUDA下载](https://developer.nvidia.com/cuda-toolkit-archive) 选择合适的版本，选择下载runfile文件\n4. [下载cuDNN library](https://developer.nvidia.com/rdp/cudnn-archive) 需要注册帐号\n5. [NVIDIA CUDA Installation Guide for Linux](http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4dMB1vD9s)\n6. [Caffe1官网](http://caffe.berkeleyvision.org/)\n7. [Caffe源码](https://github.com/BVLC/caffe)\n\n## 具体过程\n\n- 安装Nvidia显卡驱动\n- 安装CUDA9\n- 安装cuDNN\n- 安装Caffe\n\n### 安装Nvidia显卡驱动\n\n1. 从[相关链接2](https://www.nvidia.cn/Download/index.aspx?lang=cn)查询到自己系统对应的版本\n\n2. 安装驱动\n\n   ~~~shell\n   sudo add-apt-repository ppa:graphics-drivers/ppa  \n   sudo apt-get update  \n   sudo apt-get install nvidia-390 #此处要根据上面查询到的版本适当更改\n   sudo apt-get install mesa-common-dev  \n   sudo apt-get install freeglut3-dev\n   ~~~\n\n   之后重启系统让GTX1060显卡驱动生效。\n\n3. 测试。终端输入`nvidia-smi`，会显示显卡相关的信息，说明安装驱动成功。\n\n   {% asset_img nvidia安装成功.png %}\n\n4. 可以打开Nvidia x server setting切换双显卡。\n\n> ### 可能遇到的问题\n>\n> 执行`sudo apt-get install nvidia-390`命令时可能会产生依赖包冲突的问题。\n>\n> 解决方法：\n>\n> 使用aptitude安装，首先安装apitude`sudo apt-get install aptitude`，使用apitude进行安装的命令`sudo aptitude install xxxx`。根据提示选Y/N/Q，通常选N直到出现对版本做降级处理，点Y即可解决。\n\n### 安装CUDA9.0\n\n1. 从[相关链接3](https://developer.nvidia.com/cuda-toolkit-archive)下载CUDA9.0，选择funfile（下载好的文件名：cuda_9.0.176_384.81_linux.run）\n\n   {% asset_img CUDA.png %}\n\n   > **注意：**CUDA要和显卡驱动对应，如下图。[参考链接](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html)。\n   >\n   > {% asset_img CUDA和驱动版本对应.png %}\n\n2. 执行命令`sudo ./cuda_9.0.176_384.81_linux.run`启动安装程序，一直按空格到最后，输入accept接受条款。\n\n   - 输入n不安装nvidia图像驱动\n   - 输入y安装cuda 9.0工具\n   - 回车确认cuda默认安装路径：/usr/local/cuda-9.0\n   - 输入y或者n安装或者不安装指向/usr/local/cuda的符号链接\n   - 输入y安装CUDA 9.0 Samples，以便后面测试\n   - 回车确认CUDA 9.0 Samples默认安装路径：/home/eric（eric是我的用户名），该安装路径测试完可以删除\n   - 安装完显示如下图 \n\n   {% asset_img CUDA9安装.png %}\n\n   > 如果需要卸载CUDA：\n   >\n   > To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin\n\n3. 添加环境变量\n\n   执行命令`sudo gedit /etc/profile`编辑文件，在最后添加：\n\n   ~~~\n   export PATH=/usr/local/cuda-9.0/bin:$PATH\n   export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:$LD_LIBRARY_PATH\n   ~~~\n\n   重启系统！\n\n4. 测试CUDA Toolkit安装是否正确：`nvcc --version`，输出以下信息说明安装正确：\n\n   {% asset_img CUDA测试.png %}\n\n5. 编译CUDA Samples，默认路径为`~/NVIDIA_CUDA-9.0_Samples`\n\n   ```\n   make\n   ```\n\n   生成可执行文件在`~/NVIDIA_CUDA-9.0_Samples/bin/x84_64/linux/release`\n\n   ```\n   ./deviceQuery\n   ```\n\n   会有如下输出：\n\n   {% asset_img samples.png %}\n\n   > 如果在第一步下载的CUDA和显卡驱动不对应的话，会提示：\n   >\n   > ~~~\n   >  CUDA driver version is insufficient for CUDA runtime version\n   > ~~~\n\n### 安装cuDNN\n\ncuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络（Deep Neural Networks）中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。\n\n1. 从[相关链接4](https://developer.nvidia.com/rdp/cudnn-archive)下载合适版本的cuDNN（下载好的文件名：cuda_9.0.176_384.81_linux.run）\n\n   {% asset_img cuDNN.png %}\n\n2. 解压cuda_9.0.176_384.81_linux.run\n\n   ~~~shell\n   tar -xvzf cuda_9.0.176_384.81_linux.run\n   sudo cp cuda/include/cudnn.h /usr/local/cuda/include\n   sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\n   sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\n   ~~~\n\n3. 更新软链接（应该不需要这一步）\n\n   ~~~shell\n   cd /usr/local/cuda/lib64/\n   sudo rm -rf libcudnn.so libcudnn.so.5\n   sudo ln –s libcudnn.so.5.1.10 libcudnn.so.5\n   sudo ln –s libcudnn.so.5 libcudnn.so\n   ~~~\n\n\n### 安装Caffe\n\n1. 安装依赖包\n\n   ~~~shell\n   sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n   sudo apt-get install --no-install-recommends libboost-all-dev\n   sudo apt-get install libatlas-base-dev\n   sudo apt-get install build-essential\n   sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n   ~~~\n\n2. 安装python的pip和easy_install，方便安装软件包\n\n   ~~~shell\n   cd\n   wget --no-check-certificate https://bootstrap.pypa.io/ez_setup.py\n   sudo python ez_setup.py --insecure\n   wget https://bootstrap.pypa.io/get-pip.py\n   sudo python get-pip.py\n   ~~~\n\n3. 安装科学计算和python所需的部分库\n\n   ~~~shell\n   sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran python-numpy\n   ~~~\n\n4. 安装python依赖\n\n   ~~~shell\n   sudo apt-get install python-pip #安装pip\n   ~~~\n\n5. 编译Caffe\n\n   ##### 终端输入\n\n   ~~~shell\n   cd /home/eric/caffe\n   cp Makefile.config.example Makefile.config\n   gedit Makefile.config\n   ~~~\n\n   - 将`USE_CUDNN := 1`取消注释\n   - `INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include`后面打上一个空格 然后添加`/usr/include/hdf5/serial`如果没有这一句可能会报一个找不到hdf5.h的错误\n\n   ##### 终端输入 \n\n   ~~~shell\n   make\n   ~~~\n\n   > #### make过程中出现找不到lhdf5_hl和lhdf5的错误\n   >\n   > 解决方案：在计算机中搜索`libhdf5_serial.so.10.1.0`，找到后右键点击打开项目位置。该目录下空白处右键点击在终端打开，打开新终端输入   `sudo ln libhdf5_serial.so.10.1.0 libhdf5.so`   `sudo ln libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so` 。最后在终端输入`sudo ldconfig`使链接生效，原终端中输入`make clean`清除第一次编译结果，再重新编译。\n   >\n   > #### 出现`nvcc fatal   : Unsupported gpu architecture 'compute_20'`的错误\n   >\n   > 将Makefile.config文件中`CUDA_ARCH :=`包含`compute_20`的两项删除即可。\n\n   ##### 终端输入：\n\n   ~~~shell\n   make test -j4\n   make runtest -j4\n   make pycaffe -j4\n   make distribute\n   ~~~\n\n   生成发布安装包\n\n   ##### 测试python，终端输入:\n\n   ~~~shell\n   cd /home/erci/install/caffe/python\n   python\n   import caffe\n   ~~~\n\n   如果不报错就说明编译成功。\n\n   > #### 提示\n   >\n   > 如果执行`import caffe`，出现错误`ImportError: No module named skimage.io`，可以进行如下操作：\n   >\n   > - `sudo apt-get install python-skimage`\n   > - `sudo apt-get install python-numpy python-scipy python-matplotlib python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-nose python-pandas python-glags ipython`\n   > - `sudo apt-get update`\n   > - caffe目录下：`make pycaffe`\n\n## 参考资料\n\n1. [[专业亲测]Ubuntu16.04安装Nvidia显卡驱动（cuda）--解决你的所有困惑](https://blog.csdn.net/ghw15221836342/article/details/79571559)\n2. [ubuntu16.04+gtx1060+cuda8.0+caffe安装、测试经历](https://blog.csdn.net/wopawn/article/details/52302164)\n3. [Ubuntu16.04+GTX1050+CUDA8.0配置深度学习环境](https://blog.csdn.net/sikao_luwei/article/details/69375126)\n4. [ubuntu16.04下软件依赖冲突的解决方案](https://blog.csdn.net/qq_36511757/article/details/79795013)\n5. [cuDNN安装官网教程](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux)","slug":"Caffe的GPU模式安装","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbym00ayqlcr21hg03hb","content":"<hr>\n<p>这篇文章是有关Caffe GPU模式安装的内容。</p>\n<a id=\"more\"></a>\n<p>暑假终于入手了一台属于自己的可以称之为高配置的笔记本，实验室的台式机显卡太渣，不想耗费时间和精力再配置台式机，自己的笔记本随时随地方便使用，鼓捣好自己的笔记本环境配置才是王道。</p>\n<h2 id=\"笔记本配置\"><a href=\"#笔记本配置\" class=\"headerlink\" title=\"笔记本配置\"></a>笔记本配置</h2><ul>\n<li>CPU-Intel七代i7</li>\n<li>内存-16G 显存6G</li>\n<li>双显卡-GeForce GTX 1060 + Intel</li>\n<li>双系统Win10+Ubuntu16.04 </li>\n</ul>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ol>\n<li><a href=\"https://developer.nvidia.com/cuda-gpus\" target=\"_blank\" rel=\"noopener\">查看自己的GPU是否支持CUDA</a></li>\n<li><a href=\"https://www.nvidia.cn/Download/index.aspx?lang=cn\" target=\"_blank\" rel=\"noopener\">下载匹配自己显卡的驱动</a>(apt方法安装则不需要)</li>\n<li><a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\" rel=\"noopener\">CUDA下载</a> 选择合适的版本，选择下载runfile文件</li>\n<li><a href=\"https://developer.nvidia.com/rdp/cudnn-archive\" target=\"_blank\" rel=\"noopener\">下载cuDNN library</a> 需要注册帐号</li>\n<li><a href=\"http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4dMB1vD9s\" target=\"_blank\" rel=\"noopener\">NVIDIA CUDA Installation Guide for Linux</a></li>\n<li><a href=\"http://caffe.berkeleyvision.org/\" target=\"_blank\" rel=\"noopener\">Caffe1官网</a></li>\n<li><a href=\"https://github.com/BVLC/caffe\" target=\"_blank\" rel=\"noopener\">Caffe源码</a></li>\n</ol>\n<h2 id=\"具体过程\"><a href=\"#具体过程\" class=\"headerlink\" title=\"具体过程\"></a>具体过程</h2><ul>\n<li>安装Nvidia显卡驱动</li>\n<li>安装CUDA9</li>\n<li>安装cuDNN</li>\n<li>安装Caffe</li>\n</ul>\n<h3 id=\"安装Nvidia显卡驱动\"><a href=\"#安装Nvidia显卡驱动\" class=\"headerlink\" title=\"安装Nvidia显卡驱动\"></a>安装Nvidia显卡驱动</h3><ol>\n<li><p>从<a href=\"https://www.nvidia.cn/Download/index.aspx?lang=cn\" target=\"_blank\" rel=\"noopener\">相关链接2</a>查询到自己系统对应的版本</p>\n</li>\n<li><p>安装驱动</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo add-apt-repository ppa:graphics-drivers/ppa  </span><br><span class=\"line\">sudo apt-get update  </span><br><span class=\"line\">sudo apt-get install nvidia-390 #此处要根据上面查询到的版本适当更改</span><br><span class=\"line\">sudo apt-get install mesa-common-dev  </span><br><span class=\"line\">sudo apt-get install freeglut3-dev</span><br></pre></td></tr></table></figure>\n<p>之后重启系统让GTX1060显卡驱动生效。</p>\n</li>\n<li><p>测试。终端输入<code>nvidia-smi</code>，会显示显卡相关的信息，说明安装驱动成功。</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/nvidia安装成功.png\">\n</li>\n<li><p>可以打开Nvidia x server setting切换双显卡。</p>\n</li>\n</ol>\n<blockquote>\n<h3 id=\"可能遇到的问题\"><a href=\"#可能遇到的问题\" class=\"headerlink\" title=\"可能遇到的问题\"></a>可能遇到的问题</h3><p>执行<code>sudo apt-get install nvidia-390</code>命令时可能会产生依赖包冲突的问题。</p>\n<p>解决方法：</p>\n<p>使用aptitude安装，首先安装apitude<code>sudo apt-get install aptitude</code>，使用apitude进行安装的命令<code>sudo aptitude install xxxx</code>。根据提示选Y/N/Q，通常选N直到出现对版本做降级处理，点Y即可解决。</p>\n</blockquote>\n<h3 id=\"安装CUDA9-0\"><a href=\"#安装CUDA9-0\" class=\"headerlink\" title=\"安装CUDA9.0\"></a>安装CUDA9.0</h3><ol>\n<li><p>从<a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\" rel=\"noopener\">相关链接3</a>下载CUDA9.0，选择funfile（下载好的文件名：cuda_9.0.176_384.81_linux.run）</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA.png\">\n<blockquote>\n<p><strong>注意：</strong>CUDA要和显卡驱动对应，如下图。<a href=\"https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html\" target=\"_blank\" rel=\"noopener\">参考链接</a>。</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA和驱动版本对应.png\">\n</blockquote>\n</li>\n<li><p>执行命令<code>sudo ./cuda_9.0.176_384.81_linux.run</code>启动安装程序，一直按空格到最后，输入accept接受条款。</p>\n<ul>\n<li>输入n不安装nvidia图像驱动</li>\n<li>输入y安装cuda 9.0工具</li>\n<li>回车确认cuda默认安装路径：/usr/local/cuda-9.0</li>\n<li>输入y或者n安装或者不安装指向/usr/local/cuda的符号链接</li>\n<li>输入y安装CUDA 9.0 Samples，以便后面测试</li>\n<li>回车确认CUDA 9.0 Samples默认安装路径：/home/eric（eric是我的用户名），该安装路径测试完可以删除</li>\n<li>安装完显示如下图 </li>\n</ul>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA9安装.png\">\n<blockquote>\n<p>如果需要卸载CUDA：</p>\n<p>To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin</p>\n</blockquote>\n</li>\n<li><p>添加环境变量</p>\n<p>执行命令<code>sudo gedit /etc/profile</code>编辑文件，在最后添加：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export PATH=/usr/local/cuda-9.0/bin:$PATH</span><br><span class=\"line\">export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>\n<p>重启系统！</p>\n</li>\n<li><p>测试CUDA Toolkit安装是否正确：<code>nvcc --version</code>，输出以下信息说明安装正确：</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA测试.png\">\n</li>\n<li><p>编译CUDA Samples，默认路径为<code>~/NVIDIA_CUDA-9.0_Samples</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n<p>生成可执行文件在<code>~/NVIDIA_CUDA-9.0_Samples/bin/x84_64/linux/release</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./deviceQuery</span><br></pre></td></tr></table></figure>\n<p>会有如下输出：</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/samples.png\">\n<blockquote>\n<p>如果在第一步下载的CUDA和显卡驱动不对应的话，会提示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;  CUDA driver version is insufficient for CUDA runtime version</span><br><span class=\"line\">&gt;</span><br></pre></td></tr></table></figure>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"安装cuDNN\"><a href=\"#安装cuDNN\" class=\"headerlink\" title=\"安装cuDNN\"></a>安装cuDNN</h3><p>cuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络（Deep Neural Networks）中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。</p>\n<ol>\n<li><p>从<a href=\"https://developer.nvidia.com/rdp/cudnn-archive\" target=\"_blank\" rel=\"noopener\">相关链接4</a>下载合适版本的cuDNN（下载好的文件名：cuda_9.0.176_384.81_linux.run）</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/cuDNN.png\">\n</li>\n<li><p>解压cuda_9.0.176_384.81_linux.run</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -xvzf cuda_9.0.176_384.81_linux.run</span><br><span class=\"line\">sudo cp cuda/include/cudnn.h /usr/local/cuda/include</span><br><span class=\"line\">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</span><br><span class=\"line\">sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>更新软链接（应该不需要这一步）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local/cuda/lib64/</span><br><span class=\"line\">sudo rm -rf libcudnn.so libcudnn.so.5</span><br><span class=\"line\">sudo ln –s libcudnn.so.5.1.10 libcudnn.so.5</span><br><span class=\"line\">sudo ln –s libcudnn.so.5 libcudnn.so</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"安装Caffe\"><a href=\"#安装Caffe\" class=\"headerlink\" title=\"安装Caffe\"></a>安装Caffe</h3><ol>\n<li><p>安装依赖包</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class=\"line\">sudo apt-get install --no-install-recommends libboost-all-dev</span><br><span class=\"line\">sudo apt-get install libatlas-base-dev</span><br><span class=\"line\">sudo apt-get install build-essential</span><br><span class=\"line\">sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装python的pip和easy_install，方便安装软件包</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd</span><br><span class=\"line\">wget --no-check-certificate https://bootstrap.pypa.io/ez_setup.py</span><br><span class=\"line\">sudo python ez_setup.py --insecure</span><br><span class=\"line\">wget https://bootstrap.pypa.io/get-pip.py</span><br><span class=\"line\">sudo python get-pip.py</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装科学计算和python所需的部分库</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran python-numpy</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装python依赖</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install python-pip #安装pip</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>编译Caffe</p>\n<h5 id=\"终端输入\"><a href=\"#终端输入\" class=\"headerlink\" title=\"终端输入\"></a>终端输入</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /home/eric/caffe</span><br><span class=\"line\">cp Makefile.config.example Makefile.config</span><br><span class=\"line\">gedit Makefile.config</span><br></pre></td></tr></table></figure>\n<ul>\n<li>将<code>USE_CUDNN := 1</code>取消注释</li>\n<li><code>INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include</code>后面打上一个空格 然后添加<code>/usr/include/hdf5/serial</code>如果没有这一句可能会报一个找不到hdf5.h的错误</li>\n</ul>\n<h5 id=\"终端输入-1\"><a href=\"#终端输入-1\" class=\"headerlink\" title=\"终端输入\"></a>终端输入</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n<blockquote>\n<h4 id=\"make过程中出现找不到lhdf5-hl和lhdf5的错误\"><a href=\"#make过程中出现找不到lhdf5-hl和lhdf5的错误\" class=\"headerlink\" title=\"make过程中出现找不到lhdf5_hl和lhdf5的错误\"></a>make过程中出现找不到lhdf5_hl和lhdf5的错误</h4><p>解决方案：在计算机中搜索<code>libhdf5_serial.so.10.1.0</code>，找到后右键点击打开项目位置。该目录下空白处右键点击在终端打开，打开新终端输入   <code>sudo ln libhdf5_serial.so.10.1.0 libhdf5.so</code>   <code>sudo ln libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so</code> 。最后在终端输入<code>sudo ldconfig</code>使链接生效，原终端中输入<code>make clean</code>清除第一次编译结果，再重新编译。</p>\n<h4 id=\"出现nvcc-fatal-Unsupported-gpu-architecture-39-compute-20-39-的错误\"><a href=\"#出现nvcc-fatal-Unsupported-gpu-architecture-39-compute-20-39-的错误\" class=\"headerlink\" title=\"出现nvcc fatal   : Unsupported gpu architecture &#39;compute_20&#39;的错误\"></a>出现<code>nvcc fatal   : Unsupported gpu architecture &#39;compute_20&#39;</code>的错误</h4><p>将Makefile.config文件中<code>CUDA_ARCH :=</code>包含<code>compute_20</code>的两项删除即可。</p>\n</blockquote>\n<h5 id=\"终端输入：\"><a href=\"#终端输入：\" class=\"headerlink\" title=\"终端输入：\"></a>终端输入：</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make test -j4</span><br><span class=\"line\">make runtest -j4</span><br><span class=\"line\">make pycaffe -j4</span><br><span class=\"line\">make distribute</span><br></pre></td></tr></table></figure>\n<p>生成发布安装包</p>\n<h5 id=\"测试python，终端输入\"><a href=\"#测试python，终端输入\" class=\"headerlink\" title=\"测试python，终端输入:\"></a>测试python，终端输入:</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /home/erci/install/caffe/python</span><br><span class=\"line\">python</span><br><span class=\"line\">import caffe</span><br></pre></td></tr></table></figure>\n<p>如果不报错就说明编译成功。</p>\n<blockquote>\n<h4 id=\"提示\"><a href=\"#提示\" class=\"headerlink\" title=\"提示\"></a>提示</h4><p>如果执行<code>import caffe</code>，出现错误<code>ImportError: No module named skimage.io</code>，可以进行如下操作：</p>\n<ul>\n<li><code>sudo apt-get install python-skimage</code></li>\n<li><code>sudo apt-get install python-numpy python-scipy python-matplotlib python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-nose python-pandas python-glags ipython</code></li>\n<li><code>sudo apt-get update</code></li>\n<li>caffe目录下：<code>make pycaffe</code></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/ghw15221836342/article/details/79571559\" target=\"_blank\" rel=\"noopener\">[专业亲测]Ubuntu16.04安装Nvidia显卡驱动（cuda）—解决你的所有困惑</a></li>\n<li><a href=\"https://blog.csdn.net/wopawn/article/details/52302164\" target=\"_blank\" rel=\"noopener\">ubuntu16.04+gtx1060+cuda8.0+caffe安装、测试经历</a></li>\n<li><a href=\"https://blog.csdn.net/sikao_luwei/article/details/69375126\" target=\"_blank\" rel=\"noopener\">Ubuntu16.04+GTX1050+CUDA8.0配置深度学习环境</a></li>\n<li><a href=\"https://blog.csdn.net/qq_36511757/article/details/79795013\" target=\"_blank\" rel=\"noopener\">ubuntu16.04下软件依赖冲突的解决方案</a></li>\n<li><a href=\"https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux\" target=\"_blank\" rel=\"noopener\">cuDNN安装官网教程</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关Caffe GPU模式安装的内容。</p>","more":"<p>暑假终于入手了一台属于自己的可以称之为高配置的笔记本，实验室的台式机显卡太渣，不想耗费时间和精力再配置台式机，自己的笔记本随时随地方便使用，鼓捣好自己的笔记本环境配置才是王道。</p>\n<h2 id=\"笔记本配置\"><a href=\"#笔记本配置\" class=\"headerlink\" title=\"笔记本配置\"></a>笔记本配置</h2><ul>\n<li>CPU-Intel七代i7</li>\n<li>内存-16G 显存6G</li>\n<li>双显卡-GeForce GTX 1060 + Intel</li>\n<li>双系统Win10+Ubuntu16.04 </li>\n</ul>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ol>\n<li><a href=\"https://developer.nvidia.com/cuda-gpus\" target=\"_blank\" rel=\"noopener\">查看自己的GPU是否支持CUDA</a></li>\n<li><a href=\"https://www.nvidia.cn/Download/index.aspx?lang=cn\" target=\"_blank\" rel=\"noopener\">下载匹配自己显卡的驱动</a>(apt方法安装则不需要)</li>\n<li><a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\" rel=\"noopener\">CUDA下载</a> 选择合适的版本，选择下载runfile文件</li>\n<li><a href=\"https://developer.nvidia.com/rdp/cudnn-archive\" target=\"_blank\" rel=\"noopener\">下载cuDNN library</a> 需要注册帐号</li>\n<li><a href=\"http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4dMB1vD9s\" target=\"_blank\" rel=\"noopener\">NVIDIA CUDA Installation Guide for Linux</a></li>\n<li><a href=\"http://caffe.berkeleyvision.org/\" target=\"_blank\" rel=\"noopener\">Caffe1官网</a></li>\n<li><a href=\"https://github.com/BVLC/caffe\" target=\"_blank\" rel=\"noopener\">Caffe源码</a></li>\n</ol>\n<h2 id=\"具体过程\"><a href=\"#具体过程\" class=\"headerlink\" title=\"具体过程\"></a>具体过程</h2><ul>\n<li>安装Nvidia显卡驱动</li>\n<li>安装CUDA9</li>\n<li>安装cuDNN</li>\n<li>安装Caffe</li>\n</ul>\n<h3 id=\"安装Nvidia显卡驱动\"><a href=\"#安装Nvidia显卡驱动\" class=\"headerlink\" title=\"安装Nvidia显卡驱动\"></a>安装Nvidia显卡驱动</h3><ol>\n<li><p>从<a href=\"https://www.nvidia.cn/Download/index.aspx?lang=cn\" target=\"_blank\" rel=\"noopener\">相关链接2</a>查询到自己系统对应的版本</p>\n</li>\n<li><p>安装驱动</p>\n<!--�111-->\n<p>之后重启系统让GTX1060显卡驱动生效。</p>\n</li>\n<li><p>测试。终端输入<code>nvidia-smi</code>，会显示显卡相关的信息，说明安装驱动成功。</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/nvidia安装成功.png\">\n</li>\n<li><p>可以打开Nvidia x server setting切换双显卡。</p>\n</li>\n</ol>\n<blockquote>\n<h3 id=\"可能遇到的问题\"><a href=\"#可能遇到的问题\" class=\"headerlink\" title=\"可能遇到的问题\"></a>可能遇到的问题</h3><p>执行<code>sudo apt-get install nvidia-390</code>命令时可能会产生依赖包冲突的问题。</p>\n<p>解决方法：</p>\n<p>使用aptitude安装，首先安装apitude<code>sudo apt-get install aptitude</code>，使用apitude进行安装的命令<code>sudo aptitude install xxxx</code>。根据提示选Y/N/Q，通常选N直到出现对版本做降级处理，点Y即可解决。</p>\n</blockquote>\n<h3 id=\"安装CUDA9-0\"><a href=\"#安装CUDA9-0\" class=\"headerlink\" title=\"安装CUDA9.0\"></a>安装CUDA9.0</h3><ol>\n<li><p>从<a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\" rel=\"noopener\">相关链接3</a>下载CUDA9.0，选择funfile（下载好的文件名：cuda_9.0.176_384.81_linux.run）</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA.png\">\n<blockquote>\n<p><strong>注意：</strong>CUDA要和显卡驱动对应，如下图。<a href=\"https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html\" target=\"_blank\" rel=\"noopener\">参考链接</a>。</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA和驱动版本对应.png\">\n</blockquote>\n</li>\n<li><p>执行命令<code>sudo ./cuda_9.0.176_384.81_linux.run</code>启动安装程序，一直按空格到最后，输入accept接受条款。</p>\n<ul>\n<li>输入n不安装nvidia图像驱动</li>\n<li>输入y安装cuda 9.0工具</li>\n<li>回车确认cuda默认安装路径：/usr/local/cuda-9.0</li>\n<li>输入y或者n安装或者不安装指向/usr/local/cuda的符号链接</li>\n<li>输入y安装CUDA 9.0 Samples，以便后面测试</li>\n<li>回车确认CUDA 9.0 Samples默认安装路径：/home/eric（eric是我的用户名），该安装路径测试完可以删除</li>\n<li>安装完显示如下图 </li>\n</ul>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA9安装.png\">\n<blockquote>\n<p>如果需要卸载CUDA：</p>\n<p>To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin</p>\n</blockquote>\n</li>\n<li><p>添加环境变量</p>\n<p>执行命令<code>sudo gedit /etc/profile</code>编辑文件，在最后添加：</p>\n<!--�112-->\n<p>重启系统！</p>\n</li>\n<li><p>测试CUDA Toolkit安装是否正确：<code>nvcc --version</code>，输出以下信息说明安装正确：</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/CUDA测试.png\">\n</li>\n<li><p>编译CUDA Samples，默认路径为<code>~/NVIDIA_CUDA-9.0_Samples</code></p>\n<!--�113-->\n<p>生成可执行文件在<code>~/NVIDIA_CUDA-9.0_Samples/bin/x84_64/linux/release</code></p>\n<!--�114-->\n<p>会有如下输出：</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/samples.png\">\n<blockquote>\n<p>如果在第一步下载的CUDA和显卡驱动不对应的话，会提示：</p>\n<!--�115-->\n</blockquote>\n</li>\n</ol>\n<h3 id=\"安装cuDNN\"><a href=\"#安装cuDNN\" class=\"headerlink\" title=\"安装cuDNN\"></a>安装cuDNN</h3><p>cuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络（Deep Neural Networks）中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。</p>\n<ol>\n<li><p>从<a href=\"https://developer.nvidia.com/rdp/cudnn-archive\" target=\"_blank\" rel=\"noopener\">相关链接4</a>下载合适版本的cuDNN（下载好的文件名：cuda_9.0.176_384.81_linux.run）</p>\n<img src=\"/2018/09/08/Caffe的GPU模式安装/cuDNN.png\">\n</li>\n<li><p>解压cuda_9.0.176_384.81_linux.run</p>\n<!--�116-->\n</li>\n<li><p>更新软链接（应该不需要这一步）</p>\n<!--�117-->\n</li>\n</ol>\n<h3 id=\"安装Caffe\"><a href=\"#安装Caffe\" class=\"headerlink\" title=\"安装Caffe\"></a>安装Caffe</h3><ol>\n<li><p>安装依赖包</p>\n<!--�118-->\n</li>\n<li><p>安装python的pip和easy_install，方便安装软件包</p>\n<!--�119-->\n</li>\n<li><p>安装科学计算和python所需的部分库</p>\n<!--�120-->\n</li>\n<li><p>安装python依赖</p>\n<!--�121-->\n</li>\n<li><p>编译Caffe</p>\n<h5 id=\"终端输入\"><a href=\"#终端输入\" class=\"headerlink\" title=\"终端输入\"></a>终端输入</h5><!--�122-->\n<ul>\n<li>将<code>USE_CUDNN := 1</code>取消注释</li>\n<li><code>INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include</code>后面打上一个空格 然后添加<code>/usr/include/hdf5/serial</code>如果没有这一句可能会报一个找不到hdf5.h的错误</li>\n</ul>\n<h5 id=\"终端输入-1\"><a href=\"#终端输入-1\" class=\"headerlink\" title=\"终端输入\"></a>终端输入</h5><!--�123-->\n<blockquote>\n<h4 id=\"make过程中出现找不到lhdf5-hl和lhdf5的错误\"><a href=\"#make过程中出现找不到lhdf5-hl和lhdf5的错误\" class=\"headerlink\" title=\"make过程中出现找不到lhdf5_hl和lhdf5的错误\"></a>make过程中出现找不到lhdf5_hl和lhdf5的错误</h4><p>解决方案：在计算机中搜索<code>libhdf5_serial.so.10.1.0</code>，找到后右键点击打开项目位置。该目录下空白处右键点击在终端打开，打开新终端输入   <code>sudo ln libhdf5_serial.so.10.1.0 libhdf5.so</code>   <code>sudo ln libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so</code> 。最后在终端输入<code>sudo ldconfig</code>使链接生效，原终端中输入<code>make clean</code>清除第一次编译结果，再重新编译。</p>\n<h4 id=\"出现nvcc-fatal-Unsupported-gpu-architecture-39-compute-20-39-的错误\"><a href=\"#出现nvcc-fatal-Unsupported-gpu-architecture-39-compute-20-39-的错误\" class=\"headerlink\" title=\"出现nvcc fatal   : Unsupported gpu architecture &#39;compute_20&#39;的错误\"></a>出现<code>nvcc fatal   : Unsupported gpu architecture &#39;compute_20&#39;</code>的错误</h4><p>将Makefile.config文件中<code>CUDA_ARCH :=</code>包含<code>compute_20</code>的两项删除即可。</p>\n</blockquote>\n<h5 id=\"终端输入：\"><a href=\"#终端输入：\" class=\"headerlink\" title=\"终端输入：\"></a>终端输入：</h5><!--�124-->\n<p>生成发布安装包</p>\n<h5 id=\"测试python，终端输入\"><a href=\"#测试python，终端输入\" class=\"headerlink\" title=\"测试python，终端输入:\"></a>测试python，终端输入:</h5><!--�125-->\n<p>如果不报错就说明编译成功。</p>\n<blockquote>\n<h4 id=\"提示\"><a href=\"#提示\" class=\"headerlink\" title=\"提示\"></a>提示</h4><p>如果执行<code>import caffe</code>，出现错误<code>ImportError: No module named skimage.io</code>，可以进行如下操作：</p>\n<ul>\n<li><code>sudo apt-get install python-skimage</code></li>\n<li><code>sudo apt-get install python-numpy python-scipy python-matplotlib python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-nose python-pandas python-glags ipython</code></li>\n<li><code>sudo apt-get update</code></li>\n<li>caffe目录下：<code>make pycaffe</code></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/ghw15221836342/article/details/79571559\" target=\"_blank\" rel=\"noopener\">[专业亲测]Ubuntu16.04安装Nvidia显卡驱动（cuda）—解决你的所有困惑</a></li>\n<li><a href=\"https://blog.csdn.net/wopawn/article/details/52302164\" target=\"_blank\" rel=\"noopener\">ubuntu16.04+gtx1060+cuda8.0+caffe安装、测试经历</a></li>\n<li><a href=\"https://blog.csdn.net/sikao_luwei/article/details/69375126\" target=\"_blank\" rel=\"noopener\">Ubuntu16.04+GTX1050+CUDA8.0配置深度学习环境</a></li>\n<li><a href=\"https://blog.csdn.net/qq_36511757/article/details/79795013\" target=\"_blank\" rel=\"noopener\">ubuntu16.04下软件依赖冲突的解决方案</a></li>\n<li><a href=\"https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-linux\" target=\"_blank\" rel=\"noopener\">cuDNN安装官网教程</a></li>\n</ol>"},{"title":"ORB_SLAM2学习之源码分析九-ORB特征匹配","date":"2018-08-30T14:28:10.000Z","copyright":true,"_content":"\n----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征匹配有关的内容。\n\n<!--more---->\n\n## 概述\n\nORB_SLAM2系统中，负责特征匹配的类是`ORBmatcher`，定义在ORBmatcher.h文件中。该类负责特征点与特征点之间，地图点与特征点之间通过投影关系、词袋模型或者Sim3位姿匹配，用来辅助完成单目初始化、三角化恢复新的地图点、Tracking、Relocalization以及Loop Closing等任务，因此比较重要。类中提供了多个接口，这些接口分别负责完成不同的匹配任务，下面进行一一介绍。\n\n## 主要接口\n\n### 重载的`SearchByProjection`函数\n\n#### 用于追踪局部地图（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(Frame &F, const std::vector<MapPoint*> &vpMapPoints, const float th=3);\n~~~\n\n该函数负责在当前帧特征点和投影的地图点之间搜索匹配，具体来说，就是将投影的地图点`vpMapPoints`（这些地图点是上一帧的局部关键帧对应的所有局部地图点）投影到当前图像帧并搜索匹配，返回匹配到的点对数。具体匹配过程：\n\n1. 对于`vpMapPoints`中的每个地图点，搜索其在当前图像帧一个窗口内的特征点；\n2. 计算该地图点的描述子与窗口范围内的每一个特征点描述子的汉明距离；\n3. 找到汉明距离值最小bestDist和次小bestDist2的两个最佳匹配特征点；\n4. 如果两个特征点所属的金字塔层不同并且最佳匹配点的汉明距离值bestDist大于mfNNratio与次最佳匹配点的距离值bestDist2的乘积，则认为最佳匹配点就是汉明距离最小的这个特征点；将该地图点设为当前特征点对应的地图点，匹配成功，匹配数+1，继续循环匹配；\n5. 否则，继续循环匹配；\n6. 继续循环匹配，直到`vpMapPoints`中的每个地图点都匹配完毕（或匹配到或匹配不到）。\n\n#### 用于从上一图像帧追踪（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(Frame &CurrentFrame, const Frame &LastFrame, const float th, const bool bMono);\n~~~\n\n该函数负责将从上一图像帧追踪到的地图点投影到当前帧，并搜索匹配，返回匹配到的点对数量，用于`TrackWithMotionModel`。具体过程：\n\n1. 建立旋转直方图，用于检测旋转一致性；\n\n2. 分别计算当前帧和前一帧的旋转矩阵和平移矩阵；\n\n3. 通过相机模型，将前一帧的每一个地图点，投影得到在当前帧中的像素坐标；\n\n4. 在一个窗口内搜寻特征点`GetFeaturesInArea`，窗口尺寸根据尺度（特征点所处金字塔层）进行变化。因为前面ORB是进行了高斯金字塔分层，金字塔越上层的尺寸越小，搜索窗口相应就小；\n\n5. 找到地图点描述子与在窗口中的特征点描述子之间的距离的最佳值（最小值），如果距离小于设定值`TH_HIGH`，则认为是匹配点对，匹配数+1；\n\n6. 在直方图中记录特征点角度变化（做旋转一致性检测有关的记录，上一帧关键点角度和当前帧关键点角度相减）；直方图形式如下所示，旋转角度除以直方图长度，四舍五入得到横坐标（横坐标范围是`0-HISTO_LENGTH`），每个横坐标值对应一个`vector`集合，记录所有对应具有当前角度的匹配点的序号，纵坐标是集合的大小。\n\n   {% asset_img 直方图.png %}\n\n7. 循环3，继续匹配；\n\n8. 应用旋转一致性再一次筛选匹配点对（根据角度变化剔除不好的匹配），具体做法是从直方图中选出纵坐标值最大的前三个集合，剔除这三个集合以外的其他匹配点。\n\n#### 用于重定位（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(Frame &CurrentFrame, KeyFrame* pKF, const std::set<MapPoint*> &sAlreadyFound, const float th, const int ORBdist);\n~~~\n\n该函数负责将从关键帧中观测到的地图点投影到当前帧，并搜索匹配（投影匹配当前帧的特征点），返回匹配到的点对数量，用于`Relocalization`。具体过程与上一个函数类似。\n\n#### 用于回环检测（LoopClosing）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(KeyFrame* pKF, cv::Mat Scw, const std::vector<MapPoint*> &vpPoints, std::vector<MapPoint*> &vpMatched, int th);\n~~~\n\n该函数负责使用相似变换投影地图点到当前关键帧，并搜索匹配，返回匹配到的点对数量，用于`Loop Closing`。\n\n##### 参数\n\n- pKF：检测闭环时的当前关键帧\n- Scw：闭环帧（从候选帧选出的）与当前帧之间的相似变换`Scm`\n- vpPoints：闭环帧及其相连关键帧对应的地图点\n- vpMatched：已经找到的地图点（当前关键帧与所有候选关键帧SearchByBoW匹配到的地图点）\n\n##### 具体过程\n\n1. 获取相机标定参数，为之后的投影做准备；\n2. 分解相似变换矩阵：先计算得到尺度因子s，然后计算世界坐标系到相机坐标系pKF的旋转矩阵和平移向量（都是去掉尺度因子的）；\n3. 在已经找到的匹配点中，去除没有对应匹配点的地图点；\n4. 遍历每个地图点，不包括坏的地图点和已经找到的地图点\n   - 首先获取到地图点的3D世界坐标系，并通过第2步计算得到的矩阵转换到相机坐标系下，且在Pc下的深度必须为正；\n   - 再投影到像素坐标系下，坐标值必须在image范围内；\n   - 计算世界坐标系下，该地图点的深度，该深度必须在该点的尺度方差区域内，且观察视角必须小于60°（通过向量内积来判断观察角度是否小于60°）；\n   - 根据地图点的深度和关键帧预测一个高斯金字塔层，根据该层计算一个半径，获得该半径范围内的特征点；\n   - 找出半径范围内所有特征点的描述子与地图点描述子汉明距离最小的特征点，如果满足最小距离`bestDist<=TH_LOW`，则认定匹配成功。\n\n### 重载的`SearchByBow`函数\n\n#### 用于重定位（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByBoW(KeyFrame *pKF, Frame &F, std::vector<MapPoint*> &vpMapPointMatches);\n~~~\n\n该函数通过BoW对关键帧和当前图像帧的特征点进行匹配，用于`TrackReferenceKeyFrame`和`Relocalization`。\n\n#### 用于回环检测（LoopClosing）\n\n对应函数：\n\n~~~c++\nint ORBmatcher::SearchByBoW(KeyFrame *pKF1, KeyFrame *pKF2, vector<MapPoint *> &vpMatches12)\n~~~\n\n该函数通过BoW对两个关键帧（当前关键帧`pKF1`和候选关键帧之一`pKF2`）的特征点进行匹配，用于Loop Closing时对两个关键帧间的特征点匹配，返回匹配到的点对数量，将匹配到的特征点对应的地图点记录在`vpMatches12`中作为输出。\n\n##### 参数\n\n- pKF1：当前关键帧\n- pKF2：候选关键帧中的一个\n- vpMatches12：匹配到的地图点\n\n##### 具体实现\n\n1. 对四叉树中属于相同节点的特征点才考虑匹配，首先对KF1中某个节点下的特征点，遍历KF2中对应节点的所有特征点，计算描述子距离并记录信息；\n2. 根据距离和阈值关系添加匹配，记录角度变化；\n3. 根据角度变化剔除误匹配。\n\n### 重载的`Fuse`函数\n\n主要用于地图点的融合。如果地图点能匹配上当前关键帧的地图点，也就是地图点重合了，选择观测数多的地图点替换；地图点能匹配上当前帧的特征点，但是该特征点还没有生成地图点，则生成新的地图点。重载的第一个函数是为了减小尺度漂移的影响，需要知道当前关键帧的sim3位姿。\n\n#### 使用相似变换的投影\n\n对应函数：\n\n~~~c++\nint Fuse(KeyFrame* pKF, cv::Mat Scw, const std::vector<MapPoint*> &vpPoints, float th, vector<MapPoint *> &vpReplacePoint);\n~~~\n\n该函数用于回环检测线程，负责使用一个给定的相似变换`Scw`将地图点投影到关键帧，搜索重叠的地图点。具体实现：\n\n1. 分解相似变换矩阵，得到旋转矩阵和平移向量等数据；\n2. 对每一个地图点投影到相机系和图像系，检查深度、视角等信息；\n3. 由距离预测尺度进而确定搜索半径，在指定区域内获取特征点；\n4. 遍历这些特征点，计算其描述子和地图点描述子的汉明距离，计录最好距离和索引；\n5. 如果索引对应的地图点不存在则新添加一个，存在的话则标记其将要被替换。\n\n#### 不使用相似变换的投影\n\n对应函数：\n\n~~~c++\nint Fuse(KeyFrame* pKF, const vector<MapPoint *> &vpMapPoints, const float th=3.0);\n~~~\n\n该函数用于局部建图线程，负责将地图点投影到关键帧，搜索重叠的地图点，返回融合的地图点数量。具体实现：\n\n1. 遍历地图点，将其转换至相机坐标系检查深度，投影并检查是否在图像内，检查尺度和视角范围是否合适；\n2. 根据深度预测尺度从而确定搜索半径，获得范围内的特征点；\n3. 遍历这些点，计算它们和地图点投影后的坐标误差，误差太大的跳过，计算描述子距离，记录距离最小的最佳匹配点；\n4. 对于最佳匹配，如果某个点已经有了地图点，则选择观测次数多的那个点，舍弃观测次数少的点，即两点融合；如果没有对应的地图点，则添加地图点，添加观测关系。\n\n### `SearchForInitialization`函数\n\n函数原型：\n\n~~~c++\nint SearchForInitialization(Frame &F1, Frame &F2, std::vector<cv::Point2f> &vbPrevMatched, std::vector<int> &vnMatches12, int windowSize=10);\n~~~\n\n该函数用于单目初始化过程，地图初始化时两个图像帧之间的匹配，只用于单目。具体实现：\n\n1. 构造直方图；\n2. 遍历第一帧中的特征点，对于每一个特征点`kp1`；\n3. 首先在第二帧中设置搜索范围（与特征点`kp1`在同一金字塔层级），获取范围内的特征点；\n4. 遍历搜索范围内的点，对于每一个特征点，计算其描述子与`kp1`描述子的汉明距离，记录相关信息；\n5. 根据最好距离和次好距离以及阈值的关系，记录匹配，记录特征点角度变化到直方图；\n6. 根据角度变化剔除不好的匹配。\n\n### `SearchForTriangulation`函数\n\n函数原型：\n\n~~~c++\nint SearchForTriangulation(KeyFrame *pKF1, KeyFrame* pKF2, cv::Mat F12,\n              std::vector<pair<size_t, size_t> > &vMatchedPairs, const bool bOnlyStereo);\n~~~\n\n该函数利用三角化，在两个关键帧之间恢复出一些地图点，检测对极约束。具体实现：\n\n1. 对第一个关键帧中的特征点进行遍历，跳过已经有对应地图点的点，因为这个函数的目的是为了三角化进行的搜索匹配；\n2. 对于第二个关键帧中的特征点，计算描述子之间的距离，检查特征点距离极线的距离，满足要求的记录信息；\n3. 进行角度变化的统计和检查。\n\n### `SearchBySim3`函数\n\n函数原型：\n\n~~~c++\nint SearchBySim3(KeyFrame* pKF1, KeyFrame* pKF2, std::vector<MapPoint *> &vpMatches12, const float &s12, const cv::Mat &R12, const cv::Mat &t12, const float th);\n~~~\n\n该函数在关键帧pKF1和通过相似变换得到的关键帧pKF2观测到的地图点之间搜索匹配，主要是匹配之前漏匹配的点，只用于双目和RGB-D。\n\n通过sim3变换，确定pKF1中的特征点在pKF2中的大致区域，同理，确定pKF2的特征点在pKF1中的大致区域。在该区域内通过描述子进行匹配捕获pKF1和pKF2之前漏匹配的特征点，更新vpMatches12（之前使用SearchByBow进行特征点匹配时会有漏匹配）。最后有一个检查的条件，某一对匹配点在pKF1至pKF2的匹配及pKF2至pKF1的匹配都存在时才认为是有效的匹配。\n\n### `DescriptorDistance`函数\n\n对应函数：\n\n~~~c++\nstatic int DescriptorDistance(const cv::Mat &a, const cv::Mat &b);\n~~~\n\n该函数负责计算两个ORB描述子的汉明距离。\n\n## 总结\n\n1. 各种特征匹配的基本思路都是根据距离预测尺度，进而根据尺度确定一个合理的搜索范围，之后对这个范围内的点进行匹配，从匹配结果中选出满足条件的最佳匹配。\n2. 何时用投影匹配，何时用DBow2进行匹配？\n   - 在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place Recognition，因此需要用DBow。\n   - 而投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间。\n3. 以上函数在检测特征点时，都会用到角度直方图用来剔除不满足两帧之间角度旋转的外点，也就是旋转一致性检测。具体实现：\n   - 将关键帧与当前帧匹配关键点的`angle`相减，得到rot（`0≤rot＜360`），放入一个直方图中，对于每一对匹配点的角度差，均可以放入一个`bin`的范围内（`360/HISTO_LENGTH`）；\n   - 统计直方图最高的三个`bin`保留，其他范围内的匹配点剔除。\n\n## 参考资料\n\n1. [ORB-SLAM（八）ORBmatcher 特征匹配](https://www.cnblogs.com/shang-slam/p/6431017.html)\n2. [ORBSLAM2源码学习（6） ORBmatcher类](https://blog.csdn.net/u012936940/article/details/81396061)\n3. [ORBmatacher](https://www.cnblogs.com/Fighting_lan/p/7816712.html)","source":"_posts/ORB-SLAM2学习之源码分析九-ORB特征匹配.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析九-ORB特征匹配\ndate: 2018-08-30 22:28:10\ntags: \n  - ORB_SLAM2\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征匹配有关的内容。\n\n<!--more---->\n\n## 概述\n\nORB_SLAM2系统中，负责特征匹配的类是`ORBmatcher`，定义在ORBmatcher.h文件中。该类负责特征点与特征点之间，地图点与特征点之间通过投影关系、词袋模型或者Sim3位姿匹配，用来辅助完成单目初始化、三角化恢复新的地图点、Tracking、Relocalization以及Loop Closing等任务，因此比较重要。类中提供了多个接口，这些接口分别负责完成不同的匹配任务，下面进行一一介绍。\n\n## 主要接口\n\n### 重载的`SearchByProjection`函数\n\n#### 用于追踪局部地图（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(Frame &F, const std::vector<MapPoint*> &vpMapPoints, const float th=3);\n~~~\n\n该函数负责在当前帧特征点和投影的地图点之间搜索匹配，具体来说，就是将投影的地图点`vpMapPoints`（这些地图点是上一帧的局部关键帧对应的所有局部地图点）投影到当前图像帧并搜索匹配，返回匹配到的点对数。具体匹配过程：\n\n1. 对于`vpMapPoints`中的每个地图点，搜索其在当前图像帧一个窗口内的特征点；\n2. 计算该地图点的描述子与窗口范围内的每一个特征点描述子的汉明距离；\n3. 找到汉明距离值最小bestDist和次小bestDist2的两个最佳匹配特征点；\n4. 如果两个特征点所属的金字塔层不同并且最佳匹配点的汉明距离值bestDist大于mfNNratio与次最佳匹配点的距离值bestDist2的乘积，则认为最佳匹配点就是汉明距离最小的这个特征点；将该地图点设为当前特征点对应的地图点，匹配成功，匹配数+1，继续循环匹配；\n5. 否则，继续循环匹配；\n6. 继续循环匹配，直到`vpMapPoints`中的每个地图点都匹配完毕（或匹配到或匹配不到）。\n\n#### 用于从上一图像帧追踪（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(Frame &CurrentFrame, const Frame &LastFrame, const float th, const bool bMono);\n~~~\n\n该函数负责将从上一图像帧追踪到的地图点投影到当前帧，并搜索匹配，返回匹配到的点对数量，用于`TrackWithMotionModel`。具体过程：\n\n1. 建立旋转直方图，用于检测旋转一致性；\n\n2. 分别计算当前帧和前一帧的旋转矩阵和平移矩阵；\n\n3. 通过相机模型，将前一帧的每一个地图点，投影得到在当前帧中的像素坐标；\n\n4. 在一个窗口内搜寻特征点`GetFeaturesInArea`，窗口尺寸根据尺度（特征点所处金字塔层）进行变化。因为前面ORB是进行了高斯金字塔分层，金字塔越上层的尺寸越小，搜索窗口相应就小；\n\n5. 找到地图点描述子与在窗口中的特征点描述子之间的距离的最佳值（最小值），如果距离小于设定值`TH_HIGH`，则认为是匹配点对，匹配数+1；\n\n6. 在直方图中记录特征点角度变化（做旋转一致性检测有关的记录，上一帧关键点角度和当前帧关键点角度相减）；直方图形式如下所示，旋转角度除以直方图长度，四舍五入得到横坐标（横坐标范围是`0-HISTO_LENGTH`），每个横坐标值对应一个`vector`集合，记录所有对应具有当前角度的匹配点的序号，纵坐标是集合的大小。\n\n   {% asset_img 直方图.png %}\n\n7. 循环3，继续匹配；\n\n8. 应用旋转一致性再一次筛选匹配点对（根据角度变化剔除不好的匹配），具体做法是从直方图中选出纵坐标值最大的前三个集合，剔除这三个集合以外的其他匹配点。\n\n#### 用于重定位（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(Frame &CurrentFrame, KeyFrame* pKF, const std::set<MapPoint*> &sAlreadyFound, const float th, const int ORBdist);\n~~~\n\n该函数负责将从关键帧中观测到的地图点投影到当前帧，并搜索匹配（投影匹配当前帧的特征点），返回匹配到的点对数量，用于`Relocalization`。具体过程与上一个函数类似。\n\n#### 用于回环检测（LoopClosing）\n\n对应函数：\n\n~~~c++\nint SearchByProjection(KeyFrame* pKF, cv::Mat Scw, const std::vector<MapPoint*> &vpPoints, std::vector<MapPoint*> &vpMatched, int th);\n~~~\n\n该函数负责使用相似变换投影地图点到当前关键帧，并搜索匹配，返回匹配到的点对数量，用于`Loop Closing`。\n\n##### 参数\n\n- pKF：检测闭环时的当前关键帧\n- Scw：闭环帧（从候选帧选出的）与当前帧之间的相似变换`Scm`\n- vpPoints：闭环帧及其相连关键帧对应的地图点\n- vpMatched：已经找到的地图点（当前关键帧与所有候选关键帧SearchByBoW匹配到的地图点）\n\n##### 具体过程\n\n1. 获取相机标定参数，为之后的投影做准备；\n2. 分解相似变换矩阵：先计算得到尺度因子s，然后计算世界坐标系到相机坐标系pKF的旋转矩阵和平移向量（都是去掉尺度因子的）；\n3. 在已经找到的匹配点中，去除没有对应匹配点的地图点；\n4. 遍历每个地图点，不包括坏的地图点和已经找到的地图点\n   - 首先获取到地图点的3D世界坐标系，并通过第2步计算得到的矩阵转换到相机坐标系下，且在Pc下的深度必须为正；\n   - 再投影到像素坐标系下，坐标值必须在image范围内；\n   - 计算世界坐标系下，该地图点的深度，该深度必须在该点的尺度方差区域内，且观察视角必须小于60°（通过向量内积来判断观察角度是否小于60°）；\n   - 根据地图点的深度和关键帧预测一个高斯金字塔层，根据该层计算一个半径，获得该半径范围内的特征点；\n   - 找出半径范围内所有特征点的描述子与地图点描述子汉明距离最小的特征点，如果满足最小距离`bestDist<=TH_LOW`，则认定匹配成功。\n\n### 重载的`SearchByBow`函数\n\n#### 用于重定位（Tracking）\n\n对应函数：\n\n~~~c++\nint SearchByBoW(KeyFrame *pKF, Frame &F, std::vector<MapPoint*> &vpMapPointMatches);\n~~~\n\n该函数通过BoW对关键帧和当前图像帧的特征点进行匹配，用于`TrackReferenceKeyFrame`和`Relocalization`。\n\n#### 用于回环检测（LoopClosing）\n\n对应函数：\n\n~~~c++\nint ORBmatcher::SearchByBoW(KeyFrame *pKF1, KeyFrame *pKF2, vector<MapPoint *> &vpMatches12)\n~~~\n\n该函数通过BoW对两个关键帧（当前关键帧`pKF1`和候选关键帧之一`pKF2`）的特征点进行匹配，用于Loop Closing时对两个关键帧间的特征点匹配，返回匹配到的点对数量，将匹配到的特征点对应的地图点记录在`vpMatches12`中作为输出。\n\n##### 参数\n\n- pKF1：当前关键帧\n- pKF2：候选关键帧中的一个\n- vpMatches12：匹配到的地图点\n\n##### 具体实现\n\n1. 对四叉树中属于相同节点的特征点才考虑匹配，首先对KF1中某个节点下的特征点，遍历KF2中对应节点的所有特征点，计算描述子距离并记录信息；\n2. 根据距离和阈值关系添加匹配，记录角度变化；\n3. 根据角度变化剔除误匹配。\n\n### 重载的`Fuse`函数\n\n主要用于地图点的融合。如果地图点能匹配上当前关键帧的地图点，也就是地图点重合了，选择观测数多的地图点替换；地图点能匹配上当前帧的特征点，但是该特征点还没有生成地图点，则生成新的地图点。重载的第一个函数是为了减小尺度漂移的影响，需要知道当前关键帧的sim3位姿。\n\n#### 使用相似变换的投影\n\n对应函数：\n\n~~~c++\nint Fuse(KeyFrame* pKF, cv::Mat Scw, const std::vector<MapPoint*> &vpPoints, float th, vector<MapPoint *> &vpReplacePoint);\n~~~\n\n该函数用于回环检测线程，负责使用一个给定的相似变换`Scw`将地图点投影到关键帧，搜索重叠的地图点。具体实现：\n\n1. 分解相似变换矩阵，得到旋转矩阵和平移向量等数据；\n2. 对每一个地图点投影到相机系和图像系，检查深度、视角等信息；\n3. 由距离预测尺度进而确定搜索半径，在指定区域内获取特征点；\n4. 遍历这些特征点，计算其描述子和地图点描述子的汉明距离，计录最好距离和索引；\n5. 如果索引对应的地图点不存在则新添加一个，存在的话则标记其将要被替换。\n\n#### 不使用相似变换的投影\n\n对应函数：\n\n~~~c++\nint Fuse(KeyFrame* pKF, const vector<MapPoint *> &vpMapPoints, const float th=3.0);\n~~~\n\n该函数用于局部建图线程，负责将地图点投影到关键帧，搜索重叠的地图点，返回融合的地图点数量。具体实现：\n\n1. 遍历地图点，将其转换至相机坐标系检查深度，投影并检查是否在图像内，检查尺度和视角范围是否合适；\n2. 根据深度预测尺度从而确定搜索半径，获得范围内的特征点；\n3. 遍历这些点，计算它们和地图点投影后的坐标误差，误差太大的跳过，计算描述子距离，记录距离最小的最佳匹配点；\n4. 对于最佳匹配，如果某个点已经有了地图点，则选择观测次数多的那个点，舍弃观测次数少的点，即两点融合；如果没有对应的地图点，则添加地图点，添加观测关系。\n\n### `SearchForInitialization`函数\n\n函数原型：\n\n~~~c++\nint SearchForInitialization(Frame &F1, Frame &F2, std::vector<cv::Point2f> &vbPrevMatched, std::vector<int> &vnMatches12, int windowSize=10);\n~~~\n\n该函数用于单目初始化过程，地图初始化时两个图像帧之间的匹配，只用于单目。具体实现：\n\n1. 构造直方图；\n2. 遍历第一帧中的特征点，对于每一个特征点`kp1`；\n3. 首先在第二帧中设置搜索范围（与特征点`kp1`在同一金字塔层级），获取范围内的特征点；\n4. 遍历搜索范围内的点，对于每一个特征点，计算其描述子与`kp1`描述子的汉明距离，记录相关信息；\n5. 根据最好距离和次好距离以及阈值的关系，记录匹配，记录特征点角度变化到直方图；\n6. 根据角度变化剔除不好的匹配。\n\n### `SearchForTriangulation`函数\n\n函数原型：\n\n~~~c++\nint SearchForTriangulation(KeyFrame *pKF1, KeyFrame* pKF2, cv::Mat F12,\n              std::vector<pair<size_t, size_t> > &vMatchedPairs, const bool bOnlyStereo);\n~~~\n\n该函数利用三角化，在两个关键帧之间恢复出一些地图点，检测对极约束。具体实现：\n\n1. 对第一个关键帧中的特征点进行遍历，跳过已经有对应地图点的点，因为这个函数的目的是为了三角化进行的搜索匹配；\n2. 对于第二个关键帧中的特征点，计算描述子之间的距离，检查特征点距离极线的距离，满足要求的记录信息；\n3. 进行角度变化的统计和检查。\n\n### `SearchBySim3`函数\n\n函数原型：\n\n~~~c++\nint SearchBySim3(KeyFrame* pKF1, KeyFrame* pKF2, std::vector<MapPoint *> &vpMatches12, const float &s12, const cv::Mat &R12, const cv::Mat &t12, const float th);\n~~~\n\n该函数在关键帧pKF1和通过相似变换得到的关键帧pKF2观测到的地图点之间搜索匹配，主要是匹配之前漏匹配的点，只用于双目和RGB-D。\n\n通过sim3变换，确定pKF1中的特征点在pKF2中的大致区域，同理，确定pKF2的特征点在pKF1中的大致区域。在该区域内通过描述子进行匹配捕获pKF1和pKF2之前漏匹配的特征点，更新vpMatches12（之前使用SearchByBow进行特征点匹配时会有漏匹配）。最后有一个检查的条件，某一对匹配点在pKF1至pKF2的匹配及pKF2至pKF1的匹配都存在时才认为是有效的匹配。\n\n### `DescriptorDistance`函数\n\n对应函数：\n\n~~~c++\nstatic int DescriptorDistance(const cv::Mat &a, const cv::Mat &b);\n~~~\n\n该函数负责计算两个ORB描述子的汉明距离。\n\n## 总结\n\n1. 各种特征匹配的基本思路都是根据距离预测尺度，进而根据尺度确定一个合理的搜索范围，之后对这个范围内的点进行匹配，从匹配结果中选出满足条件的最佳匹配。\n2. 何时用投影匹配，何时用DBow2进行匹配？\n   - 在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place Recognition，因此需要用DBow。\n   - 而投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间。\n3. 以上函数在检测特征点时，都会用到角度直方图用来剔除不满足两帧之间角度旋转的外点，也就是旋转一致性检测。具体实现：\n   - 将关键帧与当前帧匹配关键点的`angle`相减，得到rot（`0≤rot＜360`），放入一个直方图中，对于每一对匹配点的角度差，均可以放入一个`bin`的范围内（`360/HISTO_LENGTH`）；\n   - 统计直方图最高的三个`bin`保留，其他范围内的匹配点剔除。\n\n## 参考资料\n\n1. [ORB-SLAM（八）ORBmatcher 特征匹配](https://www.cnblogs.com/shang-slam/p/6431017.html)\n2. [ORBSLAM2源码学习（6） ORBmatcher类](https://blog.csdn.net/u012936940/article/details/81396061)\n3. [ORBmatacher](https://www.cnblogs.com/Fighting_lan/p/7816712.html)","slug":"ORB-SLAM2学习之源码分析九-ORB特征匹配","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyn00b1qlcr3ha7lq9a","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征匹配有关的内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>ORB_SLAM2系统中，负责特征匹配的类是<code>ORBmatcher</code>，定义在ORBmatcher.h文件中。该类负责特征点与特征点之间，地图点与特征点之间通过投影关系、词袋模型或者Sim3位姿匹配，用来辅助完成单目初始化、三角化恢复新的地图点、Tracking、Relocalization以及Loop Closing等任务，因此比较重要。类中提供了多个接口，这些接口分别负责完成不同的匹配任务，下面进行一一介绍。</p>\n<h2 id=\"主要接口\"><a href=\"#主要接口\" class=\"headerlink\" title=\"主要接口\"></a>主要接口</h2><h3 id=\"重载的SearchByProjection函数\"><a href=\"#重载的SearchByProjection函数\" class=\"headerlink\" title=\"重载的SearchByProjection函数\"></a>重载的<code>SearchByProjection</code>函数</h3><h4 id=\"用于追踪局部地图（Tracking）\"><a href=\"#用于追踪局部地图（Tracking）\" class=\"headerlink\" title=\"用于追踪局部地图（Tracking）\"></a>用于追踪局部地图（Tracking）</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchByProjection</span><span class=\"params\">(Frame &amp;F, <span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;MapPoint*&gt; &amp;vpMapPoints, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> th=<span class=\"number\">3</span>)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数负责在当前帧特征点和投影的地图点之间搜索匹配，具体来说，就是将投影的地图点<code>vpMapPoints</code>（这些地图点是上一帧的局部关键帧对应的所有局部地图点）投影到当前图像帧并搜索匹配，返回匹配到的点对数。具体匹配过程：</p>\n<ol>\n<li>对于<code>vpMapPoints</code>中的每个地图点，搜索其在当前图像帧一个窗口内的特征点；</li>\n<li>计算该地图点的描述子与窗口范围内的每一个特征点描述子的汉明距离；</li>\n<li>找到汉明距离值最小bestDist和次小bestDist2的两个最佳匹配特征点；</li>\n<li>如果两个特征点所属的金字塔层不同并且最佳匹配点的汉明距离值bestDist大于mfNNratio与次最佳匹配点的距离值bestDist2的乘积，则认为最佳匹配点就是汉明距离最小的这个特征点；将该地图点设为当前特征点对应的地图点，匹配成功，匹配数+1，继续循环匹配；</li>\n<li>否则，继续循环匹配；</li>\n<li>继续循环匹配，直到<code>vpMapPoints</code>中的每个地图点都匹配完毕（或匹配到或匹配不到）。</li>\n</ol>\n<h4 id=\"用于从上一图像帧追踪（Tracking）\"><a href=\"#用于从上一图像帧追踪（Tracking）\" class=\"headerlink\" title=\"用于从上一图像帧追踪（Tracking）\"></a>用于从上一图像帧追踪（Tracking）</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchByProjection</span><span class=\"params\">(Frame &amp;CurrentFrame, <span class=\"keyword\">const</span> Frame &amp;LastFrame, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> th, <span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> bMono)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数负责将从上一图像帧追踪到的地图点投影到当前帧，并搜索匹配，返回匹配到的点对数量，用于<code>TrackWithMotionModel</code>。具体过程：</p>\n<ol>\n<li><p>建立旋转直方图，用于检测旋转一致性；</p>\n</li>\n<li><p>分别计算当前帧和前一帧的旋转矩阵和平移矩阵；</p>\n</li>\n<li><p>通过相机模型，将前一帧的每一个地图点，投影得到在当前帧中的像素坐标；</p>\n</li>\n<li><p>在一个窗口内搜寻特征点<code>GetFeaturesInArea</code>，窗口尺寸根据尺度（特征点所处金字塔层）进行变化。因为前面ORB是进行了高斯金字塔分层，金字塔越上层的尺寸越小，搜索窗口相应就小；</p>\n</li>\n<li><p>找到地图点描述子与在窗口中的特征点描述子之间的距离的最佳值（最小值），如果距离小于设定值<code>TH_HIGH</code>，则认为是匹配点对，匹配数+1；</p>\n</li>\n<li><p>在直方图中记录特征点角度变化（做旋转一致性检测有关的记录，上一帧关键点角度和当前帧关键点角度相减）；直方图形式如下所示，旋转角度除以直方图长度，四舍五入得到横坐标（横坐标范围是<code>0-HISTO_LENGTH</code>），每个横坐标值对应一个<code>vector</code>集合，记录所有对应具有当前角度的匹配点的序号，纵坐标是集合的大小。</p>\n<img src=\"/2018/08/30/ORB-SLAM2学习之源码分析九-ORB特征匹配/直方图.png\">\n</li>\n<li><p>循环3，继续匹配；</p>\n</li>\n<li><p>应用旋转一致性再一次筛选匹配点对（根据角度变化剔除不好的匹配），具体做法是从直方图中选出纵坐标值最大的前三个集合，剔除这三个集合以外的其他匹配点。</p>\n</li>\n</ol>\n<h4 id=\"用于重定位（Tracking）\"><a href=\"#用于重定位（Tracking）\" class=\"headerlink\" title=\"用于重定位（Tracking）\"></a>用于重定位（Tracking）</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchByProjection</span><span class=\"params\">(Frame &amp;CurrentFrame, KeyFrame* pKF, <span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">set</span>&lt;MapPoint*&gt; &amp;sAlreadyFound, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> th, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> ORBdist)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数负责将从关键帧中观测到的地图点投影到当前帧，并搜索匹配（投影匹配当前帧的特征点），返回匹配到的点对数量，用于<code>Relocalization</code>。具体过程与上一个函数类似。</p>\n<h4 id=\"用于回环检测（LoopClosing）\"><a href=\"#用于回环检测（LoopClosing）\" class=\"headerlink\" title=\"用于回环检测（LoopClosing）\"></a>用于回环检测（LoopClosing）</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchByProjection</span><span class=\"params\">(KeyFrame* pKF, cv::Mat Scw, <span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;MapPoint*&gt; &amp;vpPoints, <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;MapPoint*&gt; &amp;vpMatched, <span class=\"keyword\">int</span> th)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数负责使用相似变换投影地图点到当前关键帧，并搜索匹配，返回匹配到的点对数量，用于<code>Loop Closing</code>。</p>\n<h5 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h5><ul>\n<li>pKF：检测闭环时的当前关键帧</li>\n<li>Scw：闭环帧（从候选帧选出的）与当前帧之间的相似变换<code>Scm</code></li>\n<li>vpPoints：闭环帧及其相连关键帧对应的地图点</li>\n<li>vpMatched：已经找到的地图点（当前关键帧与所有候选关键帧SearchByBoW匹配到的地图点）</li>\n</ul>\n<h5 id=\"具体过程\"><a href=\"#具体过程\" class=\"headerlink\" title=\"具体过程\"></a>具体过程</h5><ol>\n<li>获取相机标定参数，为之后的投影做准备；</li>\n<li>分解相似变换矩阵：先计算得到尺度因子s，然后计算世界坐标系到相机坐标系pKF的旋转矩阵和平移向量（都是去掉尺度因子的）；</li>\n<li>在已经找到的匹配点中，去除没有对应匹配点的地图点；</li>\n<li>遍历每个地图点，不包括坏的地图点和已经找到的地图点<ul>\n<li>首先获取到地图点的3D世界坐标系，并通过第2步计算得到的矩阵转换到相机坐标系下，且在Pc下的深度必须为正；</li>\n<li>再投影到像素坐标系下，坐标值必须在image范围内；</li>\n<li>计算世界坐标系下，该地图点的深度，该深度必须在该点的尺度方差区域内，且观察视角必须小于60°（通过向量内积来判断观察角度是否小于60°）；</li>\n<li>根据地图点的深度和关键帧预测一个高斯金字塔层，根据该层计算一个半径，获得该半径范围内的特征点；</li>\n<li>找出半径范围内所有特征点的描述子与地图点描述子汉明距离最小的特征点，如果满足最小距离<code>bestDist&lt;=TH_LOW</code>，则认定匹配成功。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"重载的SearchByBow函数\"><a href=\"#重载的SearchByBow函数\" class=\"headerlink\" title=\"重载的SearchByBow函数\"></a>重载的<code>SearchByBow</code>函数</h3><h4 id=\"用于重定位（Tracking）-1\"><a href=\"#用于重定位（Tracking）-1\" class=\"headerlink\" title=\"用于重定位（Tracking）\"></a>用于重定位（Tracking）</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchByBoW</span><span class=\"params\">(KeyFrame *pKF, Frame &amp;F, <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;MapPoint*&gt; &amp;vpMapPointMatches)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数通过BoW对关键帧和当前图像帧的特征点进行匹配，用于<code>TrackReferenceKeyFrame</code>和<code>Relocalization</code>。</p>\n<h4 id=\"用于回环检测（LoopClosing）-1\"><a href=\"#用于回环检测（LoopClosing）-1\" class=\"headerlink\" title=\"用于回环检测（LoopClosing）\"></a>用于回环检测（LoopClosing）</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> ORBmatcher::SearchByBoW(KeyFrame *pKF1, KeyFrame *pKF2, <span class=\"built_in\">vector</span>&lt;MapPoint *&gt; &amp;vpMatches12)</span><br></pre></td></tr></table></figure>\n<p>该函数通过BoW对两个关键帧（当前关键帧<code>pKF1</code>和候选关键帧之一<code>pKF2</code>）的特征点进行匹配，用于Loop Closing时对两个关键帧间的特征点匹配，返回匹配到的点对数量，将匹配到的特征点对应的地图点记录在<code>vpMatches12</code>中作为输出。</p>\n<h5 id=\"参数-1\"><a href=\"#参数-1\" class=\"headerlink\" title=\"参数\"></a>参数</h5><ul>\n<li>pKF1：当前关键帧</li>\n<li>pKF2：候选关键帧中的一个</li>\n<li>vpMatches12：匹配到的地图点</li>\n</ul>\n<h5 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h5><ol>\n<li>对四叉树中属于相同节点的特征点才考虑匹配，首先对KF1中某个节点下的特征点，遍历KF2中对应节点的所有特征点，计算描述子距离并记录信息；</li>\n<li>根据距离和阈值关系添加匹配，记录角度变化；</li>\n<li>根据角度变化剔除误匹配。</li>\n</ol>\n<h3 id=\"重载的Fuse函数\"><a href=\"#重载的Fuse函数\" class=\"headerlink\" title=\"重载的Fuse函数\"></a>重载的<code>Fuse</code>函数</h3><p>主要用于地图点的融合。如果地图点能匹配上当前关键帧的地图点，也就是地图点重合了，选择观测数多的地图点替换；地图点能匹配上当前帧的特征点，但是该特征点还没有生成地图点，则生成新的地图点。重载的第一个函数是为了减小尺度漂移的影响，需要知道当前关键帧的sim3位姿。</p>\n<h4 id=\"使用相似变换的投影\"><a href=\"#使用相似变换的投影\" class=\"headerlink\" title=\"使用相似变换的投影\"></a>使用相似变换的投影</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">Fuse</span><span class=\"params\">(KeyFrame* pKF, cv::Mat Scw, <span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;MapPoint*&gt; &amp;vpPoints, <span class=\"keyword\">float</span> th, <span class=\"built_in\">vector</span>&lt;MapPoint *&gt; &amp;vpReplacePoint)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数用于回环检测线程，负责使用一个给定的相似变换<code>Scw</code>将地图点投影到关键帧，搜索重叠的地图点。具体实现：</p>\n<ol>\n<li>分解相似变换矩阵，得到旋转矩阵和平移向量等数据；</li>\n<li>对每一个地图点投影到相机系和图像系，检查深度、视角等信息；</li>\n<li>由距离预测尺度进而确定搜索半径，在指定区域内获取特征点；</li>\n<li>遍历这些特征点，计算其描述子和地图点描述子的汉明距离，计录最好距离和索引；</li>\n<li>如果索引对应的地图点不存在则新添加一个，存在的话则标记其将要被替换。</li>\n</ol>\n<h4 id=\"不使用相似变换的投影\"><a href=\"#不使用相似变换的投影\" class=\"headerlink\" title=\"不使用相似变换的投影\"></a>不使用相似变换的投影</h4><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">Fuse</span><span class=\"params\">(KeyFrame* pKF, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;MapPoint *&gt; &amp;vpMapPoints, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> th=<span class=\"number\">3.0</span>)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数用于局部建图线程，负责将地图点投影到关键帧，搜索重叠的地图点，返回融合的地图点数量。具体实现：</p>\n<ol>\n<li>遍历地图点，将其转换至相机坐标系检查深度，投影并检查是否在图像内，检查尺度和视角范围是否合适；</li>\n<li>根据深度预测尺度从而确定搜索半径，获得范围内的特征点；</li>\n<li>遍历这些点，计算它们和地图点投影后的坐标误差，误差太大的跳过，计算描述子距离，记录距离最小的最佳匹配点；</li>\n<li>对于最佳匹配，如果某个点已经有了地图点，则选择观测次数多的那个点，舍弃观测次数少的点，即两点融合；如果没有对应的地图点，则添加地图点，添加观测关系。</li>\n</ol>\n<h3 id=\"SearchForInitialization函数\"><a href=\"#SearchForInitialization函数\" class=\"headerlink\" title=\"SearchForInitialization函数\"></a><code>SearchForInitialization</code>函数</h3><p>函数原型：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchForInitialization</span><span class=\"params\">(Frame &amp;F1, Frame &amp;F2, <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;cv::Point2f&gt; &amp;vbPrevMatched, <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;vnMatches12, <span class=\"keyword\">int</span> windowSize=<span class=\"number\">10</span>)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数用于单目初始化过程，地图初始化时两个图像帧之间的匹配，只用于单目。具体实现：</p>\n<ol>\n<li>构造直方图；</li>\n<li>遍历第一帧中的特征点，对于每一个特征点<code>kp1</code>；</li>\n<li>首先在第二帧中设置搜索范围（与特征点<code>kp1</code>在同一金字塔层级），获取范围内的特征点；</li>\n<li>遍历搜索范围内的点，对于每一个特征点，计算其描述子与<code>kp1</code>描述子的汉明距离，记录相关信息；</li>\n<li>根据最好距离和次好距离以及阈值的关系，记录匹配，记录特征点角度变化到直方图；</li>\n<li>根据角度变化剔除不好的匹配。</li>\n</ol>\n<h3 id=\"SearchForTriangulation函数\"><a href=\"#SearchForTriangulation函数\" class=\"headerlink\" title=\"SearchForTriangulation函数\"></a><code>SearchForTriangulation</code>函数</h3><p>函数原型：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchForTriangulation</span><span class=\"params\">(KeyFrame *pKF1, KeyFrame* pKF2, cv::Mat F12,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">              <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;pair&lt;<span class=\"keyword\">size_t</span>, <span class=\"keyword\">size_t</span>&gt; &gt; &amp;vMatchedPairs, <span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> bOnlyStereo)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数利用三角化，在两个关键帧之间恢复出一些地图点，检测对极约束。具体实现：</p>\n<ol>\n<li>对第一个关键帧中的特征点进行遍历，跳过已经有对应地图点的点，因为这个函数的目的是为了三角化进行的搜索匹配；</li>\n<li>对于第二个关键帧中的特征点，计算描述子之间的距离，检查特征点距离极线的距离，满足要求的记录信息；</li>\n<li>进行角度变化的统计和检查。</li>\n</ol>\n<h3 id=\"SearchBySim3函数\"><a href=\"#SearchBySim3函数\" class=\"headerlink\" title=\"SearchBySim3函数\"></a><code>SearchBySim3</code>函数</h3><p>函数原型：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">SearchBySim3</span><span class=\"params\">(KeyFrame* pKF1, KeyFrame* pKF2, <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;MapPoint *&gt; &amp;vpMatches12, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> &amp;s12, <span class=\"keyword\">const</span> cv::Mat &amp;R12, <span class=\"keyword\">const</span> cv::Mat &amp;t12, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> th)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数在关键帧pKF1和通过相似变换得到的关键帧pKF2观测到的地图点之间搜索匹配，主要是匹配之前漏匹配的点，只用于双目和RGB-D。</p>\n<p>通过sim3变换，确定pKF1中的特征点在pKF2中的大致区域，同理，确定pKF2的特征点在pKF1中的大致区域。在该区域内通过描述子进行匹配捕获pKF1和pKF2之前漏匹配的特征点，更新vpMatches12（之前使用SearchByBow进行特征点匹配时会有漏匹配）。最后有一个检查的条件，某一对匹配点在pKF1至pKF2的匹配及pKF2至pKF1的匹配都存在时才认为是有效的匹配。</p>\n<h3 id=\"DescriptorDistance函数\"><a href=\"#DescriptorDistance函数\" class=\"headerlink\" title=\"DescriptorDistance函数\"></a><code>DescriptorDistance</code>函数</h3><p>对应函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">DescriptorDistance</span><span class=\"params\">(<span class=\"keyword\">const</span> cv::Mat &amp;a, <span class=\"keyword\">const</span> cv::Mat &amp;b)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>该函数负责计算两个ORB描述子的汉明距离。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ol>\n<li>各种特征匹配的基本思路都是根据距离预测尺度，进而根据尺度确定一个合理的搜索范围，之后对这个范围内的点进行匹配，从匹配结果中选出满足条件的最佳匹配。</li>\n<li>何时用投影匹配，何时用DBow2进行匹配？<ul>\n<li>在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place Recognition，因此需要用DBow。</li>\n<li>而投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间。</li>\n</ul>\n</li>\n<li>以上函数在检测特征点时，都会用到角度直方图用来剔除不满足两帧之间角度旋转的外点，也就是旋转一致性检测。具体实现：<ul>\n<li>将关键帧与当前帧匹配关键点的<code>angle</code>相减，得到rot（<code>0≤rot＜360</code>），放入一个直方图中，对于每一对匹配点的角度差，均可以放入一个<code>bin</code>的范围内（<code>360/HISTO_LENGTH</code>）；</li>\n<li>统计直方图最高的三个<code>bin</code>保留，其他范围内的匹配点剔除。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6431017.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（八）ORBmatcher 特征匹配</a></li>\n<li><a href=\"https://blog.csdn.net/u012936940/article/details/81396061\" target=\"_blank\" rel=\"noopener\">ORBSLAM2源码学习（6） ORBmatcher类</a></li>\n<li><a href=\"https://www.cnblogs.com/Fighting_lan/p/7816712.html\" target=\"_blank\" rel=\"noopener\">ORBmatacher</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录ORB特征匹配有关的内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>ORB_SLAM2系统中，负责特征匹配的类是<code>ORBmatcher</code>，定义在ORBmatcher.h文件中。该类负责特征点与特征点之间，地图点与特征点之间通过投影关系、词袋模型或者Sim3位姿匹配，用来辅助完成单目初始化、三角化恢复新的地图点、Tracking、Relocalization以及Loop Closing等任务，因此比较重要。类中提供了多个接口，这些接口分别负责完成不同的匹配任务，下面进行一一介绍。</p>\n<h2 id=\"主要接口\"><a href=\"#主要接口\" class=\"headerlink\" title=\"主要接口\"></a>主要接口</h2><h3 id=\"重载的SearchByProjection函数\"><a href=\"#重载的SearchByProjection函数\" class=\"headerlink\" title=\"重载的SearchByProjection函数\"></a>重载的<code>SearchByProjection</code>函数</h3><h4 id=\"用于追踪局部地图（Tracking）\"><a href=\"#用于追踪局部地图（Tracking）\" class=\"headerlink\" title=\"用于追踪局部地图（Tracking）\"></a>用于追踪局部地图（Tracking）</h4><p>对应函数：</p>\n<!--�126-->\n<p>该函数负责在当前帧特征点和投影的地图点之间搜索匹配，具体来说，就是将投影的地图点<code>vpMapPoints</code>（这些地图点是上一帧的局部关键帧对应的所有局部地图点）投影到当前图像帧并搜索匹配，返回匹配到的点对数。具体匹配过程：</p>\n<ol>\n<li>对于<code>vpMapPoints</code>中的每个地图点，搜索其在当前图像帧一个窗口内的特征点；</li>\n<li>计算该地图点的描述子与窗口范围内的每一个特征点描述子的汉明距离；</li>\n<li>找到汉明距离值最小bestDist和次小bestDist2的两个最佳匹配特征点；</li>\n<li>如果两个特征点所属的金字塔层不同并且最佳匹配点的汉明距离值bestDist大于mfNNratio与次最佳匹配点的距离值bestDist2的乘积，则认为最佳匹配点就是汉明距离最小的这个特征点；将该地图点设为当前特征点对应的地图点，匹配成功，匹配数+1，继续循环匹配；</li>\n<li>否则，继续循环匹配；</li>\n<li>继续循环匹配，直到<code>vpMapPoints</code>中的每个地图点都匹配完毕（或匹配到或匹配不到）。</li>\n</ol>\n<h4 id=\"用于从上一图像帧追踪（Tracking）\"><a href=\"#用于从上一图像帧追踪（Tracking）\" class=\"headerlink\" title=\"用于从上一图像帧追踪（Tracking）\"></a>用于从上一图像帧追踪（Tracking）</h4><p>对应函数：</p>\n<!--�127-->\n<p>该函数负责将从上一图像帧追踪到的地图点投影到当前帧，并搜索匹配，返回匹配到的点对数量，用于<code>TrackWithMotionModel</code>。具体过程：</p>\n<ol>\n<li><p>建立旋转直方图，用于检测旋转一致性；</p>\n</li>\n<li><p>分别计算当前帧和前一帧的旋转矩阵和平移矩阵；</p>\n</li>\n<li><p>通过相机模型，将前一帧的每一个地图点，投影得到在当前帧中的像素坐标；</p>\n</li>\n<li><p>在一个窗口内搜寻特征点<code>GetFeaturesInArea</code>，窗口尺寸根据尺度（特征点所处金字塔层）进行变化。因为前面ORB是进行了高斯金字塔分层，金字塔越上层的尺寸越小，搜索窗口相应就小；</p>\n</li>\n<li><p>找到地图点描述子与在窗口中的特征点描述子之间的距离的最佳值（最小值），如果距离小于设定值<code>TH_HIGH</code>，则认为是匹配点对，匹配数+1；</p>\n</li>\n<li><p>在直方图中记录特征点角度变化（做旋转一致性检测有关的记录，上一帧关键点角度和当前帧关键点角度相减）；直方图形式如下所示，旋转角度除以直方图长度，四舍五入得到横坐标（横坐标范围是<code>0-HISTO_LENGTH</code>），每个横坐标值对应一个<code>vector</code>集合，记录所有对应具有当前角度的匹配点的序号，纵坐标是集合的大小。</p>\n<img src=\"/2018/08/30/ORB-SLAM2学习之源码分析九-ORB特征匹配/直方图.png\">\n</li>\n<li><p>循环3，继续匹配；</p>\n</li>\n<li><p>应用旋转一致性再一次筛选匹配点对（根据角度变化剔除不好的匹配），具体做法是从直方图中选出纵坐标值最大的前三个集合，剔除这三个集合以外的其他匹配点。</p>\n</li>\n</ol>\n<h4 id=\"用于重定位（Tracking）\"><a href=\"#用于重定位（Tracking）\" class=\"headerlink\" title=\"用于重定位（Tracking）\"></a>用于重定位（Tracking）</h4><p>对应函数：</p>\n<!--�128-->\n<p>该函数负责将从关键帧中观测到的地图点投影到当前帧，并搜索匹配（投影匹配当前帧的特征点），返回匹配到的点对数量，用于<code>Relocalization</code>。具体过程与上一个函数类似。</p>\n<h4 id=\"用于回环检测（LoopClosing）\"><a href=\"#用于回环检测（LoopClosing）\" class=\"headerlink\" title=\"用于回环检测（LoopClosing）\"></a>用于回环检测（LoopClosing）</h4><p>对应函数：</p>\n<!--�129-->\n<p>该函数负责使用相似变换投影地图点到当前关键帧，并搜索匹配，返回匹配到的点对数量，用于<code>Loop Closing</code>。</p>\n<h5 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h5><ul>\n<li>pKF：检测闭环时的当前关键帧</li>\n<li>Scw：闭环帧（从候选帧选出的）与当前帧之间的相似变换<code>Scm</code></li>\n<li>vpPoints：闭环帧及其相连关键帧对应的地图点</li>\n<li>vpMatched：已经找到的地图点（当前关键帧与所有候选关键帧SearchByBoW匹配到的地图点）</li>\n</ul>\n<h5 id=\"具体过程\"><a href=\"#具体过程\" class=\"headerlink\" title=\"具体过程\"></a>具体过程</h5><ol>\n<li>获取相机标定参数，为之后的投影做准备；</li>\n<li>分解相似变换矩阵：先计算得到尺度因子s，然后计算世界坐标系到相机坐标系pKF的旋转矩阵和平移向量（都是去掉尺度因子的）；</li>\n<li>在已经找到的匹配点中，去除没有对应匹配点的地图点；</li>\n<li>遍历每个地图点，不包括坏的地图点和已经找到的地图点<ul>\n<li>首先获取到地图点的3D世界坐标系，并通过第2步计算得到的矩阵转换到相机坐标系下，且在Pc下的深度必须为正；</li>\n<li>再投影到像素坐标系下，坐标值必须在image范围内；</li>\n<li>计算世界坐标系下，该地图点的深度，该深度必须在该点的尺度方差区域内，且观察视角必须小于60°（通过向量内积来判断观察角度是否小于60°）；</li>\n<li>根据地图点的深度和关键帧预测一个高斯金字塔层，根据该层计算一个半径，获得该半径范围内的特征点；</li>\n<li>找出半径范围内所有特征点的描述子与地图点描述子汉明距离最小的特征点，如果满足最小距离<code>bestDist&lt;=TH_LOW</code>，则认定匹配成功。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"重载的SearchByBow函数\"><a href=\"#重载的SearchByBow函数\" class=\"headerlink\" title=\"重载的SearchByBow函数\"></a>重载的<code>SearchByBow</code>函数</h3><h4 id=\"用于重定位（Tracking）-1\"><a href=\"#用于重定位（Tracking）-1\" class=\"headerlink\" title=\"用于重定位（Tracking）\"></a>用于重定位（Tracking）</h4><p>对应函数：</p>\n<!--�130-->\n<p>该函数通过BoW对关键帧和当前图像帧的特征点进行匹配，用于<code>TrackReferenceKeyFrame</code>和<code>Relocalization</code>。</p>\n<h4 id=\"用于回环检测（LoopClosing）-1\"><a href=\"#用于回环检测（LoopClosing）-1\" class=\"headerlink\" title=\"用于回环检测（LoopClosing）\"></a>用于回环检测（LoopClosing）</h4><p>对应函数：</p>\n<!--�131-->\n<p>该函数通过BoW对两个关键帧（当前关键帧<code>pKF1</code>和候选关键帧之一<code>pKF2</code>）的特征点进行匹配，用于Loop Closing时对两个关键帧间的特征点匹配，返回匹配到的点对数量，将匹配到的特征点对应的地图点记录在<code>vpMatches12</code>中作为输出。</p>\n<h5 id=\"参数-1\"><a href=\"#参数-1\" class=\"headerlink\" title=\"参数\"></a>参数</h5><ul>\n<li>pKF1：当前关键帧</li>\n<li>pKF2：候选关键帧中的一个</li>\n<li>vpMatches12：匹配到的地图点</li>\n</ul>\n<h5 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h5><ol>\n<li>对四叉树中属于相同节点的特征点才考虑匹配，首先对KF1中某个节点下的特征点，遍历KF2中对应节点的所有特征点，计算描述子距离并记录信息；</li>\n<li>根据距离和阈值关系添加匹配，记录角度变化；</li>\n<li>根据角度变化剔除误匹配。</li>\n</ol>\n<h3 id=\"重载的Fuse函数\"><a href=\"#重载的Fuse函数\" class=\"headerlink\" title=\"重载的Fuse函数\"></a>重载的<code>Fuse</code>函数</h3><p>主要用于地图点的融合。如果地图点能匹配上当前关键帧的地图点，也就是地图点重合了，选择观测数多的地图点替换；地图点能匹配上当前帧的特征点，但是该特征点还没有生成地图点，则生成新的地图点。重载的第一个函数是为了减小尺度漂移的影响，需要知道当前关键帧的sim3位姿。</p>\n<h4 id=\"使用相似变换的投影\"><a href=\"#使用相似变换的投影\" class=\"headerlink\" title=\"使用相似变换的投影\"></a>使用相似变换的投影</h4><p>对应函数：</p>\n<!--�132-->\n<p>该函数用于回环检测线程，负责使用一个给定的相似变换<code>Scw</code>将地图点投影到关键帧，搜索重叠的地图点。具体实现：</p>\n<ol>\n<li>分解相似变换矩阵，得到旋转矩阵和平移向量等数据；</li>\n<li>对每一个地图点投影到相机系和图像系，检查深度、视角等信息；</li>\n<li>由距离预测尺度进而确定搜索半径，在指定区域内获取特征点；</li>\n<li>遍历这些特征点，计算其描述子和地图点描述子的汉明距离，计录最好距离和索引；</li>\n<li>如果索引对应的地图点不存在则新添加一个，存在的话则标记其将要被替换。</li>\n</ol>\n<h4 id=\"不使用相似变换的投影\"><a href=\"#不使用相似变换的投影\" class=\"headerlink\" title=\"不使用相似变换的投影\"></a>不使用相似变换的投影</h4><p>对应函数：</p>\n<!--�133-->\n<p>该函数用于局部建图线程，负责将地图点投影到关键帧，搜索重叠的地图点，返回融合的地图点数量。具体实现：</p>\n<ol>\n<li>遍历地图点，将其转换至相机坐标系检查深度，投影并检查是否在图像内，检查尺度和视角范围是否合适；</li>\n<li>根据深度预测尺度从而确定搜索半径，获得范围内的特征点；</li>\n<li>遍历这些点，计算它们和地图点投影后的坐标误差，误差太大的跳过，计算描述子距离，记录距离最小的最佳匹配点；</li>\n<li>对于最佳匹配，如果某个点已经有了地图点，则选择观测次数多的那个点，舍弃观测次数少的点，即两点融合；如果没有对应的地图点，则添加地图点，添加观测关系。</li>\n</ol>\n<h3 id=\"SearchForInitialization函数\"><a href=\"#SearchForInitialization函数\" class=\"headerlink\" title=\"SearchForInitialization函数\"></a><code>SearchForInitialization</code>函数</h3><p>函数原型：</p>\n<!--�134-->\n<p>该函数用于单目初始化过程，地图初始化时两个图像帧之间的匹配，只用于单目。具体实现：</p>\n<ol>\n<li>构造直方图；</li>\n<li>遍历第一帧中的特征点，对于每一个特征点<code>kp1</code>；</li>\n<li>首先在第二帧中设置搜索范围（与特征点<code>kp1</code>在同一金字塔层级），获取范围内的特征点；</li>\n<li>遍历搜索范围内的点，对于每一个特征点，计算其描述子与<code>kp1</code>描述子的汉明距离，记录相关信息；</li>\n<li>根据最好距离和次好距离以及阈值的关系，记录匹配，记录特征点角度变化到直方图；</li>\n<li>根据角度变化剔除不好的匹配。</li>\n</ol>\n<h3 id=\"SearchForTriangulation函数\"><a href=\"#SearchForTriangulation函数\" class=\"headerlink\" title=\"SearchForTriangulation函数\"></a><code>SearchForTriangulation</code>函数</h3><p>函数原型：</p>\n<!--�135-->\n<p>该函数利用三角化，在两个关键帧之间恢复出一些地图点，检测对极约束。具体实现：</p>\n<ol>\n<li>对第一个关键帧中的特征点进行遍历，跳过已经有对应地图点的点，因为这个函数的目的是为了三角化进行的搜索匹配；</li>\n<li>对于第二个关键帧中的特征点，计算描述子之间的距离，检查特征点距离极线的距离，满足要求的记录信息；</li>\n<li>进行角度变化的统计和检查。</li>\n</ol>\n<h3 id=\"SearchBySim3函数\"><a href=\"#SearchBySim3函数\" class=\"headerlink\" title=\"SearchBySim3函数\"></a><code>SearchBySim3</code>函数</h3><p>函数原型：</p>\n<!--�136-->\n<p>该函数在关键帧pKF1和通过相似变换得到的关键帧pKF2观测到的地图点之间搜索匹配，主要是匹配之前漏匹配的点，只用于双目和RGB-D。</p>\n<p>通过sim3变换，确定pKF1中的特征点在pKF2中的大致区域，同理，确定pKF2的特征点在pKF1中的大致区域。在该区域内通过描述子进行匹配捕获pKF1和pKF2之前漏匹配的特征点，更新vpMatches12（之前使用SearchByBow进行特征点匹配时会有漏匹配）。最后有一个检查的条件，某一对匹配点在pKF1至pKF2的匹配及pKF2至pKF1的匹配都存在时才认为是有效的匹配。</p>\n<h3 id=\"DescriptorDistance函数\"><a href=\"#DescriptorDistance函数\" class=\"headerlink\" title=\"DescriptorDistance函数\"></a><code>DescriptorDistance</code>函数</h3><p>对应函数：</p>\n<!--�137-->\n<p>该函数负责计算两个ORB描述子的汉明距离。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ol>\n<li>各种特征匹配的基本思路都是根据距离预测尺度，进而根据尺度确定一个合理的搜索范围，之后对这个范围内的点进行匹配，从匹配结果中选出满足条件的最佳匹配。</li>\n<li>何时用投影匹配，何时用DBow2进行匹配？<ul>\n<li>在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place Recognition，因此需要用DBow。</li>\n<li>而投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间。</li>\n</ul>\n</li>\n<li>以上函数在检测特征点时，都会用到角度直方图用来剔除不满足两帧之间角度旋转的外点，也就是旋转一致性检测。具体实现：<ul>\n<li>将关键帧与当前帧匹配关键点的<code>angle</code>相减，得到rot（<code>0≤rot＜360</code>），放入一个直方图中，对于每一对匹配点的角度差，均可以放入一个<code>bin</code>的范围内（<code>360/HISTO_LENGTH</code>）；</li>\n<li>统计直方图最高的三个<code>bin</code>保留，其他范围内的匹配点剔除。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6431017.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（八）ORBmatcher 特征匹配</a></li>\n<li><a href=\"https://blog.csdn.net/u012936940/article/details/81396061\" target=\"_blank\" rel=\"noopener\">ORBSLAM2源码学习（6） ORBmatcher类</a></li>\n<li><a href=\"https://www.cnblogs.com/Fighting_lan/p/7816712.html\" target=\"_blank\" rel=\"noopener\">ORBmatacher</a></li>\n</ol>"},{"title":"ORB_SLAM2学习之源码分析二-初始化","date":"2018-08-16T07:37:48.000Z","copyright":true,"_content":"\n----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目、双目、RGB-D初始化过程，并进行比较。\n\n<!--more--->\n\n## 概述\n\nSLAM过程初始化的目的是创建3d地图点，为后续跟踪提供初值。其中单目初始化较为复杂，双目、RGB-D初始化类似。\n\n## 图像帧创建\n\nSLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成帧，帧中包含所有SLAM过程需要的信息，包括矫正前后的关键点及数量、特征描述子、右图成像坐标信息（单目除外）、深度信息（单目除外）、时间戳、词袋、内参矩阵、畸变参数、相机位姿、旋转矩阵、平移向量、尺度金字塔信息、参考关键帧等等，通过原始图像获取到帧所需信息之后，原始图像就被丢弃，之后的处理过程和原始图像没有关系了。\n\n在进行初始化之前都要将彩色图像（3或4通道图像）处理成灰度图像（无论图片是RGB、BGR， 还是RGBA、BGRA，均转化为灰度图，放弃彩色信息），继而将图片封装成帧（`Frame`类对象）。下面介绍下图像帧的创建过程，三者初始化分别调用重载的`Frame`类构造函数，重载的构造函数都有ORB特征提取、畸变矫正等环节。重载函数传入的参数有差别，这一点很显然。**值得注意的是函数内部构造过程的一些区别，比如双目初始化需要进行双目匹配ComputeStereoMatches、RGB-D初始化需要进行双目信息计算ComputeStereoFromRGBD**，这一点涉及到`mvuRight`、`mvDepth`这两个变量，详细的理解另作记录。\n\n### 单目创建图像帧\n\n#### 函数调用\n\n~~~c++\nmCurrentFrame = Frame(mImGray, timestamp, mpIniORBextractor, mpORBextractor, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);\n~~~\n\n#### 主要过程\n\n设置尺度金字塔信息、ORB特征提取、畸变矫正、**设置无双目信息（设置`mvuRight`、`mvDepth`两个变量为负）**、关键点分布到网格。\n\n### 双目创建图像帧\n\n#### 函数调用\n\n~~~c++\nmCurrentFrame = Frame(mImGray, imGrayRight, timestamp, mpORBextractorLeft, mpORBextractorRight, mpORBVocabulary,mK, mDistCoef, mbf, mThDepth);\n~~~\n\n#### 主要过程\n\n设置尺度金字塔信息、ORB特征提取、畸变矫正、**双目匹配（计算左图中特征点对应的右图坐标，并恢复出的深度信息。设置`mvuRight`、`mvDepth`两个变量为负）**、计算基线、关键点分布到网格。\n\n### RGB-D创建图像帧\n\n#### 函数调用\n\n~~~c++\nmCurrentFrame = Frame(mImGray, imDepth, timestamp, mpORBextractorLeft, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);\n~~~\n\n#### 主要过程\n\n设置尺度金字塔信息、ORB特征提取、畸变矫正、**根据RGB-D计算双目信息（设置`mvuRight`、`mvDepth`两个变量）**、关键点分布到网格。\n\n### ORB特征提取\n\n~~~c++\nvoid Frame::ExtractORB(int flag, const cv::Mat &im)\n{\n    if(flag==0)\n        (*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors);\n    else\n        (*mpORBextractorRight)(im,cv::Mat(),mvKeysRight,mDescriptorsRight);\n}\n~~~\n\n{% asset_img ExtractORB.png %}\n\n创建图像帧的关键一步是进行ORB特征提取，`ExtractORB()`调用了`ORBextractor`类中的重载操作符`void operator()`，完成特征提取，提取结果被保存在`Frame`类的成员变量`std::vector<cv:KeyPoint> mvKeys`和`cv:Mat mDescriptors`中，即提取出特征的关键点和描述子。关于ORB特征及其提取、匹配，会在后续继续学习。\n\n## 单目初始化\n\n单目SLAM地图初始化的目标是构建初始的三维点云。由于不能仅仅从单帧得到深度信息，因此需要从图像序列中选取两帧以上的图像，估计摄像机姿态并重建出初始的三维点云。单目初始化调用Tracking::MonocularInitialization()函数。\n\n{% asset_img 单目初始化.png %}\n\n### 重点分析\n\n1. 需要获取连续两帧特征点数量超过100的图像帧，并且两帧图像匹配点大于100，才可以开始初始化，否则重新接收数据帧；连续两帧的前一帧设为参考帧；\n2. 找到连续可用的图像帧后，需要使用专门的初始化器进行初始化（`Initializer.cc`），这个通过并行计算分解单应矩阵H和基础矩阵F，得到帧间运动（位姿）（关于对极几何方法，使用并行计算F和H矩阵的初始化后续再做专门的记录）；\n3. 创建初始地图过程。首先创建关键帧和地图点，通过将关键帧和地图点插入初始地图完成初始地图的构建，接着更新关键帧之间的连接关系（以共视地图点的数量作为权重），对两帧姿态图像进行全局优化重投影误差（和回环检测调整后的大回环优化使用的是同一函数）；\n4. 比较重要的三个对象：地图、地图点、关键帧。地图就是整个的位姿和地图点。一个关键帧提取出的特征点对应一个地图点集，因此需要记下每个地图点在该帧中的编号；一个地图点会被多帧关键帧观测到，需要记下每个关键帧在该点中的编号。因此，地图点和关键帧的关系是：每个地图点会记录观测到自身的关键帧，关键帧中会记录观测到的所有地图点；\n5. 创建地图点时，地图点中需要加入的一些属性：观测到该地图点的关键帧（以及对应的特征点）；该地图点的描述子（观测到该地图点的多个特征点中（对应多个关键帧），挑选出区分度最高的描述子，作为这个地图点的描述子）； 该MapPoint的平均观测方向和观测距离的，为后面做描述子融合做准备；\n6. 局部地图、局部关键帧、局部地图点，是为了进行局部Bundle Adjustment。\n\n### 单目初始化特点\n\n1. 单目通过一帧无法估计深度，所以初始化时需要使用两帧图像；\n2. 需要使用专门的初始化器进行初始化，使用对极约束几何方法恢复运动，得到Rcw、tcw；\n3. 恢复运动之后使用三角化测量方法得到特征点的空间位置；\n4. 由于通过分解基础矩阵$E$恢复相机运动，得到$R$，$t$，如果相机发生的纯旋转，导致$t$为0，得到的$E$也将为0，无法进一步求解$R$。虽然可以依靠单应矩阵$H$求解旋转，但仅有旋转无法使用三角测量方法估计特征点的空间位置；因此，**单目初始化不能只有纯旋转，必须要有一定程度的平移（平移太小会使得位姿求解和三角化结果不稳定，从而导致失败）。**\n3. 为了让单目成功初始化（单目的初始化需要通过平移运动归一化尺度因子），初始化`Tracking`时`mpIniORBextractor`提取的特征点数量设定为普通帧的2倍（`Tracking.cc`）。\n\n## 双目、RGB-D初始化\n\n双目和RGB-D相机不需要通过两个相邻帧来恢复地图点深度，所以初始化过程极其相似，只要当前到来帧满足条件即可开始初始化，调用的是同一个函数`Tracking::StereoInitialization()`。\n\n{% asset_img 双目初始化.png %}\n\n### 重点分析\n\n1. 创建初始地图过程。首先创建关键帧和地图点，注意这里只会使用有深度的点进行初始化；然后通过将关键帧和地图点插入初始地图完成初始地图的构建。因为此初始化只用到一个图像帧，所以没有关键帧连接关系的更新和姿态的优化；\n2. 其他同单目4、5、6条。\n\n> 疑问：初始化过程中，满足条件的第一个图像帧作为参考关键帧，后来帧都以该参考关键帧为参考吗？即参考关键帧会更新吗？\n>\n> 答：后续的追踪过程还会有新的关键帧的插入（在`Tracking::CreateNewKeyFrame()中完成`），最新插入的关键帧作为参考关键帧的。即参考关键帧会更新，总是当前帧最临近的关键帧，或者说上一个关键帧。\n\n## 初始化比较\n\n单目初始化的特点是双目、RGD-D初始化过程不具备的。（废话么这不是()> _ <) ）单目初始化一定要有一定程度的平移。值得关注的一点是，在三者初始化之前图像帧的创建过程也是有区别的，单目不涉及深度和右图特征点成像平面坐标的计算，后两者需要此过程，这一点涉及到`mvuRight`、`mvDepth`这两个变量，详细的理解另作记录。\n\n## 区分\n\n### 图像帧相关\n\n1. `上一帧mLastFrame`：即上一帧图像\n\n2. `上一关键帧mpLastKeyFrame`：最邻近当前帧的关键帧，不一定是上一帧，因为图像帧要经过判断后，满足条件才能称为关键帧\n\n3. `参考关键帧mpReferenceKF`：就是当前帧的上一关键帧；若创建了新的关键帧，参考关键帧就更新为新创建的关键帧；或者是局部地图中与当前帧共享地图点最多的关键帧。\n\n   > 参考关键帧更新的时机\n   >\n   > - 创建新的关键帧时（初始化、追踪过程两处）\n   > - TrackLocalMap()更新局部关键帧的过程中\n\n\n4. `当前帧的参考关键帧`：或者是上一关键帧，或者是由当前帧创建的关键帧（即当前帧满足关键帧创建的条件），或者是局部地图中与当前帧共享地图点最多的关键帧。\n\n### 地图相关\n\n1. 全局地图`mpMap`\n\n   是`Map`类的对象，本质上也是由关键帧和地图点组成。\n\n2. 局部地图\n\n   局部地图不像全局地图一样有`Map`类表示，它只是一个概念叫法，其作用是在局部地图追踪过程中通过地图点重投影匹配关键点，进一步优化初步估计的当前帧位姿（是否还有其他作用？？？）。实际上它包括三个变量：\n\n   - 参考关键帧`mpReferenceKF`\n   - 局部关键帧集合`mvpLocalKeyFrames`\n   - 局部地图点集合`mvpLocalMapPoints`\n\n\n3. 局部建图线程接口指针`mpLocalMapper`\n\n   主要是和局部建图线程建立连接，给该线程传递关键帧并由其维护地图，也就是全局地图。\n\n\n### 地图点相关\n\n地图点有两个私有成员变量`mnVisible`、`mnfound`，前者表示该地图点在图像帧视野范围内，在创建地图点时构造函数就将该值置为1；后者表示该地图点有对应特征点的图像帧帧数。通常来说，found的地图点一定是visible的，但是visible的地图点很可能not found。\n\n## 参考资料\n\n1. [ORB-SLAM 代码笔记（四）tracking代码结构](https://www.cnblogs.com/shang-slam/p/6389129.html)\n2. [单目、双目和RGB-D视觉SLAM初始化比较](https://www.cnblogs.com/mybrave/p/9342952.html)\n3. 视觉SLAM十四讲P152","source":"_posts/ORB-SLAM2学习之源码分析二-初始化.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析二-初始化\ndate: 2018-08-16 15:37:48\ntags: \n  - ORB_SLAM2\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目、双目、RGB-D初始化过程，并进行比较。\n\n<!--more--->\n\n## 概述\n\nSLAM过程初始化的目的是创建3d地图点，为后续跟踪提供初值。其中单目初始化较为复杂，双目、RGB-D初始化类似。\n\n## 图像帧创建\n\nSLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成帧，帧中包含所有SLAM过程需要的信息，包括矫正前后的关键点及数量、特征描述子、右图成像坐标信息（单目除外）、深度信息（单目除外）、时间戳、词袋、内参矩阵、畸变参数、相机位姿、旋转矩阵、平移向量、尺度金字塔信息、参考关键帧等等，通过原始图像获取到帧所需信息之后，原始图像就被丢弃，之后的处理过程和原始图像没有关系了。\n\n在进行初始化之前都要将彩色图像（3或4通道图像）处理成灰度图像（无论图片是RGB、BGR， 还是RGBA、BGRA，均转化为灰度图，放弃彩色信息），继而将图片封装成帧（`Frame`类对象）。下面介绍下图像帧的创建过程，三者初始化分别调用重载的`Frame`类构造函数，重载的构造函数都有ORB特征提取、畸变矫正等环节。重载函数传入的参数有差别，这一点很显然。**值得注意的是函数内部构造过程的一些区别，比如双目初始化需要进行双目匹配ComputeStereoMatches、RGB-D初始化需要进行双目信息计算ComputeStereoFromRGBD**，这一点涉及到`mvuRight`、`mvDepth`这两个变量，详细的理解另作记录。\n\n### 单目创建图像帧\n\n#### 函数调用\n\n~~~c++\nmCurrentFrame = Frame(mImGray, timestamp, mpIniORBextractor, mpORBextractor, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);\n~~~\n\n#### 主要过程\n\n设置尺度金字塔信息、ORB特征提取、畸变矫正、**设置无双目信息（设置`mvuRight`、`mvDepth`两个变量为负）**、关键点分布到网格。\n\n### 双目创建图像帧\n\n#### 函数调用\n\n~~~c++\nmCurrentFrame = Frame(mImGray, imGrayRight, timestamp, mpORBextractorLeft, mpORBextractorRight, mpORBVocabulary,mK, mDistCoef, mbf, mThDepth);\n~~~\n\n#### 主要过程\n\n设置尺度金字塔信息、ORB特征提取、畸变矫正、**双目匹配（计算左图中特征点对应的右图坐标，并恢复出的深度信息。设置`mvuRight`、`mvDepth`两个变量为负）**、计算基线、关键点分布到网格。\n\n### RGB-D创建图像帧\n\n#### 函数调用\n\n~~~c++\nmCurrentFrame = Frame(mImGray, imDepth, timestamp, mpORBextractorLeft, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);\n~~~\n\n#### 主要过程\n\n设置尺度金字塔信息、ORB特征提取、畸变矫正、**根据RGB-D计算双目信息（设置`mvuRight`、`mvDepth`两个变量）**、关键点分布到网格。\n\n### ORB特征提取\n\n~~~c++\nvoid Frame::ExtractORB(int flag, const cv::Mat &im)\n{\n    if(flag==0)\n        (*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors);\n    else\n        (*mpORBextractorRight)(im,cv::Mat(),mvKeysRight,mDescriptorsRight);\n}\n~~~\n\n{% asset_img ExtractORB.png %}\n\n创建图像帧的关键一步是进行ORB特征提取，`ExtractORB()`调用了`ORBextractor`类中的重载操作符`void operator()`，完成特征提取，提取结果被保存在`Frame`类的成员变量`std::vector<cv:KeyPoint> mvKeys`和`cv:Mat mDescriptors`中，即提取出特征的关键点和描述子。关于ORB特征及其提取、匹配，会在后续继续学习。\n\n## 单目初始化\n\n单目SLAM地图初始化的目标是构建初始的三维点云。由于不能仅仅从单帧得到深度信息，因此需要从图像序列中选取两帧以上的图像，估计摄像机姿态并重建出初始的三维点云。单目初始化调用Tracking::MonocularInitialization()函数。\n\n{% asset_img 单目初始化.png %}\n\n### 重点分析\n\n1. 需要获取连续两帧特征点数量超过100的图像帧，并且两帧图像匹配点大于100，才可以开始初始化，否则重新接收数据帧；连续两帧的前一帧设为参考帧；\n2. 找到连续可用的图像帧后，需要使用专门的初始化器进行初始化（`Initializer.cc`），这个通过并行计算分解单应矩阵H和基础矩阵F，得到帧间运动（位姿）（关于对极几何方法，使用并行计算F和H矩阵的初始化后续再做专门的记录）；\n3. 创建初始地图过程。首先创建关键帧和地图点，通过将关键帧和地图点插入初始地图完成初始地图的构建，接着更新关键帧之间的连接关系（以共视地图点的数量作为权重），对两帧姿态图像进行全局优化重投影误差（和回环检测调整后的大回环优化使用的是同一函数）；\n4. 比较重要的三个对象：地图、地图点、关键帧。地图就是整个的位姿和地图点。一个关键帧提取出的特征点对应一个地图点集，因此需要记下每个地图点在该帧中的编号；一个地图点会被多帧关键帧观测到，需要记下每个关键帧在该点中的编号。因此，地图点和关键帧的关系是：每个地图点会记录观测到自身的关键帧，关键帧中会记录观测到的所有地图点；\n5. 创建地图点时，地图点中需要加入的一些属性：观测到该地图点的关键帧（以及对应的特征点）；该地图点的描述子（观测到该地图点的多个特征点中（对应多个关键帧），挑选出区分度最高的描述子，作为这个地图点的描述子）； 该MapPoint的平均观测方向和观测距离的，为后面做描述子融合做准备；\n6. 局部地图、局部关键帧、局部地图点，是为了进行局部Bundle Adjustment。\n\n### 单目初始化特点\n\n1. 单目通过一帧无法估计深度，所以初始化时需要使用两帧图像；\n2. 需要使用专门的初始化器进行初始化，使用对极约束几何方法恢复运动，得到Rcw、tcw；\n3. 恢复运动之后使用三角化测量方法得到特征点的空间位置；\n4. 由于通过分解基础矩阵$E$恢复相机运动，得到$R$，$t$，如果相机发生的纯旋转，导致$t$为0，得到的$E$也将为0，无法进一步求解$R$。虽然可以依靠单应矩阵$H$求解旋转，但仅有旋转无法使用三角测量方法估计特征点的空间位置；因此，**单目初始化不能只有纯旋转，必须要有一定程度的平移（平移太小会使得位姿求解和三角化结果不稳定，从而导致失败）。**\n3. 为了让单目成功初始化（单目的初始化需要通过平移运动归一化尺度因子），初始化`Tracking`时`mpIniORBextractor`提取的特征点数量设定为普通帧的2倍（`Tracking.cc`）。\n\n## 双目、RGB-D初始化\n\n双目和RGB-D相机不需要通过两个相邻帧来恢复地图点深度，所以初始化过程极其相似，只要当前到来帧满足条件即可开始初始化，调用的是同一个函数`Tracking::StereoInitialization()`。\n\n{% asset_img 双目初始化.png %}\n\n### 重点分析\n\n1. 创建初始地图过程。首先创建关键帧和地图点，注意这里只会使用有深度的点进行初始化；然后通过将关键帧和地图点插入初始地图完成初始地图的构建。因为此初始化只用到一个图像帧，所以没有关键帧连接关系的更新和姿态的优化；\n2. 其他同单目4、5、6条。\n\n> 疑问：初始化过程中，满足条件的第一个图像帧作为参考关键帧，后来帧都以该参考关键帧为参考吗？即参考关键帧会更新吗？\n>\n> 答：后续的追踪过程还会有新的关键帧的插入（在`Tracking::CreateNewKeyFrame()中完成`），最新插入的关键帧作为参考关键帧的。即参考关键帧会更新，总是当前帧最临近的关键帧，或者说上一个关键帧。\n\n## 初始化比较\n\n单目初始化的特点是双目、RGD-D初始化过程不具备的。（废话么这不是()> _ <) ）单目初始化一定要有一定程度的平移。值得关注的一点是，在三者初始化之前图像帧的创建过程也是有区别的，单目不涉及深度和右图特征点成像平面坐标的计算，后两者需要此过程，这一点涉及到`mvuRight`、`mvDepth`这两个变量，详细的理解另作记录。\n\n## 区分\n\n### 图像帧相关\n\n1. `上一帧mLastFrame`：即上一帧图像\n\n2. `上一关键帧mpLastKeyFrame`：最邻近当前帧的关键帧，不一定是上一帧，因为图像帧要经过判断后，满足条件才能称为关键帧\n\n3. `参考关键帧mpReferenceKF`：就是当前帧的上一关键帧；若创建了新的关键帧，参考关键帧就更新为新创建的关键帧；或者是局部地图中与当前帧共享地图点最多的关键帧。\n\n   > 参考关键帧更新的时机\n   >\n   > - 创建新的关键帧时（初始化、追踪过程两处）\n   > - TrackLocalMap()更新局部关键帧的过程中\n\n\n4. `当前帧的参考关键帧`：或者是上一关键帧，或者是由当前帧创建的关键帧（即当前帧满足关键帧创建的条件），或者是局部地图中与当前帧共享地图点最多的关键帧。\n\n### 地图相关\n\n1. 全局地图`mpMap`\n\n   是`Map`类的对象，本质上也是由关键帧和地图点组成。\n\n2. 局部地图\n\n   局部地图不像全局地图一样有`Map`类表示，它只是一个概念叫法，其作用是在局部地图追踪过程中通过地图点重投影匹配关键点，进一步优化初步估计的当前帧位姿（是否还有其他作用？？？）。实际上它包括三个变量：\n\n   - 参考关键帧`mpReferenceKF`\n   - 局部关键帧集合`mvpLocalKeyFrames`\n   - 局部地图点集合`mvpLocalMapPoints`\n\n\n3. 局部建图线程接口指针`mpLocalMapper`\n\n   主要是和局部建图线程建立连接，给该线程传递关键帧并由其维护地图，也就是全局地图。\n\n\n### 地图点相关\n\n地图点有两个私有成员变量`mnVisible`、`mnfound`，前者表示该地图点在图像帧视野范围内，在创建地图点时构造函数就将该值置为1；后者表示该地图点有对应特征点的图像帧帧数。通常来说，found的地图点一定是visible的，但是visible的地图点很可能not found。\n\n## 参考资料\n\n1. [ORB-SLAM 代码笔记（四）tracking代码结构](https://www.cnblogs.com/shang-slam/p/6389129.html)\n2. [单目、双目和RGB-D视觉SLAM初始化比较](https://www.cnblogs.com/mybrave/p/9342952.html)\n3. 视觉SLAM十四讲P152","slug":"ORB-SLAM2学习之源码分析二-初始化","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyo00b6qlcrku22ge65","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目、双目、RGB-D初始化过程，并进行比较。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>SLAM过程初始化的目的是创建3d地图点，为后续跟踪提供初值。其中单目初始化较为复杂，双目、RGB-D初始化类似。</p>\n<h2 id=\"图像帧创建\"><a href=\"#图像帧创建\" class=\"headerlink\" title=\"图像帧创建\"></a>图像帧创建</h2><p>SLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成帧，帧中包含所有SLAM过程需要的信息，包括矫正前后的关键点及数量、特征描述子、右图成像坐标信息（单目除外）、深度信息（单目除外）、时间戳、词袋、内参矩阵、畸变参数、相机位姿、旋转矩阵、平移向量、尺度金字塔信息、参考关键帧等等，通过原始图像获取到帧所需信息之后，原始图像就被丢弃，之后的处理过程和原始图像没有关系了。</p>\n<p>在进行初始化之前都要将彩色图像（3或4通道图像）处理成灰度图像（无论图片是RGB、BGR， 还是RGBA、BGRA，均转化为灰度图，放弃彩色信息），继而将图片封装成帧（<code>Frame</code>类对象）。下面介绍下图像帧的创建过程，三者初始化分别调用重载的<code>Frame</code>类构造函数，重载的构造函数都有ORB特征提取、畸变矫正等环节。重载函数传入的参数有差别，这一点很显然。<strong>值得注意的是函数内部构造过程的一些区别，比如双目初始化需要进行双目匹配ComputeStereoMatches、RGB-D初始化需要进行双目信息计算ComputeStereoFromRGBD</strong>，这一点涉及到<code>mvuRight</code>、<code>mvDepth</code>这两个变量，详细的理解另作记录。</p>\n<h3 id=\"单目创建图像帧\"><a href=\"#单目创建图像帧\" class=\"headerlink\" title=\"单目创建图像帧\"></a>单目创建图像帧</h3><h4 id=\"函数调用\"><a href=\"#函数调用\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mCurrentFrame = Frame(mImGray, timestamp, mpIniORBextractor, mpORBextractor, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);</span><br></pre></td></tr></table></figure>\n<h4 id=\"主要过程\"><a href=\"#主要过程\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h4><p>设置尺度金字塔信息、ORB特征提取、畸变矫正、<strong>设置无双目信息（设置<code>mvuRight</code>、<code>mvDepth</code>两个变量为负）</strong>、关键点分布到网格。</p>\n<h3 id=\"双目创建图像帧\"><a href=\"#双目创建图像帧\" class=\"headerlink\" title=\"双目创建图像帧\"></a>双目创建图像帧</h3><h4 id=\"函数调用-1\"><a href=\"#函数调用-1\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mCurrentFrame = Frame(mImGray, imGrayRight, timestamp, mpORBextractorLeft, mpORBextractorRight, mpORBVocabulary,mK, mDistCoef, mbf, mThDepth);</span><br></pre></td></tr></table></figure>\n<h4 id=\"主要过程-1\"><a href=\"#主要过程-1\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h4><p>设置尺度金字塔信息、ORB特征提取、畸变矫正、<strong>双目匹配（计算左图中特征点对应的右图坐标，并恢复出的深度信息。设置<code>mvuRight</code>、<code>mvDepth</code>两个变量为负）</strong>、计算基线、关键点分布到网格。</p>\n<h3 id=\"RGB-D创建图像帧\"><a href=\"#RGB-D创建图像帧\" class=\"headerlink\" title=\"RGB-D创建图像帧\"></a>RGB-D创建图像帧</h3><h4 id=\"函数调用-2\"><a href=\"#函数调用-2\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mCurrentFrame = Frame(mImGray, imDepth, timestamp, mpORBextractorLeft, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);</span><br></pre></td></tr></table></figure>\n<h4 id=\"主要过程-2\"><a href=\"#主要过程-2\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h4><p>设置尺度金字塔信息、ORB特征提取、畸变矫正、<strong>根据RGB-D计算双目信息（设置<code>mvuRight</code>、<code>mvDepth</code>两个变量）</strong>、关键点分布到网格。</p>\n<h3 id=\"ORB特征提取\"><a href=\"#ORB特征提取\" class=\"headerlink\" title=\"ORB特征提取\"></a>ORB特征提取</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> Frame::ExtractORB(<span class=\"keyword\">int</span> flag, <span class=\"keyword\">const</span> cv::Mat &amp;im)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(flag==<span class=\"number\">0</span>)</span><br><span class=\"line\">        (*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors);</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">        (*mpORBextractorRight)(im,cv::Mat(),mvKeysRight,mDescriptorsRight);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<img src=\"/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/ExtractORB.png\">\n<p>创建图像帧的关键一步是进行ORB特征提取，<code>ExtractORB()</code>调用了<code>ORBextractor</code>类中的重载操作符<code>void operator()</code>，完成特征提取，提取结果被保存在<code>Frame</code>类的成员变量<code>std::vector&lt;cv:KeyPoint&gt; mvKeys</code>和<code>cv:Mat mDescriptors</code>中，即提取出特征的关键点和描述子。关于ORB特征及其提取、匹配，会在后续继续学习。</p>\n<h2 id=\"单目初始化\"><a href=\"#单目初始化\" class=\"headerlink\" title=\"单目初始化\"></a>单目初始化</h2><p>单目SLAM地图初始化的目标是构建初始的三维点云。由于不能仅仅从单帧得到深度信息，因此需要从图像序列中选取两帧以上的图像，估计摄像机姿态并重建出初始的三维点云。单目初始化调用Tracking::MonocularInitialization()函数。</p>\n<img src=\"/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/单目初始化.png\">\n<h3 id=\"重点分析\"><a href=\"#重点分析\" class=\"headerlink\" title=\"重点分析\"></a>重点分析</h3><ol>\n<li>需要获取连续两帧特征点数量超过100的图像帧，并且两帧图像匹配点大于100，才可以开始初始化，否则重新接收数据帧；连续两帧的前一帧设为参考帧；</li>\n<li>找到连续可用的图像帧后，需要使用专门的初始化器进行初始化（<code>Initializer.cc</code>），这个通过并行计算分解单应矩阵H和基础矩阵F，得到帧间运动（位姿）（关于对极几何方法，使用并行计算F和H矩阵的初始化后续再做专门的记录）；</li>\n<li>创建初始地图过程。首先创建关键帧和地图点，通过将关键帧和地图点插入初始地图完成初始地图的构建，接着更新关键帧之间的连接关系（以共视地图点的数量作为权重），对两帧姿态图像进行全局优化重投影误差（和回环检测调整后的大回环优化使用的是同一函数）；</li>\n<li>比较重要的三个对象：地图、地图点、关键帧。地图就是整个的位姿和地图点。一个关键帧提取出的特征点对应一个地图点集，因此需要记下每个地图点在该帧中的编号；一个地图点会被多帧关键帧观测到，需要记下每个关键帧在该点中的编号。因此，地图点和关键帧的关系是：每个地图点会记录观测到自身的关键帧，关键帧中会记录观测到的所有地图点；</li>\n<li>创建地图点时，地图点中需要加入的一些属性：观测到该地图点的关键帧（以及对应的特征点）；该地图点的描述子（观测到该地图点的多个特征点中（对应多个关键帧），挑选出区分度最高的描述子，作为这个地图点的描述子）； 该MapPoint的平均观测方向和观测距离的，为后面做描述子融合做准备；</li>\n<li>局部地图、局部关键帧、局部地图点，是为了进行局部Bundle Adjustment。</li>\n</ol>\n<h3 id=\"单目初始化特点\"><a href=\"#单目初始化特点\" class=\"headerlink\" title=\"单目初始化特点\"></a>单目初始化特点</h3><ol>\n<li>单目通过一帧无法估计深度，所以初始化时需要使用两帧图像；</li>\n<li>需要使用专门的初始化器进行初始化，使用对极约束几何方法恢复运动，得到Rcw、tcw；</li>\n<li>恢复运动之后使用三角化测量方法得到特征点的空间位置；</li>\n<li>由于通过分解基础矩阵$E$恢复相机运动，得到$R$，$t$，如果相机发生的纯旋转，导致$t$为0，得到的$E$也将为0，无法进一步求解$R$。虽然可以依靠单应矩阵$H$求解旋转，但仅有旋转无法使用三角测量方法估计特征点的空间位置；因此，<strong>单目初始化不能只有纯旋转，必须要有一定程度的平移（平移太小会使得位姿求解和三角化结果不稳定，从而导致失败）。</strong></li>\n<li>为了让单目成功初始化（单目的初始化需要通过平移运动归一化尺度因子），初始化<code>Tracking</code>时<code>mpIniORBextractor</code>提取的特征点数量设定为普通帧的2倍（<code>Tracking.cc</code>）。</li>\n</ol>\n<h2 id=\"双目、RGB-D初始化\"><a href=\"#双目、RGB-D初始化\" class=\"headerlink\" title=\"双目、RGB-D初始化\"></a>双目、RGB-D初始化</h2><p>双目和RGB-D相机不需要通过两个相邻帧来恢复地图点深度，所以初始化过程极其相似，只要当前到来帧满足条件即可开始初始化，调用的是同一个函数<code>Tracking::StereoInitialization()</code>。</p>\n<img src=\"/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/双目初始化.png\">\n<h3 id=\"重点分析-1\"><a href=\"#重点分析-1\" class=\"headerlink\" title=\"重点分析\"></a>重点分析</h3><ol>\n<li>创建初始地图过程。首先创建关键帧和地图点，注意这里只会使用有深度的点进行初始化；然后通过将关键帧和地图点插入初始地图完成初始地图的构建。因为此初始化只用到一个图像帧，所以没有关键帧连接关系的更新和姿态的优化；</li>\n<li>其他同单目4、5、6条。</li>\n</ol>\n<blockquote>\n<p>疑问：初始化过程中，满足条件的第一个图像帧作为参考关键帧，后来帧都以该参考关键帧为参考吗？即参考关键帧会更新吗？</p>\n<p>答：后续的追踪过程还会有新的关键帧的插入（在<code>Tracking::CreateNewKeyFrame()中完成</code>），最新插入的关键帧作为参考关键帧的。即参考关键帧会更新，总是当前帧最临近的关键帧，或者说上一个关键帧。</p>\n</blockquote>\n<h2 id=\"初始化比较\"><a href=\"#初始化比较\" class=\"headerlink\" title=\"初始化比较\"></a>初始化比较</h2><p>单目初始化的特点是双目、RGD-D初始化过程不具备的。（废话么这不是()&gt; _ &lt;) ）单目初始化一定要有一定程度的平移。值得关注的一点是，在三者初始化之前图像帧的创建过程也是有区别的，单目不涉及深度和右图特征点成像平面坐标的计算，后两者需要此过程，这一点涉及到<code>mvuRight</code>、<code>mvDepth</code>这两个变量，详细的理解另作记录。</p>\n<h2 id=\"区分\"><a href=\"#区分\" class=\"headerlink\" title=\"区分\"></a>区分</h2><h3 id=\"图像帧相关\"><a href=\"#图像帧相关\" class=\"headerlink\" title=\"图像帧相关\"></a>图像帧相关</h3><ol>\n<li><p><code>上一帧mLastFrame</code>：即上一帧图像</p>\n</li>\n<li><p><code>上一关键帧mpLastKeyFrame</code>：最邻近当前帧的关键帧，不一定是上一帧，因为图像帧要经过判断后，满足条件才能称为关键帧</p>\n</li>\n<li><p><code>参考关键帧mpReferenceKF</code>：就是当前帧的上一关键帧；若创建了新的关键帧，参考关键帧就更新为新创建的关键帧；或者是局部地图中与当前帧共享地图点最多的关键帧。</p>\n<blockquote>\n<p>参考关键帧更新的时机</p>\n<ul>\n<li>创建新的关键帧时（初始化、追踪过程两处）</li>\n<li>TrackLocalMap()更新局部关键帧的过程中</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<ol>\n<li><code>当前帧的参考关键帧</code>：或者是上一关键帧，或者是由当前帧创建的关键帧（即当前帧满足关键帧创建的条件），或者是局部地图中与当前帧共享地图点最多的关键帧。</li>\n</ol>\n<h3 id=\"地图相关\"><a href=\"#地图相关\" class=\"headerlink\" title=\"地图相关\"></a>地图相关</h3><ol>\n<li><p>全局地图<code>mpMap</code></p>\n<p>是<code>Map</code>类的对象，本质上也是由关键帧和地图点组成。</p>\n</li>\n<li><p>局部地图</p>\n<p>局部地图不像全局地图一样有<code>Map</code>类表示，它只是一个概念叫法，其作用是在局部地图追踪过程中通过地图点重投影匹配关键点，进一步优化初步估计的当前帧位姿（是否还有其他作用？？？）。实际上它包括三个变量：</p>\n<ul>\n<li>参考关键帧<code>mpReferenceKF</code></li>\n<li>局部关键帧集合<code>mvpLocalKeyFrames</code></li>\n<li>局部地图点集合<code>mvpLocalMapPoints</code></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>局部建图线程接口指针<code>mpLocalMapper</code></p>\n<p>主要是和局部建图线程建立连接，给该线程传递关键帧并由其维护地图，也就是全局地图。</p>\n</li>\n</ol>\n<h3 id=\"地图点相关\"><a href=\"#地图点相关\" class=\"headerlink\" title=\"地图点相关\"></a>地图点相关</h3><p>地图点有两个私有成员变量<code>mnVisible</code>、<code>mnfound</code>，前者表示该地图点在图像帧视野范围内，在创建地图点时构造函数就将该值置为1；后者表示该地图点有对应特征点的图像帧帧数。通常来说，found的地图点一定是visible的，但是visible的地图点很可能not found。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6389129.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM 代码笔记（四）tracking代码结构</a></li>\n<li><a href=\"https://www.cnblogs.com/mybrave/p/9342952.html\" target=\"_blank\" rel=\"noopener\">单目、双目和RGB-D视觉SLAM初始化比较</a></li>\n<li>视觉SLAM十四讲P152</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目、双目、RGB-D初始化过程，并进行比较。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>SLAM过程初始化的目的是创建3d地图点，为后续跟踪提供初值。其中单目初始化较为复杂，双目、RGB-D初始化类似。</p>\n<h2 id=\"图像帧创建\"><a href=\"#图像帧创建\" class=\"headerlink\" title=\"图像帧创建\"></a>图像帧创建</h2><p>SLAM系统可以接收各种传感器的图像，不管是双目、单目还是RGB-D，都会将原始图像封装成帧，帧中包含所有SLAM过程需要的信息，包括矫正前后的关键点及数量、特征描述子、右图成像坐标信息（单目除外）、深度信息（单目除外）、时间戳、词袋、内参矩阵、畸变参数、相机位姿、旋转矩阵、平移向量、尺度金字塔信息、参考关键帧等等，通过原始图像获取到帧所需信息之后，原始图像就被丢弃，之后的处理过程和原始图像没有关系了。</p>\n<p>在进行初始化之前都要将彩色图像（3或4通道图像）处理成灰度图像（无论图片是RGB、BGR， 还是RGBA、BGRA，均转化为灰度图，放弃彩色信息），继而将图片封装成帧（<code>Frame</code>类对象）。下面介绍下图像帧的创建过程，三者初始化分别调用重载的<code>Frame</code>类构造函数，重载的构造函数都有ORB特征提取、畸变矫正等环节。重载函数传入的参数有差别，这一点很显然。<strong>值得注意的是函数内部构造过程的一些区别，比如双目初始化需要进行双目匹配ComputeStereoMatches、RGB-D初始化需要进行双目信息计算ComputeStereoFromRGBD</strong>，这一点涉及到<code>mvuRight</code>、<code>mvDepth</code>这两个变量，详细的理解另作记录。</p>\n<h3 id=\"单目创建图像帧\"><a href=\"#单目创建图像帧\" class=\"headerlink\" title=\"单目创建图像帧\"></a>单目创建图像帧</h3><h4 id=\"函数调用\"><a href=\"#函数调用\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><!--�138-->\n<h4 id=\"主要过程\"><a href=\"#主要过程\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h4><p>设置尺度金字塔信息、ORB特征提取、畸变矫正、<strong>设置无双目信息（设置<code>mvuRight</code>、<code>mvDepth</code>两个变量为负）</strong>、关键点分布到网格。</p>\n<h3 id=\"双目创建图像帧\"><a href=\"#双目创建图像帧\" class=\"headerlink\" title=\"双目创建图像帧\"></a>双目创建图像帧</h3><h4 id=\"函数调用-1\"><a href=\"#函数调用-1\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><!--�139-->\n<h4 id=\"主要过程-1\"><a href=\"#主要过程-1\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h4><p>设置尺度金字塔信息、ORB特征提取、畸变矫正、<strong>双目匹配（计算左图中特征点对应的右图坐标，并恢复出的深度信息。设置<code>mvuRight</code>、<code>mvDepth</code>两个变量为负）</strong>、计算基线、关键点分布到网格。</p>\n<h3 id=\"RGB-D创建图像帧\"><a href=\"#RGB-D创建图像帧\" class=\"headerlink\" title=\"RGB-D创建图像帧\"></a>RGB-D创建图像帧</h3><h4 id=\"函数调用-2\"><a href=\"#函数调用-2\" class=\"headerlink\" title=\"函数调用\"></a>函数调用</h4><!--�140-->\n<h4 id=\"主要过程-2\"><a href=\"#主要过程-2\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h4><p>设置尺度金字塔信息、ORB特征提取、畸变矫正、<strong>根据RGB-D计算双目信息（设置<code>mvuRight</code>、<code>mvDepth</code>两个变量）</strong>、关键点分布到网格。</p>\n<h3 id=\"ORB特征提取\"><a href=\"#ORB特征提取\" class=\"headerlink\" title=\"ORB特征提取\"></a>ORB特征提取</h3><!--�141-->\n<img src=\"/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/ExtractORB.png\">\n<p>创建图像帧的关键一步是进行ORB特征提取，<code>ExtractORB()</code>调用了<code>ORBextractor</code>类中的重载操作符<code>void operator()</code>，完成特征提取，提取结果被保存在<code>Frame</code>类的成员变量<code>std::vector&lt;cv:KeyPoint&gt; mvKeys</code>和<code>cv:Mat mDescriptors</code>中，即提取出特征的关键点和描述子。关于ORB特征及其提取、匹配，会在后续继续学习。</p>\n<h2 id=\"单目初始化\"><a href=\"#单目初始化\" class=\"headerlink\" title=\"单目初始化\"></a>单目初始化</h2><p>单目SLAM地图初始化的目标是构建初始的三维点云。由于不能仅仅从单帧得到深度信息，因此需要从图像序列中选取两帧以上的图像，估计摄像机姿态并重建出初始的三维点云。单目初始化调用Tracking::MonocularInitialization()函数。</p>\n<img src=\"/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/单目初始化.png\">\n<h3 id=\"重点分析\"><a href=\"#重点分析\" class=\"headerlink\" title=\"重点分析\"></a>重点分析</h3><ol>\n<li>需要获取连续两帧特征点数量超过100的图像帧，并且两帧图像匹配点大于100，才可以开始初始化，否则重新接收数据帧；连续两帧的前一帧设为参考帧；</li>\n<li>找到连续可用的图像帧后，需要使用专门的初始化器进行初始化（<code>Initializer.cc</code>），这个通过并行计算分解单应矩阵H和基础矩阵F，得到帧间运动（位姿）（关于对极几何方法，使用并行计算F和H矩阵的初始化后续再做专门的记录）；</li>\n<li>创建初始地图过程。首先创建关键帧和地图点，通过将关键帧和地图点插入初始地图完成初始地图的构建，接着更新关键帧之间的连接关系（以共视地图点的数量作为权重），对两帧姿态图像进行全局优化重投影误差（和回环检测调整后的大回环优化使用的是同一函数）；</li>\n<li>比较重要的三个对象：地图、地图点、关键帧。地图就是整个的位姿和地图点。一个关键帧提取出的特征点对应一个地图点集，因此需要记下每个地图点在该帧中的编号；一个地图点会被多帧关键帧观测到，需要记下每个关键帧在该点中的编号。因此，地图点和关键帧的关系是：每个地图点会记录观测到自身的关键帧，关键帧中会记录观测到的所有地图点；</li>\n<li>创建地图点时，地图点中需要加入的一些属性：观测到该地图点的关键帧（以及对应的特征点）；该地图点的描述子（观测到该地图点的多个特征点中（对应多个关键帧），挑选出区分度最高的描述子，作为这个地图点的描述子）； 该MapPoint的平均观测方向和观测距离的，为后面做描述子融合做准备；</li>\n<li>局部地图、局部关键帧、局部地图点，是为了进行局部Bundle Adjustment。</li>\n</ol>\n<h3 id=\"单目初始化特点\"><a href=\"#单目初始化特点\" class=\"headerlink\" title=\"单目初始化特点\"></a>单目初始化特点</h3><ol>\n<li>单目通过一帧无法估计深度，所以初始化时需要使用两帧图像；</li>\n<li>需要使用专门的初始化器进行初始化，使用对极约束几何方法恢复运动，得到Rcw、tcw；</li>\n<li>恢复运动之后使用三角化测量方法得到特征点的空间位置；</li>\n<li>由于通过分解基础矩阵$E$恢复相机运动，得到$R$，$t$，如果相机发生的纯旋转，导致$t$为0，得到的$E$也将为0，无法进一步求解$R$。虽然可以依靠单应矩阵$H$求解旋转，但仅有旋转无法使用三角测量方法估计特征点的空间位置；因此，<strong>单目初始化不能只有纯旋转，必须要有一定程度的平移（平移太小会使得位姿求解和三角化结果不稳定，从而导致失败）。</strong></li>\n<li>为了让单目成功初始化（单目的初始化需要通过平移运动归一化尺度因子），初始化<code>Tracking</code>时<code>mpIniORBextractor</code>提取的特征点数量设定为普通帧的2倍（<code>Tracking.cc</code>）。</li>\n</ol>\n<h2 id=\"双目、RGB-D初始化\"><a href=\"#双目、RGB-D初始化\" class=\"headerlink\" title=\"双目、RGB-D初始化\"></a>双目、RGB-D初始化</h2><p>双目和RGB-D相机不需要通过两个相邻帧来恢复地图点深度，所以初始化过程极其相似，只要当前到来帧满足条件即可开始初始化，调用的是同一个函数<code>Tracking::StereoInitialization()</code>。</p>\n<img src=\"/2018/08/16/ORB-SLAM2学习之源码分析二-初始化/双目初始化.png\">\n<h3 id=\"重点分析-1\"><a href=\"#重点分析-1\" class=\"headerlink\" title=\"重点分析\"></a>重点分析</h3><ol>\n<li>创建初始地图过程。首先创建关键帧和地图点，注意这里只会使用有深度的点进行初始化；然后通过将关键帧和地图点插入初始地图完成初始地图的构建。因为此初始化只用到一个图像帧，所以没有关键帧连接关系的更新和姿态的优化；</li>\n<li>其他同单目4、5、6条。</li>\n</ol>\n<blockquote>\n<p>疑问：初始化过程中，满足条件的第一个图像帧作为参考关键帧，后来帧都以该参考关键帧为参考吗？即参考关键帧会更新吗？</p>\n<p>答：后续的追踪过程还会有新的关键帧的插入（在<code>Tracking::CreateNewKeyFrame()中完成</code>），最新插入的关键帧作为参考关键帧的。即参考关键帧会更新，总是当前帧最临近的关键帧，或者说上一个关键帧。</p>\n</blockquote>\n<h2 id=\"初始化比较\"><a href=\"#初始化比较\" class=\"headerlink\" title=\"初始化比较\"></a>初始化比较</h2><p>单目初始化的特点是双目、RGD-D初始化过程不具备的。（废话么这不是()&gt; _ &lt;) ）单目初始化一定要有一定程度的平移。值得关注的一点是，在三者初始化之前图像帧的创建过程也是有区别的，单目不涉及深度和右图特征点成像平面坐标的计算，后两者需要此过程，这一点涉及到<code>mvuRight</code>、<code>mvDepth</code>这两个变量，详细的理解另作记录。</p>\n<h2 id=\"区分\"><a href=\"#区分\" class=\"headerlink\" title=\"区分\"></a>区分</h2><h3 id=\"图像帧相关\"><a href=\"#图像帧相关\" class=\"headerlink\" title=\"图像帧相关\"></a>图像帧相关</h3><ol>\n<li><p><code>上一帧mLastFrame</code>：即上一帧图像</p>\n</li>\n<li><p><code>上一关键帧mpLastKeyFrame</code>：最邻近当前帧的关键帧，不一定是上一帧，因为图像帧要经过判断后，满足条件才能称为关键帧</p>\n</li>\n<li><p><code>参考关键帧mpReferenceKF</code>：就是当前帧的上一关键帧；若创建了新的关键帧，参考关键帧就更新为新创建的关键帧；或者是局部地图中与当前帧共享地图点最多的关键帧。</p>\n<blockquote>\n<p>参考关键帧更新的时机</p>\n<ul>\n<li>创建新的关键帧时（初始化、追踪过程两处）</li>\n<li>TrackLocalMap()更新局部关键帧的过程中</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<ol>\n<li><code>当前帧的参考关键帧</code>：或者是上一关键帧，或者是由当前帧创建的关键帧（即当前帧满足关键帧创建的条件），或者是局部地图中与当前帧共享地图点最多的关键帧。</li>\n</ol>\n<h3 id=\"地图相关\"><a href=\"#地图相关\" class=\"headerlink\" title=\"地图相关\"></a>地图相关</h3><ol>\n<li><p>全局地图<code>mpMap</code></p>\n<p>是<code>Map</code>类的对象，本质上也是由关键帧和地图点组成。</p>\n</li>\n<li><p>局部地图</p>\n<p>局部地图不像全局地图一样有<code>Map</code>类表示，它只是一个概念叫法，其作用是在局部地图追踪过程中通过地图点重投影匹配关键点，进一步优化初步估计的当前帧位姿（是否还有其他作用？？？）。实际上它包括三个变量：</p>\n<ul>\n<li>参考关键帧<code>mpReferenceKF</code></li>\n<li>局部关键帧集合<code>mvpLocalKeyFrames</code></li>\n<li>局部地图点集合<code>mvpLocalMapPoints</code></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>局部建图线程接口指针<code>mpLocalMapper</code></p>\n<p>主要是和局部建图线程建立连接，给该线程传递关键帧并由其维护地图，也就是全局地图。</p>\n</li>\n</ol>\n<h3 id=\"地图点相关\"><a href=\"#地图点相关\" class=\"headerlink\" title=\"地图点相关\"></a>地图点相关</h3><p>地图点有两个私有成员变量<code>mnVisible</code>、<code>mnfound</code>，前者表示该地图点在图像帧视野范围内，在创建地图点时构造函数就将该值置为1；后者表示该地图点有对应特征点的图像帧帧数。通常来说，found的地图点一定是visible的，但是visible的地图点很可能not found。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6389129.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM 代码笔记（四）tracking代码结构</a></li>\n<li><a href=\"https://www.cnblogs.com/mybrave/p/9342952.html\" target=\"_blank\" rel=\"noopener\">单目、双目和RGB-D视觉SLAM初始化比较</a></li>\n<li>视觉SLAM十四讲P152</li>\n</ol>"},{"title":"ORB_SLAM2学习之源码分析八-单目初始化再学习","date":"2018-08-29T13:48:50.000Z","mathjax":true,"copyright":true,"_content":"\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目初始化过程中初始化器的工作，该过程通过对极几何方法计算基础矩阵、单应矩阵进而估计相机运动，再利用三角测量计算特征点的空间位置。\n\n<!--more--->\n\n## 概述\n\n单目初始化的内容定义在`Inlitializer.h`头文件中，该文件定义的内容都是用于单目的，因为双目和RGB-D不需要初始化。地图初始化的目的是得到两帧图像的相对运动$R$，$t$，然后根据相机运动和这两帧匹配好的关键点，三角化初始的三维地图。主要分为五个步骤。\n\n## 主要过程\n\n1. **特征提取与匹配。**在当前帧与参考帧之间（金字塔0层上）提取ORB特征，进行匹配，得到像素坐标下的匹配点，如果匹配点对数过少，就重置参考帧，在`Tracking::MonocularInitialization`中；\n\n2. **并行计算H矩阵和F矩阵。**H矩阵用于特征点都在同平面的情况，使用归一化的DLT（直接线性变换）（normalized DLT）方法、四个匹配点进行计算；F矩阵用于特征点不在同一平面的情况，使用归一化8点法。代码中随机的选8个点（当前帧和参考帧的8个匹配好的点对，一共8对），一共挑选200次（迭代次数），选出得分最高的$H$，$F$；得分计算方法如下：\n\n   {% asset_img 得分计算公式.png %}\n\n   具体解释：$M$可取$F$或$H$。我们以$M=F$为例，首先看到的是，$S_F$是一个累加。因为选了8个点，所以累加8次。$ρ_F$的计算已经给出。最重要的是$d^2$的计算， 是指把第一帧里面的每一个选中的点，重投影到第二帧后得到的重投影误差求平方，以及第二帧里面选中的投影到第一帧里面形成的重投影误差求平方。然后$Γ$ 取5.99，计算出得分。\n\n3. **使用打分机制选择模型。**如果场景接近平面，或者视差较小，可以使用单应性矩阵来解释。根据公式得到$R_H$  $RH>0.40$选择$H$，否则选择$F$。选择模型公式如下：\n\n   {% asset_img 模型打分公式.png %}\n\n4. **恢复出运动和地图的三维结构（sfm）。**利用选择的模型恢复运动和地图点，从$H$或$F$中分解出$R$和$T$，然后根据$R$，$T$三角化匹配好的关键点，得到这些关键点的3D坐标。这就是所谓的初始化地图。分解H矩阵可以恢复出8种姿态，SVD分解E矩阵也可以恢复出4种姿态，通过深度值以及场景的先验信息，一般可以得到唯一满足要求的。但是小视角情况下会出现判断错误的情况出现，因此ORB-SLAM中选择使用这些备选姿态直接三角化出地图点，再通过视角，深度以及重投影误差来判定是否有唯一解，若没有，则放弃，重新回到第一步去初始化。\n\n5. 若初始化成功，则进行**GlobalBundleAdjustment**。\n\n## 重要函数\n\n1. 构造函数：给出参考帧和迭代系数。\n\n   ~~~c++\n   Initializer(const Frame &ReferenceFrame, float sigma = 1.0, int iterations = 200);\n   ~~~\n\n2. 初始化器：单目初始化调用接口。\n\n   ~~~c++\n    bool Initialize(const Frame &CurrentFrame, const vector<int> &vMatches12,\n     cv::Mat &R21, cv::Mat &t21, vector<cv::Point3f> &vP3D, vector<bool> &vbTriangulated);\n   ~~~\n\n   ### 参数\n\n   - CurrentFrame：输入的参考帧                      \n   - vMatches12：输入的匹配\n   - R21：输出的旋转矩阵\n   - t21：输出的平移向量\n   - vP3D：输出的三维地图，即初始化的地图\n   - vbTriangulated：标记一组特征点能否进行三角化\n\n   ### 具体实现\n\n   首先找到参考帧和当前帧的配对关系。把这个一一对应关系放入**mvMatches12**变量。然后构造一个200行8列的二维数组mvSets。最后开启两个线程计算$H$，$F$。\n\n3. 单应矩阵和基础矩阵获取算法\n\n   ~~~c++\n   void FindHomography(vector<bool> &vbMatchesInliers, float &score, cv::Mat &H21);\n   ~~~\n\n   ~~~c++\n   void FindFundamental(vector<bool> &vbInliers, float &score, cv::Mat &F21);\n   ~~~\n\n   两个函数分别按照设定的规则获取单应矩阵和基础矩阵，它们的三个参数都是输出。\n\n   ### 具体实现\n\n   两个函数实现是类似的。首先将第一帧图像的关键点和第二帧图像的关键点全部normalize。然后，循环200次（默认的迭代次数），每次循环通过`ComputeH21`（`ComputeF21`）计算出单应矩阵（基础矩阵），并通过`CheckHomography`（`CheckFundamental`）计算它们的得分，找出最高的得分，以及最高得分对应的$H$（$F$）。\n\n4. 单应矩阵和基础矩阵计算函数\n\n   ~~~c++\n   cv::Mat ComputeH21(const vector<cv::Point2f> &vP1, const vector<cv::Point2f> &vP2);\n   ~~~\n\n   ~~~c++\n   cv::Mat ComputeF21(const vector<cv::Point2f> &vP1, const vector<cv::Point2f> &vP2);\n   ~~~\n\n   两个函数的参数都是输入，函数返回值就是$H$（$F$）矩阵。\n\n   ### 具体实现\n\n   根据8个点对，由对极约束或者是$H$的约束，获得$F$或$H$。具体可参考对极几何相关的内容。\n\n5. 单应矩阵和基础矩阵得分计算\n\n   ~~~c++\n   float CheckHomography(const cv::Mat &H21, const cv::Mat &H12, vector<bool> &vbMatchesInliers, float sigma);\n   ~~~\n\n   ~~~c++\n   float CheckFundamental(const cv::Mat &F21, vector<bool> &vbMatchesInliers, float sigma);\n   ~~~\n\n   两个函数输入单应矩阵（基础矩阵），输出相应的得分。\n\n   ### 具体实现\n\n   主要过程2内容的实现。\n\n6. 分解单应矩阵和基础矩阵恢复运动\n\n   ~~~c++\n   bool ReconstructH(vector<bool> &vbMatchesInliers, cv::Mat &H21, cv::Mat &K,\n                         cv::Mat &R21, cv::Mat &t21, vector<cv::Point3f> &vP3D, vector<bool> &vbTriangulated, float minParallax, int minTriangulated);\n   ~~~\n\n   ~~~c++\n   bool ReconstructF(vector<bool> &vbMatchesInliers, cv::Mat &F21, cv::Mat &K,\n                         cv::Mat &R21, cv::Mat &t21, vector<cv::Point3f> &vP3D, vector<bool> &vbTriangulated, float minParallax, int minTriangulated);\n   ~~~\n\n   ### 参数\n\n   - vbMatchesInliers：输入参数                                          \n   - F21：输入参数，计算得到的F矩阵\n   - K：输入参数，代表相机参数\n   - R21：输出的R\n   - t21：输出的t                                                                                      \n   - vP3D：输出的3D点\n   - vbTriangulated：输出，表示点是不是三角化了\n   - minParallax：输入，最小的视差\n   - minTriangulated：输入，最少需要三角化的点（50）\n\n   ### 具体实现\n\n   因为从$E$，$H$中直接分解出$R$和$T$是不唯一的，会分解出4种（8种）情况，这两个函数就是根据一些手段和先验知识恢复得到正确唯一的$R$和 $t$。其中`ReconstructF`函数首先通过基础矩阵计算得到本质矩阵，再使用`DecomposeE`计算$E$，然后完成验证解。\n\n7. 三角化\n\n   ~~~c++\n   void Triangulate(const cv::KeyPoint &kp1, const cv::KeyPoint &kp2, const cv::Mat &P1, const cv::Mat &P2, cv::Mat &x3D);\n   ~~~\n\n   三角化实现的函数。\n\n   ### 参数\n\n   - kp1：输入的第一帧关键点\n   - kp2：输入与第一帧匹配的第二帧关键点 \n   - P1 ：第一帧的相机参数KT\n   - P2：第二帧的相机参数KT\n   - x3D：输出的三角化的点\n\n8. 正则化\n\n   ~~~c++\n   void Normalize(const vector<cv::KeyPoint> &vKeys, vector<cv::Point2f> &vNormalizedPoints, cv::Mat &T);\n   ~~~\n\n   ### 参数\n\n   - vKeys：输入的关键点\n   - vNormalizedPoints：输出的点\n   - T：输出的T，在`void FindHomography(vector<bool> &vbMatchesInliers,  float &score, cv::Mat &H21);`和`void  FindFundamental(vector<bool> &vbInliers, float &score,  cv::Mat &F21);`函数里面用到。\n\n   ### 具体实现\n\n   首次算出输入的所有关键点的平均值`meanX`，`meanY`（关键点`x`，`y`的平均值）；\n\n   然后，每个关键点的`x`，`y`与这个平均值`meanX`，`meanY`做差，将所有得到的差值的绝对值加起来求平均值，得到`meanDevX`，`meanDevY`；\n\n   将上面那些差值除以`meanDevXm`，`meanDevY`，就得到输出的`vNormalizedPoints`。\n\n9. 检测视差、深度、重投影误差\n\n   ~~~c++\n   int CheckRT(const cv::Mat &R, const cv::Mat &t, \n               const vector<cv::KeyPoint> &vKeys1, \t\t\t\n               const vector<cv::KeyPoint> &vKeys2,\n               const vector<Match> &vMatches12, vector<bool> &vbInliers,\n               const cv::Mat &K, vector<cv::Point3f> &vP3D, float th2, vector<bool> \t\t\t\t&vbGood, float &parallax);\t\n   ~~~\n\n   ### 参数\n\n   - R：输入 1->2                                                      \n   - t ：输入 1->2\n   - vKeys1：输入         \n   - vKeys2：输入                            \n   - vMatches12：输入          \n   - vbInliers：输入      \n   - K：相机参数输入                                              \n   - vP3D：输出 \n   - th2  ：输入（重投影误差的平方误差）  \n   - vbGood ：输出                                                     \n   - parallax  ：输出视差\n\n   ### 具体实现\n\n   首先将第一个相机放在原点，构造两个3X4的矩阵，该矩阵等于相机参数$K$乘以该帧的$T$，得到第二个相机中心在第一个相机坐标系（可以看成世界坐标系）下的坐标；然后进入一个循环，循环每次都要计算视差；最后检测视差；分别检测两帧下的深度和重投影误差；返回3D点；返回视差。\n\n   > #### 关于视差\n   >\n   > 首先计算匹配好的点在世界坐标系下（第一个相机坐标系下）的3D坐标，从第一个相机中心出发连接这个3D点得到一条射线，从第二个相机的中心出发连接这个3D点得到一条射线，这两条射线之间的夹角就是视差(parallax)。\n\n10. 本质矩阵分解\n\n    ~~~c++\n    void Initializer::DecomposeE(const cv::Mat &E, cv::Mat &R1, cv::Mat &R2, cv::Mat &t)\n    ~~~\n\n    该函数实现本质矩阵$E$的分解。\n\n## 参考资料\n\n1. [ORB-SLAM2详解（三）自动地图初始化](https://blog.csdn.net/u010128736/article/details/53218140)\n2. [ORB-SLAM2学习4  initializer.h](https://www.cnblogs.com/panda1/p/7001105.html)\n3. [ORB-SLAM （四）Initializer单目初始化](https://www.cnblogs.com/shang-slam/p/6496411.html)","source":"_posts/ORB-SLAM2学习之源码分析八-单目初始化再学习.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析八-单目初始化再学习\ndate: 2018-08-29 21:48:50\ntags: \n  - ORB_SLAM2\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目初始化过程中初始化器的工作，该过程通过对极几何方法计算基础矩阵、单应矩阵进而估计相机运动，再利用三角测量计算特征点的空间位置。\n\n<!--more--->\n\n## 概述\n\n单目初始化的内容定义在`Inlitializer.h`头文件中，该文件定义的内容都是用于单目的，因为双目和RGB-D不需要初始化。地图初始化的目的是得到两帧图像的相对运动$R$，$t$，然后根据相机运动和这两帧匹配好的关键点，三角化初始的三维地图。主要分为五个步骤。\n\n## 主要过程\n\n1. **特征提取与匹配。**在当前帧与参考帧之间（金字塔0层上）提取ORB特征，进行匹配，得到像素坐标下的匹配点，如果匹配点对数过少，就重置参考帧，在`Tracking::MonocularInitialization`中；\n\n2. **并行计算H矩阵和F矩阵。**H矩阵用于特征点都在同平面的情况，使用归一化的DLT（直接线性变换）（normalized DLT）方法、四个匹配点进行计算；F矩阵用于特征点不在同一平面的情况，使用归一化8点法。代码中随机的选8个点（当前帧和参考帧的8个匹配好的点对，一共8对），一共挑选200次（迭代次数），选出得分最高的$H$，$F$；得分计算方法如下：\n\n   {% asset_img 得分计算公式.png %}\n\n   具体解释：$M$可取$F$或$H$。我们以$M=F$为例，首先看到的是，$S_F$是一个累加。因为选了8个点，所以累加8次。$ρ_F$的计算已经给出。最重要的是$d^2$的计算， 是指把第一帧里面的每一个选中的点，重投影到第二帧后得到的重投影误差求平方，以及第二帧里面选中的投影到第一帧里面形成的重投影误差求平方。然后$Γ$ 取5.99，计算出得分。\n\n3. **使用打分机制选择模型。**如果场景接近平面，或者视差较小，可以使用单应性矩阵来解释。根据公式得到$R_H$  $RH>0.40$选择$H$，否则选择$F$。选择模型公式如下：\n\n   {% asset_img 模型打分公式.png %}\n\n4. **恢复出运动和地图的三维结构（sfm）。**利用选择的模型恢复运动和地图点，从$H$或$F$中分解出$R$和$T$，然后根据$R$，$T$三角化匹配好的关键点，得到这些关键点的3D坐标。这就是所谓的初始化地图。分解H矩阵可以恢复出8种姿态，SVD分解E矩阵也可以恢复出4种姿态，通过深度值以及场景的先验信息，一般可以得到唯一满足要求的。但是小视角情况下会出现判断错误的情况出现，因此ORB-SLAM中选择使用这些备选姿态直接三角化出地图点，再通过视角，深度以及重投影误差来判定是否有唯一解，若没有，则放弃，重新回到第一步去初始化。\n\n5. 若初始化成功，则进行**GlobalBundleAdjustment**。\n\n## 重要函数\n\n1. 构造函数：给出参考帧和迭代系数。\n\n   ~~~c++\n   Initializer(const Frame &ReferenceFrame, float sigma = 1.0, int iterations = 200);\n   ~~~\n\n2. 初始化器：单目初始化调用接口。\n\n   ~~~c++\n    bool Initialize(const Frame &CurrentFrame, const vector<int> &vMatches12,\n     cv::Mat &R21, cv::Mat &t21, vector<cv::Point3f> &vP3D, vector<bool> &vbTriangulated);\n   ~~~\n\n   ### 参数\n\n   - CurrentFrame：输入的参考帧                      \n   - vMatches12：输入的匹配\n   - R21：输出的旋转矩阵\n   - t21：输出的平移向量\n   - vP3D：输出的三维地图，即初始化的地图\n   - vbTriangulated：标记一组特征点能否进行三角化\n\n   ### 具体实现\n\n   首先找到参考帧和当前帧的配对关系。把这个一一对应关系放入**mvMatches12**变量。然后构造一个200行8列的二维数组mvSets。最后开启两个线程计算$H$，$F$。\n\n3. 单应矩阵和基础矩阵获取算法\n\n   ~~~c++\n   void FindHomography(vector<bool> &vbMatchesInliers, float &score, cv::Mat &H21);\n   ~~~\n\n   ~~~c++\n   void FindFundamental(vector<bool> &vbInliers, float &score, cv::Mat &F21);\n   ~~~\n\n   两个函数分别按照设定的规则获取单应矩阵和基础矩阵，它们的三个参数都是输出。\n\n   ### 具体实现\n\n   两个函数实现是类似的。首先将第一帧图像的关键点和第二帧图像的关键点全部normalize。然后，循环200次（默认的迭代次数），每次循环通过`ComputeH21`（`ComputeF21`）计算出单应矩阵（基础矩阵），并通过`CheckHomography`（`CheckFundamental`）计算它们的得分，找出最高的得分，以及最高得分对应的$H$（$F$）。\n\n4. 单应矩阵和基础矩阵计算函数\n\n   ~~~c++\n   cv::Mat ComputeH21(const vector<cv::Point2f> &vP1, const vector<cv::Point2f> &vP2);\n   ~~~\n\n   ~~~c++\n   cv::Mat ComputeF21(const vector<cv::Point2f> &vP1, const vector<cv::Point2f> &vP2);\n   ~~~\n\n   两个函数的参数都是输入，函数返回值就是$H$（$F$）矩阵。\n\n   ### 具体实现\n\n   根据8个点对，由对极约束或者是$H$的约束，获得$F$或$H$。具体可参考对极几何相关的内容。\n\n5. 单应矩阵和基础矩阵得分计算\n\n   ~~~c++\n   float CheckHomography(const cv::Mat &H21, const cv::Mat &H12, vector<bool> &vbMatchesInliers, float sigma);\n   ~~~\n\n   ~~~c++\n   float CheckFundamental(const cv::Mat &F21, vector<bool> &vbMatchesInliers, float sigma);\n   ~~~\n\n   两个函数输入单应矩阵（基础矩阵），输出相应的得分。\n\n   ### 具体实现\n\n   主要过程2内容的实现。\n\n6. 分解单应矩阵和基础矩阵恢复运动\n\n   ~~~c++\n   bool ReconstructH(vector<bool> &vbMatchesInliers, cv::Mat &H21, cv::Mat &K,\n                         cv::Mat &R21, cv::Mat &t21, vector<cv::Point3f> &vP3D, vector<bool> &vbTriangulated, float minParallax, int minTriangulated);\n   ~~~\n\n   ~~~c++\n   bool ReconstructF(vector<bool> &vbMatchesInliers, cv::Mat &F21, cv::Mat &K,\n                         cv::Mat &R21, cv::Mat &t21, vector<cv::Point3f> &vP3D, vector<bool> &vbTriangulated, float minParallax, int minTriangulated);\n   ~~~\n\n   ### 参数\n\n   - vbMatchesInliers：输入参数                                          \n   - F21：输入参数，计算得到的F矩阵\n   - K：输入参数，代表相机参数\n   - R21：输出的R\n   - t21：输出的t                                                                                      \n   - vP3D：输出的3D点\n   - vbTriangulated：输出，表示点是不是三角化了\n   - minParallax：输入，最小的视差\n   - minTriangulated：输入，最少需要三角化的点（50）\n\n   ### 具体实现\n\n   因为从$E$，$H$中直接分解出$R$和$T$是不唯一的，会分解出4种（8种）情况，这两个函数就是根据一些手段和先验知识恢复得到正确唯一的$R$和 $t$。其中`ReconstructF`函数首先通过基础矩阵计算得到本质矩阵，再使用`DecomposeE`计算$E$，然后完成验证解。\n\n7. 三角化\n\n   ~~~c++\n   void Triangulate(const cv::KeyPoint &kp1, const cv::KeyPoint &kp2, const cv::Mat &P1, const cv::Mat &P2, cv::Mat &x3D);\n   ~~~\n\n   三角化实现的函数。\n\n   ### 参数\n\n   - kp1：输入的第一帧关键点\n   - kp2：输入与第一帧匹配的第二帧关键点 \n   - P1 ：第一帧的相机参数KT\n   - P2：第二帧的相机参数KT\n   - x3D：输出的三角化的点\n\n8. 正则化\n\n   ~~~c++\n   void Normalize(const vector<cv::KeyPoint> &vKeys, vector<cv::Point2f> &vNormalizedPoints, cv::Mat &T);\n   ~~~\n\n   ### 参数\n\n   - vKeys：输入的关键点\n   - vNormalizedPoints：输出的点\n   - T：输出的T，在`void FindHomography(vector<bool> &vbMatchesInliers,  float &score, cv::Mat &H21);`和`void  FindFundamental(vector<bool> &vbInliers, float &score,  cv::Mat &F21);`函数里面用到。\n\n   ### 具体实现\n\n   首次算出输入的所有关键点的平均值`meanX`，`meanY`（关键点`x`，`y`的平均值）；\n\n   然后，每个关键点的`x`，`y`与这个平均值`meanX`，`meanY`做差，将所有得到的差值的绝对值加起来求平均值，得到`meanDevX`，`meanDevY`；\n\n   将上面那些差值除以`meanDevXm`，`meanDevY`，就得到输出的`vNormalizedPoints`。\n\n9. 检测视差、深度、重投影误差\n\n   ~~~c++\n   int CheckRT(const cv::Mat &R, const cv::Mat &t, \n               const vector<cv::KeyPoint> &vKeys1, \t\t\t\n               const vector<cv::KeyPoint> &vKeys2,\n               const vector<Match> &vMatches12, vector<bool> &vbInliers,\n               const cv::Mat &K, vector<cv::Point3f> &vP3D, float th2, vector<bool> \t\t\t\t&vbGood, float &parallax);\t\n   ~~~\n\n   ### 参数\n\n   - R：输入 1->2                                                      \n   - t ：输入 1->2\n   - vKeys1：输入         \n   - vKeys2：输入                            \n   - vMatches12：输入          \n   - vbInliers：输入      \n   - K：相机参数输入                                              \n   - vP3D：输出 \n   - th2  ：输入（重投影误差的平方误差）  \n   - vbGood ：输出                                                     \n   - parallax  ：输出视差\n\n   ### 具体实现\n\n   首先将第一个相机放在原点，构造两个3X4的矩阵，该矩阵等于相机参数$K$乘以该帧的$T$，得到第二个相机中心在第一个相机坐标系（可以看成世界坐标系）下的坐标；然后进入一个循环，循环每次都要计算视差；最后检测视差；分别检测两帧下的深度和重投影误差；返回3D点；返回视差。\n\n   > #### 关于视差\n   >\n   > 首先计算匹配好的点在世界坐标系下（第一个相机坐标系下）的3D坐标，从第一个相机中心出发连接这个3D点得到一条射线，从第二个相机的中心出发连接这个3D点得到一条射线，这两条射线之间的夹角就是视差(parallax)。\n\n10. 本质矩阵分解\n\n    ~~~c++\n    void Initializer::DecomposeE(const cv::Mat &E, cv::Mat &R1, cv::Mat &R2, cv::Mat &t)\n    ~~~\n\n    该函数实现本质矩阵$E$的分解。\n\n## 参考资料\n\n1. [ORB-SLAM2详解（三）自动地图初始化](https://blog.csdn.net/u010128736/article/details/53218140)\n2. [ORB-SLAM2学习4  initializer.h](https://www.cnblogs.com/panda1/p/7001105.html)\n3. [ORB-SLAM （四）Initializer单目初始化](https://www.cnblogs.com/shang-slam/p/6496411.html)","slug":"ORB-SLAM2学习之源码分析八-单目初始化再学习","published":1,"updated":"2019-05-30T12:29:26.283Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyp00b9qlcrhvvirpkf","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目初始化过程中初始化器的工作，该过程通过对极几何方法计算基础矩阵、单应矩阵进而估计相机运动，再利用三角测量计算特征点的空间位置。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>单目初始化的内容定义在<code>Inlitializer.h</code>头文件中，该文件定义的内容都是用于单目的，因为双目和RGB-D不需要初始化。地图初始化的目的是得到两帧图像的相对运动$R$，$t$，然后根据相机运动和这两帧匹配好的关键点，三角化初始的三维地图。主要分为五个步骤。</p>\n<h2 id=\"主要过程\"><a href=\"#主要过程\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h2><ol>\n<li><p><strong>特征提取与匹配。</strong>在当前帧与参考帧之间（金字塔0层上）提取ORB特征，进行匹配，得到像素坐标下的匹配点，如果匹配点对数过少，就重置参考帧，在<code>Tracking::MonocularInitialization</code>中；</p>\n</li>\n<li><p><strong>并行计算H矩阵和F矩阵。</strong>H矩阵用于特征点都在同平面的情况，使用归一化的DLT（直接线性变换）（normalized DLT）方法、四个匹配点进行计算；F矩阵用于特征点不在同一平面的情况，使用归一化8点法。代码中随机的选8个点（当前帧和参考帧的8个匹配好的点对，一共8对），一共挑选200次（迭代次数），选出得分最高的$H$，$F$；得分计算方法如下：</p>\n<img src=\"/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/得分计算公式.png\">\n<p>具体解释：$M$可取$F$或$H$。我们以$M=F$为例，首先看到的是，$S_F$是一个累加。因为选了8个点，所以累加8次。$ρ_F$的计算已经给出。最重要的是$d^2$的计算， 是指把第一帧里面的每一个选中的点，重投影到第二帧后得到的重投影误差求平方，以及第二帧里面选中的投影到第一帧里面形成的重投影误差求平方。然后$Γ$ 取5.99，计算出得分。</p>\n</li>\n<li><p><strong>使用打分机制选择模型。</strong>如果场景接近平面，或者视差较小，可以使用单应性矩阵来解释。根据公式得到$R_H$  $RH&gt;0.40$选择$H$，否则选择$F$。选择模型公式如下：</p>\n<img src=\"/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/模型打分公式.png\">\n</li>\n<li><p><strong>恢复出运动和地图的三维结构（sfm）。</strong>利用选择的模型恢复运动和地图点，从$H$或$F$中分解出$R$和$T$，然后根据$R$，$T$三角化匹配好的关键点，得到这些关键点的3D坐标。这就是所谓的初始化地图。分解H矩阵可以恢复出8种姿态，SVD分解E矩阵也可以恢复出4种姿态，通过深度值以及场景的先验信息，一般可以得到唯一满足要求的。但是小视角情况下会出现判断错误的情况出现，因此ORB-SLAM中选择使用这些备选姿态直接三角化出地图点，再通过视角，深度以及重投影误差来判定是否有唯一解，若没有，则放弃，重新回到第一步去初始化。</p>\n</li>\n<li><p>若初始化成功，则进行<strong>GlobalBundleAdjustment</strong>。</p>\n</li>\n</ol>\n<h2 id=\"重要函数\"><a href=\"#重要函数\" class=\"headerlink\" title=\"重要函数\"></a>重要函数</h2><ol>\n<li><p>构造函数：给出参考帧和迭代系数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Initializer(<span class=\"keyword\">const</span> Frame &amp;ReferenceFrame, <span class=\"keyword\">float</span> sigma = <span class=\"number\">1.0</span>, <span class=\"keyword\">int</span> iterations = <span class=\"number\">200</span>);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>初始化器：单目初始化调用接口。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Initialize</span><span class=\"params\">(<span class=\"keyword\">const</span> Frame &amp;CurrentFrame, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;vMatches12,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"> cv::Mat &amp;R21, cv::Mat &amp;t21, <span class=\"built_in\">vector</span>&lt;cv::Point3f&gt; &amp;vP3D, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbTriangulated)</span></span>;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>CurrentFrame：输入的参考帧                      </li>\n<li>vMatches12：输入的匹配</li>\n<li>R21：输出的旋转矩阵</li>\n<li>t21：输出的平移向量</li>\n<li>vP3D：输出的三维地图，即初始化的地图</li>\n<li>vbTriangulated：标记一组特征点能否进行三角化</li>\n</ul>\n<h3 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>首先找到参考帧和当前帧的配对关系。把这个一一对应关系放入<strong>mvMatches12</strong>变量。然后构造一个200行8列的二维数组mvSets。最后开启两个线程计算$H$，$F$。</p>\n</li>\n<li><p>单应矩阵和基础矩阵获取算法</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">FindHomography</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbMatchesInliers, <span class=\"keyword\">float</span> &amp;score, cv::Mat &amp;H21)</span></span>;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">FindFundamental</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbInliers, <span class=\"keyword\">float</span> &amp;score, cv::Mat &amp;F21)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>两个函数分别按照设定的规则获取单应矩阵和基础矩阵，它们的三个参数都是输出。</p>\n<h3 id=\"具体实现-1\"><a href=\"#具体实现-1\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>两个函数实现是类似的。首先将第一帧图像的关键点和第二帧图像的关键点全部normalize。然后，循环200次（默认的迭代次数），每次循环通过<code>ComputeH21</code>（<code>ComputeF21</code>）计算出单应矩阵（基础矩阵），并通过<code>CheckHomography</code>（<code>CheckFundamental</code>）计算它们的得分，找出最高的得分，以及最高得分对应的$H$（$F$）。</p>\n</li>\n<li><p>单应矩阵和基础矩阵计算函数</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cv::<span class=\"function\">Mat <span class=\"title\">ComputeH21</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::Point2f&gt; &amp;vP1, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::Point2f&gt; &amp;vP2)</span></span>;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cv::<span class=\"function\">Mat <span class=\"title\">ComputeF21</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::Point2f&gt; &amp;vP1, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::Point2f&gt; &amp;vP2)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>两个函数的参数都是输入，函数返回值就是$H$（$F$）矩阵。</p>\n<h3 id=\"具体实现-2\"><a href=\"#具体实现-2\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>根据8个点对，由对极约束或者是$H$的约束，获得$F$或$H$。具体可参考对极几何相关的内容。</p>\n</li>\n<li><p>单应矩阵和基础矩阵得分计算</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">float</span> <span class=\"title\">CheckHomography</span><span class=\"params\">(<span class=\"keyword\">const</span> cv::Mat &amp;H21, <span class=\"keyword\">const</span> cv::Mat &amp;H12, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbMatchesInliers, <span class=\"keyword\">float</span> sigma)</span></span>;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">float</span> <span class=\"title\">CheckFundamental</span><span class=\"params\">(<span class=\"keyword\">const</span> cv::Mat &amp;F21, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbMatchesInliers, <span class=\"keyword\">float</span> sigma)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>两个函数输入单应矩阵（基础矩阵），输出相应的得分。</p>\n<h3 id=\"具体实现-3\"><a href=\"#具体实现-3\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>主要过程2内容的实现。</p>\n</li>\n<li><p>分解单应矩阵和基础矩阵恢复运动</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">ReconstructH</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbMatchesInliers, cv::Mat &amp;H21, cv::Mat &amp;K,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                      cv::Mat &amp;R21, cv::Mat &amp;t21, <span class=\"built_in\">vector</span>&lt;cv::Point3f&gt; &amp;vP3D, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbTriangulated, <span class=\"keyword\">float</span> minParallax, <span class=\"keyword\">int</span> minTriangulated)</span></span>;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">ReconstructF</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbMatchesInliers, cv::Mat &amp;F21, cv::Mat &amp;K,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                      cv::Mat &amp;R21, cv::Mat &amp;t21, <span class=\"built_in\">vector</span>&lt;cv::Point3f&gt; &amp;vP3D, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbTriangulated, <span class=\"keyword\">float</span> minParallax, <span class=\"keyword\">int</span> minTriangulated)</span></span>;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数-1\"><a href=\"#参数-1\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>vbMatchesInliers：输入参数                                          </li>\n<li>F21：输入参数，计算得到的F矩阵</li>\n<li>K：输入参数，代表相机参数</li>\n<li>R21：输出的R</li>\n<li>t21：输出的t                                                                                      </li>\n<li>vP3D：输出的3D点</li>\n<li>vbTriangulated：输出，表示点是不是三角化了</li>\n<li>minParallax：输入，最小的视差</li>\n<li>minTriangulated：输入，最少需要三角化的点（50）</li>\n</ul>\n<h3 id=\"具体实现-4\"><a href=\"#具体实现-4\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>因为从$E$，$H$中直接分解出$R$和$T$是不唯一的，会分解出4种（8种）情况，这两个函数就是根据一些手段和先验知识恢复得到正确唯一的$R$和 $t$。其中<code>ReconstructF</code>函数首先通过基础矩阵计算得到本质矩阵，再使用<code>DecomposeE</code>计算$E$，然后完成验证解。</p>\n</li>\n<li><p>三角化</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Triangulate</span><span class=\"params\">(<span class=\"keyword\">const</span> cv::KeyPoint &amp;kp1, <span class=\"keyword\">const</span> cv::KeyPoint &amp;kp2, <span class=\"keyword\">const</span> cv::Mat &amp;P1, <span class=\"keyword\">const</span> cv::Mat &amp;P2, cv::Mat &amp;x3D)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>三角化实现的函数。</p>\n<h3 id=\"参数-2\"><a href=\"#参数-2\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>kp1：输入的第一帧关键点</li>\n<li>kp2：输入与第一帧匹配的第二帧关键点 </li>\n<li>P1 ：第一帧的相机参数KT</li>\n<li>P2：第二帧的相机参数KT</li>\n<li>x3D：输出的三角化的点</li>\n</ul>\n</li>\n<li><p>正则化</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Normalize</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::KeyPoint&gt; &amp;vKeys, <span class=\"built_in\">vector</span>&lt;cv::Point2f&gt; &amp;vNormalizedPoints, cv::Mat &amp;T)</span></span>;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数-3\"><a href=\"#参数-3\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>vKeys：输入的关键点</li>\n<li>vNormalizedPoints：输出的点</li>\n<li>T：输出的T，在<code>void FindHomography(vector&lt;bool&gt; &amp;vbMatchesInliers,  float &amp;score, cv::Mat &amp;H21);</code>和<code>void  FindFundamental(vector&lt;bool&gt; &amp;vbInliers, float &amp;score,  cv::Mat &amp;F21);</code>函数里面用到。</li>\n</ul>\n<h3 id=\"具体实现-5\"><a href=\"#具体实现-5\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>首次算出输入的所有关键点的平均值<code>meanX</code>，<code>meanY</code>（关键点<code>x</code>，<code>y</code>的平均值）；</p>\n<p>然后，每个关键点的<code>x</code>，<code>y</code>与这个平均值<code>meanX</code>，<code>meanY</code>做差，将所有得到的差值的绝对值加起来求平均值，得到<code>meanDevX</code>，<code>meanDevY</code>；</p>\n<p>将上面那些差值除以<code>meanDevXm</code>，<code>meanDevY</code>，就得到输出的<code>vNormalizedPoints</code>。</p>\n</li>\n<li><p>检测视差、深度、重投影误差</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">CheckRT</span><span class=\"params\">(<span class=\"keyword\">const</span> cv::Mat &amp;R, <span class=\"keyword\">const</span> cv::Mat &amp;t, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">            <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::KeyPoint&gt; &amp;vKeys1, \t\t\t</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">            <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;cv::KeyPoint&gt; &amp;vKeys2,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">            <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Match&gt; &amp;vMatches12, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; &amp;vbInliers,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">            <span class=\"keyword\">const</span> cv::Mat &amp;K, <span class=\"built_in\">vector</span>&lt;cv::Point3f&gt; &amp;vP3D, <span class=\"keyword\">float</span> th2, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt; \t\t\t\t&amp;vbGood, <span class=\"keyword\">float</span> &amp;parallax)</span></span>;</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数-4\"><a href=\"#参数-4\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>R：输入 1-&gt;2                                                      </li>\n<li>t ：输入 1-&gt;2</li>\n<li>vKeys1：输入         </li>\n<li>vKeys2：输入                            </li>\n<li>vMatches12：输入          </li>\n<li>vbInliers：输入      </li>\n<li>K：相机参数输入                                              </li>\n<li>vP3D：输出 </li>\n<li>th2  ：输入（重投影误差的平方误差）  </li>\n<li>vbGood ：输出                                                     </li>\n<li>parallax  ：输出视差</li>\n</ul>\n<h3 id=\"具体实现-6\"><a href=\"#具体实现-6\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>首先将第一个相机放在原点，构造两个3X4的矩阵，该矩阵等于相机参数$K$乘以该帧的$T$，得到第二个相机中心在第一个相机坐标系（可以看成世界坐标系）下的坐标；然后进入一个循环，循环每次都要计算视差；最后检测视差；分别检测两帧下的深度和重投影误差；返回3D点；返回视差。</p>\n<blockquote>\n<h4 id=\"关于视差\"><a href=\"#关于视差\" class=\"headerlink\" title=\"关于视差\"></a>关于视差</h4><p>首先计算匹配好的点在世界坐标系下（第一个相机坐标系下）的3D坐标，从第一个相机中心出发连接这个3D点得到一条射线，从第二个相机的中心出发连接这个3D点得到一条射线，这两条射线之间的夹角就是视差(parallax)。</p>\n</blockquote>\n</li>\n<li><p>本质矩阵分解</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> Initializer::DecomposeE(<span class=\"keyword\">const</span> cv::Mat &amp;E, cv::Mat &amp;R1, cv::Mat &amp;R2, cv::Mat &amp;t)</span><br></pre></td></tr></table></figure>\n<p>该函数实现本质矩阵$E$的分解。</p>\n</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/u010128736/article/details/53218140\" target=\"_blank\" rel=\"noopener\">ORB-SLAM2详解（三）自动地图初始化</a></li>\n<li><a href=\"https://www.cnblogs.com/panda1/p/7001105.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM2学习4  initializer.h</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6496411.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM （四）Initializer单目初始化</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录单目初始化过程中初始化器的工作，该过程通过对极几何方法计算基础矩阵、单应矩阵进而估计相机运动，再利用三角测量计算特征点的空间位置。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>单目初始化的内容定义在<code>Inlitializer.h</code>头文件中，该文件定义的内容都是用于单目的，因为双目和RGB-D不需要初始化。地图初始化的目的是得到两帧图像的相对运动$R$，$t$，然后根据相机运动和这两帧匹配好的关键点，三角化初始的三维地图。主要分为五个步骤。</p>\n<h2 id=\"主要过程\"><a href=\"#主要过程\" class=\"headerlink\" title=\"主要过程\"></a>主要过程</h2><ol>\n<li><p><strong>特征提取与匹配。</strong>在当前帧与参考帧之间（金字塔0层上）提取ORB特征，进行匹配，得到像素坐标下的匹配点，如果匹配点对数过少，就重置参考帧，在<code>Tracking::MonocularInitialization</code>中；</p>\n</li>\n<li><p><strong>并行计算H矩阵和F矩阵。</strong>H矩阵用于特征点都在同平面的情况，使用归一化的DLT（直接线性变换）（normalized DLT）方法、四个匹配点进行计算；F矩阵用于特征点不在同一平面的情况，使用归一化8点法。代码中随机的选8个点（当前帧和参考帧的8个匹配好的点对，一共8对），一共挑选200次（迭代次数），选出得分最高的$H$，$F$；得分计算方法如下：</p>\n<img src=\"/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/得分计算公式.png\">\n<p>具体解释：$M$可取$F$或$H$。我们以$M=F$为例，首先看到的是，$S_F$是一个累加。因为选了8个点，所以累加8次。$ρ_F$的计算已经给出。最重要的是$d^2$的计算， 是指把第一帧里面的每一个选中的点，重投影到第二帧后得到的重投影误差求平方，以及第二帧里面选中的投影到第一帧里面形成的重投影误差求平方。然后$Γ$ 取5.99，计算出得分。</p>\n</li>\n<li><p><strong>使用打分机制选择模型。</strong>如果场景接近平面，或者视差较小，可以使用单应性矩阵来解释。根据公式得到$R_H$  $RH&gt;0.40$选择$H$，否则选择$F$。选择模型公式如下：</p>\n<img src=\"/2018/08/29/ORB-SLAM2学习之源码分析八-单目初始化再学习/模型打分公式.png\">\n</li>\n<li><p><strong>恢复出运动和地图的三维结构（sfm）。</strong>利用选择的模型恢复运动和地图点，从$H$或$F$中分解出$R$和$T$，然后根据$R$，$T$三角化匹配好的关键点，得到这些关键点的3D坐标。这就是所谓的初始化地图。分解H矩阵可以恢复出8种姿态，SVD分解E矩阵也可以恢复出4种姿态，通过深度值以及场景的先验信息，一般可以得到唯一满足要求的。但是小视角情况下会出现判断错误的情况出现，因此ORB-SLAM中选择使用这些备选姿态直接三角化出地图点，再通过视角，深度以及重投影误差来判定是否有唯一解，若没有，则放弃，重新回到第一步去初始化。</p>\n</li>\n<li><p>若初始化成功，则进行<strong>GlobalBundleAdjustment</strong>。</p>\n</li>\n</ol>\n<h2 id=\"重要函数\"><a href=\"#重要函数\" class=\"headerlink\" title=\"重要函数\"></a>重要函数</h2><ol>\n<li><p>构造函数：给出参考帧和迭代系数。</p>\n<!--�142-->\n</li>\n<li><p>初始化器：单目初始化调用接口。</p>\n<!--�143-->\n<h3 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>CurrentFrame：输入的参考帧                      </li>\n<li>vMatches12：输入的匹配</li>\n<li>R21：输出的旋转矩阵</li>\n<li>t21：输出的平移向量</li>\n<li>vP3D：输出的三维地图，即初始化的地图</li>\n<li>vbTriangulated：标记一组特征点能否进行三角化</li>\n</ul>\n<h3 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>首先找到参考帧和当前帧的配对关系。把这个一一对应关系放入<strong>mvMatches12</strong>变量。然后构造一个200行8列的二维数组mvSets。最后开启两个线程计算$H$，$F$。</p>\n</li>\n<li><p>单应矩阵和基础矩阵获取算法</p>\n<!--�144-->\n<!--�145-->\n<p>两个函数分别按照设定的规则获取单应矩阵和基础矩阵，它们的三个参数都是输出。</p>\n<h3 id=\"具体实现-1\"><a href=\"#具体实现-1\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>两个函数实现是类似的。首先将第一帧图像的关键点和第二帧图像的关键点全部normalize。然后，循环200次（默认的迭代次数），每次循环通过<code>ComputeH21</code>（<code>ComputeF21</code>）计算出单应矩阵（基础矩阵），并通过<code>CheckHomography</code>（<code>CheckFundamental</code>）计算它们的得分，找出最高的得分，以及最高得分对应的$H$（$F$）。</p>\n</li>\n<li><p>单应矩阵和基础矩阵计算函数</p>\n<!--�146-->\n<!--�147-->\n<p>两个函数的参数都是输入，函数返回值就是$H$（$F$）矩阵。</p>\n<h3 id=\"具体实现-2\"><a href=\"#具体实现-2\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>根据8个点对，由对极约束或者是$H$的约束，获得$F$或$H$。具体可参考对极几何相关的内容。</p>\n</li>\n<li><p>单应矩阵和基础矩阵得分计算</p>\n<!--�148-->\n<!--�149-->\n<p>两个函数输入单应矩阵（基础矩阵），输出相应的得分。</p>\n<h3 id=\"具体实现-3\"><a href=\"#具体实现-3\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>主要过程2内容的实现。</p>\n</li>\n<li><p>分解单应矩阵和基础矩阵恢复运动</p>\n<!--�150-->\n<!--�151-->\n<h3 id=\"参数-1\"><a href=\"#参数-1\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>vbMatchesInliers：输入参数                                          </li>\n<li>F21：输入参数，计算得到的F矩阵</li>\n<li>K：输入参数，代表相机参数</li>\n<li>R21：输出的R</li>\n<li>t21：输出的t                                                                                      </li>\n<li>vP3D：输出的3D点</li>\n<li>vbTriangulated：输出，表示点是不是三角化了</li>\n<li>minParallax：输入，最小的视差</li>\n<li>minTriangulated：输入，最少需要三角化的点（50）</li>\n</ul>\n<h3 id=\"具体实现-4\"><a href=\"#具体实现-4\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>因为从$E$，$H$中直接分解出$R$和$T$是不唯一的，会分解出4种（8种）情况，这两个函数就是根据一些手段和先验知识恢复得到正确唯一的$R$和 $t$。其中<code>ReconstructF</code>函数首先通过基础矩阵计算得到本质矩阵，再使用<code>DecomposeE</code>计算$E$，然后完成验证解。</p>\n</li>\n<li><p>三角化</p>\n<!--�152-->\n<p>三角化实现的函数。</p>\n<h3 id=\"参数-2\"><a href=\"#参数-2\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>kp1：输入的第一帧关键点</li>\n<li>kp2：输入与第一帧匹配的第二帧关键点 </li>\n<li>P1 ：第一帧的相机参数KT</li>\n<li>P2：第二帧的相机参数KT</li>\n<li>x3D：输出的三角化的点</li>\n</ul>\n</li>\n<li><p>正则化</p>\n<!--�153-->\n<h3 id=\"参数-3\"><a href=\"#参数-3\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>vKeys：输入的关键点</li>\n<li>vNormalizedPoints：输出的点</li>\n<li>T：输出的T，在<code>void FindHomography(vector&lt;bool&gt; &amp;vbMatchesInliers,  float &amp;score, cv::Mat &amp;H21);</code>和<code>void  FindFundamental(vector&lt;bool&gt; &amp;vbInliers, float &amp;score,  cv::Mat &amp;F21);</code>函数里面用到。</li>\n</ul>\n<h3 id=\"具体实现-5\"><a href=\"#具体实现-5\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>首次算出输入的所有关键点的平均值<code>meanX</code>，<code>meanY</code>（关键点<code>x</code>，<code>y</code>的平均值）；</p>\n<p>然后，每个关键点的<code>x</code>，<code>y</code>与这个平均值<code>meanX</code>，<code>meanY</code>做差，将所有得到的差值的绝对值加起来求平均值，得到<code>meanDevX</code>，<code>meanDevY</code>；</p>\n<p>将上面那些差值除以<code>meanDevXm</code>，<code>meanDevY</code>，就得到输出的<code>vNormalizedPoints</code>。</p>\n</li>\n<li><p>检测视差、深度、重投影误差</p>\n<!--�154-->\n<h3 id=\"参数-4\"><a href=\"#参数-4\" class=\"headerlink\" title=\"参数\"></a>参数</h3><ul>\n<li>R：输入 1-&gt;2                                                      </li>\n<li>t ：输入 1-&gt;2</li>\n<li>vKeys1：输入         </li>\n<li>vKeys2：输入                            </li>\n<li>vMatches12：输入          </li>\n<li>vbInliers：输入      </li>\n<li>K：相机参数输入                                              </li>\n<li>vP3D：输出 </li>\n<li>th2  ：输入（重投影误差的平方误差）  </li>\n<li>vbGood ：输出                                                     </li>\n<li>parallax  ：输出视差</li>\n</ul>\n<h3 id=\"具体实现-6\"><a href=\"#具体实现-6\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h3><p>首先将第一个相机放在原点，构造两个3X4的矩阵，该矩阵等于相机参数$K$乘以该帧的$T$，得到第二个相机中心在第一个相机坐标系（可以看成世界坐标系）下的坐标；然后进入一个循环，循环每次都要计算视差；最后检测视差；分别检测两帧下的深度和重投影误差；返回3D点；返回视差。</p>\n<blockquote>\n<h4 id=\"关于视差\"><a href=\"#关于视差\" class=\"headerlink\" title=\"关于视差\"></a>关于视差</h4><p>首先计算匹配好的点在世界坐标系下（第一个相机坐标系下）的3D坐标，从第一个相机中心出发连接这个3D点得到一条射线，从第二个相机的中心出发连接这个3D点得到一条射线，这两条射线之间的夹角就是视差(parallax)。</p>\n</blockquote>\n</li>\n<li><p>本质矩阵分解</p>\n<!--�155-->\n<p>该函数实现本质矩阵$E$的分解。</p>\n</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://blog.csdn.net/u010128736/article/details/53218140\" target=\"_blank\" rel=\"noopener\">ORB-SLAM2详解（三）自动地图初始化</a></li>\n<li><a href=\"https://www.cnblogs.com/panda1/p/7001105.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM2学习4  initializer.h</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6496411.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM （四）Initializer单目初始化</a></li>\n</ol>"},{"title":"C++学习之字符和字符串","date":"2018-03-23T02:30:56.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++字符和字符串的学习内容。\n\n<!---more-->\n\n上午给大一的C++课学生答疑，一个学弟在做“福尔摩斯的密码”问题，程序里面字符数组的定义出现了错误，他的定义是：`char b[7][4] = {'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'}`，在VS2018里面编译只是有警告大概是”int常量转换为cha类型“，放到网站测试代码就会报错，错误提示是一样的。学弟的本意是在二维字符数组的每一行存三个字母。但是这么初始化字符数组肯定是错误的，因为单引号是字符，只能有单个字符，学弟的写法应该改成双引号。这也激起我对字符和字符串的细致的学习，从这篇文章开始，我会逐渐积累C++的知识点，希望自己不断地进步。\n\n先附上C++的API链接，[cplusplus](http://www.cplusplus.com/)，好多细节的知识可以从这里学习到。\n\n在C/C++里，单个字符和字符串是有区别的，而这又取决于使用的是单引号或双引号。\n\n1. 表达式`'A'`代表一个单个字符。编译期间，C++将表达式替换为字符`“A”`的ACSII编码，该编码的十进制值是`65`。\n2. 而`“A”`代表一个长度为`1`的字符串，C++编译器会把以下两个字节放到数据区里：\n   - 字母`\"A\"`的ASCII代码\n   - 一个零值（字符串结束标记）\n\nC++编译器随后会把表达式`“A”`替换为这两个字节数组的地址。\n\n`'A'`和`\"A \"`是不同的，前者将被转换为一个整数值，后者被转换为一个地址。\n\n下面来具体看一下C和C++中的字符和字符串。\n\n# C中的字符和字符串\n\n1. C中的字符使用单引号`‘ ’`，引号内只能有一个字符。\n\n2. C中并没有字符串数据类型，有两种方式表示字符串。\n\n   - 一种方式是使用字符数组来保存字符串，c字符串实际上是一个以`‘null’`（`‘\\0’`）字符结尾的字符数组，`’null‘`字符表示字符串的结束。例如：`char str[10] = \"woshilee\";`\n\n     **注意：只有以null字符结尾的字符数组才是C字符串，否则只是一般的C字符数组。**\n\n   - 另一种方式是使用字符指针来访问一个字符串，通过字符指针指向存放字符串数组的首元素地址来进行访问。\n\n     例如：`char* str = \"12345\";`\n\n   其实两种方式中的变量`str`意义是一样的，都是指向字符串数组的首地址。\n\n   **C字符串定义时可以使用`=`进行初始化，但不能使用`=`对C字符串进行赋值，对C字符串的操作需要使用`string`文件中定义的字符串处理函数。**\n\n   字符串处理函数（头文件`<string.h>`或`<cstring>）`：\n\n   - `strlen(const char *str)`：返回字符串的长度，但不包含字符串结尾的`’\\0’`。\n\n     例子：`char mystr[100]=\"test string\";`\n\n     **注意：**`sizeof(mystr) `值为100（`sizeof`返回占用的字节数，如果是`char arr[]=\"string\"，sizeof(arr)=7`，`sizeof`包括`‘\\0’`），`strlen(mystr)`值为 11。\n\n   - `strcpy(char *destination, const char *source)`：复制`source`指针指向的字符串到des，包括`’null‘`结束字符。des空间要足够，避免内存溢出，两者空间不能重叠。\n\n   - `strncpy(char *destination, const char *source, size_t num)`：从`source`复制前`num`个字符到des；如果`source`的字符数少于`num`个，在des中会自动补`0`凑够`num`个；如果`source`的字符数大于`num`，des结尾就不会有隐式的结束符，要手动添加`‘0’`，否则读des会溢出。参数`size_t`是无符号整型。\n\n   - `strcat(char *destination, const char *source)`：拼接两个字符串，des的结尾字符被覆盖，拼接后的字符串结尾自动添加`’null‘`结束字符。des空间要足够，以避免**内存溢出**；**des和`source`空间不能重叠**。\n\n   - `strncat(char *destination, const char *source, size_t num)`：拼接`source`的前`num`个字符串到des，结尾自动添加`’null‘`结束字符；`source`的字符数小于`num`时，只有到结束字符的内容被复制。\n\n   - `strcmp(const char *str1, const char *str2)`：从第一个字符开始，两两比较两个字符串是否相等，相等返回`0`，否则返回`非0`（`<0`或`>0`，取决于第一个不同的字符的值的大小）。\n\n   - `strncmp(const char *str1, const char *str2, size_t num)`：比较两个字符串的前`num`个字符是否相等，相等返回`0`，否则返回`非0`（`<0`或`>0`，取决于第一个不同的字符的值的大小）。\n\n3. C中字符串的输入\n\n   - `scanf`和`scanf_s`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     例如：\n\n     ```c\n     char str[10] = { 0 };\n     scanf(\"%s\", str);\n     char str[10] = { 0 };\n     scanf_s(\"%s\", str, 10);\n     ```\n\n     **注意：**\n\n     - 使用`scanf `函数时，若输入的字符数大于定义的字符数组长度就会出现缓冲区溢出； \n     - 当输入的字符串中包含空格时，`scanf` 和` scanf_s` 函数只会接收空格前的字符串。例如：`hello world `则只会接收到：`hello `。\n     - `scanf_s `函数最后一个参数代表缓冲区的大小，示例中缓冲区大小为10，但最多能放入9个字符，因为最后一个需要放`’\\0’`。\n\n   - `gets`和`gets_s`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     `gets`函数从标准输入流`stdin`中读取字符，并存储在字符串指针所指的内存空间，直到读取到换行符或文件结束符，换行符不会读入字符串；结束符号`‘null’`会自动添加到结尾。\n\n     ```c\n     char str[10] = { 0 };\n     gets(str);\n     gets_s(str, 10);\n     ```\n\n     **注意：**\n\n     - `gets `函数解决了`scanf `和 `scanf_s `不能输入空格的问题，但是没有解决缓冲区溢出的问题。 \n     - `gets `函数由于也不安全所以被 `gets_s `函数代替，该函数的后一个参数代表缓冲区大小。\n\n     但是，`get_s`在linux中用不了，会提示没有定义，因为该函数是微软自创的，要在windows下vs中使用才行，可以使用`fgets` 函数替代。\n\n   - `fgets` 函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     函数原型：\n\n     ```c\n     char * fgets (char *str, int num, FILE *stream);\n     ```\n\n     `fgets`接受一个流参数，将读取到的字符保存在C字符串中，直到读取到`num-1`个字符或读到换行符或文件结束符；与`gets`函数不同的是它会将换行符读入字符串，作为字符串的一部分；结束符号`‘null’`会自动添加到结尾。其中参数`num`包含结束符号`‘null'`。\n\n     **总结一下`fgets`和`gets`的区别：**\n\n     - `gets`函数从标准输入流`stdin`读取字符，换行符不会加入字符串；`fgets`接受一个流参数，换行符会加入字符串；\n     - `fgets`函数限制了接收字符的个数，改进了`gets`函数缓冲区溢出的问题，是安全函数；\n     - `fgets`是为读取文件设计的，读取键盘时没有`gets`函数方便。\n\n4. C中字符串的输出\n\n   - `printf`和`printf_s`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     `printf`函数输出字符串到标准输出流`stdout`。\n\n   - `puts`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     将字符串数据写到标准输出流`stdout`，直到遇到结束符号`'\\0'`(不输出结束符号)，并在末尾自动添加一个换行符`’\\n'`。\n\n     例如：\n\n     ```c\n     char *str=\"hello world\";\n     puts(str);\n     ```\n\n   - `fputs`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     将字符串数据写到流，一个指向标识输出流的FILE对象的指针，直到遇到结束符号`'\\0'`(不输出结束符号)。\n\n     函数原型：\n\n     ~~~ c\n     int fputs(const char *str, FILE *stream);\n     ~~~\n\n     例如：\n\n     ~~~c\n     char *str=\"hello world\";\n     fputs(str, stdout);\n     ~~~\n\n# C++中的字符和字符串\n\n不同于C中的使用字符数组或字符指针表示字符串，C++中定义了字符串类`String`类，引用头文件`<string>`可以直接定义`string`类的对象，即字符串对象，使用该变量对字符串进行操作。`string`是C++标准库的一个重要的部分，主要用于字符串处理。可以使用输入输出流方式直接进行操作，也可以通过文件等手段进行操作。同时C++的算法库对`string`也有着很好的支持，而且string还和C语言的字符串之间有着良好的接口。当然也存在一些弊端。\n\n1. C++字符串的输入 \n\n   - 使用输入操作符填充一个字符串变量\n\n     例如：\n\n     ```c++\n     string str;\n     cin>>str;\n     ```\n\n     **注意：读取过程会忽略最初的空白字符(空格、制表符和换行符)，同时输入会在下一个空格或者换行符处停止。例如：`hello world `则只会接收到：`hello `。**\n\n   - 使用预定义函数`getline()`获取整行输入（包括空格）\n\n     从输入流中提取字符。\n\n     函数原型：\n\n     ```c++\n     istream& getline (istream&  is, string& str);//其中之一\n     ```\n\n     `getline()`的两个参数：\n\n     - `is`：输入流\n     - `str`：用于接收输入的字符串变量\n\n     例如：\n\n     ```c++\n     string str;\n     getline(cin, str);\n     ```\n\n     **注意：`getline()`函数在遇到行结束（换行符或`‘\\n’`）时停止接收字符。**\n\n2. `string`类型的变量可以使用`+`、`=`等运算操作符，直接对字符串变量进行操作。\n\n# 字符串中的小细节\n\n1. string对象和C字符串直接的转换\n\n   - 可以将C字符串存储在string类型的变量中\n\n     例如：\n\n     ~~~c++\n     char str[] = \"hhhha\";\n     string s;\n     s = str;\n     ~~~\n\n\n   - string对象不能自动的转换为C字符串，需要进行显式的类型转换，用到string类的成员函数c_str()\n\n     例如：\n\n     ~~~c++\n     strcpy(str, s.c_str());\n     ~~~\n\n2. 字符串到数字的转换\n\n   可以使用`atoi`函数获取一个字符串参数，该函数返回字符串对应的`int`值。如果参数不与一个`int`值对应，`atoi`就会返回0。`atoi`函数在文件为`cstdlib`的库中。如果数字太大，不能转换成int类型的值，可以使用`atol`将字符串转换为long类型的值。如果想转换为浮点数，可以使用`atof`函数。\n\n   例如：\n\n   ~~~c++\n   atoi(\"1234\");   //返回整数1234\n   atoi(\"#123\");   //返回0\n   char* str1 = \"29.3547\";\n   float f = atof(str1);//给f赋值为29.354700\n   char* str2 = \"31465666\";\n   long l = atof(str2);//给l赋值为31465666\n   ~~~\n\n3. C++对于单引号“字符串”的处理\n\n   以`‘ABCD’`为例，在C++中将单引号引用的部分看作一个字符，它表示一个整形常量。\n\n   ~~~c++\n   int flag = 'ab';  \n   cout<< flag <<endl;\n   printf(\"%X\\n\", flag); \n   char * array = (char *)&flag;  \n   char buff[5] = {0};  \n   strncpy(buff, array, 4);  \n   cout << buff <<endl;\n   ~~~\n\n   输出：\n\n   ~~~\n   24930\n   6162\n   ba\n   ~~~\n\n   C++在处理单引号引出的多个字符时，用4个字节大小的整数来表示，‘`ab’`的每个字符逐个赋给了`flag`这个变量的每个字节，Intel的CPU基于x86的架构，X86采用的是小端模式，即将整形的高位放在了内存的低地址处，所以`a`看成高位，`b`看成低位。如果使用`printf(\"%X\\n\", flag)`会看到输出为`6162`。在C++内部的运算：`a`的ACSII是`97`，`b`的ACSII是`98`，经过运算`97*256+98=24930`或`97 << 8 + 98 = 24930`（左移操作符相当于扩大为2^4倍）。值得注意的是，如果大小超过4字节，就会溢出。\n\n关于字符和字符串的知识先总结到这里，在今后的学习中会继续学习积累，希望能不断进步。加油～～:smile:","source":"_posts/C++学习之字符和字符串.md","raw":"---\ntitle: C++学习之字符和字符串\ndate: 2018-03-23 10:30:56\ntags:\n  - C\n  - C++\n  - 面试\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++字符和字符串的学习内容。\n\n<!---more-->\n\n上午给大一的C++课学生答疑，一个学弟在做“福尔摩斯的密码”问题，程序里面字符数组的定义出现了错误，他的定义是：`char b[7][4] = {'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'}`，在VS2018里面编译只是有警告大概是”int常量转换为cha类型“，放到网站测试代码就会报错，错误提示是一样的。学弟的本意是在二维字符数组的每一行存三个字母。但是这么初始化字符数组肯定是错误的，因为单引号是字符，只能有单个字符，学弟的写法应该改成双引号。这也激起我对字符和字符串的细致的学习，从这篇文章开始，我会逐渐积累C++的知识点，希望自己不断地进步。\n\n先附上C++的API链接，[cplusplus](http://www.cplusplus.com/)，好多细节的知识可以从这里学习到。\n\n在C/C++里，单个字符和字符串是有区别的，而这又取决于使用的是单引号或双引号。\n\n1. 表达式`'A'`代表一个单个字符。编译期间，C++将表达式替换为字符`“A”`的ACSII编码，该编码的十进制值是`65`。\n2. 而`“A”`代表一个长度为`1`的字符串，C++编译器会把以下两个字节放到数据区里：\n   - 字母`\"A\"`的ASCII代码\n   - 一个零值（字符串结束标记）\n\nC++编译器随后会把表达式`“A”`替换为这两个字节数组的地址。\n\n`'A'`和`\"A \"`是不同的，前者将被转换为一个整数值，后者被转换为一个地址。\n\n下面来具体看一下C和C++中的字符和字符串。\n\n# C中的字符和字符串\n\n1. C中的字符使用单引号`‘ ’`，引号内只能有一个字符。\n\n2. C中并没有字符串数据类型，有两种方式表示字符串。\n\n   - 一种方式是使用字符数组来保存字符串，c字符串实际上是一个以`‘null’`（`‘\\0’`）字符结尾的字符数组，`’null‘`字符表示字符串的结束。例如：`char str[10] = \"woshilee\";`\n\n     **注意：只有以null字符结尾的字符数组才是C字符串，否则只是一般的C字符数组。**\n\n   - 另一种方式是使用字符指针来访问一个字符串，通过字符指针指向存放字符串数组的首元素地址来进行访问。\n\n     例如：`char* str = \"12345\";`\n\n   其实两种方式中的变量`str`意义是一样的，都是指向字符串数组的首地址。\n\n   **C字符串定义时可以使用`=`进行初始化，但不能使用`=`对C字符串进行赋值，对C字符串的操作需要使用`string`文件中定义的字符串处理函数。**\n\n   字符串处理函数（头文件`<string.h>`或`<cstring>）`：\n\n   - `strlen(const char *str)`：返回字符串的长度，但不包含字符串结尾的`’\\0’`。\n\n     例子：`char mystr[100]=\"test string\";`\n\n     **注意：**`sizeof(mystr) `值为100（`sizeof`返回占用的字节数，如果是`char arr[]=\"string\"，sizeof(arr)=7`，`sizeof`包括`‘\\0’`），`strlen(mystr)`值为 11。\n\n   - `strcpy(char *destination, const char *source)`：复制`source`指针指向的字符串到des，包括`’null‘`结束字符。des空间要足够，避免内存溢出，两者空间不能重叠。\n\n   - `strncpy(char *destination, const char *source, size_t num)`：从`source`复制前`num`个字符到des；如果`source`的字符数少于`num`个，在des中会自动补`0`凑够`num`个；如果`source`的字符数大于`num`，des结尾就不会有隐式的结束符，要手动添加`‘0’`，否则读des会溢出。参数`size_t`是无符号整型。\n\n   - `strcat(char *destination, const char *source)`：拼接两个字符串，des的结尾字符被覆盖，拼接后的字符串结尾自动添加`’null‘`结束字符。des空间要足够，以避免**内存溢出**；**des和`source`空间不能重叠**。\n\n   - `strncat(char *destination, const char *source, size_t num)`：拼接`source`的前`num`个字符串到des，结尾自动添加`’null‘`结束字符；`source`的字符数小于`num`时，只有到结束字符的内容被复制。\n\n   - `strcmp(const char *str1, const char *str2)`：从第一个字符开始，两两比较两个字符串是否相等，相等返回`0`，否则返回`非0`（`<0`或`>0`，取决于第一个不同的字符的值的大小）。\n\n   - `strncmp(const char *str1, const char *str2, size_t num)`：比较两个字符串的前`num`个字符是否相等，相等返回`0`，否则返回`非0`（`<0`或`>0`，取决于第一个不同的字符的值的大小）。\n\n3. C中字符串的输入\n\n   - `scanf`和`scanf_s`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     例如：\n\n     ```c\n     char str[10] = { 0 };\n     scanf(\"%s\", str);\n     char str[10] = { 0 };\n     scanf_s(\"%s\", str, 10);\n     ```\n\n     **注意：**\n\n     - 使用`scanf `函数时，若输入的字符数大于定义的字符数组长度就会出现缓冲区溢出； \n     - 当输入的字符串中包含空格时，`scanf` 和` scanf_s` 函数只会接收空格前的字符串。例如：`hello world `则只会接收到：`hello `。\n     - `scanf_s `函数最后一个参数代表缓冲区的大小，示例中缓冲区大小为10，但最多能放入9个字符，因为最后一个需要放`’\\0’`。\n\n   - `gets`和`gets_s`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     `gets`函数从标准输入流`stdin`中读取字符，并存储在字符串指针所指的内存空间，直到读取到换行符或文件结束符，换行符不会读入字符串；结束符号`‘null’`会自动添加到结尾。\n\n     ```c\n     char str[10] = { 0 };\n     gets(str);\n     gets_s(str, 10);\n     ```\n\n     **注意：**\n\n     - `gets `函数解决了`scanf `和 `scanf_s `不能输入空格的问题，但是没有解决缓冲区溢出的问题。 \n     - `gets `函数由于也不安全所以被 `gets_s `函数代替，该函数的后一个参数代表缓冲区大小。\n\n     但是，`get_s`在linux中用不了，会提示没有定义，因为该函数是微软自创的，要在windows下vs中使用才行，可以使用`fgets` 函数替代。\n\n   - `fgets` 函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     函数原型：\n\n     ```c\n     char * fgets (char *str, int num, FILE *stream);\n     ```\n\n     `fgets`接受一个流参数，将读取到的字符保存在C字符串中，直到读取到`num-1`个字符或读到换行符或文件结束符；与`gets`函数不同的是它会将换行符读入字符串，作为字符串的一部分；结束符号`‘null’`会自动添加到结尾。其中参数`num`包含结束符号`‘null'`。\n\n     **总结一下`fgets`和`gets`的区别：**\n\n     - `gets`函数从标准输入流`stdin`读取字符，换行符不会加入字符串；`fgets`接受一个流参数，换行符会加入字符串；\n     - `fgets`函数限制了接收字符的个数，改进了`gets`函数缓冲区溢出的问题，是安全函数；\n     - `fgets`是为读取文件设计的，读取键盘时没有`gets`函数方便。\n\n4. C中字符串的输出\n\n   - `printf`和`printf_s`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     `printf`函数输出字符串到标准输出流`stdout`。\n\n   - `puts`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     将字符串数据写到标准输出流`stdout`，直到遇到结束符号`'\\0'`(不输出结束符号)，并在末尾自动添加一个换行符`’\\n'`。\n\n     例如：\n\n     ```c\n     char *str=\"hello world\";\n     puts(str);\n     ```\n\n   - `fputs`函数（头文件`<cstdio>`或`<stdio.h>`）\n\n     将字符串数据写到流，一个指向标识输出流的FILE对象的指针，直到遇到结束符号`'\\0'`(不输出结束符号)。\n\n     函数原型：\n\n     ~~~ c\n     int fputs(const char *str, FILE *stream);\n     ~~~\n\n     例如：\n\n     ~~~c\n     char *str=\"hello world\";\n     fputs(str, stdout);\n     ~~~\n\n# C++中的字符和字符串\n\n不同于C中的使用字符数组或字符指针表示字符串，C++中定义了字符串类`String`类，引用头文件`<string>`可以直接定义`string`类的对象，即字符串对象，使用该变量对字符串进行操作。`string`是C++标准库的一个重要的部分，主要用于字符串处理。可以使用输入输出流方式直接进行操作，也可以通过文件等手段进行操作。同时C++的算法库对`string`也有着很好的支持，而且string还和C语言的字符串之间有着良好的接口。当然也存在一些弊端。\n\n1. C++字符串的输入 \n\n   - 使用输入操作符填充一个字符串变量\n\n     例如：\n\n     ```c++\n     string str;\n     cin>>str;\n     ```\n\n     **注意：读取过程会忽略最初的空白字符(空格、制表符和换行符)，同时输入会在下一个空格或者换行符处停止。例如：`hello world `则只会接收到：`hello `。**\n\n   - 使用预定义函数`getline()`获取整行输入（包括空格）\n\n     从输入流中提取字符。\n\n     函数原型：\n\n     ```c++\n     istream& getline (istream&  is, string& str);//其中之一\n     ```\n\n     `getline()`的两个参数：\n\n     - `is`：输入流\n     - `str`：用于接收输入的字符串变量\n\n     例如：\n\n     ```c++\n     string str;\n     getline(cin, str);\n     ```\n\n     **注意：`getline()`函数在遇到行结束（换行符或`‘\\n’`）时停止接收字符。**\n\n2. `string`类型的变量可以使用`+`、`=`等运算操作符，直接对字符串变量进行操作。\n\n# 字符串中的小细节\n\n1. string对象和C字符串直接的转换\n\n   - 可以将C字符串存储在string类型的变量中\n\n     例如：\n\n     ~~~c++\n     char str[] = \"hhhha\";\n     string s;\n     s = str;\n     ~~~\n\n\n   - string对象不能自动的转换为C字符串，需要进行显式的类型转换，用到string类的成员函数c_str()\n\n     例如：\n\n     ~~~c++\n     strcpy(str, s.c_str());\n     ~~~\n\n2. 字符串到数字的转换\n\n   可以使用`atoi`函数获取一个字符串参数，该函数返回字符串对应的`int`值。如果参数不与一个`int`值对应，`atoi`就会返回0。`atoi`函数在文件为`cstdlib`的库中。如果数字太大，不能转换成int类型的值，可以使用`atol`将字符串转换为long类型的值。如果想转换为浮点数，可以使用`atof`函数。\n\n   例如：\n\n   ~~~c++\n   atoi(\"1234\");   //返回整数1234\n   atoi(\"#123\");   //返回0\n   char* str1 = \"29.3547\";\n   float f = atof(str1);//给f赋值为29.354700\n   char* str2 = \"31465666\";\n   long l = atof(str2);//给l赋值为31465666\n   ~~~\n\n3. C++对于单引号“字符串”的处理\n\n   以`‘ABCD’`为例，在C++中将单引号引用的部分看作一个字符，它表示一个整形常量。\n\n   ~~~c++\n   int flag = 'ab';  \n   cout<< flag <<endl;\n   printf(\"%X\\n\", flag); \n   char * array = (char *)&flag;  \n   char buff[5] = {0};  \n   strncpy(buff, array, 4);  \n   cout << buff <<endl;\n   ~~~\n\n   输出：\n\n   ~~~\n   24930\n   6162\n   ba\n   ~~~\n\n   C++在处理单引号引出的多个字符时，用4个字节大小的整数来表示，‘`ab’`的每个字符逐个赋给了`flag`这个变量的每个字节，Intel的CPU基于x86的架构，X86采用的是小端模式，即将整形的高位放在了内存的低地址处，所以`a`看成高位，`b`看成低位。如果使用`printf(\"%X\\n\", flag)`会看到输出为`6162`。在C++内部的运算：`a`的ACSII是`97`，`b`的ACSII是`98`，经过运算`97*256+98=24930`或`97 << 8 + 98 = 24930`（左移操作符相当于扩大为2^4倍）。值得注意的是，如果大小超过4字节，就会溢出。\n\n关于字符和字符串的知识先总结到这里，在今后的学习中会继续学习积累，希望能不断进步。加油～～:smile:","slug":"C++学习之字符和字符串","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyq00bdqlcrdz3tlrjh","content":"<hr>\n<p>这篇文章是有关C++字符和字符串的学习内容。</p>\n<a id=\"more\"></a>\n<p>上午给大一的C++课学生答疑，一个学弟在做“福尔摩斯的密码”问题，程序里面字符数组的定义出现了错误，他的定义是：<code>char b[7][4] = {&#39;Mon&#39;, &#39;Tue&#39;, &#39;Wed&#39;, &#39;Thu&#39;, &#39;Fri&#39;, &#39;Sat&#39;, &#39;Sun&#39;}</code>，在VS2018里面编译只是有警告大概是”int常量转换为cha类型“，放到网站测试代码就会报错，错误提示是一样的。学弟的本意是在二维字符数组的每一行存三个字母。但是这么初始化字符数组肯定是错误的，因为单引号是字符，只能有单个字符，学弟的写法应该改成双引号。这也激起我对字符和字符串的细致的学习，从这篇文章开始，我会逐渐积累C++的知识点，希望自己不断地进步。</p>\n<p>先附上C++的API链接，<a href=\"http://www.cplusplus.com/\" target=\"_blank\" rel=\"noopener\">cplusplus</a>，好多细节的知识可以从这里学习到。</p>\n<p>在C/C++里，单个字符和字符串是有区别的，而这又取决于使用的是单引号或双引号。</p>\n<ol>\n<li>表达式<code>&#39;A&#39;</code>代表一个单个字符。编译期间，C++将表达式替换为字符<code>“A”</code>的ACSII编码，该编码的十进制值是<code>65</code>。</li>\n<li>而<code>“A”</code>代表一个长度为<code>1</code>的字符串，C++编译器会把以下两个字节放到数据区里：<ul>\n<li>字母<code>&quot;A&quot;</code>的ASCII代码</li>\n<li>一个零值（字符串结束标记）</li>\n</ul>\n</li>\n</ol>\n<p>C++编译器随后会把表达式<code>“A”</code>替换为这两个字节数组的地址。</p>\n<p><code>&#39;A&#39;</code>和<code>&quot;A &quot;</code>是不同的，前者将被转换为一个整数值，后者被转换为一个地址。</p>\n<p>下面来具体看一下C和C++中的字符和字符串。</p>\n<h1 id=\"C中的字符和字符串\"><a href=\"#C中的字符和字符串\" class=\"headerlink\" title=\"C中的字符和字符串\"></a>C中的字符和字符串</h1><ol>\n<li><p>C中的字符使用单引号<code>‘ ’</code>，引号内只能有一个字符。</p>\n</li>\n<li><p>C中并没有字符串数据类型，有两种方式表示字符串。</p>\n<ul>\n<li><p>一种方式是使用字符数组来保存字符串，c字符串实际上是一个以<code>‘null’</code>（<code>‘\\0’</code>）字符结尾的字符数组，<code>’null‘</code>字符表示字符串的结束。例如：<code>char str[10] = &quot;woshilee&quot;;</code></p>\n<p><strong>注意：只有以null字符结尾的字符数组才是C字符串，否则只是一般的C字符数组。</strong></p>\n</li>\n<li><p>另一种方式是使用字符指针来访问一个字符串，通过字符指针指向存放字符串数组的首元素地址来进行访问。</p>\n<p>例如：<code>char* str = &quot;12345&quot;;</code></p>\n</li>\n</ul>\n<p>其实两种方式中的变量<code>str</code>意义是一样的，都是指向字符串数组的首地址。</p>\n<p><strong>C字符串定义时可以使用<code>=</code>进行初始化，但不能使用<code>=</code>对C字符串进行赋值，对C字符串的操作需要使用<code>string</code>文件中定义的字符串处理函数。</strong></p>\n<p>字符串处理函数（头文件<code>&lt;string.h&gt;</code>或<code>&lt;cstring&gt;）</code>：</p>\n<ul>\n<li><p><code>strlen(const char *str)</code>：返回字符串的长度，但不包含字符串结尾的<code>’\\0’</code>。</p>\n<p>例子：<code>char mystr[100]=&quot;test string&quot;;</code></p>\n<p><strong>注意：</strong><code>sizeof(mystr)</code>值为100（<code>sizeof</code>返回占用的字节数，如果是<code>char arr[]=&quot;string&quot;，sizeof(arr)=7</code>，<code>sizeof</code>包括<code>‘\\0’</code>），<code>strlen(mystr)</code>值为 11。</p>\n</li>\n<li><p><code>strcpy(char *destination, const char *source)</code>：复制<code>source</code>指针指向的字符串到des，包括<code>’null‘</code>结束字符。des空间要足够，避免内存溢出，两者空间不能重叠。</p>\n</li>\n<li><p><code>strncpy(char *destination, const char *source, size_t num)</code>：从<code>source</code>复制前<code>num</code>个字符到des；如果<code>source</code>的字符数少于<code>num</code>个，在des中会自动补<code>0</code>凑够<code>num</code>个；如果<code>source</code>的字符数大于<code>num</code>，des结尾就不会有隐式的结束符，要手动添加<code>‘0’</code>，否则读des会溢出。参数<code>size_t</code>是无符号整型。</p>\n</li>\n<li><p><code>strcat(char *destination, const char *source)</code>：拼接两个字符串，des的结尾字符被覆盖，拼接后的字符串结尾自动添加<code>’null‘</code>结束字符。des空间要足够，以避免<strong>内存溢出</strong>；<strong>des和<code>source</code>空间不能重叠</strong>。</p>\n</li>\n<li><p><code>strncat(char *destination, const char *source, size_t num)</code>：拼接<code>source</code>的前<code>num</code>个字符串到des，结尾自动添加<code>’null‘</code>结束字符；<code>source</code>的字符数小于<code>num</code>时，只有到结束字符的内容被复制。</p>\n</li>\n<li><p><code>strcmp(const char *str1, const char *str2)</code>：从第一个字符开始，两两比较两个字符串是否相等，相等返回<code>0</code>，否则返回<code>非0</code>（<code>&lt;0</code>或<code>&gt;0</code>，取决于第一个不同的字符的值的大小）。</p>\n</li>\n<li><p><code>strncmp(const char *str1, const char *str2, size_t num)</code>：比较两个字符串的前<code>num</code>个字符是否相等，相等返回<code>0</code>，否则返回<code>非0</code>（<code>&lt;0</code>或<code>&gt;0</code>，取决于第一个不同的字符的值的大小）。</p>\n</li>\n</ul>\n</li>\n<li><p>C中字符串的输入</p>\n<ul>\n<li><p><code>scanf</code>和<code>scanf_s</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>例如：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> str[<span class=\"number\">10</span>] = &#123; <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\"><span class=\"built_in\">scanf</span>(<span class=\"string\">\"%s\"</span>, str);</span><br><span class=\"line\"><span class=\"keyword\">char</span> str[<span class=\"number\">10</span>] = &#123; <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\">scanf_s(<span class=\"string\">\"%s\"</span>, str, <span class=\"number\">10</span>);</span><br></pre></td></tr></table></figure>\n<p><strong>注意：</strong></p>\n<ul>\n<li>使用<code>scanf</code>函数时，若输入的字符数大于定义的字符数组长度就会出现缓冲区溢出； </li>\n<li>当输入的字符串中包含空格时，<code>scanf</code> 和<code>scanf_s</code> 函数只会接收空格前的字符串。例如：<code>hello world</code>则只会接收到：<code>hello</code>。</li>\n<li><code>scanf_s</code>函数最后一个参数代表缓冲区的大小，示例中缓冲区大小为10，但最多能放入9个字符，因为最后一个需要放<code>’\\0’</code>。</li>\n</ul>\n</li>\n<li><p><code>gets</code>和<code>gets_s</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p><code>gets</code>函数从标准输入流<code>stdin</code>中读取字符，并存储在字符串指针所指的内存空间，直到读取到换行符或文件结束符，换行符不会读入字符串；结束符号<code>‘null’</code>会自动添加到结尾。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> str[<span class=\"number\">10</span>] = &#123; <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\">gets(str);</span><br><span class=\"line\">gets_s(str, <span class=\"number\">10</span>);</span><br></pre></td></tr></table></figure>\n<p><strong>注意：</strong></p>\n<ul>\n<li><code>gets</code>函数解决了<code>scanf</code>和 <code>scanf_s</code>不能输入空格的问题，但是没有解决缓冲区溢出的问题。 </li>\n<li><code>gets</code>函数由于也不安全所以被 <code>gets_s</code>函数代替，该函数的后一个参数代表缓冲区大小。</li>\n</ul>\n<p>但是，<code>get_s</code>在linux中用不了，会提示没有定义，因为该函数是微软自创的，要在windows下vs中使用才行，可以使用<code>fgets</code> 函数替代。</p>\n</li>\n<li><p><code>fgets</code> 函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>函数原型：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> * <span class=\"title\">fgets</span> <span class=\"params\">(<span class=\"keyword\">char</span> *str, <span class=\"keyword\">int</span> num, FILE *stream)</span></span>;</span><br></pre></td></tr></table></figure>\n<p><code>fgets</code>接受一个流参数，将读取到的字符保存在C字符串中，直到读取到<code>num-1</code>个字符或读到换行符或文件结束符；与<code>gets</code>函数不同的是它会将换行符读入字符串，作为字符串的一部分；结束符号<code>‘null’</code>会自动添加到结尾。其中参数<code>num</code>包含结束符号<code>‘null&#39;</code>。</p>\n<p><strong>总结一下<code>fgets</code>和<code>gets</code>的区别：</strong></p>\n<ul>\n<li><code>gets</code>函数从标准输入流<code>stdin</code>读取字符，换行符不会加入字符串；<code>fgets</code>接受一个流参数，换行符会加入字符串；</li>\n<li><code>fgets</code>函数限制了接收字符的个数，改进了<code>gets</code>函数缓冲区溢出的问题，是安全函数；</li>\n<li><code>fgets</code>是为读取文件设计的，读取键盘时没有<code>gets</code>函数方便。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>C中字符串的输出</p>\n<ul>\n<li><p><code>printf</code>和<code>printf_s</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p><code>printf</code>函数输出字符串到标准输出流<code>stdout</code>。</p>\n</li>\n<li><p><code>puts</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>将字符串数据写到标准输出流<code>stdout</code>，直到遇到结束符号<code>&#39;\\0&#39;</code>(不输出结束符号)，并在末尾自动添加一个换行符<code>’\\n&#39;</code>。</p>\n<p>例如：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> *str=<span class=\"string\">\"hello world\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">puts</span>(str);</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>fputs</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>将字符串数据写到流，一个指向标识输出流的FILE对象的指针，直到遇到结束符号<code>&#39;\\0&#39;</code>(不输出结束符号)。</p>\n<p>函数原型：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">fputs</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *str, FILE *stream)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>例如：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> *str=<span class=\"string\">\"hello world\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">fputs</span>(str, <span class=\"built_in\">stdout</span>);</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"C-中的字符和字符串\"><a href=\"#C-中的字符和字符串\" class=\"headerlink\" title=\"C++中的字符和字符串\"></a>C++中的字符和字符串</h1><p>不同于C中的使用字符数组或字符指针表示字符串，C++中定义了字符串类<code>String</code>类，引用头文件<code>&lt;string&gt;</code>可以直接定义<code>string</code>类的对象，即字符串对象，使用该变量对字符串进行操作。<code>string</code>是C++标准库的一个重要的部分，主要用于字符串处理。可以使用输入输出流方式直接进行操作，也可以通过文件等手段进行操作。同时C++的算法库对<code>string</code>也有着很好的支持，而且string还和C语言的字符串之间有着良好的接口。当然也存在一些弊端。</p>\n<ol>\n<li><p>C++字符串的输入 </p>\n<ul>\n<li><p>使用输入操作符填充一个字符串变量</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> str;</span><br><span class=\"line\"><span class=\"built_in\">cin</span>&gt;&gt;str;</span><br></pre></td></tr></table></figure>\n<p><strong>注意：读取过程会忽略最初的空白字符(空格、制表符和换行符)，同时输入会在下一个空格或者换行符处停止。例如：<code>hello world</code>则只会接收到：<code>hello</code>。</strong></p>\n</li>\n<li><p>使用预定义函数<code>getline()</code>获取整行输入（包括空格）</p>\n<p>从输入流中提取字符。</p>\n<p>函数原型：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">istream&amp; <span class=\"title\">getline</span> <span class=\"params\">(istream&amp;  is, <span class=\"built_in\">string</span>&amp; str)</span></span>;<span class=\"comment\">//其中之一</span></span><br></pre></td></tr></table></figure>\n<p><code>getline()</code>的两个参数：</p>\n<ul>\n<li><code>is</code>：输入流</li>\n<li><code>str</code>：用于接收输入的字符串变量</li>\n</ul>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> str;</span><br><span class=\"line\">getline(<span class=\"built_in\">cin</span>, str);</span><br></pre></td></tr></table></figure>\n<p><strong>注意：<code>getline()</code>函数在遇到行结束（换行符或<code>‘\\n’</code>）时停止接收字符。</strong></p>\n</li>\n</ul>\n</li>\n<li><p><code>string</code>类型的变量可以使用<code>+</code>、<code>=</code>等运算操作符，直接对字符串变量进行操作。</p>\n</li>\n</ol>\n<h1 id=\"字符串中的小细节\"><a href=\"#字符串中的小细节\" class=\"headerlink\" title=\"字符串中的小细节\"></a>字符串中的小细节</h1><ol>\n<li><p>string对象和C字符串直接的转换</p>\n<ul>\n<li><p>可以将C字符串存储在string类型的变量中</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">char</span> str[] = <span class=\"string\">\"hhhha\"</span>;</span><br><span class=\"line\"><span class=\"built_in\">string</span> s;</span><br><span class=\"line\">s = str;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>string对象不能自动的转换为C字符串，需要进行显式的类型转换，用到string类的成员函数c_str()</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">strcpy</span>(str, s.c_str());</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>字符串到数字的转换</p>\n<p>可以使用<code>atoi</code>函数获取一个字符串参数，该函数返回字符串对应的<code>int</code>值。如果参数不与一个<code>int</code>值对应，<code>atoi</code>就会返回0。<code>atoi</code>函数在文件为<code>cstdlib</code>的库中。如果数字太大，不能转换成int类型的值，可以使用<code>atol</code>将字符串转换为long类型的值。如果想转换为浮点数，可以使用<code>atof</code>函数。</p>\n<p>例如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">atoi(<span class=\"string\">\"1234\"</span>);   <span class=\"comment\">//返回整数1234</span></span><br><span class=\"line\">atoi(<span class=\"string\">\"#123\"</span>);   <span class=\"comment\">//返回0</span></span><br><span class=\"line\"><span class=\"keyword\">char</span>* str1 = <span class=\"string\">\"29.3547\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">float</span> f = atof(str1);<span class=\"comment\">//给f赋值为29.354700</span></span><br><span class=\"line\"><span class=\"keyword\">char</span>* str2 = <span class=\"string\">\"31465666\"</span>;</span><br><span class=\"line\"><span class=\"keyword\">long</span> l = atof(str2);<span class=\"comment\">//给l赋值为31465666</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>C++对于单引号“字符串”的处理</p>\n<p>以<code>‘ABCD’</code>为例，在C++中将单引号引用的部分看作一个字符，它表示一个整形常量。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int flag = 'ab';  </span><br><span class=\"line\"><span class=\"built_in\">cout</span>&lt;&lt; flag &lt;&lt;<span class=\"built_in\">endl</span>;</span><br><span class=\"line\"><span class=\"built_in\">printf</span>(<span class=\"string\">\"%X\\n\"</span>, flag); </span><br><span class=\"line\"><span class=\"keyword\">char</span> * <span class=\"built_in\">array</span> = (<span class=\"keyword\">char</span> *)&amp;flag;  </span><br><span class=\"line\"><span class=\"keyword\">char</span> buff[<span class=\"number\">5</span>] = &#123;<span class=\"number\">0</span>&#125;;  </span><br><span class=\"line\"><span class=\"built_in\">strncpy</span>(buff, <span class=\"built_in\">array</span>, <span class=\"number\">4</span>);  </span><br><span class=\"line\"><span class=\"built_in\">cout</span> &lt;&lt; buff &lt;&lt;<span class=\"built_in\">endl</span>;</span><br></pre></td></tr></table></figure>\n<p>输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">24930</span><br><span class=\"line\">6162</span><br><span class=\"line\">ba</span><br></pre></td></tr></table></figure>\n<p>C++在处理单引号引出的多个字符时，用4个字节大小的整数来表示，‘<code>ab’</code>的每个字符逐个赋给了<code>flag</code>这个变量的每个字节，Intel的CPU基于x86的架构，X86采用的是小端模式，即将整形的高位放在了内存的低地址处，所以<code>a</code>看成高位，<code>b</code>看成低位。如果使用<code>printf(&quot;%X\\n&quot;, flag)</code>会看到输出为<code>6162</code>。在C++内部的运算：<code>a</code>的ACSII是<code>97</code>，<code>b</code>的ACSII是<code>98</code>，经过运算<code>97*256+98=24930</code>或<code>97 &lt;&lt; 8 + 98 = 24930</code>（左移操作符相当于扩大为2^4倍）。值得注意的是，如果大小超过4字节，就会溢出。</p>\n</li>\n</ol>\n<p>关于字符和字符串的知识先总结到这里，在今后的学习中会继续学习积累，希望能不断进步。加油～～:smile:</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++字符和字符串的学习内容。</p>","more":"<p>上午给大一的C++课学生答疑，一个学弟在做“福尔摩斯的密码”问题，程序里面字符数组的定义出现了错误，他的定义是：<code>char b[7][4] = {&#39;Mon&#39;, &#39;Tue&#39;, &#39;Wed&#39;, &#39;Thu&#39;, &#39;Fri&#39;, &#39;Sat&#39;, &#39;Sun&#39;}</code>，在VS2018里面编译只是有警告大概是”int常量转换为cha类型“，放到网站测试代码就会报错，错误提示是一样的。学弟的本意是在二维字符数组的每一行存三个字母。但是这么初始化字符数组肯定是错误的，因为单引号是字符，只能有单个字符，学弟的写法应该改成双引号。这也激起我对字符和字符串的细致的学习，从这篇文章开始，我会逐渐积累C++的知识点，希望自己不断地进步。</p>\n<p>先附上C++的API链接，<a href=\"http://www.cplusplus.com/\" target=\"_blank\" rel=\"noopener\">cplusplus</a>，好多细节的知识可以从这里学习到。</p>\n<p>在C/C++里，单个字符和字符串是有区别的，而这又取决于使用的是单引号或双引号。</p>\n<ol>\n<li>表达式<code>&#39;A&#39;</code>代表一个单个字符。编译期间，C++将表达式替换为字符<code>“A”</code>的ACSII编码，该编码的十进制值是<code>65</code>。</li>\n<li>而<code>“A”</code>代表一个长度为<code>1</code>的字符串，C++编译器会把以下两个字节放到数据区里：<ul>\n<li>字母<code>&quot;A&quot;</code>的ASCII代码</li>\n<li>一个零值（字符串结束标记）</li>\n</ul>\n</li>\n</ol>\n<p>C++编译器随后会把表达式<code>“A”</code>替换为这两个字节数组的地址。</p>\n<p><code>&#39;A&#39;</code>和<code>&quot;A &quot;</code>是不同的，前者将被转换为一个整数值，后者被转换为一个地址。</p>\n<p>下面来具体看一下C和C++中的字符和字符串。</p>\n<h1 id=\"C中的字符和字符串\"><a href=\"#C中的字符和字符串\" class=\"headerlink\" title=\"C中的字符和字符串\"></a>C中的字符和字符串</h1><ol>\n<li><p>C中的字符使用单引号<code>‘ ’</code>，引号内只能有一个字符。</p>\n</li>\n<li><p>C中并没有字符串数据类型，有两种方式表示字符串。</p>\n<ul>\n<li><p>一种方式是使用字符数组来保存字符串，c字符串实际上是一个以<code>‘null’</code>（<code>‘\\0’</code>）字符结尾的字符数组，<code>’null‘</code>字符表示字符串的结束。例如：<code>char str[10] = &quot;woshilee&quot;;</code></p>\n<p><strong>注意：只有以null字符结尾的字符数组才是C字符串，否则只是一般的C字符数组。</strong></p>\n</li>\n<li><p>另一种方式是使用字符指针来访问一个字符串，通过字符指针指向存放字符串数组的首元素地址来进行访问。</p>\n<p>例如：<code>char* str = &quot;12345&quot;;</code></p>\n</li>\n</ul>\n<p>其实两种方式中的变量<code>str</code>意义是一样的，都是指向字符串数组的首地址。</p>\n<p><strong>C字符串定义时可以使用<code>=</code>进行初始化，但不能使用<code>=</code>对C字符串进行赋值，对C字符串的操作需要使用<code>string</code>文件中定义的字符串处理函数。</strong></p>\n<p>字符串处理函数（头文件<code>&lt;string.h&gt;</code>或<code>&lt;cstring&gt;）</code>：</p>\n<ul>\n<li><p><code>strlen(const char *str)</code>：返回字符串的长度，但不包含字符串结尾的<code>’\\0’</code>。</p>\n<p>例子：<code>char mystr[100]=&quot;test string&quot;;</code></p>\n<p><strong>注意：</strong><code>sizeof(mystr)</code>值为100（<code>sizeof</code>返回占用的字节数，如果是<code>char arr[]=&quot;string&quot;，sizeof(arr)=7</code>，<code>sizeof</code>包括<code>‘\\0’</code>），<code>strlen(mystr)</code>值为 11。</p>\n</li>\n<li><p><code>strcpy(char *destination, const char *source)</code>：复制<code>source</code>指针指向的字符串到des，包括<code>’null‘</code>结束字符。des空间要足够，避免内存溢出，两者空间不能重叠。</p>\n</li>\n<li><p><code>strncpy(char *destination, const char *source, size_t num)</code>：从<code>source</code>复制前<code>num</code>个字符到des；如果<code>source</code>的字符数少于<code>num</code>个，在des中会自动补<code>0</code>凑够<code>num</code>个；如果<code>source</code>的字符数大于<code>num</code>，des结尾就不会有隐式的结束符，要手动添加<code>‘0’</code>，否则读des会溢出。参数<code>size_t</code>是无符号整型。</p>\n</li>\n<li><p><code>strcat(char *destination, const char *source)</code>：拼接两个字符串，des的结尾字符被覆盖，拼接后的字符串结尾自动添加<code>’null‘</code>结束字符。des空间要足够，以避免<strong>内存溢出</strong>；<strong>des和<code>source</code>空间不能重叠</strong>。</p>\n</li>\n<li><p><code>strncat(char *destination, const char *source, size_t num)</code>：拼接<code>source</code>的前<code>num</code>个字符串到des，结尾自动添加<code>’null‘</code>结束字符；<code>source</code>的字符数小于<code>num</code>时，只有到结束字符的内容被复制。</p>\n</li>\n<li><p><code>strcmp(const char *str1, const char *str2)</code>：从第一个字符开始，两两比较两个字符串是否相等，相等返回<code>0</code>，否则返回<code>非0</code>（<code>&lt;0</code>或<code>&gt;0</code>，取决于第一个不同的字符的值的大小）。</p>\n</li>\n<li><p><code>strncmp(const char *str1, const char *str2, size_t num)</code>：比较两个字符串的前<code>num</code>个字符是否相等，相等返回<code>0</code>，否则返回<code>非0</code>（<code>&lt;0</code>或<code>&gt;0</code>，取决于第一个不同的字符的值的大小）。</p>\n</li>\n</ul>\n</li>\n<li><p>C中字符串的输入</p>\n<ul>\n<li><p><code>scanf</code>和<code>scanf_s</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>例如：</p>\n<!--�156-->\n<p><strong>注意：</strong></p>\n<ul>\n<li>使用<code>scanf</code>函数时，若输入的字符数大于定义的字符数组长度就会出现缓冲区溢出； </li>\n<li>当输入的字符串中包含空格时，<code>scanf</code> 和<code>scanf_s</code> 函数只会接收空格前的字符串。例如：<code>hello world</code>则只会接收到：<code>hello</code>。</li>\n<li><code>scanf_s</code>函数最后一个参数代表缓冲区的大小，示例中缓冲区大小为10，但最多能放入9个字符，因为最后一个需要放<code>’\\0’</code>。</li>\n</ul>\n</li>\n<li><p><code>gets</code>和<code>gets_s</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p><code>gets</code>函数从标准输入流<code>stdin</code>中读取字符，并存储在字符串指针所指的内存空间，直到读取到换行符或文件结束符，换行符不会读入字符串；结束符号<code>‘null’</code>会自动添加到结尾。</p>\n<!--�157-->\n<p><strong>注意：</strong></p>\n<ul>\n<li><code>gets</code>函数解决了<code>scanf</code>和 <code>scanf_s</code>不能输入空格的问题，但是没有解决缓冲区溢出的问题。 </li>\n<li><code>gets</code>函数由于也不安全所以被 <code>gets_s</code>函数代替，该函数的后一个参数代表缓冲区大小。</li>\n</ul>\n<p>但是，<code>get_s</code>在linux中用不了，会提示没有定义，因为该函数是微软自创的，要在windows下vs中使用才行，可以使用<code>fgets</code> 函数替代。</p>\n</li>\n<li><p><code>fgets</code> 函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>函数原型：</p>\n<!--�158-->\n<p><code>fgets</code>接受一个流参数，将读取到的字符保存在C字符串中，直到读取到<code>num-1</code>个字符或读到换行符或文件结束符；与<code>gets</code>函数不同的是它会将换行符读入字符串，作为字符串的一部分；结束符号<code>‘null’</code>会自动添加到结尾。其中参数<code>num</code>包含结束符号<code>‘null&#39;</code>。</p>\n<p><strong>总结一下<code>fgets</code>和<code>gets</code>的区别：</strong></p>\n<ul>\n<li><code>gets</code>函数从标准输入流<code>stdin</code>读取字符，换行符不会加入字符串；<code>fgets</code>接受一个流参数，换行符会加入字符串；</li>\n<li><code>fgets</code>函数限制了接收字符的个数，改进了<code>gets</code>函数缓冲区溢出的问题，是安全函数；</li>\n<li><code>fgets</code>是为读取文件设计的，读取键盘时没有<code>gets</code>函数方便。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>C中字符串的输出</p>\n<ul>\n<li><p><code>printf</code>和<code>printf_s</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p><code>printf</code>函数输出字符串到标准输出流<code>stdout</code>。</p>\n</li>\n<li><p><code>puts</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>将字符串数据写到标准输出流<code>stdout</code>，直到遇到结束符号<code>&#39;\\0&#39;</code>(不输出结束符号)，并在末尾自动添加一个换行符<code>’\\n&#39;</code>。</p>\n<p>例如：</p>\n<!--�159-->\n</li>\n<li><p><code>fputs</code>函数（头文件<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>）</p>\n<p>将字符串数据写到流，一个指向标识输出流的FILE对象的指针，直到遇到结束符号<code>&#39;\\0&#39;</code>(不输出结束符号)。</p>\n<p>函数原型：</p>\n<!--�160-->\n<p>例如：</p>\n<!--�161-->\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"C-中的字符和字符串\"><a href=\"#C-中的字符和字符串\" class=\"headerlink\" title=\"C++中的字符和字符串\"></a>C++中的字符和字符串</h1><p>不同于C中的使用字符数组或字符指针表示字符串，C++中定义了字符串类<code>String</code>类，引用头文件<code>&lt;string&gt;</code>可以直接定义<code>string</code>类的对象，即字符串对象，使用该变量对字符串进行操作。<code>string</code>是C++标准库的一个重要的部分，主要用于字符串处理。可以使用输入输出流方式直接进行操作，也可以通过文件等手段进行操作。同时C++的算法库对<code>string</code>也有着很好的支持，而且string还和C语言的字符串之间有着良好的接口。当然也存在一些弊端。</p>\n<ol>\n<li><p>C++字符串的输入 </p>\n<ul>\n<li><p>使用输入操作符填充一个字符串变量</p>\n<p>例如：</p>\n<!--�162-->\n<p><strong>注意：读取过程会忽略最初的空白字符(空格、制表符和换行符)，同时输入会在下一个空格或者换行符处停止。例如：<code>hello world</code>则只会接收到：<code>hello</code>。</strong></p>\n</li>\n<li><p>使用预定义函数<code>getline()</code>获取整行输入（包括空格）</p>\n<p>从输入流中提取字符。</p>\n<p>函数原型：</p>\n<!--�163-->\n<p><code>getline()</code>的两个参数：</p>\n<ul>\n<li><code>is</code>：输入流</li>\n<li><code>str</code>：用于接收输入的字符串变量</li>\n</ul>\n<p>例如：</p>\n<!--�164-->\n<p><strong>注意：<code>getline()</code>函数在遇到行结束（换行符或<code>‘\\n’</code>）时停止接收字符。</strong></p>\n</li>\n</ul>\n</li>\n<li><p><code>string</code>类型的变量可以使用<code>+</code>、<code>=</code>等运算操作符，直接对字符串变量进行操作。</p>\n</li>\n</ol>\n<h1 id=\"字符串中的小细节\"><a href=\"#字符串中的小细节\" class=\"headerlink\" title=\"字符串中的小细节\"></a>字符串中的小细节</h1><ol>\n<li><p>string对象和C字符串直接的转换</p>\n<ul>\n<li><p>可以将C字符串存储在string类型的变量中</p>\n<p>例如：</p>\n<!--�165-->\n</li>\n<li><p>string对象不能自动的转换为C字符串，需要进行显式的类型转换，用到string类的成员函数c_str()</p>\n<p>例如：</p>\n<!--�166-->\n</li>\n</ul>\n</li>\n<li><p>字符串到数字的转换</p>\n<p>可以使用<code>atoi</code>函数获取一个字符串参数，该函数返回字符串对应的<code>int</code>值。如果参数不与一个<code>int</code>值对应，<code>atoi</code>就会返回0。<code>atoi</code>函数在文件为<code>cstdlib</code>的库中。如果数字太大，不能转换成int类型的值，可以使用<code>atol</code>将字符串转换为long类型的值。如果想转换为浮点数，可以使用<code>atof</code>函数。</p>\n<p>例如：</p>\n<!--�167-->\n</li>\n<li><p>C++对于单引号“字符串”的处理</p>\n<p>以<code>‘ABCD’</code>为例，在C++中将单引号引用的部分看作一个字符，它表示一个整形常量。</p>\n<!--�168-->\n<p>输出：</p>\n<!--�169-->\n<p>C++在处理单引号引出的多个字符时，用4个字节大小的整数来表示，‘<code>ab’</code>的每个字符逐个赋给了<code>flag</code>这个变量的每个字节，Intel的CPU基于x86的架构，X86采用的是小端模式，即将整形的高位放在了内存的低地址处，所以<code>a</code>看成高位，<code>b</code>看成低位。如果使用<code>printf(&quot;%X\\n&quot;, flag)</code>会看到输出为<code>6162</code>。在C++内部的运算：<code>a</code>的ACSII是<code>97</code>，<code>b</code>的ACSII是<code>98</code>，经过运算<code>97*256+98=24930</code>或<code>97 &lt;&lt; 8 + 98 = 24930</code>（左移操作符相当于扩大为2^4倍）。值得注意的是，如果大小超过4字节，就会溢出。</p>\n</li>\n</ol>\n<p>关于字符和字符串的知识先总结到这里，在今后的学习中会继续学习积累，希望能不断进步。加油～～:smile:</p>"},{"title":"ORB_SLAM2学习之源码分析一-追踪","date":"2018-08-12T12:01:21.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录Tracking模块部分。\n\n<!--more-->\n\nORB-SLAM2系统追踪、局部建图、回环检测、可视化四个线程，其中追踪模块是在主线程中完成的，SLAM视觉里程计主体就是在该线程中完成的。先介绍追踪模块的算法内容，这里从已经完成模块初始化开始。ORB_SLAM2中，重定位和闭环检测过程主要使用DBoW2来完成。\n\n# Tracking代码分析\n\n程序分为两种模式：**SLAM模式**和**Localization模式**，由变量`mbOnlyTracking`标记。SLAM模式中，三个线程全部都在工作，即在定位也在建图。而Localization模式中，只有Tracking线程在工作，即只定位，输出追踪结果（姿态），不会更新地图和关键帧。Localization模式主要用于已经有场景地图的情况下（在SLAM模式下完成建图后可以无缝切换到Localization模式）。Localization模式下追踪方法涉及到的关键函数是一样的，只是策略有所不同。\n\n{% asset_img Track.png %}\n\n{% asset_img Tracking跟踪模型.png %}\n\n上图是参考资料1中的流程图，介绍的比较详细，可供参考。\n\n## 初始追踪\n\n初始化完成后，对于相机获取当前图像`mCurrentFrame`，通过跟踪匹配上一帧`mLastFrame`特征点的方式，可以获取一个相机位姿的初始值；为了兼顾计算量和跟踪鲁棒性，追踪部分主要用了三种模型：运动模型（TrackWithMotionModel）、关键帧（TrackReferenceKeyFrame）和重定位（Relocalization）。三种跟踪模型都是为了获取相机位姿一个粗略的初值，后面会通过跟踪局部地图TrackLocalMap对位姿进行BundleAdjustment（捆集调整），进一步优化位姿。\n\n1. TrackWithMotionModel\n\n   该模型根据两帧之间的约束关系来求解估算位姿。假设物体处于匀速运动，那么可以用上一帧的位姿和速度来估计当前帧的位姿。上一帧的速度可以通过前面几帧的位姿计算得到。这个模型适用于运动速度和方向比较一致、没有大转动的情形，比如匀速运动的汽车、机器人、人等。如果是静止状态或者运动模型匹配失效（运用恒速模型后反投影发现LastFrame的地图点和CurrentFrame的特征点匹配很少），通过增大参考帧的地图点反投影匹配范围，获取较多匹配后，计算当前位姿；而对于运动比较随意的目标，上述操作失效的情况下，就会用到下面两个模型。\n\n2. TrackReferenceKeyFrame\n\n   假如motion model已经失效，那么首先可以尝试和最近一个关键帧（即参考关键帧）去做匹配。毕竟当前帧和上一个关键帧的距离还不是很远。作者利用了bag of words（BoW）来加速匹配。首先，计算当前帧的BoW，并设定初始位姿为上一帧的位姿；其次，根据位姿和BoW词典来寻找特征匹配（参见[ORB－SLAM（六）回环检测](http://www.cnblogs.com/luyb/p/5599042.html%20)）；最后，利用匹配的特征优化位姿（参见[ORB－SLAM（五）优化](http://www.cnblogs.com/luyb/p/5447497.html)）。\n\n3. Relocalization\n\n   使用DBoW2实现。假如当前帧与最近邻关键帧的匹配也失败了，意味着此时当前帧已经丢了，无法确定其真实位置。此时，只有去和所有关键帧匹配，看能否找到合适的位置。\n\n   重定位的过程大概是这样的：\n\n   1. 计算当前帧的特征BoW向量；\n   2. 利用BoW词典，根据词袋模型的特征匹配度，在关键帧数据库中找到与当前图像帧相似的候选关键帧，使用`KeyFrameDatabase::DetectRelocalizationCandidates`（**注意这里是参考普通图像帧（当前图像帧）寻找候选关键帧，与回环检测过程不同，回环检测使用参考关键帧去寻找闭环候选帧，使用`KeyFrameDatabase::DetectLoopCandidates`，所以两种情况选取候选关键帧的策略不同**）；\n   3. 通过BoW匹配当前帧和每一个候选关键帧，如果匹配数足够，进行EPnP求解；\n   4. 对求解结果使用BA优化，如果内点较少，则反投影当前帧的地图点到候选关键帧获取额外的匹配点；若这样依然不够，放弃该候选关键帧，若足够，则将通过反投影获取的额外地图点加入，再进行优化。\n   5. 如果内点满足要求(>50)则成功重定位，将最新重定位的id更新：mnLastRelocFrameId = mCurrentFrame.mnId;　　否则返回false。\n\n## TrackLocalMap\n\n一旦我们通过上面三种模型获取了初始的相机位姿和初始的特征匹配，就可以将完整的地图（地图点）投影到当前帧中，去搜索更多的匹配。但是投影完整的地图，在large scale的场景中是很耗计算而且也没有必要的，因此，这里使用了局部地图LocalMap来进行投影匹配。对局部地图的更新包括对局部关键帧和局部地图点的更新。**局部地图包含**：与当前帧相连的关键帧K1（所有能观察到当前帧对应地图点的关键帧，图中Pos2），以及与K1相连的关键帧K2（一级二级相连关键帧，图中Pos1），并且限制了关键数量不超过80；K1、K2对应的地图点（图中X1，貌似X0不包括在内，为啥？？）；参考关键帧Kf。[下图](http://www.cnblogs.com/luyb/p/5447497.html)局部地图就是红色椭圆圈出的部分，参与局部优化，其中红色代表取值会被优化，灰色代表取值保持不变。\n\n{% asset_img 局部地图示意图.png %}\n\n匹配过程如下：　　\n\n1. 抛弃投影范围超出相机画面的；　　\n2. 抛弃观测视角和地图点平均观测方向相差60o以上的；　　\n3. 抛弃特征点的尺度和地图点的尺度（通过高斯金字塔层数表示）不匹配的；　　\n4. 计算当前帧中特征点的尺度；　　\n5. 将地图点的描述子和当前帧ORB特征的描述子匹配，需要根据地图点尺度在初始位姿获取的粗略x投影位置附近搜索；　　\n6. 根据所有匹配点进行PoseOptimization优化。 \n\n### 位姿优化\n\n姿态优化部分的主要思路是**在当前帧和（局部）地图之间寻找尽可能多的对应关系，来优化当前帧的位姿。**实际程序中，作者选取了非常多的关键帧和地图点。在跑Euroc数据集MH_01_easy时，几乎有一半以上的关键帧和地图点（后期>3000个）会在这一步被选中。然而，每一帧中只有200~300个地图点可以在当前帧上找到特征匹配点。这一步保证了非关键帧姿态估计的精度和鲁棒性。\n\n## 其他操作\n\n在处理完mCurrentFrame的跟踪定位后，需要**更新motion model**，并**判断当前帧是否是新的关键帧**。\n\n### 新的关键帧的创建\n\n以下条件必须同时满足，才可以加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度，同时在LocalMapping线程最后会进行关键帧的剔除，又确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。但是，ORB的作者又提到了，Tracking中除了提取特征点，TrackLocalMap也挺耗时，可以通过减少关键帧的数量来降低Local Map的规模，提高Tracking速度（但是精确度可能降低）。\n\n1. 距离上一次重定位距离至少20帧；\n2. 局部地图线程空闲，或者距离上一次加入关键帧过去了20帧；如果需要关键帧插入（过了20帧）而LocalMapping线程忙，则发送信号给LocalMapping线程，停止局部地图优化，使得新的关键帧可以被及时处理（20帧，大概过去了不到1s）；\n3. 当前帧跟踪至少50个点；确保了跟踪定位的精确度；\n4. 当前帧跟踪到LocalMap中参考帧的地图点数量少于90%；确保关键帧之间有明显的视觉变化。\n\n如果满足了创建关键帧的条件，在`Tracking::CreateNewKeyFrame()`函数中完成关键帧创建，将关键帧传递到LocalMapping线程（`mpLocalMapper->InsertKeyFrame(pKF)`），再由LocalMapping完成其他工作。此外，在创建关键帧之后，对于双目、RGB-D的情况，会使用深度值大于0的关键点重投影得到地图点，得到的地图点会和当前关键帧关联，并加入到`Map`。\n\n> **注意：**\n>\n> 这里只是判断是否需要将当前帧创建为关键帧，并没有真的加入全局地图，因为Tracking线程的主要功能是局部定位，而处理地图中的关键帧、地图点，包括如何加入、如何删除的工作是在LocalMapping线程完成的，这里也可以看出作者的思路是比较清楚的，Tracking负责localization，LocalMapping负责Mapping，就构建了粗略的完整SLAM框架，然后加入初始化和闭环检测以及一些可视化模块，形成完整的SLAM。\n\n## 总结\n\n{% asset_img Tracking重点环节.png %}\n\n追踪模块是实现SLAM框架中视觉里程计模块的主体部分，其主要过程包括：初始化、初始追踪（初始位姿估计）、局部地图追踪（进一步的位姿估计）、局部优化、决定是否创建新的关键帧等。初始位姿估计仅仅完成了视觉里程计中的帧间追踪，该过程要么选择上一帧，要么选择参考关键帧，要么从全局关键帧数据库中选取候选关键帧与当前帧进行特征匹配，分别进行恒速运动模型（通过投影上一帧的地图点到当前帧，实现投影匹配）、参考关键帧追踪模型（通过投影参考关键帧的地图点到当前帧，实现投影匹配）、重定位模型（用DBow2实现匹配）。此外，还需要进行局部地图的追踪（通过投影局部地图点到当前帧，实现投影匹配），提高精度。\n\n> ### 小记\n>\n> 在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place \n> Recognition，因此需要用DBow；\n>\n> 投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间，恒速运动模型、参考关键帧追踪模型、局部地图追踪模型都是使用的投影匹配。\n\n\n\n## 后续再深入学习其他内容\n\n1. ORB特征提取（涉及到Fast关键点检测、rBRIEF描述子、SIFT特征）\n2. 尺度空间、金字塔、变化尺度（尺度因子）\n3. [DBoW2](https://blog.csdn.net/u010821666/article/details/52915238?locationNum=1&fps=1)、BoW向量\n4. [以上在ORB_SLAM中的应用](https://blog.csdn.net/c602273091/article/details/54955663)\n\n5. 相机运动估计\n\n> #### 地图点投影（匹配）、三角测量\n>\n> ####  [2D-2D：对极几何（本质矩阵 单应矩阵）](https://www.cnblogs.com/shang-slam/p/6496411.html)\n>\n> http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/\n>\n> #### 参考资料\n>\n> 1. 视觉slam十四讲P153\n> 2. 计算机视觉算法与应用P264\n> 3. 视觉slam十四讲P141\n>\n>\n\n6. [双目立体成像](https://www.cnblogs.com/german-iris/p/4937712.html)与畸变校正（双目矫正）\n\n\n7. 三角剖分\n\n## 参考资料\n\n1. http://www.cnblogs.com/luyb/p/5357790.html\n2. https://www.cnblogs.com/shang-slam/p/6395514.html","source":"_posts/ORB_SLAM2学习之源码分析一-追踪.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析一-追踪\ndate: 2018-08-12 20:01:21\ntags: \n  - ORB_SLAM2\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n---\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录Tracking模块部分。\n\n<!--more-->\n\nORB-SLAM2系统追踪、局部建图、回环检测、可视化四个线程，其中追踪模块是在主线程中完成的，SLAM视觉里程计主体就是在该线程中完成的。先介绍追踪模块的算法内容，这里从已经完成模块初始化开始。ORB_SLAM2中，重定位和闭环检测过程主要使用DBoW2来完成。\n\n# Tracking代码分析\n\n程序分为两种模式：**SLAM模式**和**Localization模式**，由变量`mbOnlyTracking`标记。SLAM模式中，三个线程全部都在工作，即在定位也在建图。而Localization模式中，只有Tracking线程在工作，即只定位，输出追踪结果（姿态），不会更新地图和关键帧。Localization模式主要用于已经有场景地图的情况下（在SLAM模式下完成建图后可以无缝切换到Localization模式）。Localization模式下追踪方法涉及到的关键函数是一样的，只是策略有所不同。\n\n{% asset_img Track.png %}\n\n{% asset_img Tracking跟踪模型.png %}\n\n上图是参考资料1中的流程图，介绍的比较详细，可供参考。\n\n## 初始追踪\n\n初始化完成后，对于相机获取当前图像`mCurrentFrame`，通过跟踪匹配上一帧`mLastFrame`特征点的方式，可以获取一个相机位姿的初始值；为了兼顾计算量和跟踪鲁棒性，追踪部分主要用了三种模型：运动模型（TrackWithMotionModel）、关键帧（TrackReferenceKeyFrame）和重定位（Relocalization）。三种跟踪模型都是为了获取相机位姿一个粗略的初值，后面会通过跟踪局部地图TrackLocalMap对位姿进行BundleAdjustment（捆集调整），进一步优化位姿。\n\n1. TrackWithMotionModel\n\n   该模型根据两帧之间的约束关系来求解估算位姿。假设物体处于匀速运动，那么可以用上一帧的位姿和速度来估计当前帧的位姿。上一帧的速度可以通过前面几帧的位姿计算得到。这个模型适用于运动速度和方向比较一致、没有大转动的情形，比如匀速运动的汽车、机器人、人等。如果是静止状态或者运动模型匹配失效（运用恒速模型后反投影发现LastFrame的地图点和CurrentFrame的特征点匹配很少），通过增大参考帧的地图点反投影匹配范围，获取较多匹配后，计算当前位姿；而对于运动比较随意的目标，上述操作失效的情况下，就会用到下面两个模型。\n\n2. TrackReferenceKeyFrame\n\n   假如motion model已经失效，那么首先可以尝试和最近一个关键帧（即参考关键帧）去做匹配。毕竟当前帧和上一个关键帧的距离还不是很远。作者利用了bag of words（BoW）来加速匹配。首先，计算当前帧的BoW，并设定初始位姿为上一帧的位姿；其次，根据位姿和BoW词典来寻找特征匹配（参见[ORB－SLAM（六）回环检测](http://www.cnblogs.com/luyb/p/5599042.html%20)）；最后，利用匹配的特征优化位姿（参见[ORB－SLAM（五）优化](http://www.cnblogs.com/luyb/p/5447497.html)）。\n\n3. Relocalization\n\n   使用DBoW2实现。假如当前帧与最近邻关键帧的匹配也失败了，意味着此时当前帧已经丢了，无法确定其真实位置。此时，只有去和所有关键帧匹配，看能否找到合适的位置。\n\n   重定位的过程大概是这样的：\n\n   1. 计算当前帧的特征BoW向量；\n   2. 利用BoW词典，根据词袋模型的特征匹配度，在关键帧数据库中找到与当前图像帧相似的候选关键帧，使用`KeyFrameDatabase::DetectRelocalizationCandidates`（**注意这里是参考普通图像帧（当前图像帧）寻找候选关键帧，与回环检测过程不同，回环检测使用参考关键帧去寻找闭环候选帧，使用`KeyFrameDatabase::DetectLoopCandidates`，所以两种情况选取候选关键帧的策略不同**）；\n   3. 通过BoW匹配当前帧和每一个候选关键帧，如果匹配数足够，进行EPnP求解；\n   4. 对求解结果使用BA优化，如果内点较少，则反投影当前帧的地图点到候选关键帧获取额外的匹配点；若这样依然不够，放弃该候选关键帧，若足够，则将通过反投影获取的额外地图点加入，再进行优化。\n   5. 如果内点满足要求(>50)则成功重定位，将最新重定位的id更新：mnLastRelocFrameId = mCurrentFrame.mnId;　　否则返回false。\n\n## TrackLocalMap\n\n一旦我们通过上面三种模型获取了初始的相机位姿和初始的特征匹配，就可以将完整的地图（地图点）投影到当前帧中，去搜索更多的匹配。但是投影完整的地图，在large scale的场景中是很耗计算而且也没有必要的，因此，这里使用了局部地图LocalMap来进行投影匹配。对局部地图的更新包括对局部关键帧和局部地图点的更新。**局部地图包含**：与当前帧相连的关键帧K1（所有能观察到当前帧对应地图点的关键帧，图中Pos2），以及与K1相连的关键帧K2（一级二级相连关键帧，图中Pos1），并且限制了关键数量不超过80；K1、K2对应的地图点（图中X1，貌似X0不包括在内，为啥？？）；参考关键帧Kf。[下图](http://www.cnblogs.com/luyb/p/5447497.html)局部地图就是红色椭圆圈出的部分，参与局部优化，其中红色代表取值会被优化，灰色代表取值保持不变。\n\n{% asset_img 局部地图示意图.png %}\n\n匹配过程如下：　　\n\n1. 抛弃投影范围超出相机画面的；　　\n2. 抛弃观测视角和地图点平均观测方向相差60o以上的；　　\n3. 抛弃特征点的尺度和地图点的尺度（通过高斯金字塔层数表示）不匹配的；　　\n4. 计算当前帧中特征点的尺度；　　\n5. 将地图点的描述子和当前帧ORB特征的描述子匹配，需要根据地图点尺度在初始位姿获取的粗略x投影位置附近搜索；　　\n6. 根据所有匹配点进行PoseOptimization优化。 \n\n### 位姿优化\n\n姿态优化部分的主要思路是**在当前帧和（局部）地图之间寻找尽可能多的对应关系，来优化当前帧的位姿。**实际程序中，作者选取了非常多的关键帧和地图点。在跑Euroc数据集MH_01_easy时，几乎有一半以上的关键帧和地图点（后期>3000个）会在这一步被选中。然而，每一帧中只有200~300个地图点可以在当前帧上找到特征匹配点。这一步保证了非关键帧姿态估计的精度和鲁棒性。\n\n## 其他操作\n\n在处理完mCurrentFrame的跟踪定位后，需要**更新motion model**，并**判断当前帧是否是新的关键帧**。\n\n### 新的关键帧的创建\n\n以下条件必须同时满足，才可以加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度，同时在LocalMapping线程最后会进行关键帧的剔除，又确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。但是，ORB的作者又提到了，Tracking中除了提取特征点，TrackLocalMap也挺耗时，可以通过减少关键帧的数量来降低Local Map的规模，提高Tracking速度（但是精确度可能降低）。\n\n1. 距离上一次重定位距离至少20帧；\n2. 局部地图线程空闲，或者距离上一次加入关键帧过去了20帧；如果需要关键帧插入（过了20帧）而LocalMapping线程忙，则发送信号给LocalMapping线程，停止局部地图优化，使得新的关键帧可以被及时处理（20帧，大概过去了不到1s）；\n3. 当前帧跟踪至少50个点；确保了跟踪定位的精确度；\n4. 当前帧跟踪到LocalMap中参考帧的地图点数量少于90%；确保关键帧之间有明显的视觉变化。\n\n如果满足了创建关键帧的条件，在`Tracking::CreateNewKeyFrame()`函数中完成关键帧创建，将关键帧传递到LocalMapping线程（`mpLocalMapper->InsertKeyFrame(pKF)`），再由LocalMapping完成其他工作。此外，在创建关键帧之后，对于双目、RGB-D的情况，会使用深度值大于0的关键点重投影得到地图点，得到的地图点会和当前关键帧关联，并加入到`Map`。\n\n> **注意：**\n>\n> 这里只是判断是否需要将当前帧创建为关键帧，并没有真的加入全局地图，因为Tracking线程的主要功能是局部定位，而处理地图中的关键帧、地图点，包括如何加入、如何删除的工作是在LocalMapping线程完成的，这里也可以看出作者的思路是比较清楚的，Tracking负责localization，LocalMapping负责Mapping，就构建了粗略的完整SLAM框架，然后加入初始化和闭环检测以及一些可视化模块，形成完整的SLAM。\n\n## 总结\n\n{% asset_img Tracking重点环节.png %}\n\n追踪模块是实现SLAM框架中视觉里程计模块的主体部分，其主要过程包括：初始化、初始追踪（初始位姿估计）、局部地图追踪（进一步的位姿估计）、局部优化、决定是否创建新的关键帧等。初始位姿估计仅仅完成了视觉里程计中的帧间追踪，该过程要么选择上一帧，要么选择参考关键帧，要么从全局关键帧数据库中选取候选关键帧与当前帧进行特征匹配，分别进行恒速运动模型（通过投影上一帧的地图点到当前帧，实现投影匹配）、参考关键帧追踪模型（通过投影参考关键帧的地图点到当前帧，实现投影匹配）、重定位模型（用DBow2实现匹配）。此外，还需要进行局部地图的追踪（通过投影局部地图点到当前帧，实现投影匹配），提高精度。\n\n> ### 小记\n>\n> 在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place \n> Recognition，因此需要用DBow；\n>\n> 投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间，恒速运动模型、参考关键帧追踪模型、局部地图追踪模型都是使用的投影匹配。\n\n\n\n## 后续再深入学习其他内容\n\n1. ORB特征提取（涉及到Fast关键点检测、rBRIEF描述子、SIFT特征）\n2. 尺度空间、金字塔、变化尺度（尺度因子）\n3. [DBoW2](https://blog.csdn.net/u010821666/article/details/52915238?locationNum=1&fps=1)、BoW向量\n4. [以上在ORB_SLAM中的应用](https://blog.csdn.net/c602273091/article/details/54955663)\n\n5. 相机运动估计\n\n> #### 地图点投影（匹配）、三角测量\n>\n> ####  [2D-2D：对极几何（本质矩阵 单应矩阵）](https://www.cnblogs.com/shang-slam/p/6496411.html)\n>\n> http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/\n>\n> #### 参考资料\n>\n> 1. 视觉slam十四讲P153\n> 2. 计算机视觉算法与应用P264\n> 3. 视觉slam十四讲P141\n>\n>\n\n6. [双目立体成像](https://www.cnblogs.com/german-iris/p/4937712.html)与畸变校正（双目矫正）\n\n\n7. 三角剖分\n\n## 参考资料\n\n1. http://www.cnblogs.com/luyb/p/5357790.html\n2. https://www.cnblogs.com/shang-slam/p/6395514.html","slug":"ORB_SLAM2学习之源码分析一-追踪","published":1,"updated":"2019-05-30T12:29:26.291Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbys00bgqlcr1z4a9o3v","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录Tracking模块部分。</p>\n<a id=\"more\"></a>\n<p>ORB-SLAM2系统追踪、局部建图、回环检测、可视化四个线程，其中追踪模块是在主线程中完成的，SLAM视觉里程计主体就是在该线程中完成的。先介绍追踪模块的算法内容，这里从已经完成模块初始化开始。ORB_SLAM2中，重定位和闭环检测过程主要使用DBoW2来完成。</p>\n<h1 id=\"Tracking代码分析\"><a href=\"#Tracking代码分析\" class=\"headerlink\" title=\"Tracking代码分析\"></a>Tracking代码分析</h1><p>程序分为两种模式：<strong>SLAM模式</strong>和<strong>Localization模式</strong>，由变量<code>mbOnlyTracking</code>标记。SLAM模式中，三个线程全部都在工作，即在定位也在建图。而Localization模式中，只有Tracking线程在工作，即只定位，输出追踪结果（姿态），不会更新地图和关键帧。Localization模式主要用于已经有场景地图的情况下（在SLAM模式下完成建图后可以无缝切换到Localization模式）。Localization模式下追踪方法涉及到的关键函数是一样的，只是策略有所不同。</p>\n<img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Track.png\">\n<img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Tracking跟踪模型.png\">\n<p>上图是参考资料1中的流程图，介绍的比较详细，可供参考。</p>\n<h2 id=\"初始追踪\"><a href=\"#初始追踪\" class=\"headerlink\" title=\"初始追踪\"></a>初始追踪</h2><p>初始化完成后，对于相机获取当前图像<code>mCurrentFrame</code>，通过跟踪匹配上一帧<code>mLastFrame</code>特征点的方式，可以获取一个相机位姿的初始值；为了兼顾计算量和跟踪鲁棒性，追踪部分主要用了三种模型：运动模型（TrackWithMotionModel）、关键帧（TrackReferenceKeyFrame）和重定位（Relocalization）。三种跟踪模型都是为了获取相机位姿一个粗略的初值，后面会通过跟踪局部地图TrackLocalMap对位姿进行BundleAdjustment（捆集调整），进一步优化位姿。</p>\n<ol>\n<li><p>TrackWithMotionModel</p>\n<p>该模型根据两帧之间的约束关系来求解估算位姿。假设物体处于匀速运动，那么可以用上一帧的位姿和速度来估计当前帧的位姿。上一帧的速度可以通过前面几帧的位姿计算得到。这个模型适用于运动速度和方向比较一致、没有大转动的情形，比如匀速运动的汽车、机器人、人等。如果是静止状态或者运动模型匹配失效（运用恒速模型后反投影发现LastFrame的地图点和CurrentFrame的特征点匹配很少），通过增大参考帧的地图点反投影匹配范围，获取较多匹配后，计算当前位姿；而对于运动比较随意的目标，上述操作失效的情况下，就会用到下面两个模型。</p>\n</li>\n<li><p>TrackReferenceKeyFrame</p>\n<p>假如motion model已经失效，那么首先可以尝试和最近一个关键帧（即参考关键帧）去做匹配。毕竟当前帧和上一个关键帧的距离还不是很远。作者利用了bag of words（BoW）来加速匹配。首先，计算当前帧的BoW，并设定初始位姿为上一帧的位姿；其次，根据位姿和BoW词典来寻找特征匹配（参见<a href=\"http://www.cnblogs.com/luyb/p/5599042.html%20\" target=\"_blank\" rel=\"noopener\">ORB－SLAM（六）回环检测</a>）；最后，利用匹配的特征优化位姿（参见<a href=\"http://www.cnblogs.com/luyb/p/5447497.html\" target=\"_blank\" rel=\"noopener\">ORB－SLAM（五）优化</a>）。</p>\n</li>\n<li><p>Relocalization</p>\n<p>使用DBoW2实现。假如当前帧与最近邻关键帧的匹配也失败了，意味着此时当前帧已经丢了，无法确定其真实位置。此时，只有去和所有关键帧匹配，看能否找到合适的位置。</p>\n<p>重定位的过程大概是这样的：</p>\n<ol>\n<li>计算当前帧的特征BoW向量；</li>\n<li>利用BoW词典，根据词袋模型的特征匹配度，在关键帧数据库中找到与当前图像帧相似的候选关键帧，使用<code>KeyFrameDatabase::DetectRelocalizationCandidates</code>（<strong>注意这里是参考普通图像帧（当前图像帧）寻找候选关键帧，与回环检测过程不同，回环检测使用参考关键帧去寻找闭环候选帧，使用<code>KeyFrameDatabase::DetectLoopCandidates</code>，所以两种情况选取候选关键帧的策略不同</strong>）；</li>\n<li>通过BoW匹配当前帧和每一个候选关键帧，如果匹配数足够，进行EPnP求解；</li>\n<li>对求解结果使用BA优化，如果内点较少，则反投影当前帧的地图点到候选关键帧获取额外的匹配点；若这样依然不够，放弃该候选关键帧，若足够，则将通过反投影获取的额外地图点加入，再进行优化。</li>\n<li>如果内点满足要求(&gt;50)则成功重定位，将最新重定位的id更新：mnLastRelocFrameId = mCurrentFrame.mnId;　　否则返回false。</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"TrackLocalMap\"><a href=\"#TrackLocalMap\" class=\"headerlink\" title=\"TrackLocalMap\"></a>TrackLocalMap</h2><p>一旦我们通过上面三种模型获取了初始的相机位姿和初始的特征匹配，就可以将完整的地图（地图点）投影到当前帧中，去搜索更多的匹配。但是投影完整的地图，在large scale的场景中是很耗计算而且也没有必要的，因此，这里使用了局部地图LocalMap来进行投影匹配。对局部地图的更新包括对局部关键帧和局部地图点的更新。<strong>局部地图包含</strong>：与当前帧相连的关键帧K1（所有能观察到当前帧对应地图点的关键帧，图中Pos2），以及与K1相连的关键帧K2（一级二级相连关键帧，图中Pos1），并且限制了关键数量不超过80；K1、K2对应的地图点（图中X1，貌似X0不包括在内，为啥？？）；参考关键帧Kf。<a href=\"http://www.cnblogs.com/luyb/p/5447497.html\" target=\"_blank\" rel=\"noopener\">下图</a>局部地图就是红色椭圆圈出的部分，参与局部优化，其中红色代表取值会被优化，灰色代表取值保持不变。</p>\n<img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/局部地图示意图.png\">\n<p>匹配过程如下：　　</p>\n<ol>\n<li>抛弃投影范围超出相机画面的；　　</li>\n<li>抛弃观测视角和地图点平均观测方向相差60o以上的；　　</li>\n<li>抛弃特征点的尺度和地图点的尺度（通过高斯金字塔层数表示）不匹配的；　　</li>\n<li>计算当前帧中特征点的尺度；　　</li>\n<li>将地图点的描述子和当前帧ORB特征的描述子匹配，需要根据地图点尺度在初始位姿获取的粗略x投影位置附近搜索；　　</li>\n<li>根据所有匹配点进行PoseOptimization优化。 </li>\n</ol>\n<h3 id=\"位姿优化\"><a href=\"#位姿优化\" class=\"headerlink\" title=\"位姿优化\"></a>位姿优化</h3><p>姿态优化部分的主要思路是<strong>在当前帧和（局部）地图之间寻找尽可能多的对应关系，来优化当前帧的位姿。</strong>实际程序中，作者选取了非常多的关键帧和地图点。在跑Euroc数据集MH_01_easy时，几乎有一半以上的关键帧和地图点（后期&gt;3000个）会在这一步被选中。然而，每一帧中只有200~300个地图点可以在当前帧上找到特征匹配点。这一步保证了非关键帧姿态估计的精度和鲁棒性。</p>\n<h2 id=\"其他操作\"><a href=\"#其他操作\" class=\"headerlink\" title=\"其他操作\"></a>其他操作</h2><p>在处理完mCurrentFrame的跟踪定位后，需要<strong>更新motion model</strong>，并<strong>判断当前帧是否是新的关键帧</strong>。</p>\n<h3 id=\"新的关键帧的创建\"><a href=\"#新的关键帧的创建\" class=\"headerlink\" title=\"新的关键帧的创建\"></a>新的关键帧的创建</h3><p>以下条件必须同时满足，才可以加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度，同时在LocalMapping线程最后会进行关键帧的剔除，又确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。但是，ORB的作者又提到了，Tracking中除了提取特征点，TrackLocalMap也挺耗时，可以通过减少关键帧的数量来降低Local Map的规模，提高Tracking速度（但是精确度可能降低）。</p>\n<ol>\n<li>距离上一次重定位距离至少20帧；</li>\n<li>局部地图线程空闲，或者距离上一次加入关键帧过去了20帧；如果需要关键帧插入（过了20帧）而LocalMapping线程忙，则发送信号给LocalMapping线程，停止局部地图优化，使得新的关键帧可以被及时处理（20帧，大概过去了不到1s）；</li>\n<li>当前帧跟踪至少50个点；确保了跟踪定位的精确度；</li>\n<li>当前帧跟踪到LocalMap中参考帧的地图点数量少于90%；确保关键帧之间有明显的视觉变化。</li>\n</ol>\n<p>如果满足了创建关键帧的条件，在<code>Tracking::CreateNewKeyFrame()</code>函数中完成关键帧创建，将关键帧传递到LocalMapping线程（<code>mpLocalMapper-&gt;InsertKeyFrame(pKF)</code>），再由LocalMapping完成其他工作。此外，在创建关键帧之后，对于双目、RGB-D的情况，会使用深度值大于0的关键点重投影得到地图点，得到的地图点会和当前关键帧关联，并加入到<code>Map</code>。</p>\n<blockquote>\n<p><strong>注意：</strong></p>\n<p>这里只是判断是否需要将当前帧创建为关键帧，并没有真的加入全局地图，因为Tracking线程的主要功能是局部定位，而处理地图中的关键帧、地图点，包括如何加入、如何删除的工作是在LocalMapping线程完成的，这里也可以看出作者的思路是比较清楚的，Tracking负责localization，LocalMapping负责Mapping，就构建了粗略的完整SLAM框架，然后加入初始化和闭环检测以及一些可视化模块，形成完整的SLAM。</p>\n</blockquote>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Tracking重点环节.png\">\n<p>追踪模块是实现SLAM框架中视觉里程计模块的主体部分，其主要过程包括：初始化、初始追踪（初始位姿估计）、局部地图追踪（进一步的位姿估计）、局部优化、决定是否创建新的关键帧等。初始位姿估计仅仅完成了视觉里程计中的帧间追踪，该过程要么选择上一帧，要么选择参考关键帧，要么从全局关键帧数据库中选取候选关键帧与当前帧进行特征匹配，分别进行恒速运动模型（通过投影上一帧的地图点到当前帧，实现投影匹配）、参考关键帧追踪模型（通过投影参考关键帧的地图点到当前帧，实现投影匹配）、重定位模型（用DBow2实现匹配）。此外，还需要进行局部地图的追踪（通过投影局部地图点到当前帧，实现投影匹配），提高精度。</p>\n<blockquote>\n<h3 id=\"小记\"><a href=\"#小记\" class=\"headerlink\" title=\"小记\"></a>小记</h3><p>在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place<br>Recognition，因此需要用DBow；</p>\n<p>投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间，恒速运动模型、参考关键帧追踪模型、局部地图追踪模型都是使用的投影匹配。</p>\n</blockquote>\n<h2 id=\"后续再深入学习其他内容\"><a href=\"#后续再深入学习其他内容\" class=\"headerlink\" title=\"后续再深入学习其他内容\"></a>后续再深入学习其他内容</h2><ol>\n<li>ORB特征提取（涉及到Fast关键点检测、rBRIEF描述子、SIFT特征）</li>\n<li>尺度空间、金字塔、变化尺度（尺度因子）</li>\n<li><a href=\"https://blog.csdn.net/u010821666/article/details/52915238?locationNum=1&amp;fps=1\" target=\"_blank\" rel=\"noopener\">DBoW2</a>、BoW向量</li>\n<li><p><a href=\"https://blog.csdn.net/c602273091/article/details/54955663\" target=\"_blank\" rel=\"noopener\">以上在ORB_SLAM中的应用</a></p>\n</li>\n<li><p>相机运动估计</p>\n</li>\n</ol>\n<blockquote>\n<h4 id=\"地图点投影（匹配）、三角测量\"><a href=\"#地图点投影（匹配）、三角测量\" class=\"headerlink\" title=\"地图点投影（匹配）、三角测量\"></a>地图点投影（匹配）、三角测量</h4><h4 id=\"2D-2D：对极几何（本质矩阵-单应矩阵）\"><a href=\"#2D-2D：对极几何（本质矩阵-单应矩阵）\" class=\"headerlink\" title=\"2D-2D：对极几何（本质矩阵 单应矩阵）\"></a><a href=\"https://www.cnblogs.com/shang-slam/p/6496411.html\" target=\"_blank\" rel=\"noopener\">2D-2D：对极几何（本质矩阵 单应矩阵）</a></h4><p><a href=\"http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/\" target=\"_blank\" rel=\"noopener\">http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/</a></p>\n<h4 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h4><ol>\n<li>视觉slam十四讲P153</li>\n<li>计算机视觉算法与应用P264</li>\n<li>视觉slam十四讲P141</li>\n</ol>\n</blockquote>\n<ol>\n<li><a href=\"https://www.cnblogs.com/german-iris/p/4937712.html\" target=\"_blank\" rel=\"noopener\">双目立体成像</a>与畸变校正（双目矫正）</li>\n</ol>\n<ol>\n<li>三角剖分</li>\n</ol>\n<h2 id=\"参考资料-1\"><a href=\"#参考资料-1\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://www.cnblogs.com/luyb/p/5357790.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/luyb/p/5357790.html</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6395514.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shang-slam/p/6395514.html</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录Tracking模块部分。</p>","more":"<p>ORB-SLAM2系统追踪、局部建图、回环检测、可视化四个线程，其中追踪模块是在主线程中完成的，SLAM视觉里程计主体就是在该线程中完成的。先介绍追踪模块的算法内容，这里从已经完成模块初始化开始。ORB_SLAM2中，重定位和闭环检测过程主要使用DBoW2来完成。</p>\n<h1 id=\"Tracking代码分析\"><a href=\"#Tracking代码分析\" class=\"headerlink\" title=\"Tracking代码分析\"></a>Tracking代码分析</h1><p>程序分为两种模式：<strong>SLAM模式</strong>和<strong>Localization模式</strong>，由变量<code>mbOnlyTracking</code>标记。SLAM模式中，三个线程全部都在工作，即在定位也在建图。而Localization模式中，只有Tracking线程在工作，即只定位，输出追踪结果（姿态），不会更新地图和关键帧。Localization模式主要用于已经有场景地图的情况下（在SLAM模式下完成建图后可以无缝切换到Localization模式）。Localization模式下追踪方法涉及到的关键函数是一样的，只是策略有所不同。</p>\n<img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Track.png\">\n<img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Tracking跟踪模型.png\">\n<p>上图是参考资料1中的流程图，介绍的比较详细，可供参考。</p>\n<h2 id=\"初始追踪\"><a href=\"#初始追踪\" class=\"headerlink\" title=\"初始追踪\"></a>初始追踪</h2><p>初始化完成后，对于相机获取当前图像<code>mCurrentFrame</code>，通过跟踪匹配上一帧<code>mLastFrame</code>特征点的方式，可以获取一个相机位姿的初始值；为了兼顾计算量和跟踪鲁棒性，追踪部分主要用了三种模型：运动模型（TrackWithMotionModel）、关键帧（TrackReferenceKeyFrame）和重定位（Relocalization）。三种跟踪模型都是为了获取相机位姿一个粗略的初值，后面会通过跟踪局部地图TrackLocalMap对位姿进行BundleAdjustment（捆集调整），进一步优化位姿。</p>\n<ol>\n<li><p>TrackWithMotionModel</p>\n<p>该模型根据两帧之间的约束关系来求解估算位姿。假设物体处于匀速运动，那么可以用上一帧的位姿和速度来估计当前帧的位姿。上一帧的速度可以通过前面几帧的位姿计算得到。这个模型适用于运动速度和方向比较一致、没有大转动的情形，比如匀速运动的汽车、机器人、人等。如果是静止状态或者运动模型匹配失效（运用恒速模型后反投影发现LastFrame的地图点和CurrentFrame的特征点匹配很少），通过增大参考帧的地图点反投影匹配范围，获取较多匹配后，计算当前位姿；而对于运动比较随意的目标，上述操作失效的情况下，就会用到下面两个模型。</p>\n</li>\n<li><p>TrackReferenceKeyFrame</p>\n<p>假如motion model已经失效，那么首先可以尝试和最近一个关键帧（即参考关键帧）去做匹配。毕竟当前帧和上一个关键帧的距离还不是很远。作者利用了bag of words（BoW）来加速匹配。首先，计算当前帧的BoW，并设定初始位姿为上一帧的位姿；其次，根据位姿和BoW词典来寻找特征匹配（参见<a href=\"http://www.cnblogs.com/luyb/p/5599042.html%20\" target=\"_blank\" rel=\"noopener\">ORB－SLAM（六）回环检测</a>）；最后，利用匹配的特征优化位姿（参见<a href=\"http://www.cnblogs.com/luyb/p/5447497.html\" target=\"_blank\" rel=\"noopener\">ORB－SLAM（五）优化</a>）。</p>\n</li>\n<li><p>Relocalization</p>\n<p>使用DBoW2实现。假如当前帧与最近邻关键帧的匹配也失败了，意味着此时当前帧已经丢了，无法确定其真实位置。此时，只有去和所有关键帧匹配，看能否找到合适的位置。</p>\n<p>重定位的过程大概是这样的：</p>\n<ol>\n<li>计算当前帧的特征BoW向量；</li>\n<li>利用BoW词典，根据词袋模型的特征匹配度，在关键帧数据库中找到与当前图像帧相似的候选关键帧，使用<code>KeyFrameDatabase::DetectRelocalizationCandidates</code>（<strong>注意这里是参考普通图像帧（当前图像帧）寻找候选关键帧，与回环检测过程不同，回环检测使用参考关键帧去寻找闭环候选帧，使用<code>KeyFrameDatabase::DetectLoopCandidates</code>，所以两种情况选取候选关键帧的策略不同</strong>）；</li>\n<li>通过BoW匹配当前帧和每一个候选关键帧，如果匹配数足够，进行EPnP求解；</li>\n<li>对求解结果使用BA优化，如果内点较少，则反投影当前帧的地图点到候选关键帧获取额外的匹配点；若这样依然不够，放弃该候选关键帧，若足够，则将通过反投影获取的额外地图点加入，再进行优化。</li>\n<li>如果内点满足要求(&gt;50)则成功重定位，将最新重定位的id更新：mnLastRelocFrameId = mCurrentFrame.mnId;　　否则返回false。</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"TrackLocalMap\"><a href=\"#TrackLocalMap\" class=\"headerlink\" title=\"TrackLocalMap\"></a>TrackLocalMap</h2><p>一旦我们通过上面三种模型获取了初始的相机位姿和初始的特征匹配，就可以将完整的地图（地图点）投影到当前帧中，去搜索更多的匹配。但是投影完整的地图，在large scale的场景中是很耗计算而且也没有必要的，因此，这里使用了局部地图LocalMap来进行投影匹配。对局部地图的更新包括对局部关键帧和局部地图点的更新。<strong>局部地图包含</strong>：与当前帧相连的关键帧K1（所有能观察到当前帧对应地图点的关键帧，图中Pos2），以及与K1相连的关键帧K2（一级二级相连关键帧，图中Pos1），并且限制了关键数量不超过80；K1、K2对应的地图点（图中X1，貌似X0不包括在内，为啥？？）；参考关键帧Kf。<a href=\"http://www.cnblogs.com/luyb/p/5447497.html\" target=\"_blank\" rel=\"noopener\">下图</a>局部地图就是红色椭圆圈出的部分，参与局部优化，其中红色代表取值会被优化，灰色代表取值保持不变。</p>\n<img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/局部地图示意图.png\">\n<p>匹配过程如下：　　</p>\n<ol>\n<li>抛弃投影范围超出相机画面的；　　</li>\n<li>抛弃观测视角和地图点平均观测方向相差60o以上的；　　</li>\n<li>抛弃特征点的尺度和地图点的尺度（通过高斯金字塔层数表示）不匹配的；　　</li>\n<li>计算当前帧中特征点的尺度；　　</li>\n<li>将地图点的描述子和当前帧ORB特征的描述子匹配，需要根据地图点尺度在初始位姿获取的粗略x投影位置附近搜索；　　</li>\n<li>根据所有匹配点进行PoseOptimization优化。 </li>\n</ol>\n<h3 id=\"位姿优化\"><a href=\"#位姿优化\" class=\"headerlink\" title=\"位姿优化\"></a>位姿优化</h3><p>姿态优化部分的主要思路是<strong>在当前帧和（局部）地图之间寻找尽可能多的对应关系，来优化当前帧的位姿。</strong>实际程序中，作者选取了非常多的关键帧和地图点。在跑Euroc数据集MH_01_easy时，几乎有一半以上的关键帧和地图点（后期&gt;3000个）会在这一步被选中。然而，每一帧中只有200~300个地图点可以在当前帧上找到特征匹配点。这一步保证了非关键帧姿态估计的精度和鲁棒性。</p>\n<h2 id=\"其他操作\"><a href=\"#其他操作\" class=\"headerlink\" title=\"其他操作\"></a>其他操作</h2><p>在处理完mCurrentFrame的跟踪定位后，需要<strong>更新motion model</strong>，并<strong>判断当前帧是否是新的关键帧</strong>。</p>\n<h3 id=\"新的关键帧的创建\"><a href=\"#新的关键帧的创建\" class=\"headerlink\" title=\"新的关键帧的创建\"></a>新的关键帧的创建</h3><p>以下条件必须同时满足，才可以加入关键帧，但是其实ORB-SLAM中关键帧的加入是比较密集的，这样确保了定位的精度，同时在LocalMapping线程最后会进行关键帧的剔除，又确保了关键帧的数量不会无限增加，不会对large scale的场景造成计算负担。但是，ORB的作者又提到了，Tracking中除了提取特征点，TrackLocalMap也挺耗时，可以通过减少关键帧的数量来降低Local Map的规模，提高Tracking速度（但是精确度可能降低）。</p>\n<ol>\n<li>距离上一次重定位距离至少20帧；</li>\n<li>局部地图线程空闲，或者距离上一次加入关键帧过去了20帧；如果需要关键帧插入（过了20帧）而LocalMapping线程忙，则发送信号给LocalMapping线程，停止局部地图优化，使得新的关键帧可以被及时处理（20帧，大概过去了不到1s）；</li>\n<li>当前帧跟踪至少50个点；确保了跟踪定位的精确度；</li>\n<li>当前帧跟踪到LocalMap中参考帧的地图点数量少于90%；确保关键帧之间有明显的视觉变化。</li>\n</ol>\n<p>如果满足了创建关键帧的条件，在<code>Tracking::CreateNewKeyFrame()</code>函数中完成关键帧创建，将关键帧传递到LocalMapping线程（<code>mpLocalMapper-&gt;InsertKeyFrame(pKF)</code>），再由LocalMapping完成其他工作。此外，在创建关键帧之后，对于双目、RGB-D的情况，会使用深度值大于0的关键点重投影得到地图点，得到的地图点会和当前关键帧关联，并加入到<code>Map</code>。</p>\n<blockquote>\n<p><strong>注意：</strong></p>\n<p>这里只是判断是否需要将当前帧创建为关键帧，并没有真的加入全局地图，因为Tracking线程的主要功能是局部定位，而处理地图中的关键帧、地图点，包括如何加入、如何删除的工作是在LocalMapping线程完成的，这里也可以看出作者的思路是比较清楚的，Tracking负责localization，LocalMapping负责Mapping，就构建了粗略的完整SLAM框架，然后加入初始化和闭环检测以及一些可视化模块，形成完整的SLAM。</p>\n</blockquote>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><img src=\"/2018/08/12/ORB_SLAM2学习之源码分析一-追踪/Tracking重点环节.png\">\n<p>追踪模块是实现SLAM框架中视觉里程计模块的主体部分，其主要过程包括：初始化、初始追踪（初始位姿估计）、局部地图追踪（进一步的位姿估计）、局部优化、决定是否创建新的关键帧等。初始位姿估计仅仅完成了视觉里程计中的帧间追踪，该过程要么选择上一帧，要么选择参考关键帧，要么从全局关键帧数据库中选取候选关键帧与当前帧进行特征匹配，分别进行恒速运动模型（通过投影上一帧的地图点到当前帧，实现投影匹配）、参考关键帧追踪模型（通过投影参考关键帧的地图点到当前帧，实现投影匹配）、重定位模型（用DBow2实现匹配）。此外，还需要进行局部地图的追踪（通过投影局部地图点到当前帧，实现投影匹配），提高精度。</p>\n<blockquote>\n<h3 id=\"小记\"><a href=\"#小记\" class=\"headerlink\" title=\"小记\"></a>小记</h3><p>在Relocalization和LoopClosing中进行匹配的是在很多帧关键帧集合中匹配，属于Place<br>Recognition，因此需要用DBow；</p>\n<p>投影匹配适用于两帧之间，或者投影范围内（局部地图，前一个关键帧对应地图点）的MapPoints与当前帧之间，恒速运动模型、参考关键帧追踪模型、局部地图追踪模型都是使用的投影匹配。</p>\n</blockquote>\n<h2 id=\"后续再深入学习其他内容\"><a href=\"#后续再深入学习其他内容\" class=\"headerlink\" title=\"后续再深入学习其他内容\"></a>后续再深入学习其他内容</h2><ol>\n<li>ORB特征提取（涉及到Fast关键点检测、rBRIEF描述子、SIFT特征）</li>\n<li>尺度空间、金字塔、变化尺度（尺度因子）</li>\n<li><a href=\"https://blog.csdn.net/u010821666/article/details/52915238?locationNum=1&amp;fps=1\" target=\"_blank\" rel=\"noopener\">DBoW2</a>、BoW向量</li>\n<li><p><a href=\"https://blog.csdn.net/c602273091/article/details/54955663\" target=\"_blank\" rel=\"noopener\">以上在ORB_SLAM中的应用</a></p>\n</li>\n<li><p>相机运动估计</p>\n</li>\n</ol>\n<blockquote>\n<h4 id=\"地图点投影（匹配）、三角测量\"><a href=\"#地图点投影（匹配）、三角测量\" class=\"headerlink\" title=\"地图点投影（匹配）、三角测量\"></a>地图点投影（匹配）、三角测量</h4><h4 id=\"2D-2D：对极几何（本质矩阵-单应矩阵）\"><a href=\"#2D-2D：对极几何（本质矩阵-单应矩阵）\" class=\"headerlink\" title=\"2D-2D：对极几何（本质矩阵 单应矩阵）\"></a><a href=\"https://www.cnblogs.com/shang-slam/p/6496411.html\" target=\"_blank\" rel=\"noopener\">2D-2D：对极几何（本质矩阵 单应矩阵）</a></h4><p><a href=\"http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/\" target=\"_blank\" rel=\"noopener\">http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/</a></p>\n<h4 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h4><ol>\n<li>视觉slam十四讲P153</li>\n<li>计算机视觉算法与应用P264</li>\n<li>视觉slam十四讲P141</li>\n</ol>\n</blockquote>\n<ol>\n<li><a href=\"https://www.cnblogs.com/german-iris/p/4937712.html\" target=\"_blank\" rel=\"noopener\">双目立体成像</a>与畸变校正（双目矫正）</li>\n</ol>\n<ol>\n<li>三角剖分</li>\n</ol>\n<h2 id=\"参考资料-1\"><a href=\"#参考资料-1\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://www.cnblogs.com/luyb/p/5357790.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/luyb/p/5357790.html</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6395514.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shang-slam/p/6395514.html</a></li>\n</ol>"},{"title":"ORB_SLAM2学习之源码分析三-优化","date":"2018-08-18T09:19:59.000Z","mathjax":true,"copyright":true,"_content":"\n----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录位姿优化有关的内容。\n\n<!--more--->\n\n## 概述\n\n因为摄像机标定（camera  calibration）和追踪（tracking）的精度不够。摄像机标定的误差会体现在重建中（比如三角法重建时），而追踪的误差则会体现在不同关键帧之间的位姿中和重建中（单目）。误差的不断累积会导致后面帧的位姿离实际位姿越来越远，最终会限制系统整体的精度。\n\n### 关于摄像机标定\n\n单目SLAM文献中一般假设摄像机标定的结果是准确的，并不考虑这个因素带来的误差（大概因为很多时候跑标准的数据集，认为摄像机标定的误差是相似的）。然而对于一个产品，不同类型的传感器对应的标定误差并不相同，甚至有可能差异很大。因此，如果要评估整个系统的精度，这方面的误差必须要考虑进去。\n\n### 关于追踪\n\n无论在单目、双目还是RGBD中，追踪得到的位姿都是有误差的。单目SLAM中，如果两帧之间有足够的对应点，那么既可以直接得到两帧之间的位姿（像初始化中那样），也可以通过求解一个优化问题得到（如solvePnP）。由于单目中尺度的不确定性，还会引入尺度的误差（尺度漂移scale-drift）。由于tracking得到的总是相对位姿，前面某一帧的误差会一直传递到后面去，导致tracking到最后位姿误差有可能非常大。为了提高tracking的精度，可以1.  在局部和全局优化位姿；2. 利用闭环检测（loop closure）来优化位姿。\n\n## 优化方法\n\n在SLAM问题中，优化的目标函数常见的几种约束条件为：\n\n  1. 三维点到二维特征的映射关系（通过投影矩阵）；\n\n  2. 位姿和位姿之间的变换关系（通过三维刚体变换）；\n\n  3. 二维特征到二维特征的匹配关系（通过F矩阵）；\n\n  4. 其它关系（比如单目中有相似变换关系）。\n\n     > ### 关于相似变换Sim3\n     >\n     > 相似变换比欧式变换多了一个自由度，有7个自由度，它允许物体进行均匀缩放（体积比不变），其矩阵表示为：\n     >\n     > $T_s=Sim3=\\left[ \\begin{matrix}sR &t\\\\ 0^T &  1   \\end{matrix} \\right]$\n     >\n     > 式中旋转部分多了一个缩放因子$s$，表示我们在对向量旋转之后，可以在x，y，z三个坐标上进行均匀缩放。由于含有缩放，相似变换不再保持图形的面积不变。\n\n如果我们能够知道其中的某些关系是准确的，那么可以在g2o中定义这样的关系及其对应的残差，通过不断迭代优化位姿来逐步减小残差和，从而达到优化位姿的目标。下面介绍ORB-SLAM2系统中主要的优化函数，它们是定义在`Optimizer.h`文件中的静态函数，可以直接通过类名访问，而不必创建类的对象。ORB中使用的这些优化函数是非常重要的，在视觉SLAM中有很强的通用性，自己实现的时候完全可以参考其实现方法。\n\n### 局部优化\n\n#### 对应函数\n\n~~~c++\nvoid Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap)\n~~~\n\n函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\ng2o::BlockSolver_6_3::LinearSolverType * linearSolver;\n\nlinearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_6_3::PoseMatrixType>();\n\ng2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);\n\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n用于LocalMapping线程中，在剔除关键帧之前进行的局部地图优化。当新的关键帧加入到convisibility  graph时，作者在关键帧附近进行一次局部优化，如下图所示。Pos3是新加入的关键帧，其初始估计位姿已经得到。此时，Pos2是和Pos3相连的关键帧，X2是Pos3看到的三维点，X1是Pos2看到的三维点，这些都属于局部信息，共同参与Bundle  Adjustment。同时，Pos1也可以看到X1，但它和Pos3没有直接的联系，属于Pos3关联的局部信息，参与Bundle  Adjustment，但取值保持不变。Pos0和X0不参与Bundle Adjustment。\n\n因此，参与优化的是下图中红色椭圆圈出的部分，其中红色代表取值会被优化，灰色代表取值保持不变。(u,v)是X在Pos下的二维投影点，即X在Pos下的测量（measurement）。优化的目标是最小重投影误差。\n\n{% asset_img 局部优化.png %}\n\n### 全局优化\n\n#### 对应函数\n\n~~~c++\nvoid Optimizer::GlobalBundleAdjustemnt(Map* pMap, int nIterations, bool* pbStopFlag, const unsigned long nLoopKF, const bool bRobust)\n//调用    \nvoid Optimizer::BundleAdjustment(const vector<KeyFrame *> &vpKFs, const vector<MapPoint *> &vpMP, int nIterations, bool* pbStopFlag, const unsigned long nLoopKF, const bool bRobust)\n~~~\n\n函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\n// solver for BA/3D SLAM\ng2o::BlockSolver_6_3::LinearSolverType * linearSolver;\n// 线性方程求解器 使用的求解库为Eigen\nlinearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_6_3::PoseMatrixType>();\n// 稀疏矩阵块求解器\ng2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);\n// 梯度下降算法\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n用于单目初始化的`CreateInitialMapMonocular`函数以及闭环优化的`RunGlobalBundleAdjustment`函数（在闭环结束前新开一个线程，进行全局优化，在此之前会`OptimizeEssentialGraph`，论文中说其实这里全局优化提升的精度有限，所以其实可以考虑不使用全局优化）。在全局优化中，所有的关键帧（除了第一帧）和三维点都参与优化。\n\n{% asset_img 全局优化.png %}CorrectLoop\n\n### 闭环处的Sim3位姿优化\n\n#### 对应函数\n\n~~~c++\nint Optimizer::OptimizeSim3(KeyFrame *pKF1, KeyFrame *pKF2, vector<MapPoint *> &vpMatches1, g2o::Sim3 &g2oS12, const float th2, const bool bFixScale)\n~~~\n\n如果`DetectLoop`检测到回环，则调用`ComputeSim3`计算相似变换矩阵，再进行下一步的闭环调整。计算相似变换矩阵过程中，在用RANSAC求解过Sim3以及通过Sim3匹配更多的地图点后，对当前关键帧、闭环关键帧以及匹配的地图点进行优化，以获得更准确的Sim3位姿。获得当前关键帧相对于闭环关键帧的Sim3，然后传播到相连关键帧，并调整地图点，从而完成闭环调整。函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\n//variable size solver\ng2o::BlockSolverX::LinearSolverType * linearSolver;\n// 线性方程求解器 使用的求解库为Dense\nlinearSolver = new g2o::LinearSolverDense<g2o::BlockSolverX::PoseMatrixType>();\n// 稀疏矩阵块求解器\ng2o::BlockSolverX * solver_ptr = new g2o::BlockSolverX(linearSolver);\n// 梯度下降算法\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n当检测到闭环时，闭环连接的两个关键帧的位姿需要通过Sim3优化（以使得其尺度一致）。优化求解两帧之间的相似变换矩阵，使得二维对应点（feature）的投影误差最小。如下图所示，Pos6和Pos2为一个可能的闭环。通过$(u_{4,2},v_{4,2})$和$(u_{4,6},v_{4,6})$之间的投影误差来优化$S_{6,2}$。\n\n{% asset_img 闭环处优化.png %}\n\n### Sim3上的位姿优化\n\n#### 对应函数\n\n~~~c++\nvoid Optimizer::OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* pCurKF,\nconst LoopClosing::KeyFrameAndPose &NonCorrectedSim3,\nconst LoopClosing::KeyFrameAndPose &CorrectedSim3,\nconst map<KeyFrame *, set<KeyFrame *> > &LoopConnections, const bool &bFixScale)\n~~~\n\nEssentialGraph包括所有的关键帧顶点，但是优化边大大减少，包括spanning tree（生成树）和共视权重θ>100的边，以及闭环连接边。用于闭环检测Sim3调整后，闭环调整`CorrectLoop`过程中的优化。函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\noptimizer.setVerbose(false);\ng2o::BlockSolver_7_3::LinearSolverType * linearSolver =\nnew g2o::LinearSolverEigen<g2o::BlockSolver_7_3::PoseMatrixType>();\ng2o::BlockSolver_7_3 * solver_ptr= new g2o::BlockSolver_7_3(linearSolver);\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\n\nsolver->setUserLambdaInit(1e-16);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n单目SLAM一般都会发生尺度（scale）漂移，因此Sim3上的优化是必要的。相对于SE3，Sim3的自由度要多一个，而且优化的目标是矫正尺度因子，因此优化并没有加入更多的变量（如三维点）。作者在检测到闭环时在Sim3上对所有的位姿进行一次优化。定义Sim3上的残差如下：\n\n$e_{i,j}=log_{Sim3}(S_{ij}S_{jw}S^{−1}_{iw})$\n\n其中$S_{iw}$的初值是尺度为1的Pos i相对于世界坐标系的变换矩阵。$S_{i,j}$为Pos i和Pos j之间的（Sim3优化之前的）相对位姿矩阵，表示$S_{iw}$和$S_{j,w}$之间的测量（measurement）。此处相当于认为局部的相对位姿是准确的，而全局位姿有累计误差，是不准确的。\n\n{% asset_img Sim3上的位姿优化.png %}\n\n### 位姿优化\n\n#### 对应函数\n\n~~~c++\nint Optimizer::PoseOptimization(Frame *pFrame)\n~~~\n\n#### 具体实现\n\n- 只优化当前帧pose，地图点固定。\n- 用于LocalTracking中运动模型跟踪、参考帧跟踪、地图跟踪TrackLocalMap、重定位，每进行过一次PnP投影操作将地图点投影到当前平面上之后，都会进行一次`PoseOptimization`位姿优化，通过BA优化重投影误差。\n\n## ORB-SLAM2中的图\n\n参考：[知乎问题](https://www.zhihu.com/question/42050992)\n\n### Covisibility Graph\n\n共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。\n\n### Essential Graph\n\n为了在优化阶段减小计算量，ORB-SLAM2作者提出了**Essential Graph**的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。\n\n### Spanning Graph\n\n生成树\n\n## 参考资料\n\n1. [ORB-SLAM（五）优化](https://www.cnblogs.com/luyb/p/5447497.html)\n2. [ORB-SLAM（十二）优化](https://www.cnblogs.com/shang-slam/p/6483725.html)\n3. [ORBSlam2的位姿优化算法](https://blog.csdn.net/chishuideyu/article/details/76013854)","source":"_posts/ORB_SLAM2学习之源码分析三-优化.md","raw":"---\ntitle: ORB_SLAM2学习之源码分析三-优化\ndate: 2018-08-18 17:19:59\ntags: \n  - ORB_SLAM2\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n----\n\n这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录位姿优化有关的内容。\n\n<!--more--->\n\n## 概述\n\n因为摄像机标定（camera  calibration）和追踪（tracking）的精度不够。摄像机标定的误差会体现在重建中（比如三角法重建时），而追踪的误差则会体现在不同关键帧之间的位姿中和重建中（单目）。误差的不断累积会导致后面帧的位姿离实际位姿越来越远，最终会限制系统整体的精度。\n\n### 关于摄像机标定\n\n单目SLAM文献中一般假设摄像机标定的结果是准确的，并不考虑这个因素带来的误差（大概因为很多时候跑标准的数据集，认为摄像机标定的误差是相似的）。然而对于一个产品，不同类型的传感器对应的标定误差并不相同，甚至有可能差异很大。因此，如果要评估整个系统的精度，这方面的误差必须要考虑进去。\n\n### 关于追踪\n\n无论在单目、双目还是RGBD中，追踪得到的位姿都是有误差的。单目SLAM中，如果两帧之间有足够的对应点，那么既可以直接得到两帧之间的位姿（像初始化中那样），也可以通过求解一个优化问题得到（如solvePnP）。由于单目中尺度的不确定性，还会引入尺度的误差（尺度漂移scale-drift）。由于tracking得到的总是相对位姿，前面某一帧的误差会一直传递到后面去，导致tracking到最后位姿误差有可能非常大。为了提高tracking的精度，可以1.  在局部和全局优化位姿；2. 利用闭环检测（loop closure）来优化位姿。\n\n## 优化方法\n\n在SLAM问题中，优化的目标函数常见的几种约束条件为：\n\n  1. 三维点到二维特征的映射关系（通过投影矩阵）；\n\n  2. 位姿和位姿之间的变换关系（通过三维刚体变换）；\n\n  3. 二维特征到二维特征的匹配关系（通过F矩阵）；\n\n  4. 其它关系（比如单目中有相似变换关系）。\n\n     > ### 关于相似变换Sim3\n     >\n     > 相似变换比欧式变换多了一个自由度，有7个自由度，它允许物体进行均匀缩放（体积比不变），其矩阵表示为：\n     >\n     > $T_s=Sim3=\\left[ \\begin{matrix}sR &t\\\\ 0^T &  1   \\end{matrix} \\right]$\n     >\n     > 式中旋转部分多了一个缩放因子$s$，表示我们在对向量旋转之后，可以在x，y，z三个坐标上进行均匀缩放。由于含有缩放，相似变换不再保持图形的面积不变。\n\n如果我们能够知道其中的某些关系是准确的，那么可以在g2o中定义这样的关系及其对应的残差，通过不断迭代优化位姿来逐步减小残差和，从而达到优化位姿的目标。下面介绍ORB-SLAM2系统中主要的优化函数，它们是定义在`Optimizer.h`文件中的静态函数，可以直接通过类名访问，而不必创建类的对象。ORB中使用的这些优化函数是非常重要的，在视觉SLAM中有很强的通用性，自己实现的时候完全可以参考其实现方法。\n\n### 局部优化\n\n#### 对应函数\n\n~~~c++\nvoid Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap)\n~~~\n\n函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\ng2o::BlockSolver_6_3::LinearSolverType * linearSolver;\n\nlinearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_6_3::PoseMatrixType>();\n\ng2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);\n\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n用于LocalMapping线程中，在剔除关键帧之前进行的局部地图优化。当新的关键帧加入到convisibility  graph时，作者在关键帧附近进行一次局部优化，如下图所示。Pos3是新加入的关键帧，其初始估计位姿已经得到。此时，Pos2是和Pos3相连的关键帧，X2是Pos3看到的三维点，X1是Pos2看到的三维点，这些都属于局部信息，共同参与Bundle  Adjustment。同时，Pos1也可以看到X1，但它和Pos3没有直接的联系，属于Pos3关联的局部信息，参与Bundle  Adjustment，但取值保持不变。Pos0和X0不参与Bundle Adjustment。\n\n因此，参与优化的是下图中红色椭圆圈出的部分，其中红色代表取值会被优化，灰色代表取值保持不变。(u,v)是X在Pos下的二维投影点，即X在Pos下的测量（measurement）。优化的目标是最小重投影误差。\n\n{% asset_img 局部优化.png %}\n\n### 全局优化\n\n#### 对应函数\n\n~~~c++\nvoid Optimizer::GlobalBundleAdjustemnt(Map* pMap, int nIterations, bool* pbStopFlag, const unsigned long nLoopKF, const bool bRobust)\n//调用    \nvoid Optimizer::BundleAdjustment(const vector<KeyFrame *> &vpKFs, const vector<MapPoint *> &vpMP, int nIterations, bool* pbStopFlag, const unsigned long nLoopKF, const bool bRobust)\n~~~\n\n函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\n// solver for BA/3D SLAM\ng2o::BlockSolver_6_3::LinearSolverType * linearSolver;\n// 线性方程求解器 使用的求解库为Eigen\nlinearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_6_3::PoseMatrixType>();\n// 稀疏矩阵块求解器\ng2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);\n// 梯度下降算法\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n用于单目初始化的`CreateInitialMapMonocular`函数以及闭环优化的`RunGlobalBundleAdjustment`函数（在闭环结束前新开一个线程，进行全局优化，在此之前会`OptimizeEssentialGraph`，论文中说其实这里全局优化提升的精度有限，所以其实可以考虑不使用全局优化）。在全局优化中，所有的关键帧（除了第一帧）和三维点都参与优化。\n\n{% asset_img 全局优化.png %}CorrectLoop\n\n### 闭环处的Sim3位姿优化\n\n#### 对应函数\n\n~~~c++\nint Optimizer::OptimizeSim3(KeyFrame *pKF1, KeyFrame *pKF2, vector<MapPoint *> &vpMatches1, g2o::Sim3 &g2oS12, const float th2, const bool bFixScale)\n~~~\n\n如果`DetectLoop`检测到回环，则调用`ComputeSim3`计算相似变换矩阵，再进行下一步的闭环调整。计算相似变换矩阵过程中，在用RANSAC求解过Sim3以及通过Sim3匹配更多的地图点后，对当前关键帧、闭环关键帧以及匹配的地图点进行优化，以获得更准确的Sim3位姿。获得当前关键帧相对于闭环关键帧的Sim3，然后传播到相连关键帧，并调整地图点，从而完成闭环调整。函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\n//variable size solver\ng2o::BlockSolverX::LinearSolverType * linearSolver;\n// 线性方程求解器 使用的求解库为Dense\nlinearSolver = new g2o::LinearSolverDense<g2o::BlockSolverX::PoseMatrixType>();\n// 稀疏矩阵块求解器\ng2o::BlockSolverX * solver_ptr = new g2o::BlockSolverX(linearSolver);\n// 梯度下降算法\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n当检测到闭环时，闭环连接的两个关键帧的位姿需要通过Sim3优化（以使得其尺度一致）。优化求解两帧之间的相似变换矩阵，使得二维对应点（feature）的投影误差最小。如下图所示，Pos6和Pos2为一个可能的闭环。通过$(u_{4,2},v_{4,2})$和$(u_{4,6},v_{4,6})$之间的投影误差来优化$S_{6,2}$。\n\n{% asset_img 闭环处优化.png %}\n\n### Sim3上的位姿优化\n\n#### 对应函数\n\n~~~c++\nvoid Optimizer::OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* pCurKF,\nconst LoopClosing::KeyFrameAndPose &NonCorrectedSim3,\nconst LoopClosing::KeyFrameAndPose &CorrectedSim3,\nconst map<KeyFrame *, set<KeyFrame *> > &LoopConnections, const bool &bFixScale)\n~~~\n\nEssentialGraph包括所有的关键帧顶点，但是优化边大大减少，包括spanning tree（生成树）和共视权重θ>100的边，以及闭环连接边。用于闭环检测Sim3调整后，闭环调整`CorrectLoop`过程中的优化。函数中优化求解器初始化过程如下：\n\n~~~c++\ng2o::SparseOptimizer optimizer;\noptimizer.setVerbose(false);\ng2o::BlockSolver_7_3::LinearSolverType * linearSolver =\nnew g2o::LinearSolverEigen<g2o::BlockSolver_7_3::PoseMatrixType>();\ng2o::BlockSolver_7_3 * solver_ptr= new g2o::BlockSolver_7_3(linearSolver);\ng2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);\n\nsolver->setUserLambdaInit(1e-16);\noptimizer.setAlgorithm(solver);\n~~~\n\n#### 具体实现\n\n单目SLAM一般都会发生尺度（scale）漂移，因此Sim3上的优化是必要的。相对于SE3，Sim3的自由度要多一个，而且优化的目标是矫正尺度因子，因此优化并没有加入更多的变量（如三维点）。作者在检测到闭环时在Sim3上对所有的位姿进行一次优化。定义Sim3上的残差如下：\n\n$e_{i,j}=log_{Sim3}(S_{ij}S_{jw}S^{−1}_{iw})$\n\n其中$S_{iw}$的初值是尺度为1的Pos i相对于世界坐标系的变换矩阵。$S_{i,j}$为Pos i和Pos j之间的（Sim3优化之前的）相对位姿矩阵，表示$S_{iw}$和$S_{j,w}$之间的测量（measurement）。此处相当于认为局部的相对位姿是准确的，而全局位姿有累计误差，是不准确的。\n\n{% asset_img Sim3上的位姿优化.png %}\n\n### 位姿优化\n\n#### 对应函数\n\n~~~c++\nint Optimizer::PoseOptimization(Frame *pFrame)\n~~~\n\n#### 具体实现\n\n- 只优化当前帧pose，地图点固定。\n- 用于LocalTracking中运动模型跟踪、参考帧跟踪、地图跟踪TrackLocalMap、重定位，每进行过一次PnP投影操作将地图点投影到当前平面上之后，都会进行一次`PoseOptimization`位姿优化，通过BA优化重投影误差。\n\n## ORB-SLAM2中的图\n\n参考：[知乎问题](https://www.zhihu.com/question/42050992)\n\n### Covisibility Graph\n\n共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。\n\n### Essential Graph\n\n为了在优化阶段减小计算量，ORB-SLAM2作者提出了**Essential Graph**的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。\n\n### Spanning Graph\n\n生成树\n\n## 参考资料\n\n1. [ORB-SLAM（五）优化](https://www.cnblogs.com/luyb/p/5447497.html)\n2. [ORB-SLAM（十二）优化](https://www.cnblogs.com/shang-slam/p/6483725.html)\n3. [ORBSlam2的位姿优化算法](https://blog.csdn.net/chishuideyu/article/details/76013854)","slug":"ORB_SLAM2学习之源码分析三-优化","published":1,"updated":"2019-05-30T12:29:26.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbyt00bkqlcrrpknhfqn","content":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录位姿优化有关的内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>因为摄像机标定（camera  calibration）和追踪（tracking）的精度不够。摄像机标定的误差会体现在重建中（比如三角法重建时），而追踪的误差则会体现在不同关键帧之间的位姿中和重建中（单目）。误差的不断累积会导致后面帧的位姿离实际位姿越来越远，最终会限制系统整体的精度。</p>\n<h3 id=\"关于摄像机标定\"><a href=\"#关于摄像机标定\" class=\"headerlink\" title=\"关于摄像机标定\"></a>关于摄像机标定</h3><p>单目SLAM文献中一般假设摄像机标定的结果是准确的，并不考虑这个因素带来的误差（大概因为很多时候跑标准的数据集，认为摄像机标定的误差是相似的）。然而对于一个产品，不同类型的传感器对应的标定误差并不相同，甚至有可能差异很大。因此，如果要评估整个系统的精度，这方面的误差必须要考虑进去。</p>\n<h3 id=\"关于追踪\"><a href=\"#关于追踪\" class=\"headerlink\" title=\"关于追踪\"></a>关于追踪</h3><p>无论在单目、双目还是RGBD中，追踪得到的位姿都是有误差的。单目SLAM中，如果两帧之间有足够的对应点，那么既可以直接得到两帧之间的位姿（像初始化中那样），也可以通过求解一个优化问题得到（如solvePnP）。由于单目中尺度的不确定性，还会引入尺度的误差（尺度漂移scale-drift）。由于tracking得到的总是相对位姿，前面某一帧的误差会一直传递到后面去，导致tracking到最后位姿误差有可能非常大。为了提高tracking的精度，可以1.  在局部和全局优化位姿；2. 利用闭环检测（loop closure）来优化位姿。</p>\n<h2 id=\"优化方法\"><a href=\"#优化方法\" class=\"headerlink\" title=\"优化方法\"></a>优化方法</h2><p>在SLAM问题中，优化的目标函数常见的几种约束条件为：</p>\n<ol>\n<li><p>三维点到二维特征的映射关系（通过投影矩阵）；</p>\n</li>\n<li><p>位姿和位姿之间的变换关系（通过三维刚体变换）；</p>\n</li>\n<li><p>二维特征到二维特征的匹配关系（通过F矩阵）；</p>\n</li>\n<li><p>其它关系（比如单目中有相似变换关系）。</p>\n<blockquote>\n<h3 id=\"关于相似变换Sim3\"><a href=\"#关于相似变换Sim3\" class=\"headerlink\" title=\"关于相似变换Sim3\"></a>关于相似变换Sim3</h3><p>相似变换比欧式变换多了一个自由度，有7个自由度，它允许物体进行均匀缩放（体积比不变），其矩阵表示为：</p>\n<p>$T_s=Sim3=\\left[ \\begin{matrix}sR &amp;t\\ 0^T &amp;  1   \\end{matrix} \\right]$</p>\n<p>式中旋转部分多了一个缩放因子$s$，表示我们在对向量旋转之后，可以在x，y，z三个坐标上进行均匀缩放。由于含有缩放，相似变换不再保持图形的面积不变。</p>\n</blockquote>\n</li>\n</ol>\n<p>如果我们能够知道其中的某些关系是准确的，那么可以在g2o中定义这样的关系及其对应的残差，通过不断迭代优化位姿来逐步减小残差和，从而达到优化位姿的目标。下面介绍ORB-SLAM2系统中主要的优化函数，它们是定义在<code>Optimizer.h</code>文件中的静态函数，可以直接通过类名访问，而不必创建类的对象。ORB中使用的这些优化函数是非常重要的，在视觉SLAM中有很强的通用性，自己实现的时候完全可以参考其实现方法。</p>\n<h3 id=\"局部优化\"><a href=\"#局部优化\" class=\"headerlink\" title=\"局部优化\"></a>局部优化</h3><h4 id=\"对应函数\"><a href=\"#对应函数\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> Optimizer::LocalBundleAdjustment(KeyFrame *pKF, <span class=\"keyword\">bool</span>* pbStopFlag, Map* pMap)</span><br></pre></td></tr></table></figure>\n<p>函数中优化求解器初始化过程如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g2o::SparseOptimizer optimizer;</span><br><span class=\"line\">g2o::BlockSolver_6_3::LinearSolverType * linearSolver;</span><br><span class=\"line\"></span><br><span class=\"line\">linearSolver = <span class=\"keyword\">new</span> g2o::LinearSolverEigen&lt;g2o::BlockSolver_6_3::PoseMatrixType&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">g2o::BlockSolver_6_3 * solver_ptr = <span class=\"keyword\">new</span> g2o::BlockSolver_6_3(linearSolver);</span><br><span class=\"line\"></span><br><span class=\"line\">g2o::OptimizationAlgorithmLevenberg* solver = <span class=\"keyword\">new</span> g2o::OptimizationAlgorithmLevenberg(solver_ptr);</span><br><span class=\"line\">optimizer.setAlgorithm(solver);</span><br></pre></td></tr></table></figure>\n<h4 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>用于LocalMapping线程中，在剔除关键帧之前进行的局部地图优化。当新的关键帧加入到convisibility  graph时，作者在关键帧附近进行一次局部优化，如下图所示。Pos3是新加入的关键帧，其初始估计位姿已经得到。此时，Pos2是和Pos3相连的关键帧，X2是Pos3看到的三维点，X1是Pos2看到的三维点，这些都属于局部信息，共同参与Bundle  Adjustment。同时，Pos1也可以看到X1，但它和Pos3没有直接的联系，属于Pos3关联的局部信息，参与Bundle  Adjustment，但取值保持不变。Pos0和X0不参与Bundle Adjustment。</p>\n<p>因此，参与优化的是下图中红色椭圆圈出的部分，其中红色代表取值会被优化，灰色代表取值保持不变。(u,v)是X在Pos下的二维投影点，即X在Pos下的测量（measurement）。优化的目标是最小重投影误差。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/局部优化.png\">\n<h3 id=\"全局优化\"><a href=\"#全局优化\" class=\"headerlink\" title=\"全局优化\"></a>全局优化</h3><h4 id=\"对应函数-1\"><a href=\"#对应函数-1\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> Optimizer::GlobalBundleAdjustemnt(Map* pMap, <span class=\"keyword\">int</span> nIterations, <span class=\"keyword\">bool</span>* pbStopFlag, <span class=\"keyword\">const</span> <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> nLoopKF, <span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> bRobust)</span><br><span class=\"line\"><span class=\"comment\">//调用    </span></span><br><span class=\"line\"><span class=\"keyword\">void</span> Optimizer::BundleAdjustment(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;KeyFrame *&gt; &amp;vpKFs, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;MapPoint *&gt; &amp;vpMP, <span class=\"keyword\">int</span> nIterations, <span class=\"keyword\">bool</span>* pbStopFlag, <span class=\"keyword\">const</span> <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> nLoopKF, <span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> bRobust)</span><br></pre></td></tr></table></figure>\n<p>函数中优化求解器初始化过程如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g2o::SparseOptimizer optimizer;</span><br><span class=\"line\"><span class=\"comment\">// solver for BA/3D SLAM</span></span><br><span class=\"line\">g2o::BlockSolver_6_3::LinearSolverType * linearSolver;</span><br><span class=\"line\"><span class=\"comment\">// 线性方程求解器 使用的求解库为Eigen</span></span><br><span class=\"line\">linearSolver = <span class=\"keyword\">new</span> g2o::LinearSolverEigen&lt;g2o::BlockSolver_6_3::PoseMatrixType&gt;();</span><br><span class=\"line\"><span class=\"comment\">// 稀疏矩阵块求解器</span></span><br><span class=\"line\">g2o::BlockSolver_6_3 * solver_ptr = <span class=\"keyword\">new</span> g2o::BlockSolver_6_3(linearSolver);</span><br><span class=\"line\"><span class=\"comment\">// 梯度下降算法</span></span><br><span class=\"line\">g2o::OptimizationAlgorithmLevenberg* solver = <span class=\"keyword\">new</span> g2o::OptimizationAlgorithmLevenberg(solver_ptr);</span><br><span class=\"line\">optimizer.setAlgorithm(solver);</span><br></pre></td></tr></table></figure>\n<h4 id=\"具体实现-1\"><a href=\"#具体实现-1\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>用于单目初始化的<code>CreateInitialMapMonocular</code>函数以及闭环优化的<code>RunGlobalBundleAdjustment</code>函数（在闭环结束前新开一个线程，进行全局优化，在此之前会<code>OptimizeEssentialGraph</code>，论文中说其实这里全局优化提升的精度有限，所以其实可以考虑不使用全局优化）。在全局优化中，所有的关键帧（除了第一帧）和三维点都参与优化。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/全局优化.png\">CorrectLoop\n\n### 闭环处的Sim3位姿优化\n\n#### 对应函数\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> Optimizer::OptimizeSim3(KeyFrame *pKF1, KeyFrame *pKF2, <span class=\"built_in\">vector</span>&lt;MapPoint *&gt; &amp;vpMatches1, g2o::Sim3 &amp;g2oS12, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> th2, <span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> bFixScale)</span><br></pre></td></tr></table></figure>\n<p>如果<code>DetectLoop</code>检测到回环，则调用<code>ComputeSim3</code>计算相似变换矩阵，再进行下一步的闭环调整。计算相似变换矩阵过程中，在用RANSAC求解过Sim3以及通过Sim3匹配更多的地图点后，对当前关键帧、闭环关键帧以及匹配的地图点进行优化，以获得更准确的Sim3位姿。获得当前关键帧相对于闭环关键帧的Sim3，然后传播到相连关键帧，并调整地图点，从而完成闭环调整。函数中优化求解器初始化过程如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g2o::SparseOptimizer optimizer;</span><br><span class=\"line\"><span class=\"comment\">//variable size solver</span></span><br><span class=\"line\">g2o::BlockSolverX::LinearSolverType * linearSolver;</span><br><span class=\"line\"><span class=\"comment\">// 线性方程求解器 使用的求解库为Dense</span></span><br><span class=\"line\">linearSolver = <span class=\"keyword\">new</span> g2o::LinearSolverDense&lt;g2o::BlockSolverX::PoseMatrixType&gt;();</span><br><span class=\"line\"><span class=\"comment\">// 稀疏矩阵块求解器</span></span><br><span class=\"line\">g2o::BlockSolverX * solver_ptr = <span class=\"keyword\">new</span> g2o::BlockSolverX(linearSolver);</span><br><span class=\"line\"><span class=\"comment\">// 梯度下降算法</span></span><br><span class=\"line\">g2o::OptimizationAlgorithmLevenberg* solver = <span class=\"keyword\">new</span> g2o::OptimizationAlgorithmLevenberg(solver_ptr);</span><br><span class=\"line\">optimizer.setAlgorithm(solver);</span><br></pre></td></tr></table></figure>\n<h4 id=\"具体实现-2\"><a href=\"#具体实现-2\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>当检测到闭环时，闭环连接的两个关键帧的位姿需要通过Sim3优化（以使得其尺度一致）。优化求解两帧之间的相似变换矩阵，使得二维对应点（feature）的投影误差最小。如下图所示，Pos6和Pos2为一个可能的闭环。通过$(u<em>{4,2},v</em>{4,2})$和$(u<em>{4,6},v</em>{4,6})$之间的投影误差来优化$S_{6,2}$。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/闭环处优化.png\">\n<h3 id=\"Sim3上的位姿优化\"><a href=\"#Sim3上的位姿优化\" class=\"headerlink\" title=\"Sim3上的位姿优化\"></a>Sim3上的位姿优化</h3><h4 id=\"对应函数-2\"><a href=\"#对应函数-2\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">void</span> Optimizer::OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* pCurKF,</span><br><span class=\"line\"><span class=\"keyword\">const</span> LoopClosing::KeyFrameAndPose &amp;NonCorrectedSim3,</span><br><span class=\"line\"><span class=\"keyword\">const</span> LoopClosing::KeyFrameAndPose &amp;CorrectedSim3,</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"built_in\">map</span>&lt;KeyFrame *, <span class=\"built_in\">set</span>&lt;KeyFrame *&gt; &gt; &amp;LoopConnections, <span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> &amp;bFixScale)</span><br></pre></td></tr></table></figure>\n<p>EssentialGraph包括所有的关键帧顶点，但是优化边大大减少，包括spanning tree（生成树）和共视权重θ&gt;100的边，以及闭环连接边。用于闭环检测Sim3调整后，闭环调整<code>CorrectLoop</code>过程中的优化。函数中优化求解器初始化过程如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g2o::SparseOptimizer optimizer;</span><br><span class=\"line\">optimizer.setVerbose(<span class=\"literal\">false</span>);</span><br><span class=\"line\">g2o::BlockSolver_7_3::LinearSolverType * linearSolver =</span><br><span class=\"line\"><span class=\"keyword\">new</span> g2o::LinearSolverEigen&lt;g2o::BlockSolver_7_3::PoseMatrixType&gt;();</span><br><span class=\"line\">g2o::BlockSolver_7_3 * solver_ptr= <span class=\"keyword\">new</span> g2o::BlockSolver_7_3(linearSolver);</span><br><span class=\"line\">g2o::OptimizationAlgorithmLevenberg* solver = <span class=\"keyword\">new</span> g2o::OptimizationAlgorithmLevenberg(solver_ptr);</span><br><span class=\"line\"></span><br><span class=\"line\">solver-&gt;setUserLambdaInit(<span class=\"number\">1e-16</span>);</span><br><span class=\"line\">optimizer.setAlgorithm(solver);</span><br></pre></td></tr></table></figure>\n<h4 id=\"具体实现-3\"><a href=\"#具体实现-3\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>单目SLAM一般都会发生尺度（scale）漂移，因此Sim3上的优化是必要的。相对于SE3，Sim3的自由度要多一个，而且优化的目标是矫正尺度因子，因此优化并没有加入更多的变量（如三维点）。作者在检测到闭环时在Sim3上对所有的位姿进行一次优化。定义Sim3上的残差如下：</p>\n<p>$e<em>{i,j}=log</em>{Sim3}(S<em>{ij}S</em>{jw}S^{−1}_{iw})$</p>\n<p>其中$S<em>{iw}$的初值是尺度为1的Pos i相对于世界坐标系的变换矩阵。$S</em>{i,j}$为Pos i和Pos j之间的（Sim3优化之前的）相对位姿矩阵，表示$S<em>{iw}$和$S</em>{j,w}$之间的测量（measurement）。此处相当于认为局部的相对位姿是准确的，而全局位姿有累计误差，是不准确的。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/Sim3上的位姿优化.png\">\n<h3 id=\"位姿优化\"><a href=\"#位姿优化\" class=\"headerlink\" title=\"位姿优化\"></a>位姿优化</h3><h4 id=\"对应函数-3\"><a href=\"#对应函数-3\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> Optimizer::PoseOptimization(Frame *pFrame)</span><br></pre></td></tr></table></figure>\n<h4 id=\"具体实现-4\"><a href=\"#具体实现-4\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><ul>\n<li>只优化当前帧pose，地图点固定。</li>\n<li>用于LocalTracking中运动模型跟踪、参考帧跟踪、地图跟踪TrackLocalMap、重定位，每进行过一次PnP投影操作将地图点投影到当前平面上之后，都会进行一次<code>PoseOptimization</code>位姿优化，通过BA优化重投影误差。</li>\n</ul>\n<h2 id=\"ORB-SLAM2中的图\"><a href=\"#ORB-SLAM2中的图\" class=\"headerlink\" title=\"ORB-SLAM2中的图\"></a>ORB-SLAM2中的图</h2><p>参考：<a href=\"https://www.zhihu.com/question/42050992\" target=\"_blank\" rel=\"noopener\">知乎问题</a></p>\n<h3 id=\"Covisibility-Graph\"><a href=\"#Covisibility-Graph\" class=\"headerlink\" title=\"Covisibility Graph\"></a>Covisibility Graph</h3><p>共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。</p>\n<h3 id=\"Essential-Graph\"><a href=\"#Essential-Graph\" class=\"headerlink\" title=\"Essential Graph\"></a>Essential Graph</h3><p>为了在优化阶段减小计算量，ORB-SLAM2作者提出了<strong>Essential Graph</strong>的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。</p>\n<h3 id=\"Spanning-Graph\"><a href=\"#Spanning-Graph\" class=\"headerlink\" title=\"Spanning Graph\"></a>Spanning Graph</h3><p>生成树</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/luyb/p/5447497.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（五）优化</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6483725.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（十二）优化</a></li>\n<li><a href=\"https://blog.csdn.net/chishuideyu/article/details/76013854\" target=\"_blank\" rel=\"noopener\">ORBSlam2的位姿优化算法</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ORB_SLAM2系统源码分析的内容，主要记录位姿优化有关的内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>因为摄像机标定（camera  calibration）和追踪（tracking）的精度不够。摄像机标定的误差会体现在重建中（比如三角法重建时），而追踪的误差则会体现在不同关键帧之间的位姿中和重建中（单目）。误差的不断累积会导致后面帧的位姿离实际位姿越来越远，最终会限制系统整体的精度。</p>\n<h3 id=\"关于摄像机标定\"><a href=\"#关于摄像机标定\" class=\"headerlink\" title=\"关于摄像机标定\"></a>关于摄像机标定</h3><p>单目SLAM文献中一般假设摄像机标定的结果是准确的，并不考虑这个因素带来的误差（大概因为很多时候跑标准的数据集，认为摄像机标定的误差是相似的）。然而对于一个产品，不同类型的传感器对应的标定误差并不相同，甚至有可能差异很大。因此，如果要评估整个系统的精度，这方面的误差必须要考虑进去。</p>\n<h3 id=\"关于追踪\"><a href=\"#关于追踪\" class=\"headerlink\" title=\"关于追踪\"></a>关于追踪</h3><p>无论在单目、双目还是RGBD中，追踪得到的位姿都是有误差的。单目SLAM中，如果两帧之间有足够的对应点，那么既可以直接得到两帧之间的位姿（像初始化中那样），也可以通过求解一个优化问题得到（如solvePnP）。由于单目中尺度的不确定性，还会引入尺度的误差（尺度漂移scale-drift）。由于tracking得到的总是相对位姿，前面某一帧的误差会一直传递到后面去，导致tracking到最后位姿误差有可能非常大。为了提高tracking的精度，可以1.  在局部和全局优化位姿；2. 利用闭环检测（loop closure）来优化位姿。</p>\n<h2 id=\"优化方法\"><a href=\"#优化方法\" class=\"headerlink\" title=\"优化方法\"></a>优化方法</h2><p>在SLAM问题中，优化的目标函数常见的几种约束条件为：</p>\n<ol>\n<li><p>三维点到二维特征的映射关系（通过投影矩阵）；</p>\n</li>\n<li><p>位姿和位姿之间的变换关系（通过三维刚体变换）；</p>\n</li>\n<li><p>二维特征到二维特征的匹配关系（通过F矩阵）；</p>\n</li>\n<li><p>其它关系（比如单目中有相似变换关系）。</p>\n<blockquote>\n<h3 id=\"关于相似变换Sim3\"><a href=\"#关于相似变换Sim3\" class=\"headerlink\" title=\"关于相似变换Sim3\"></a>关于相似变换Sim3</h3><p>相似变换比欧式变换多了一个自由度，有7个自由度，它允许物体进行均匀缩放（体积比不变），其矩阵表示为：</p>\n<p>$T_s=Sim3=\\left[ \\begin{matrix}sR &amp;t\\ 0^T &amp;  1   \\end{matrix} \\right]$</p>\n<p>式中旋转部分多了一个缩放因子$s$，表示我们在对向量旋转之后，可以在x，y，z三个坐标上进行均匀缩放。由于含有缩放，相似变换不再保持图形的面积不变。</p>\n</blockquote>\n</li>\n</ol>\n<p>如果我们能够知道其中的某些关系是准确的，那么可以在g2o中定义这样的关系及其对应的残差，通过不断迭代优化位姿来逐步减小残差和，从而达到优化位姿的目标。下面介绍ORB-SLAM2系统中主要的优化函数，它们是定义在<code>Optimizer.h</code>文件中的静态函数，可以直接通过类名访问，而不必创建类的对象。ORB中使用的这些优化函数是非常重要的，在视觉SLAM中有很强的通用性，自己实现的时候完全可以参考其实现方法。</p>\n<h3 id=\"局部优化\"><a href=\"#局部优化\" class=\"headerlink\" title=\"局部优化\"></a>局部优化</h3><h4 id=\"对应函数\"><a href=\"#对应函数\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><!--�170-->\n<p>函数中优化求解器初始化过程如下：</p>\n<!--�171-->\n<h4 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>用于LocalMapping线程中，在剔除关键帧之前进行的局部地图优化。当新的关键帧加入到convisibility  graph时，作者在关键帧附近进行一次局部优化，如下图所示。Pos3是新加入的关键帧，其初始估计位姿已经得到。此时，Pos2是和Pos3相连的关键帧，X2是Pos3看到的三维点，X1是Pos2看到的三维点，这些都属于局部信息，共同参与Bundle  Adjustment。同时，Pos1也可以看到X1，但它和Pos3没有直接的联系，属于Pos3关联的局部信息，参与Bundle  Adjustment，但取值保持不变。Pos0和X0不参与Bundle Adjustment。</p>\n<p>因此，参与优化的是下图中红色椭圆圈出的部分，其中红色代表取值会被优化，灰色代表取值保持不变。(u,v)是X在Pos下的二维投影点，即X在Pos下的测量（measurement）。优化的目标是最小重投影误差。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/局部优化.png\">\n<h3 id=\"全局优化\"><a href=\"#全局优化\" class=\"headerlink\" title=\"全局优化\"></a>全局优化</h3><h4 id=\"对应函数-1\"><a href=\"#对应函数-1\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><!--�172-->\n<p>函数中优化求解器初始化过程如下：</p>\n<!--�173-->\n<h4 id=\"具体实现-1\"><a href=\"#具体实现-1\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>用于单目初始化的<code>CreateInitialMapMonocular</code>函数以及闭环优化的<code>RunGlobalBundleAdjustment</code>函数（在闭环结束前新开一个线程，进行全局优化，在此之前会<code>OptimizeEssentialGraph</code>，论文中说其实这里全局优化提升的精度有限，所以其实可以考虑不使用全局优化）。在全局优化中，所有的关键帧（除了第一帧）和三维点都参与优化。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/全局优化.png\">CorrectLoop\n\n### 闭环处的Sim3位姿优化\n\n#### 对应函数\n\n<!--�174-->\n<p>如果<code>DetectLoop</code>检测到回环，则调用<code>ComputeSim3</code>计算相似变换矩阵，再进行下一步的闭环调整。计算相似变换矩阵过程中，在用RANSAC求解过Sim3以及通过Sim3匹配更多的地图点后，对当前关键帧、闭环关键帧以及匹配的地图点进行优化，以获得更准确的Sim3位姿。获得当前关键帧相对于闭环关键帧的Sim3，然后传播到相连关键帧，并调整地图点，从而完成闭环调整。函数中优化求解器初始化过程如下：</p>\n<!--�175-->\n<h4 id=\"具体实现-2\"><a href=\"#具体实现-2\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>当检测到闭环时，闭环连接的两个关键帧的位姿需要通过Sim3优化（以使得其尺度一致）。优化求解两帧之间的相似变换矩阵，使得二维对应点（feature）的投影误差最小。如下图所示，Pos6和Pos2为一个可能的闭环。通过$(u<em>{4,2},v</em>{4,2})$和$(u<em>{4,6},v</em>{4,6})$之间的投影误差来优化$S_{6,2}$。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/闭环处优化.png\">\n<h3 id=\"Sim3上的位姿优化\"><a href=\"#Sim3上的位姿优化\" class=\"headerlink\" title=\"Sim3上的位姿优化\"></a>Sim3上的位姿优化</h3><h4 id=\"对应函数-2\"><a href=\"#对应函数-2\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><!--�176-->\n<p>EssentialGraph包括所有的关键帧顶点，但是优化边大大减少，包括spanning tree（生成树）和共视权重θ&gt;100的边，以及闭环连接边。用于闭环检测Sim3调整后，闭环调整<code>CorrectLoop</code>过程中的优化。函数中优化求解器初始化过程如下：</p>\n<!--�177-->\n<h4 id=\"具体实现-3\"><a href=\"#具体实现-3\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><p>单目SLAM一般都会发生尺度（scale）漂移，因此Sim3上的优化是必要的。相对于SE3，Sim3的自由度要多一个，而且优化的目标是矫正尺度因子，因此优化并没有加入更多的变量（如三维点）。作者在检测到闭环时在Sim3上对所有的位姿进行一次优化。定义Sim3上的残差如下：</p>\n<p>$e<em>{i,j}=log</em>{Sim3}(S<em>{ij}S</em>{jw}S^{−1}_{iw})$</p>\n<p>其中$S<em>{iw}$的初值是尺度为1的Pos i相对于世界坐标系的变换矩阵。$S</em>{i,j}$为Pos i和Pos j之间的（Sim3优化之前的）相对位姿矩阵，表示$S<em>{iw}$和$S</em>{j,w}$之间的测量（measurement）。此处相当于认为局部的相对位姿是准确的，而全局位姿有累计误差，是不准确的。</p>\n<img src=\"/2018/08/18/ORB_SLAM2学习之源码分析三-优化/Sim3上的位姿优化.png\">\n<h3 id=\"位姿优化\"><a href=\"#位姿优化\" class=\"headerlink\" title=\"位姿优化\"></a>位姿优化</h3><h4 id=\"对应函数-3\"><a href=\"#对应函数-3\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><!--�178-->\n<h4 id=\"具体实现-4\"><a href=\"#具体实现-4\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h4><ul>\n<li>只优化当前帧pose，地图点固定。</li>\n<li>用于LocalTracking中运动模型跟踪、参考帧跟踪、地图跟踪TrackLocalMap、重定位，每进行过一次PnP投影操作将地图点投影到当前平面上之后，都会进行一次<code>PoseOptimization</code>位姿优化，通过BA优化重投影误差。</li>\n</ul>\n<h2 id=\"ORB-SLAM2中的图\"><a href=\"#ORB-SLAM2中的图\" class=\"headerlink\" title=\"ORB-SLAM2中的图\"></a>ORB-SLAM2中的图</h2><p>参考：<a href=\"https://www.zhihu.com/question/42050992\" target=\"_blank\" rel=\"noopener\">知乎问题</a></p>\n<h3 id=\"Covisibility-Graph\"><a href=\"#Covisibility-Graph\" class=\"headerlink\" title=\"Covisibility Graph\"></a>Covisibility Graph</h3><p>共视图，是一个无向有权图（Graph），这个概念最早来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，连接边的权重就是两个关键帧共享的3D点的个数。</p>\n<h3 id=\"Essential-Graph\"><a href=\"#Essential-Graph\" class=\"headerlink\" title=\"Essential Graph\"></a>Essential Graph</h3><p>为了在优化阶段减小计算量，ORB-SLAM2作者提出了<strong>Essential Graph</strong>的概念，主要用它来进行全局优化。它是共视图的子集，即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某个关键帧和与之拥有最多共享的地图点的关键帧。这样能够连接所有的顶点，但是边会减少很多。</p>\n<h3 id=\"Spanning-Graph\"><a href=\"#Spanning-Graph\" class=\"headerlink\" title=\"Spanning Graph\"></a>Spanning Graph</h3><p>生成树</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/luyb/p/5447497.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（五）优化</a></li>\n<li><a href=\"https://www.cnblogs.com/shang-slam/p/6483725.html\" target=\"_blank\" rel=\"noopener\">ORB-SLAM（十二）优化</a></li>\n<li><a href=\"https://blog.csdn.net/chishuideyu/article/details/76013854\" target=\"_blank\" rel=\"noopener\">ORBSlam2的位姿优化算法</a></li>\n</ol>"},{"title":"ROS学习之actionlib库（１）-actionlib库的介绍","date":"2018-03-29T14:42:46.000Z","copyright":true,"_content":"\n------\n\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more--->\n\n# 介绍\n\nactionlib软件包为ROS中的可抢占任务提供了一个基于话题的通用接口。在任何一个比较大的基于ROS的系统，都会有这样的情况，向某个节点发送请求执行某一个任务，并返回相应的执行结果，这种请求-响应式的使用场景通常使用ROS提供的服务（services）机制完成。然而，有一些情况服务执行的时间很长，在执行中想要定期获得任务处理的进度，或可能取消执行任务（或请求），例如如果执行各种运动的动作，像控制机械手臂去抓取一个杯子，这个过程可能复杂而漫长，执行过程中还可能强制中断或反馈信息，service机制就无法满足需求，而actionlib就能实现这样的功能。它是ROS中一个很重要的功能包集合（库），可以实现一些简单的状态机功能，算的上是SMACH的一个弱化版。\n\n扩展：\n\nSMACH是一个用于快速创建复杂机器人行为的任务级体系结构。SMACH的核心是独立于ROS的Python库，用于构建分层状态机。SMACH是一个新的库，它利用非常古老的概念来快速创建具有可维护和模块化代码的强大机器人行为。可以使用SMACH建立一个有限状态机，但SMACH能做的更多。SMACH是一个任务级的执行和协调库，并提供集中“状态容器”。一个这样的容器是一个有限状态机，但是这个容器也可以是另一个容器中的状态。更多内容[参考wiki](http://wiki.ros.org/cn/smach)。\n\n# 细节描述\n\nactionlib堆栈提供了一个标准化的接口同可抢占任务进行交互，这方面的例子包括将底座移动到目标位置、执行激光扫描并返回产生的点云、检测门的手柄等等。\n\n## 介绍\n\n下面将描述动作客户端和服务器相互交互的底层机制，如果只是简单的使用actionlib就没必要深入学习了。\n\n## 高级客户端/服务器交互\n\n### 服务器描述\n\n#### 服务器状态机\n\ngoal是在ActionClient端启动的（因为client会发送sendgoal嘛），一旦ActionServer接收到goal请求，它就会为这个goal创建一个状态机，来追踪goal的状态转换。注意，状态机跟踪的是goal！而不是不是跟踪ActionServer本身！所以系统中对于每一个goal都会有一个状态机。状态转换图如下所示：\n\n![server_states_detailed.png](http://wiki.ros.org/actionlib/DetailedDescription?action=AttachFile&do=get&target=server_states_detailed.png)\n\n#### 服务器转换状态\n\n这些状态的转换大多是服务的实施者（其实就是服务的程序）触发的，用小一串命令：\n\n- **setAccepted** - 检查到有goal之后，决定开始处理它 \n- **setRejected** - 检察到goal后，决定不去处理它，因为它是个无效请求（溢出，资源不可用，无效等） \n- **setSucceeded** - 告知goal被正确执行\n- **setAborted** - 告知goal在处理时遇到了问题不得不被终止了\n- **setCanceled** - 告知因cancle请求，goal不再被执行了\n\naction client也能异步触发状态转换：\n\n- **CancelRequest**: 客户端通知action server它想要server停止处理这个goal服务端状态\n\n服务端状态\n\n1. 中间状态\n\n   （前面说了，simple的状态有三个，就是等待执行挂起）\n\n   - **Pending** - goal还没有被ActionServer处理\n   - **Active** - goal正在被AS处理 \n   - **Recalling** - goal没有被处理并且从客户端已发送取消它的命令，但AS还不确定goal已经被取消了（时差导致的？）\n   - **Preempting** - goal正被处理呢，从AC端收到了取消请求，但AS还不确定goal已经被取消\n\n\n2. 终点状态 \n   - **Rejected** - AC没有发cancle请求，goal被AS不处理直接拒绝了The goal was rejected by the action server without being processed and without a request from the action client to cancel \n   - **Succeeded** - goal被AS成功实现 was achieved successfully by the action server \n   - **Aborted** - goal被AS终止没有AC的cancle请求\n   - **Recalled** - 在AS开始执行之前这个goal被另一个goal或者cancle请求取消了\n   - **Preempted** - 处理中的goal被另一个goal或者AC的取消请求给取消了\n\n### 客户端描述\n\n#### 客户端状态机\n\n\n\n#### 客户端状态\n\n## Action接口和传输层（协议）\n\n### 数据与\n\n### 信息\n\n#### goal话题\n\n#### cancel话题\n\n#### status话题\n\n#### feedback话题\n\n#### result话题\n\n## 协议\n\n### 简单的行为客户端\n\n#### 客户端状态歧义\n\n#### 多目标策略\n\n#### 线程模型\n\n### 简单的行为服务器\n\n#### 目标通知\n\n#### 线程模型\n\n# Client-Server交互\n\n如下图所示，actionlib的框架实际是一种特殊的客户-服务的模式。除了服务请求的功能外，还可以实时获取服务器执行任务的进度状态，以及强制中断服务的功能。action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息。action客户端和服务端通过函数调用和回调的方式，向用户提供用于请求目标（在客户端发生）或执行目标（服务器端发生）的接口。\n\n![client_server_interaction.png](http://wiki.ros.org/actionlib?action=AttachFile&do=get&target=client_server_interaction.png)\n\n# Action清单：Goal,Feedback,Result\n\n为了使得客户端和服务器之间进行通信，需要定义一些用于二者之间通信的消息，这就是*action清单*。该清单定义客户端和服务器之间通信的Goal、Feedback、Result信息。\n\n- Goal：为了使用action来完成任务，引入可以由ActionClient发送到服务器的Goal概念。对于移动底座的情况，Goal将是PoseStamped消息，其中包含关于机器人应该在世界坐标系移动到何处的信息。对于控制倾斜激光扫描仪的情况，\tGoal应该包含扫描参数（最小角、最大角、速度等）。\n- Feedback：Feedback为服务器实施者提供了一种方法，告知ActionClient目标的增量变化情况。对于移动底座的情况，它可能是机器人沿着路径运动时当前的姿势；对于控制倾斜激光扫描仪的情况，它可能是扫描完成之前剩下的时间。\n- Result：完成目标后，结果会从ActionServer发送到ActionClient。Result同Feedback不同，因为它只发送一次，当行动的目标是提供某种信息时，这一点就非常有用。对于移动底座的情况，Result不是非常重要，但它可以是机器人的最终位姿；对于控制倾斜激光扫描仪的情况，结果可能包含根据请求的扫描生成的点云。\n\n# .action文件\n\n在介绍.action文件之前，先创建一个程序包，用于后续内容的学习，actinlib库相关的文件都放在该程序包下：\n\n```shell\ncatkin_create_pkg actionlib_tutorials actionlib message_generation roscpp rospy std_msgs actionlib_msgs\n```\n\nROS中使用一个.action文件定义action清单，该文件包含goal、result、feedback的定义，使用---分隔开，它一般会被放置在程序包的action目录下。以洗碟子为例，描述该过程的action清单如下所示：\n\n`actionlib_tutorials/action/DoDishes.action`\n\n~~~\n# Define the goal\nuint32 dishwasher_id  # Specify which dishwasher we want to use\n---\n# Define the result\nuint32 total_dishes_cleaned\n---\n# Define a feedback message\nfloat32 percent_complete\n~~~\n\n基于`.action`文件会产生６个消息用于客户端和服务器的通信，这一过程在`catkin_make`编译过程自动触发完成。\n\n## Catkin\n\n在当前程序包`CMakeList.txt`文件中`catkin_package()`之前添加：\n\n~~~cmake\nadd_action_files(\n  FILES\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n~~~\n\n同时需要在`package.xml`文件中包含如下依赖：\n\n```xml\n<build_depend>actionlib</build_depend>\n<build_depend>actionlib_msgs</build_depend>\n<run_depend>actionlib</run_depend>\n<run_depend>actionlib_msgs</run_depend>\n```\n\n## Results\n\n执行命令：\n\n```shell\nroscd actionlib_tutorials\nrosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action\n```\n\n`genaction.py`文件位于`/opt/ros/kinetic/lib/actionlib_msgs/`目录下。\n\n会出现如下提示信息：\n\n```shell\nGenerating for action Fibonacci\n```\n通过手动执行`generation.py`文件，我们就使用DoDishes.action生成了以下消息，并保存在了程序包的`msg/`目录下。这些消息文件将被actionlib内部用于ActionClient和ActionServer之间的通信。\n\n- `DoDishesAction.msg` \n- `DoDishesActionGoal.msg` \n- `DoDishesActionResult.msg` \n- `DoDishesActionFeedback.msg` \n- `DoDishesGoal.msg` \n- `DoDishesResult.msg` \n- `DoDishesFeedback.msg`\n\n**注意**：其实我们可以完全不用手动执行如上操作，手动生成消息文件。我们可以在工作空间目录下执行`catkin_make`命令，就会自动生成的`.msg`和`.h`文件，并分别保存在`工作空间/devel/share/actionlib_tutorials/msg`和`工作空间/devel/include/actionlib_tutorials`目录下。\n\n# ActionClient的使用-C++ SimpleActionClient\n\n以下程序实现了如何将goal发送到名为`do_dishes`的DoDishes ActionServer。创建文件`actionlib_tutorials/src/do_dishes_client.cpp`：\n\n~~~c++\n#include <actionlib_tutorials/DoDishesAction.h> // Note: \"Action\" is appended\n#include <actionlib/client/simple_action_client.h>\n\ntypedef actionlib::SimpleActionClient<actionlib_tutorials::DoDishesAction> Client;\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"do_dishes_client\");\n  Client client(\"do_dishes\", true); // true -> don't need ros::spin()\n  client.waitForServer();\n  actionlib_tutorials::DoDishesGoal goal;\n  // Fill in goal here\n  client.sendGoal(goal);\n  client.waitForResult(ros::Duration(5.0));\n  if (client.getState() == actionlib::SimpleClientGoalState::SUCCEEDED)\n    printf(\"Yay! The dishes are now clean\");\n  printf(\"Current State: %s\\n\", client.getState().toString().c_str());\n  return 0;\n}\n~~~\n\n注意：对于C++SimpleActionClient，在一个单独的线程正在服务客户端的回调队列时，`waitForServer`方法才会工作。这需要传递给客户端构造函数的spin_thread选项，使用多线程微调器运行，或者使用您自己的线程为ROS回调队列提供服务。\n\n# ActionServer的使用-C++ SimpleActionServer\n\n以下片段显示了如何编写一个名为“do_dishes”的DoDishes ActionServer。创建文件`actionlib_tutorials/src/do_dishes_server.cpp`：\n\n~~~c++\n#include <actionlib_tutorials/DoDishesAction.h>  // Note: \"Action\" is appended\n#include <actionlib/server/simple_action_server.h>\n\ntypedef actionlib::SimpleActionServer<actionlib_tutorials::DoDishesAction> Server;\n\nvoid execute(const actionlib_tutorials::DoDishesGoalConstPtr& goal, Server* as)  // Note: \"Action\" is not appended to DoDishes here\n{\n  // Do lots of awesome groundbreaking robot stuff here\n  as->setSucceeded();\n}\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"do_dishes_server\");\n  ros::NodeHandle n;\n  Server server(n, \"do_dishes\", boost::bind(&execute, _1, &server), false);\n  server.start();\n  ros::spin();\n  return 0;\n}\n~~~\n\n# 测试Action\n\n工作空间目录下执行：\n\n~~~\ncatkin_make\n~~~\n\n执行完会自动生成可执行文件`do_dishes_client`、`do_dishes_server`，保存在`工作空间/devel/lib/actionlib_tutorials`目录下。\n\n终端启动ROS：\n\n```shell\nroscore\n```\n\n运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials do_dishes_client\n```\n\n运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials do_dishes_server\n```\n\n执行完成客户端会有如下输出信息：\n\n~~~\nYay! The dishes are now cleanCurrent State: SUCCEEDED\n~~~\n\n执行`rqt_graph`命令查看节点图：\n\n{% asset_img 节点图.png  %}","source":"_posts/ROS学习之actionlib库（１）-actionlib库的介绍.md","raw":"---\ntitle: ROS学习之actionlib库（１）-actionlib库的介绍\ndate: 2018-03-29 22:42:46\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n------\n\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more--->\n\n# 介绍\n\nactionlib软件包为ROS中的可抢占任务提供了一个基于话题的通用接口。在任何一个比较大的基于ROS的系统，都会有这样的情况，向某个节点发送请求执行某一个任务，并返回相应的执行结果，这种请求-响应式的使用场景通常使用ROS提供的服务（services）机制完成。然而，有一些情况服务执行的时间很长，在执行中想要定期获得任务处理的进度，或可能取消执行任务（或请求），例如如果执行各种运动的动作，像控制机械手臂去抓取一个杯子，这个过程可能复杂而漫长，执行过程中还可能强制中断或反馈信息，service机制就无法满足需求，而actionlib就能实现这样的功能。它是ROS中一个很重要的功能包集合（库），可以实现一些简单的状态机功能，算的上是SMACH的一个弱化版。\n\n扩展：\n\nSMACH是一个用于快速创建复杂机器人行为的任务级体系结构。SMACH的核心是独立于ROS的Python库，用于构建分层状态机。SMACH是一个新的库，它利用非常古老的概念来快速创建具有可维护和模块化代码的强大机器人行为。可以使用SMACH建立一个有限状态机，但SMACH能做的更多。SMACH是一个任务级的执行和协调库，并提供集中“状态容器”。一个这样的容器是一个有限状态机，但是这个容器也可以是另一个容器中的状态。更多内容[参考wiki](http://wiki.ros.org/cn/smach)。\n\n# 细节描述\n\nactionlib堆栈提供了一个标准化的接口同可抢占任务进行交互，这方面的例子包括将底座移动到目标位置、执行激光扫描并返回产生的点云、检测门的手柄等等。\n\n## 介绍\n\n下面将描述动作客户端和服务器相互交互的底层机制，如果只是简单的使用actionlib就没必要深入学习了。\n\n## 高级客户端/服务器交互\n\n### 服务器描述\n\n#### 服务器状态机\n\ngoal是在ActionClient端启动的（因为client会发送sendgoal嘛），一旦ActionServer接收到goal请求，它就会为这个goal创建一个状态机，来追踪goal的状态转换。注意，状态机跟踪的是goal！而不是不是跟踪ActionServer本身！所以系统中对于每一个goal都会有一个状态机。状态转换图如下所示：\n\n![server_states_detailed.png](http://wiki.ros.org/actionlib/DetailedDescription?action=AttachFile&do=get&target=server_states_detailed.png)\n\n#### 服务器转换状态\n\n这些状态的转换大多是服务的实施者（其实就是服务的程序）触发的，用小一串命令：\n\n- **setAccepted** - 检查到有goal之后，决定开始处理它 \n- **setRejected** - 检察到goal后，决定不去处理它，因为它是个无效请求（溢出，资源不可用，无效等） \n- **setSucceeded** - 告知goal被正确执行\n- **setAborted** - 告知goal在处理时遇到了问题不得不被终止了\n- **setCanceled** - 告知因cancle请求，goal不再被执行了\n\naction client也能异步触发状态转换：\n\n- **CancelRequest**: 客户端通知action server它想要server停止处理这个goal服务端状态\n\n服务端状态\n\n1. 中间状态\n\n   （前面说了，simple的状态有三个，就是等待执行挂起）\n\n   - **Pending** - goal还没有被ActionServer处理\n   - **Active** - goal正在被AS处理 \n   - **Recalling** - goal没有被处理并且从客户端已发送取消它的命令，但AS还不确定goal已经被取消了（时差导致的？）\n   - **Preempting** - goal正被处理呢，从AC端收到了取消请求，但AS还不确定goal已经被取消\n\n\n2. 终点状态 \n   - **Rejected** - AC没有发cancle请求，goal被AS不处理直接拒绝了The goal was rejected by the action server without being processed and without a request from the action client to cancel \n   - **Succeeded** - goal被AS成功实现 was achieved successfully by the action server \n   - **Aborted** - goal被AS终止没有AC的cancle请求\n   - **Recalled** - 在AS开始执行之前这个goal被另一个goal或者cancle请求取消了\n   - **Preempted** - 处理中的goal被另一个goal或者AC的取消请求给取消了\n\n### 客户端描述\n\n#### 客户端状态机\n\n\n\n#### 客户端状态\n\n## Action接口和传输层（协议）\n\n### 数据与\n\n### 信息\n\n#### goal话题\n\n#### cancel话题\n\n#### status话题\n\n#### feedback话题\n\n#### result话题\n\n## 协议\n\n### 简单的行为客户端\n\n#### 客户端状态歧义\n\n#### 多目标策略\n\n#### 线程模型\n\n### 简单的行为服务器\n\n#### 目标通知\n\n#### 线程模型\n\n# Client-Server交互\n\n如下图所示，actionlib的框架实际是一种特殊的客户-服务的模式。除了服务请求的功能外，还可以实时获取服务器执行任务的进度状态，以及强制中断服务的功能。action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息。action客户端和服务端通过函数调用和回调的方式，向用户提供用于请求目标（在客户端发生）或执行目标（服务器端发生）的接口。\n\n![client_server_interaction.png](http://wiki.ros.org/actionlib?action=AttachFile&do=get&target=client_server_interaction.png)\n\n# Action清单：Goal,Feedback,Result\n\n为了使得客户端和服务器之间进行通信，需要定义一些用于二者之间通信的消息，这就是*action清单*。该清单定义客户端和服务器之间通信的Goal、Feedback、Result信息。\n\n- Goal：为了使用action来完成任务，引入可以由ActionClient发送到服务器的Goal概念。对于移动底座的情况，Goal将是PoseStamped消息，其中包含关于机器人应该在世界坐标系移动到何处的信息。对于控制倾斜激光扫描仪的情况，\tGoal应该包含扫描参数（最小角、最大角、速度等）。\n- Feedback：Feedback为服务器实施者提供了一种方法，告知ActionClient目标的增量变化情况。对于移动底座的情况，它可能是机器人沿着路径运动时当前的姿势；对于控制倾斜激光扫描仪的情况，它可能是扫描完成之前剩下的时间。\n- Result：完成目标后，结果会从ActionServer发送到ActionClient。Result同Feedback不同，因为它只发送一次，当行动的目标是提供某种信息时，这一点就非常有用。对于移动底座的情况，Result不是非常重要，但它可以是机器人的最终位姿；对于控制倾斜激光扫描仪的情况，结果可能包含根据请求的扫描生成的点云。\n\n# .action文件\n\n在介绍.action文件之前，先创建一个程序包，用于后续内容的学习，actinlib库相关的文件都放在该程序包下：\n\n```shell\ncatkin_create_pkg actionlib_tutorials actionlib message_generation roscpp rospy std_msgs actionlib_msgs\n```\n\nROS中使用一个.action文件定义action清单，该文件包含goal、result、feedback的定义，使用---分隔开，它一般会被放置在程序包的action目录下。以洗碟子为例，描述该过程的action清单如下所示：\n\n`actionlib_tutorials/action/DoDishes.action`\n\n~~~\n# Define the goal\nuint32 dishwasher_id  # Specify which dishwasher we want to use\n---\n# Define the result\nuint32 total_dishes_cleaned\n---\n# Define a feedback message\nfloat32 percent_complete\n~~~\n\n基于`.action`文件会产生６个消息用于客户端和服务器的通信，这一过程在`catkin_make`编译过程自动触发完成。\n\n## Catkin\n\n在当前程序包`CMakeList.txt`文件中`catkin_package()`之前添加：\n\n~~~cmake\nadd_action_files(\n  FILES\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n~~~\n\n同时需要在`package.xml`文件中包含如下依赖：\n\n```xml\n<build_depend>actionlib</build_depend>\n<build_depend>actionlib_msgs</build_depend>\n<run_depend>actionlib</run_depend>\n<run_depend>actionlib_msgs</run_depend>\n```\n\n## Results\n\n执行命令：\n\n```shell\nroscd actionlib_tutorials\nrosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action\n```\n\n`genaction.py`文件位于`/opt/ros/kinetic/lib/actionlib_msgs/`目录下。\n\n会出现如下提示信息：\n\n```shell\nGenerating for action Fibonacci\n```\n通过手动执行`generation.py`文件，我们就使用DoDishes.action生成了以下消息，并保存在了程序包的`msg/`目录下。这些消息文件将被actionlib内部用于ActionClient和ActionServer之间的通信。\n\n- `DoDishesAction.msg` \n- `DoDishesActionGoal.msg` \n- `DoDishesActionResult.msg` \n- `DoDishesActionFeedback.msg` \n- `DoDishesGoal.msg` \n- `DoDishesResult.msg` \n- `DoDishesFeedback.msg`\n\n**注意**：其实我们可以完全不用手动执行如上操作，手动生成消息文件。我们可以在工作空间目录下执行`catkin_make`命令，就会自动生成的`.msg`和`.h`文件，并分别保存在`工作空间/devel/share/actionlib_tutorials/msg`和`工作空间/devel/include/actionlib_tutorials`目录下。\n\n# ActionClient的使用-C++ SimpleActionClient\n\n以下程序实现了如何将goal发送到名为`do_dishes`的DoDishes ActionServer。创建文件`actionlib_tutorials/src/do_dishes_client.cpp`：\n\n~~~c++\n#include <actionlib_tutorials/DoDishesAction.h> // Note: \"Action\" is appended\n#include <actionlib/client/simple_action_client.h>\n\ntypedef actionlib::SimpleActionClient<actionlib_tutorials::DoDishesAction> Client;\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"do_dishes_client\");\n  Client client(\"do_dishes\", true); // true -> don't need ros::spin()\n  client.waitForServer();\n  actionlib_tutorials::DoDishesGoal goal;\n  // Fill in goal here\n  client.sendGoal(goal);\n  client.waitForResult(ros::Duration(5.0));\n  if (client.getState() == actionlib::SimpleClientGoalState::SUCCEEDED)\n    printf(\"Yay! The dishes are now clean\");\n  printf(\"Current State: %s\\n\", client.getState().toString().c_str());\n  return 0;\n}\n~~~\n\n注意：对于C++SimpleActionClient，在一个单独的线程正在服务客户端的回调队列时，`waitForServer`方法才会工作。这需要传递给客户端构造函数的spin_thread选项，使用多线程微调器运行，或者使用您自己的线程为ROS回调队列提供服务。\n\n# ActionServer的使用-C++ SimpleActionServer\n\n以下片段显示了如何编写一个名为“do_dishes”的DoDishes ActionServer。创建文件`actionlib_tutorials/src/do_dishes_server.cpp`：\n\n~~~c++\n#include <actionlib_tutorials/DoDishesAction.h>  // Note: \"Action\" is appended\n#include <actionlib/server/simple_action_server.h>\n\ntypedef actionlib::SimpleActionServer<actionlib_tutorials::DoDishesAction> Server;\n\nvoid execute(const actionlib_tutorials::DoDishesGoalConstPtr& goal, Server* as)  // Note: \"Action\" is not appended to DoDishes here\n{\n  // Do lots of awesome groundbreaking robot stuff here\n  as->setSucceeded();\n}\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"do_dishes_server\");\n  ros::NodeHandle n;\n  Server server(n, \"do_dishes\", boost::bind(&execute, _1, &server), false);\n  server.start();\n  ros::spin();\n  return 0;\n}\n~~~\n\n# 测试Action\n\n工作空间目录下执行：\n\n~~~\ncatkin_make\n~~~\n\n执行完会自动生成可执行文件`do_dishes_client`、`do_dishes_server`，保存在`工作空间/devel/lib/actionlib_tutorials`目录下。\n\n终端启动ROS：\n\n```shell\nroscore\n```\n\n运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials do_dishes_client\n```\n\n运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials do_dishes_server\n```\n\n执行完成客户端会有如下输出信息：\n\n~~~\nYay! The dishes are now cleanCurrent State: SUCCEEDED\n~~~\n\n执行`rqt_graph`命令查看节点图：\n\n{% asset_img 节点图.png  %}","slug":"ROS学习之actionlib库（１）-actionlib库的介绍","published":1,"updated":"2019-05-30T12:29:26.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbz600bnqlcr2audx4n6","content":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h1><p>actionlib软件包为ROS中的可抢占任务提供了一个基于话题的通用接口。在任何一个比较大的基于ROS的系统，都会有这样的情况，向某个节点发送请求执行某一个任务，并返回相应的执行结果，这种请求-响应式的使用场景通常使用ROS提供的服务（services）机制完成。然而，有一些情况服务执行的时间很长，在执行中想要定期获得任务处理的进度，或可能取消执行任务（或请求），例如如果执行各种运动的动作，像控制机械手臂去抓取一个杯子，这个过程可能复杂而漫长，执行过程中还可能强制中断或反馈信息，service机制就无法满足需求，而actionlib就能实现这样的功能。它是ROS中一个很重要的功能包集合（库），可以实现一些简单的状态机功能，算的上是SMACH的一个弱化版。</p>\n<p>扩展：</p>\n<p>SMACH是一个用于快速创建复杂机器人行为的任务级体系结构。SMACH的核心是独立于ROS的Python库，用于构建分层状态机。SMACH是一个新的库，它利用非常古老的概念来快速创建具有可维护和模块化代码的强大机器人行为。可以使用SMACH建立一个有限状态机，但SMACH能做的更多。SMACH是一个任务级的执行和协调库，并提供集中“状态容器”。一个这样的容器是一个有限状态机，但是这个容器也可以是另一个容器中的状态。更多内容<a href=\"http://wiki.ros.org/cn/smach\" target=\"_blank\" rel=\"noopener\">参考wiki</a>。</p>\n<h1 id=\"细节描述\"><a href=\"#细节描述\" class=\"headerlink\" title=\"细节描述\"></a>细节描述</h1><p>actionlib堆栈提供了一个标准化的接口同可抢占任务进行交互，这方面的例子包括将底座移动到目标位置、执行激光扫描并返回产生的点云、检测门的手柄等等。</p>\n<h2 id=\"介绍-1\"><a href=\"#介绍-1\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><p>下面将描述动作客户端和服务器相互交互的底层机制，如果只是简单的使用actionlib就没必要深入学习了。</p>\n<h2 id=\"高级客户端-服务器交互\"><a href=\"#高级客户端-服务器交互\" class=\"headerlink\" title=\"高级客户端/服务器交互\"></a>高级客户端/服务器交互</h2><h3 id=\"服务器描述\"><a href=\"#服务器描述\" class=\"headerlink\" title=\"服务器描述\"></a>服务器描述</h3><h4 id=\"服务器状态机\"><a href=\"#服务器状态机\" class=\"headerlink\" title=\"服务器状态机\"></a>服务器状态机</h4><p>goal是在ActionClient端启动的（因为client会发送sendgoal嘛），一旦ActionServer接收到goal请求，它就会为这个goal创建一个状态机，来追踪goal的状态转换。注意，状态机跟踪的是goal！而不是不是跟踪ActionServer本身！所以系统中对于每一个goal都会有一个状态机。状态转换图如下所示：</p>\n<p><img src=\"http://wiki.ros.org/actionlib/DetailedDescription?action=AttachFile&amp;do=get&amp;target=server_states_detailed.png\" alt=\"server_states_detailed.png\"></p>\n<h4 id=\"服务器转换状态\"><a href=\"#服务器转换状态\" class=\"headerlink\" title=\"服务器转换状态\"></a>服务器转换状态</h4><p>这些状态的转换大多是服务的实施者（其实就是服务的程序）触发的，用小一串命令：</p>\n<ul>\n<li><strong>setAccepted</strong> - 检查到有goal之后，决定开始处理它 </li>\n<li><strong>setRejected</strong> - 检察到goal后，决定不去处理它，因为它是个无效请求（溢出，资源不可用，无效等） </li>\n<li><strong>setSucceeded</strong> - 告知goal被正确执行</li>\n<li><strong>setAborted</strong> - 告知goal在处理时遇到了问题不得不被终止了</li>\n<li><strong>setCanceled</strong> - 告知因cancle请求，goal不再被执行了</li>\n</ul>\n<p>action client也能异步触发状态转换：</p>\n<ul>\n<li><strong>CancelRequest</strong>: 客户端通知action server它想要server停止处理这个goal服务端状态</li>\n</ul>\n<p>服务端状态</p>\n<ol>\n<li><p>中间状态</p>\n<p>（前面说了，simple的状态有三个，就是等待执行挂起）</p>\n<ul>\n<li><strong>Pending</strong> - goal还没有被ActionServer处理</li>\n<li><strong>Active</strong> - goal正在被AS处理 </li>\n<li><strong>Recalling</strong> - goal没有被处理并且从客户端已发送取消它的命令，但AS还不确定goal已经被取消了（时差导致的？）</li>\n<li><strong>Preempting</strong> - goal正被处理呢，从AC端收到了取消请求，但AS还不确定goal已经被取消</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li>终点状态 <ul>\n<li><strong>Rejected</strong> - AC没有发cancle请求，goal被AS不处理直接拒绝了The goal was rejected by the action server without being processed and without a request from the action client to cancel </li>\n<li><strong>Succeeded</strong> - goal被AS成功实现 was achieved successfully by the action server </li>\n<li><strong>Aborted</strong> - goal被AS终止没有AC的cancle请求</li>\n<li><strong>Recalled</strong> - 在AS开始执行之前这个goal被另一个goal或者cancle请求取消了</li>\n<li><strong>Preempted</strong> - 处理中的goal被另一个goal或者AC的取消请求给取消了</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"客户端描述\"><a href=\"#客户端描述\" class=\"headerlink\" title=\"客户端描述\"></a>客户端描述</h3><h4 id=\"客户端状态机\"><a href=\"#客户端状态机\" class=\"headerlink\" title=\"客户端状态机\"></a>客户端状态机</h4><h4 id=\"客户端状态\"><a href=\"#客户端状态\" class=\"headerlink\" title=\"客户端状态\"></a>客户端状态</h4><h2 id=\"Action接口和传输层（协议）\"><a href=\"#Action接口和传输层（协议）\" class=\"headerlink\" title=\"Action接口和传输层（协议）\"></a>Action接口和传输层（协议）</h2><h3 id=\"数据与\"><a href=\"#数据与\" class=\"headerlink\" title=\"数据与\"></a>数据与</h3><h3 id=\"信息\"><a href=\"#信息\" class=\"headerlink\" title=\"信息\"></a>信息</h3><h4 id=\"goal话题\"><a href=\"#goal话题\" class=\"headerlink\" title=\"goal话题\"></a>goal话题</h4><h4 id=\"cancel话题\"><a href=\"#cancel话题\" class=\"headerlink\" title=\"cancel话题\"></a>cancel话题</h4><h4 id=\"status话题\"><a href=\"#status话题\" class=\"headerlink\" title=\"status话题\"></a>status话题</h4><h4 id=\"feedback话题\"><a href=\"#feedback话题\" class=\"headerlink\" title=\"feedback话题\"></a>feedback话题</h4><h4 id=\"result话题\"><a href=\"#result话题\" class=\"headerlink\" title=\"result话题\"></a>result话题</h4><h2 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h2><h3 id=\"简单的行为客户端\"><a href=\"#简单的行为客户端\" class=\"headerlink\" title=\"简单的行为客户端\"></a>简单的行为客户端</h3><h4 id=\"客户端状态歧义\"><a href=\"#客户端状态歧义\" class=\"headerlink\" title=\"客户端状态歧义\"></a>客户端状态歧义</h4><h4 id=\"多目标策略\"><a href=\"#多目标策略\" class=\"headerlink\" title=\"多目标策略\"></a>多目标策略</h4><h4 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h4><h3 id=\"简单的行为服务器\"><a href=\"#简单的行为服务器\" class=\"headerlink\" title=\"简单的行为服务器\"></a>简单的行为服务器</h3><h4 id=\"目标通知\"><a href=\"#目标通知\" class=\"headerlink\" title=\"目标通知\"></a>目标通知</h4><h4 id=\"线程模型-1\"><a href=\"#线程模型-1\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h4><h1 id=\"Client-Server交互\"><a href=\"#Client-Server交互\" class=\"headerlink\" title=\"Client-Server交互\"></a>Client-Server交互</h1><p>如下图所示，actionlib的框架实际是一种特殊的客户-服务的模式。除了服务请求的功能外，还可以实时获取服务器执行任务的进度状态，以及强制中断服务的功能。action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息。action客户端和服务端通过函数调用和回调的方式，向用户提供用于请求目标（在客户端发生）或执行目标（服务器端发生）的接口。</p>\n<p><img src=\"http://wiki.ros.org/actionlib?action=AttachFile&amp;do=get&amp;target=client_server_interaction.png\" alt=\"client_server_interaction.png\"></p>\n<h1 id=\"Action清单：Goal-Feedback-Result\"><a href=\"#Action清单：Goal-Feedback-Result\" class=\"headerlink\" title=\"Action清单：Goal,Feedback,Result\"></a>Action清单：Goal,Feedback,Result</h1><p>为了使得客户端和服务器之间进行通信，需要定义一些用于二者之间通信的消息，这就是<em>action清单</em>。该清单定义客户端和服务器之间通信的Goal、Feedback、Result信息。</p>\n<ul>\n<li>Goal：为了使用action来完成任务，引入可以由ActionClient发送到服务器的Goal概念。对于移动底座的情况，Goal将是PoseStamped消息，其中包含关于机器人应该在世界坐标系移动到何处的信息。对于控制倾斜激光扫描仪的情况，    Goal应该包含扫描参数（最小角、最大角、速度等）。</li>\n<li>Feedback：Feedback为服务器实施者提供了一种方法，告知ActionClient目标的增量变化情况。对于移动底座的情况，它可能是机器人沿着路径运动时当前的姿势；对于控制倾斜激光扫描仪的情况，它可能是扫描完成之前剩下的时间。</li>\n<li>Result：完成目标后，结果会从ActionServer发送到ActionClient。Result同Feedback不同，因为它只发送一次，当行动的目标是提供某种信息时，这一点就非常有用。对于移动底座的情况，Result不是非常重要，但它可以是机器人的最终位姿；对于控制倾斜激光扫描仪的情况，结果可能包含根据请求的扫描生成的点云。</li>\n</ul>\n<h1 id=\"action文件\"><a href=\"#action文件\" class=\"headerlink\" title=\".action文件\"></a>.action文件</h1><p>在介绍.action文件之前，先创建一个程序包，用于后续内容的学习，actinlib库相关的文件都放在该程序包下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_create_pkg actionlib_tutorials actionlib message_generation roscpp rospy std_msgs actionlib_msgs</span><br></pre></td></tr></table></figure>\n<p>ROS中使用一个.action文件定义action清单，该文件包含goal、result、feedback的定义，使用—-分隔开，它一般会被放置在程序包的action目录下。以洗碟子为例，描述该过程的action清单如下所示：</p>\n<p><code>actionlib_tutorials/action/DoDishes.action</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Define the goal</span><br><span class=\"line\">uint32 dishwasher_id  # Specify which dishwasher we want to use</span><br><span class=\"line\">---</span><br><span class=\"line\"># Define the result</span><br><span class=\"line\">uint32 total_dishes_cleaned</span><br><span class=\"line\">---</span><br><span class=\"line\"># Define a feedback message</span><br><span class=\"line\">float32 percent_complete</span><br></pre></td></tr></table></figure>\n<p>基于<code>.action</code>文件会产生６个消息用于客户端和服务器的通信，这一过程在<code>catkin_make</code>编译过程自动触发完成。</p>\n<h2 id=\"Catkin\"><a href=\"#Catkin\" class=\"headerlink\" title=\"Catkin\"></a>Catkin</h2><p>在当前程序包<code>CMakeList.txt</code>文件中<code>catkin_package()</code>之前添加：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_action_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  DoDishes.action</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>同时需要在<code>package.xml</code>文件中包含如下依赖：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>actionlib<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>actionlib_msgs<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">run_depend</span>&gt;</span>actionlib<span class=\"tag\">&lt;/<span class=\"name\">run_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">run_depend</span>&gt;</span>actionlib_msgs<span class=\"tag\">&lt;/<span class=\"name\">run_depend</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>执行命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscd actionlib_tutorials</span><br><span class=\"line\">rosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action</span><br></pre></td></tr></table></figure>\n<p><code>genaction.py</code>文件位于<code>/opt/ros/kinetic/lib/actionlib_msgs/</code>目录下。</p>\n<p>会出现如下提示信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Generating for action Fibonacci</span><br></pre></td></tr></table></figure>\n<p>通过手动执行<code>generation.py</code>文件，我们就使用DoDishes.action生成了以下消息，并保存在了程序包的<code>msg/</code>目录下。这些消息文件将被actionlib内部用于ActionClient和ActionServer之间的通信。</p>\n<ul>\n<li><code>DoDishesAction.msg</code> </li>\n<li><code>DoDishesActionGoal.msg</code> </li>\n<li><code>DoDishesActionResult.msg</code> </li>\n<li><code>DoDishesActionFeedback.msg</code> </li>\n<li><code>DoDishesGoal.msg</code> </li>\n<li><code>DoDishesResult.msg</code> </li>\n<li><code>DoDishesFeedback.msg</code></li>\n</ul>\n<p><strong>注意</strong>：其实我们可以完全不用手动执行如上操作，手动生成消息文件。我们可以在工作空间目录下执行<code>catkin_make</code>命令，就会自动生成的<code>.msg</code>和<code>.h</code>文件，并分别保存在<code>工作空间/devel/share/actionlib_tutorials/msg</code>和<code>工作空间/devel/include/actionlib_tutorials</code>目录下。</p>\n<h1 id=\"ActionClient的使用-C-SimpleActionClient\"><a href=\"#ActionClient的使用-C-SimpleActionClient\" class=\"headerlink\" title=\"ActionClient的使用-C++ SimpleActionClient\"></a>ActionClient的使用-C++ SimpleActionClient</h1><p>以下程序实现了如何将goal发送到名为<code>do_dishes</code>的DoDishes ActionServer。创建文件<code>actionlib_tutorials/src/do_dishes_client.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib_tutorials/DoDishesAction.h&gt; // Note: \"Action\" is appended</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/simple_action_client.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> actionlib::SimpleActionClient&lt;actionlib_tutorials::DoDishesAction&gt; Client;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"do_dishes_client\"</span>);</span><br><span class=\"line\">  <span class=\"function\">Client <span class=\"title\">client</span><span class=\"params\">(<span class=\"string\">\"do_dishes\"</span>, <span class=\"literal\">true</span>)</span></span>; <span class=\"comment\">// true -&gt; don't need ros::spin()</span></span><br><span class=\"line\">  client.waitForServer();</span><br><span class=\"line\">  actionlib_tutorials::DoDishesGoal goal;</span><br><span class=\"line\">  <span class=\"comment\">// Fill in goal here</span></span><br><span class=\"line\">  client.sendGoal(goal);</span><br><span class=\"line\">  client.waitForResult(ros::Duration(<span class=\"number\">5.0</span>));</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (client.getState() == actionlib::SimpleClientGoalState::SUCCEEDED)</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Yay! The dishes are now clean\"</span>);</span><br><span class=\"line\">  <span class=\"built_in\">printf</span>(<span class=\"string\">\"Current State: %s\\n\"</span>, client.getState().toString().c_str());</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>注意：对于C++SimpleActionClient，在一个单独的线程正在服务客户端的回调队列时，<code>waitForServer</code>方法才会工作。这需要传递给客户端构造函数的spin_thread选项，使用多线程微调器运行，或者使用您自己的线程为ROS回调队列提供服务。</p>\n<h1 id=\"ActionServer的使用-C-SimpleActionServer\"><a href=\"#ActionServer的使用-C-SimpleActionServer\" class=\"headerlink\" title=\"ActionServer的使用-C++ SimpleActionServer\"></a>ActionServer的使用-C++ SimpleActionServer</h1><p>以下片段显示了如何编写一个名为“do_dishes”的DoDishes ActionServer。创建文件<code>actionlib_tutorials/src/do_dishes_server.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib_tutorials/DoDishesAction.h&gt;  // Note: \"Action\" is appended</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/server/simple_action_server.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> actionlib::SimpleActionServer&lt;actionlib_tutorials::DoDishesAction&gt; Server;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(<span class=\"keyword\">const</span> actionlib_tutorials::DoDishesGoalConstPtr&amp; goal, Server* as)</span>  <span class=\"comment\">// Note: \"Action\" is not appended to DoDishes here</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"comment\">// Do lots of awesome groundbreaking robot stuff here</span></span><br><span class=\"line\">  as-&gt;setSucceeded();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"do_dishes_server\"</span>);</span><br><span class=\"line\">  ros::NodeHandle n;</span><br><span class=\"line\">  Server server(n, \"do_dishes\", boost::bind(&amp;execute, _1, &amp;server), false);</span><br><span class=\"line\">  server.start();</span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"测试Action\"><a href=\"#测试Action\" class=\"headerlink\" title=\"测试Action\"></a>测试Action</h1><p>工作空间目录下执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_make</span><br></pre></td></tr></table></figure>\n<p>执行完会自动生成可执行文件<code>do_dishes_client</code>、<code>do_dishes_server</code>，保存在<code>工作空间/devel/lib/actionlib_tutorials</code>目录下。</p>\n<p>终端启动ROS：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscore</span><br></pre></td></tr></table></figure>\n<p>运行行为客户端：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials do_dishes_client</span><br></pre></td></tr></table></figure>\n<p>运行行为服务器：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials do_dishes_server</span><br></pre></td></tr></table></figure>\n<p>执行完成客户端会有如下输出信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Yay! The dishes are now cleanCurrent State: SUCCEEDED</span><br></pre></td></tr></table></figure>\n<p>执行<code>rqt_graph</code>命令查看节点图：</p>\n<img src=\"/2018/03/29/ROS学习之actionlib库（１）-actionlib库的介绍/节点图.png\">","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>","more":"<h1 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h1><p>actionlib软件包为ROS中的可抢占任务提供了一个基于话题的通用接口。在任何一个比较大的基于ROS的系统，都会有这样的情况，向某个节点发送请求执行某一个任务，并返回相应的执行结果，这种请求-响应式的使用场景通常使用ROS提供的服务（services）机制完成。然而，有一些情况服务执行的时间很长，在执行中想要定期获得任务处理的进度，或可能取消执行任务（或请求），例如如果执行各种运动的动作，像控制机械手臂去抓取一个杯子，这个过程可能复杂而漫长，执行过程中还可能强制中断或反馈信息，service机制就无法满足需求，而actionlib就能实现这样的功能。它是ROS中一个很重要的功能包集合（库），可以实现一些简单的状态机功能，算的上是SMACH的一个弱化版。</p>\n<p>扩展：</p>\n<p>SMACH是一个用于快速创建复杂机器人行为的任务级体系结构。SMACH的核心是独立于ROS的Python库，用于构建分层状态机。SMACH是一个新的库，它利用非常古老的概念来快速创建具有可维护和模块化代码的强大机器人行为。可以使用SMACH建立一个有限状态机，但SMACH能做的更多。SMACH是一个任务级的执行和协调库，并提供集中“状态容器”。一个这样的容器是一个有限状态机，但是这个容器也可以是另一个容器中的状态。更多内容<a href=\"http://wiki.ros.org/cn/smach\" target=\"_blank\" rel=\"noopener\">参考wiki</a>。</p>\n<h1 id=\"细节描述\"><a href=\"#细节描述\" class=\"headerlink\" title=\"细节描述\"></a>细节描述</h1><p>actionlib堆栈提供了一个标准化的接口同可抢占任务进行交互，这方面的例子包括将底座移动到目标位置、执行激光扫描并返回产生的点云、检测门的手柄等等。</p>\n<h2 id=\"介绍-1\"><a href=\"#介绍-1\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><p>下面将描述动作客户端和服务器相互交互的底层机制，如果只是简单的使用actionlib就没必要深入学习了。</p>\n<h2 id=\"高级客户端-服务器交互\"><a href=\"#高级客户端-服务器交互\" class=\"headerlink\" title=\"高级客户端/服务器交互\"></a>高级客户端/服务器交互</h2><h3 id=\"服务器描述\"><a href=\"#服务器描述\" class=\"headerlink\" title=\"服务器描述\"></a>服务器描述</h3><h4 id=\"服务器状态机\"><a href=\"#服务器状态机\" class=\"headerlink\" title=\"服务器状态机\"></a>服务器状态机</h4><p>goal是在ActionClient端启动的（因为client会发送sendgoal嘛），一旦ActionServer接收到goal请求，它就会为这个goal创建一个状态机，来追踪goal的状态转换。注意，状态机跟踪的是goal！而不是不是跟踪ActionServer本身！所以系统中对于每一个goal都会有一个状态机。状态转换图如下所示：</p>\n<p><img src=\"http://wiki.ros.org/actionlib/DetailedDescription?action=AttachFile&amp;do=get&amp;target=server_states_detailed.png\" alt=\"server_states_detailed.png\"></p>\n<h4 id=\"服务器转换状态\"><a href=\"#服务器转换状态\" class=\"headerlink\" title=\"服务器转换状态\"></a>服务器转换状态</h4><p>这些状态的转换大多是服务的实施者（其实就是服务的程序）触发的，用小一串命令：</p>\n<ul>\n<li><strong>setAccepted</strong> - 检查到有goal之后，决定开始处理它 </li>\n<li><strong>setRejected</strong> - 检察到goal后，决定不去处理它，因为它是个无效请求（溢出，资源不可用，无效等） </li>\n<li><strong>setSucceeded</strong> - 告知goal被正确执行</li>\n<li><strong>setAborted</strong> - 告知goal在处理时遇到了问题不得不被终止了</li>\n<li><strong>setCanceled</strong> - 告知因cancle请求，goal不再被执行了</li>\n</ul>\n<p>action client也能异步触发状态转换：</p>\n<ul>\n<li><strong>CancelRequest</strong>: 客户端通知action server它想要server停止处理这个goal服务端状态</li>\n</ul>\n<p>服务端状态</p>\n<ol>\n<li><p>中间状态</p>\n<p>（前面说了，simple的状态有三个，就是等待执行挂起）</p>\n<ul>\n<li><strong>Pending</strong> - goal还没有被ActionServer处理</li>\n<li><strong>Active</strong> - goal正在被AS处理 </li>\n<li><strong>Recalling</strong> - goal没有被处理并且从客户端已发送取消它的命令，但AS还不确定goal已经被取消了（时差导致的？）</li>\n<li><strong>Preempting</strong> - goal正被处理呢，从AC端收到了取消请求，但AS还不确定goal已经被取消</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li>终点状态 <ul>\n<li><strong>Rejected</strong> - AC没有发cancle请求，goal被AS不处理直接拒绝了The goal was rejected by the action server without being processed and without a request from the action client to cancel </li>\n<li><strong>Succeeded</strong> - goal被AS成功实现 was achieved successfully by the action server </li>\n<li><strong>Aborted</strong> - goal被AS终止没有AC的cancle请求</li>\n<li><strong>Recalled</strong> - 在AS开始执行之前这个goal被另一个goal或者cancle请求取消了</li>\n<li><strong>Preempted</strong> - 处理中的goal被另一个goal或者AC的取消请求给取消了</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"客户端描述\"><a href=\"#客户端描述\" class=\"headerlink\" title=\"客户端描述\"></a>客户端描述</h3><h4 id=\"客户端状态机\"><a href=\"#客户端状态机\" class=\"headerlink\" title=\"客户端状态机\"></a>客户端状态机</h4><h4 id=\"客户端状态\"><a href=\"#客户端状态\" class=\"headerlink\" title=\"客户端状态\"></a>客户端状态</h4><h2 id=\"Action接口和传输层（协议）\"><a href=\"#Action接口和传输层（协议）\" class=\"headerlink\" title=\"Action接口和传输层（协议）\"></a>Action接口和传输层（协议）</h2><h3 id=\"数据与\"><a href=\"#数据与\" class=\"headerlink\" title=\"数据与\"></a>数据与</h3><h3 id=\"信息\"><a href=\"#信息\" class=\"headerlink\" title=\"信息\"></a>信息</h3><h4 id=\"goal话题\"><a href=\"#goal话题\" class=\"headerlink\" title=\"goal话题\"></a>goal话题</h4><h4 id=\"cancel话题\"><a href=\"#cancel话题\" class=\"headerlink\" title=\"cancel话题\"></a>cancel话题</h4><h4 id=\"status话题\"><a href=\"#status话题\" class=\"headerlink\" title=\"status话题\"></a>status话题</h4><h4 id=\"feedback话题\"><a href=\"#feedback话题\" class=\"headerlink\" title=\"feedback话题\"></a>feedback话题</h4><h4 id=\"result话题\"><a href=\"#result话题\" class=\"headerlink\" title=\"result话题\"></a>result话题</h4><h2 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h2><h3 id=\"简单的行为客户端\"><a href=\"#简单的行为客户端\" class=\"headerlink\" title=\"简单的行为客户端\"></a>简单的行为客户端</h3><h4 id=\"客户端状态歧义\"><a href=\"#客户端状态歧义\" class=\"headerlink\" title=\"客户端状态歧义\"></a>客户端状态歧义</h4><h4 id=\"多目标策略\"><a href=\"#多目标策略\" class=\"headerlink\" title=\"多目标策略\"></a>多目标策略</h4><h4 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h4><h3 id=\"简单的行为服务器\"><a href=\"#简单的行为服务器\" class=\"headerlink\" title=\"简单的行为服务器\"></a>简单的行为服务器</h3><h4 id=\"目标通知\"><a href=\"#目标通知\" class=\"headerlink\" title=\"目标通知\"></a>目标通知</h4><h4 id=\"线程模型-1\"><a href=\"#线程模型-1\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h4><h1 id=\"Client-Server交互\"><a href=\"#Client-Server交互\" class=\"headerlink\" title=\"Client-Server交互\"></a>Client-Server交互</h1><p>如下图所示，actionlib的框架实际是一种特殊的客户-服务的模式。除了服务请求的功能外，还可以实时获取服务器执行任务的进度状态，以及强制中断服务的功能。action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息。action客户端和服务端通过函数调用和回调的方式，向用户提供用于请求目标（在客户端发生）或执行目标（服务器端发生）的接口。</p>\n<p><img src=\"http://wiki.ros.org/actionlib?action=AttachFile&amp;do=get&amp;target=client_server_interaction.png\" alt=\"client_server_interaction.png\"></p>\n<h1 id=\"Action清单：Goal-Feedback-Result\"><a href=\"#Action清单：Goal-Feedback-Result\" class=\"headerlink\" title=\"Action清单：Goal,Feedback,Result\"></a>Action清单：Goal,Feedback,Result</h1><p>为了使得客户端和服务器之间进行通信，需要定义一些用于二者之间通信的消息，这就是<em>action清单</em>。该清单定义客户端和服务器之间通信的Goal、Feedback、Result信息。</p>\n<ul>\n<li>Goal：为了使用action来完成任务，引入可以由ActionClient发送到服务器的Goal概念。对于移动底座的情况，Goal将是PoseStamped消息，其中包含关于机器人应该在世界坐标系移动到何处的信息。对于控制倾斜激光扫描仪的情况，    Goal应该包含扫描参数（最小角、最大角、速度等）。</li>\n<li>Feedback：Feedback为服务器实施者提供了一种方法，告知ActionClient目标的增量变化情况。对于移动底座的情况，它可能是机器人沿着路径运动时当前的姿势；对于控制倾斜激光扫描仪的情况，它可能是扫描完成之前剩下的时间。</li>\n<li>Result：完成目标后，结果会从ActionServer发送到ActionClient。Result同Feedback不同，因为它只发送一次，当行动的目标是提供某种信息时，这一点就非常有用。对于移动底座的情况，Result不是非常重要，但它可以是机器人的最终位姿；对于控制倾斜激光扫描仪的情况，结果可能包含根据请求的扫描生成的点云。</li>\n</ul>\n<h1 id=\"action文件\"><a href=\"#action文件\" class=\"headerlink\" title=\".action文件\"></a>.action文件</h1><p>在介绍.action文件之前，先创建一个程序包，用于后续内容的学习，actinlib库相关的文件都放在该程序包下：</p>\n<!--�179-->\n<p>ROS中使用一个.action文件定义action清单，该文件包含goal、result、feedback的定义，使用—-分隔开，它一般会被放置在程序包的action目录下。以洗碟子为例，描述该过程的action清单如下所示：</p>\n<p><code>actionlib_tutorials/action/DoDishes.action</code></p>\n<!--�180-->\n<p>基于<code>.action</code>文件会产生６个消息用于客户端和服务器的通信，这一过程在<code>catkin_make</code>编译过程自动触发完成。</p>\n<h2 id=\"Catkin\"><a href=\"#Catkin\" class=\"headerlink\" title=\"Catkin\"></a>Catkin</h2><p>在当前程序包<code>CMakeList.txt</code>文件中<code>catkin_package()</code>之前添加：</p>\n<!--�181-->\n<p>同时需要在<code>package.xml</code>文件中包含如下依赖：</p>\n<!--�182-->\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>执行命令：</p>\n<!--�183-->\n<p><code>genaction.py</code>文件位于<code>/opt/ros/kinetic/lib/actionlib_msgs/</code>目录下。</p>\n<p>会出现如下提示信息：</p>\n<!--�184-->\n<p>通过手动执行<code>generation.py</code>文件，我们就使用DoDishes.action生成了以下消息，并保存在了程序包的<code>msg/</code>目录下。这些消息文件将被actionlib内部用于ActionClient和ActionServer之间的通信。</p>\n<ul>\n<li><code>DoDishesAction.msg</code> </li>\n<li><code>DoDishesActionGoal.msg</code> </li>\n<li><code>DoDishesActionResult.msg</code> </li>\n<li><code>DoDishesActionFeedback.msg</code> </li>\n<li><code>DoDishesGoal.msg</code> </li>\n<li><code>DoDishesResult.msg</code> </li>\n<li><code>DoDishesFeedback.msg</code></li>\n</ul>\n<p><strong>注意</strong>：其实我们可以完全不用手动执行如上操作，手动生成消息文件。我们可以在工作空间目录下执行<code>catkin_make</code>命令，就会自动生成的<code>.msg</code>和<code>.h</code>文件，并分别保存在<code>工作空间/devel/share/actionlib_tutorials/msg</code>和<code>工作空间/devel/include/actionlib_tutorials</code>目录下。</p>\n<h1 id=\"ActionClient的使用-C-SimpleActionClient\"><a href=\"#ActionClient的使用-C-SimpleActionClient\" class=\"headerlink\" title=\"ActionClient的使用-C++ SimpleActionClient\"></a>ActionClient的使用-C++ SimpleActionClient</h1><p>以下程序实现了如何将goal发送到名为<code>do_dishes</code>的DoDishes ActionServer。创建文件<code>actionlib_tutorials/src/do_dishes_client.cpp</code>：</p>\n<!--�185-->\n<p>注意：对于C++SimpleActionClient，在一个单独的线程正在服务客户端的回调队列时，<code>waitForServer</code>方法才会工作。这需要传递给客户端构造函数的spin_thread选项，使用多线程微调器运行，或者使用您自己的线程为ROS回调队列提供服务。</p>\n<h1 id=\"ActionServer的使用-C-SimpleActionServer\"><a href=\"#ActionServer的使用-C-SimpleActionServer\" class=\"headerlink\" title=\"ActionServer的使用-C++ SimpleActionServer\"></a>ActionServer的使用-C++ SimpleActionServer</h1><p>以下片段显示了如何编写一个名为“do_dishes”的DoDishes ActionServer。创建文件<code>actionlib_tutorials/src/do_dishes_server.cpp</code>：</p>\n<!--�186-->\n<h1 id=\"测试Action\"><a href=\"#测试Action\" class=\"headerlink\" title=\"测试Action\"></a>测试Action</h1><p>工作空间目录下执行：</p>\n<!--�187-->\n<p>执行完会自动生成可执行文件<code>do_dishes_client</code>、<code>do_dishes_server</code>，保存在<code>工作空间/devel/lib/actionlib_tutorials</code>目录下。</p>\n<p>终端启动ROS：</p>\n<!--�188-->\n<p>运行行为客户端：</p>\n<!--�189-->\n<p>运行行为服务器：</p>\n<!--�190-->\n<p>执行完成客户端会有如下输出信息：</p>\n<!--�191-->\n<p>执行<code>rqt_graph</code>命令查看节点图：</p>\n<img src=\"/2018/03/29/ROS学习之actionlib库（１）-actionlib库的介绍/节点图.png\">"},{"title":"ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器","date":"2018-03-30T02:42:46.000Z","copyright":true,"_content":"-----\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more-->\n\n# 创建行为消息\n\n行为消息自动从`.action`文件生成，该文件放置在程序包的`action`目录下，它定义行为消息的目标、结果和行为反馈话题的类型和格式。下面是一个例子。\n\n在程序包中创建文件`actionlib_tutorials/action/Fibonacci.action`：\n\n```\n#goal definition\nint32 order\n---\n#result definition\nint32[] sequence\n---\n#feedback\nint32[] sequence\n```\n\n# 生成消息文件\n\n使用编辑好的`.action`文件生成`.msg`消息文件，有两种方式，笔者认为手动生成方式其实不是必须的，只是提供了一种生成消息文件的方式而已，一般实践过程中只需要在`CMakeList.txt`文件添加必要的信息，自动生成消息文件。\n\n- 通过设置`CMakeList.txt`文件在编译过程中自动生成，生成的`.msg`消息文件会自动放在 `工作空间/devel/share/程序包名/msg/` 路径下；\n- 使用`generation.py`脚本手动生成，生成的`.msg`消息文件可以自定义放置的目录，例如可以放在`工作空间/src/程序包名/msg/` 路径下，这时可以在当前程序包下执行命令`rosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action`。\n\n## 手动生成\n\n```shell\nroscd actionlib_tutorials\nrosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action\n```\n\n`genaction.py`文件位于`/opt/ros/kinetic/lib/actionlib_msgs/`目录下。\n\n会出现如下提示信息：\n\n```shell\nGenerating for action Fibonacci\n```\n\n## 自动生成\n\n在编译过程中自动生成消息需要添加一些内容到`CMakeList.txt`文件。\n\n```cmake\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n```\n\n运行：\n\n```shell\ncatkin_make #　工作空间下运行\n```\n\n使用如下命令就可以看到自动生成的`.msg`和`.h`文件：\n\n```shell\nls devel/share/actionlib_tutorials/msg/\nls devel/include/actionlib_tutorials/\n```\n\n# 创建行为服务器\n\n创建文件`actionlib_tutorials/src/fibonacci_server.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <actionlib/server/simple_action_server.h>\n#include <actionlib_tutorials/FibonacciAction.h>\n\nclass FibonacciAction\n{\nprotected:\n\n  ros::NodeHandle nh_;//　将会传递到行为服务器中\n  actionlib::SimpleActionServer<actionlib_tutorials::FibonacciAction> as_; // NodeHandle instance must be created before this line. Otherwise strange error occurs.\n  std::string action_name_;\n  // create messages that are used to published feedback/result\n  actionlib_tutorials::FibonacciFeedback feedback_;//　反馈消息\n  actionlib_tutorials::FibonacciResult result_;//　结果消息\n\npublic:\n  FibonacciAction(std::string name) :\n    as_(nh_, name, boost::bind(&FibonacciAction::executeCB, this, _1), false),\n    action_name_(name)\n  {\n    as_.start();\n  }//　行为构造函数构造行为服务器as_,它会得到一个节点句柄（node handle）、行为名称和选择一个运行回调函数（executeCB）参数。\n\n  ~FibonacciAction(void)\n  {\n  }\n  void executeCB(const actionlib_tutorials::FibonacciGoalConstPtr &goal)//　传递一个指向目标消息的指针，它是一个boost共享指针\n  {\n    // helper variables\n    ros::Rate r(1);\n    bool success = true;\n\n    // push_back the seeds for the fibonacci sequence\n    feedback_.sequence.clear();\n    feedback_.sequence.push_back(0);\n    feedback_.sequence.push_back(1);\n\n    // publish info to the console for the user\n    ROS_INFO(\"%s: Executing, creating fibonacci sequence of order %i with seeds %i, %i\", action_name_.c_str(), goal->order, feedback_.sequence[0], feedback_.sequence[1]);\n\n    // 开始执行行为服务器\n    for(int i=1; i<=goal->order; i++)\n    {\n      // 检测一个客户端请求是否抢占当前目标。体现行为服务器的一个重要组成部分：允许行为客户端请求取消当前目标执行\n      if (as_.isPreemptRequested() || !ros::ok())\n      {\n        ROS_INFO(\"%s: Preempted\", action_name_.c_str());\n        // set the action state to preempted\n        as_.setPreempted();//发出该行为已经被用户请求抢占信号\n        success = false;\n        break;\n      }\n      feedback_.sequence.push_back(feedback_.sequence[i] + feedback_.sequence[i-1]);//设置检查抢占请求服务器的等级到服务器系统\n      // 发布反馈：Fibonacci序列赋值给feedback变量，然后通过行为服务器提供的反馈频道发布出去\n      as_.publishFeedback(feedback_);\n      // this sleep is not necessary, the sequence is computed at 1 Hz for demonstration purposes\n      r.sleep();\n    }\n\n    if(success)\n    {\n      result_.sequence = feedback_.sequence;\n      ROS_INFO(\"%s: Succeeded\", action_name_.c_str());\n      // set the action state to succeeded\n      as_.setSucceeded(result_);//　一旦行为完成计算Fibonacci序列，通知行为客户端操作设置成功\n    }\n  }\n};\n\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"fibonacci\");\n\n  FibonacciAction fibonacci(\"fibonacci\");//创建行为\n  ros::spin();//spin节点，行为会运行并等待接收目标\n\n  return 0;\n}\n```\n\n# 创建行为客户端\n\n创建行为客户端文件`actionlib_tutorials/src/fibonacci_client.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <actionlib/client/simple_action_client.h>\n#include <actionlib/client/terminal_state.h>\n#include <actionlib_tutorials/FibonacciAction.h>\n\nint main (int argc, char **argv)\n{\n  ros::init(argc, argv, \"test_fibonacci\");\n\n  // 创建行为客户端\n  // 成功会开启客户端创建自己的线程\n  actionlib::SimpleActionClient<actionlib_tutorials::FibonacciAction> ac(\"fibonacci\", true);\n\n  ROS_INFO(\"Waiting for action server to start.\");\n  //等待行为服务器开启\n  ac.waitForServer(); //will wait for infinite time\n\n  ROS_INFO(\"Action server started, sending goal.\");\n  // 发送目标到行为服务器\n  actionlib_tutorials::FibonacciGoal goal;\n  goal.order = 20;\n  ac.sendGoal(goal);\n\n  //等待行为返回\n  bool finished_before_timeout = ac.waitForResult(ros::Duration(30.0));\n\n  if (finished_before_timeout)\n  {\n    actionlib::SimpleClientGoalState state = ac.getState();\n    ROS_INFO(\"Action finished: %s\",state.toString().c_str());\n  }\n  else\n    ROS_INFO(\"Action did not finish before the time out.\");\n\n  //exit\n  return 0;\n}\n```\n\n# 编译行为\n\n在`CMakeLists.txt`文件末尾添加以下几行： \n\n```cmake\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries(fibonacci_client ${catkin_LIBRARIES})\n```\n\n完整的`CMakeList.txt`文件如下：\n\n~~~cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(actionlib_tutorials)\n\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n\ninclude_directories(include ${catkin_INCLUDE_DIRS} ${Boost_INCLUDE_DIRS})\n\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server  ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries( fibonacci_client  ${catkin_LIBRARIES})\n~~~\n\n工作空间下执行`catkin_make`命令。\n\n其实还需要在`package.xml`中添加如下信息，只不过在最开始创建程序包的时候`catkin_create_pkg`命令添加了对`actionlib`和`actionlib_msgs`的依赖，生成的程序包文件`package.xml`中已经自动添加了这些信息，不需要手动添加了。完美～\n\n~~~xml\n  <build_depend>actionlib</build_depend>\n  <build_depend>actionlib_msgs</build_depend>\n  <build_export_depend>actionlib</build_export_depend>\n  <build_export_depend>actionlib_msgs</build_export_depend>\n  <exec_depend>actionlib</exec_depend>\n  <exec_depend>actionlib_msgs</exec_depend>\n~~~\n\n# 运行行为－连接服务器和客户端\n\n1. 终端启动ROS：\n\n```shell\nroscore\n```\n\n2. 查看行为反馈：\n\n```shell\nrostopic echo /fibonacci/feedback\n```\n\n会有一系列的输出信息，最后的一条信息为：\n\n~~~shell\n---\nheader: \n  seq: 19\n  stamp: \n    secs: 1522552545\n    nsecs: 242077849\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522552526\n      nsecs: 241284287\n    id: \"/test_fibonacci-1-1522552526.241284287\"\n  status: 1\n  text: \"This goal has been accepted by the simple action server\"\nfeedback: \n  sequence: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946]\n~~~\n\n3. 查看行为结果：\n\n```shell\nrostopic echo /fibonacci/result\n```\n\n执行完成输出信息：\n\n~~~shell\neric@eric:~$ rostopic echo /fibonacci/result\nWARNING: topic [/fibonacci/result] does not appear to be published yet\nheader: \n  seq: 0\n  stamp: \n    secs: 1522552546\n    nsecs: 242312501\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522552526\n      nsecs: 241284287\n    id: \"/test_fibonacci-1-1522552526.241284287\"\n  status: 3\n  text: ''\nresult: \n  sequence: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946]\n---\n~~~\n\n4. 运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials fibonacci_client \n```\n执行完成的输出信息：\n\n~~~shell\neric@eric:~$ rosrun actionlib_tutorials fibonacci_client\n[ INFO] [1522552522.129016184]: Waiting for action server to start.\n[ INFO] [1522552526.241189187]: Action server started, sending goal.\n[ INFO] [1522552546.242949052]: Action finished: SUCCEEDED\n~~~\n\n5. 运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials fibonacci_server\n```\n\n执行完成的输出信息：\n\n~~~shell\neric@eric:~rosrun actionlib_tutorials fibonacci_server\n[ INFO] [1522552526.242112000]: fibonacci: Executing, creating fibonacci sequence of order 20 with seeds 0, 1\n[ INFO] [1522552546.242205514]: fibonacci: Succeeded\n~~~\n\n6. 查看发布的话题列表（检查行为运行是否正常）：\n\n~~~shell\nrostopic list -v\n~~~\n\n得到如下信息：\n\n~~~shell\neric@eric:~$ rostopic list -v\n\nPublished topics:\n * /turtle1/color_sensor [turtlesim/Color] 1 publisher\n * /fibonacci/feedback [actionlib_tutorials/FibonacciActionFeedback] 1 publisher\n * /fibonacci/cancel [actionlib_msgs/GoalID] 1 publisher\n * /rosout [rosgraph_msgs/Log] 5 publishers\n * /fibonacci/goal [actionlib_tutorials/FibonacciActionGoal] 1 publisher\n * /rosout_agg [rosgraph_msgs/Log] 1 publisher\n * /fibonacci/status [actionlib_msgs/GoalStatusArray] 1 publisher\n * /fibonacci/result [actionlib_tutorials/FibonacciActionResult] 1 publisher\n * /turtle1/pose [turtlesim/Pose] 1 publisher\n\nSubscribed topics:\n * /fibonacci/feedback [actionlib_tutorials/FibonacciActionFeedback] 2 subscribers\n * /rosout [rosgraph_msgs/Log] 1 subscriber\n * /fibonacci/cancel [actionlib_msgs/GoalID] 1 subscriber\n * /fibonacci/goal [actionlib_tutorials/FibonacciActionGoal] 1 subscriber\n * /fibonacci/status [actionlib_msgs/GoalStatusArray] 1 subscriber\n * /fibonacci/result [actionlib_tutorials/FibonacciActionResult] 2 subscribers\n * /turtle1/cmd_vel [geometry_msgs/Twist] 1 subscriber\n~~~\n\n7. 查看行为节点图：\n\n~~~shell\nrqt_graph\n~~~\n显式如下节点图：\n\n{% asset_img 节点图.png  %}","source":"_posts/ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器.md","raw":"---\ntitle: ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器\ndate: 2018-03-30 10:42:46\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n-----\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more-->\n\n# 创建行为消息\n\n行为消息自动从`.action`文件生成，该文件放置在程序包的`action`目录下，它定义行为消息的目标、结果和行为反馈话题的类型和格式。下面是一个例子。\n\n在程序包中创建文件`actionlib_tutorials/action/Fibonacci.action`：\n\n```\n#goal definition\nint32 order\n---\n#result definition\nint32[] sequence\n---\n#feedback\nint32[] sequence\n```\n\n# 生成消息文件\n\n使用编辑好的`.action`文件生成`.msg`消息文件，有两种方式，笔者认为手动生成方式其实不是必须的，只是提供了一种生成消息文件的方式而已，一般实践过程中只需要在`CMakeList.txt`文件添加必要的信息，自动生成消息文件。\n\n- 通过设置`CMakeList.txt`文件在编译过程中自动生成，生成的`.msg`消息文件会自动放在 `工作空间/devel/share/程序包名/msg/` 路径下；\n- 使用`generation.py`脚本手动生成，生成的`.msg`消息文件可以自定义放置的目录，例如可以放在`工作空间/src/程序包名/msg/` 路径下，这时可以在当前程序包下执行命令`rosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action`。\n\n## 手动生成\n\n```shell\nroscd actionlib_tutorials\nrosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action\n```\n\n`genaction.py`文件位于`/opt/ros/kinetic/lib/actionlib_msgs/`目录下。\n\n会出现如下提示信息：\n\n```shell\nGenerating for action Fibonacci\n```\n\n## 自动生成\n\n在编译过程中自动生成消息需要添加一些内容到`CMakeList.txt`文件。\n\n```cmake\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n```\n\n运行：\n\n```shell\ncatkin_make #　工作空间下运行\n```\n\n使用如下命令就可以看到自动生成的`.msg`和`.h`文件：\n\n```shell\nls devel/share/actionlib_tutorials/msg/\nls devel/include/actionlib_tutorials/\n```\n\n# 创建行为服务器\n\n创建文件`actionlib_tutorials/src/fibonacci_server.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <actionlib/server/simple_action_server.h>\n#include <actionlib_tutorials/FibonacciAction.h>\n\nclass FibonacciAction\n{\nprotected:\n\n  ros::NodeHandle nh_;//　将会传递到行为服务器中\n  actionlib::SimpleActionServer<actionlib_tutorials::FibonacciAction> as_; // NodeHandle instance must be created before this line. Otherwise strange error occurs.\n  std::string action_name_;\n  // create messages that are used to published feedback/result\n  actionlib_tutorials::FibonacciFeedback feedback_;//　反馈消息\n  actionlib_tutorials::FibonacciResult result_;//　结果消息\n\npublic:\n  FibonacciAction(std::string name) :\n    as_(nh_, name, boost::bind(&FibonacciAction::executeCB, this, _1), false),\n    action_name_(name)\n  {\n    as_.start();\n  }//　行为构造函数构造行为服务器as_,它会得到一个节点句柄（node handle）、行为名称和选择一个运行回调函数（executeCB）参数。\n\n  ~FibonacciAction(void)\n  {\n  }\n  void executeCB(const actionlib_tutorials::FibonacciGoalConstPtr &goal)//　传递一个指向目标消息的指针，它是一个boost共享指针\n  {\n    // helper variables\n    ros::Rate r(1);\n    bool success = true;\n\n    // push_back the seeds for the fibonacci sequence\n    feedback_.sequence.clear();\n    feedback_.sequence.push_back(0);\n    feedback_.sequence.push_back(1);\n\n    // publish info to the console for the user\n    ROS_INFO(\"%s: Executing, creating fibonacci sequence of order %i with seeds %i, %i\", action_name_.c_str(), goal->order, feedback_.sequence[0], feedback_.sequence[1]);\n\n    // 开始执行行为服务器\n    for(int i=1; i<=goal->order; i++)\n    {\n      // 检测一个客户端请求是否抢占当前目标。体现行为服务器的一个重要组成部分：允许行为客户端请求取消当前目标执行\n      if (as_.isPreemptRequested() || !ros::ok())\n      {\n        ROS_INFO(\"%s: Preempted\", action_name_.c_str());\n        // set the action state to preempted\n        as_.setPreempted();//发出该行为已经被用户请求抢占信号\n        success = false;\n        break;\n      }\n      feedback_.sequence.push_back(feedback_.sequence[i] + feedback_.sequence[i-1]);//设置检查抢占请求服务器的等级到服务器系统\n      // 发布反馈：Fibonacci序列赋值给feedback变量，然后通过行为服务器提供的反馈频道发布出去\n      as_.publishFeedback(feedback_);\n      // this sleep is not necessary, the sequence is computed at 1 Hz for demonstration purposes\n      r.sleep();\n    }\n\n    if(success)\n    {\n      result_.sequence = feedback_.sequence;\n      ROS_INFO(\"%s: Succeeded\", action_name_.c_str());\n      // set the action state to succeeded\n      as_.setSucceeded(result_);//　一旦行为完成计算Fibonacci序列，通知行为客户端操作设置成功\n    }\n  }\n};\n\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"fibonacci\");\n\n  FibonacciAction fibonacci(\"fibonacci\");//创建行为\n  ros::spin();//spin节点，行为会运行并等待接收目标\n\n  return 0;\n}\n```\n\n# 创建行为客户端\n\n创建行为客户端文件`actionlib_tutorials/src/fibonacci_client.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <actionlib/client/simple_action_client.h>\n#include <actionlib/client/terminal_state.h>\n#include <actionlib_tutorials/FibonacciAction.h>\n\nint main (int argc, char **argv)\n{\n  ros::init(argc, argv, \"test_fibonacci\");\n\n  // 创建行为客户端\n  // 成功会开启客户端创建自己的线程\n  actionlib::SimpleActionClient<actionlib_tutorials::FibonacciAction> ac(\"fibonacci\", true);\n\n  ROS_INFO(\"Waiting for action server to start.\");\n  //等待行为服务器开启\n  ac.waitForServer(); //will wait for infinite time\n\n  ROS_INFO(\"Action server started, sending goal.\");\n  // 发送目标到行为服务器\n  actionlib_tutorials::FibonacciGoal goal;\n  goal.order = 20;\n  ac.sendGoal(goal);\n\n  //等待行为返回\n  bool finished_before_timeout = ac.waitForResult(ros::Duration(30.0));\n\n  if (finished_before_timeout)\n  {\n    actionlib::SimpleClientGoalState state = ac.getState();\n    ROS_INFO(\"Action finished: %s\",state.toString().c_str());\n  }\n  else\n    ROS_INFO(\"Action did not finish before the time out.\");\n\n  //exit\n  return 0;\n}\n```\n\n# 编译行为\n\n在`CMakeLists.txt`文件末尾添加以下几行： \n\n```cmake\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries(fibonacci_client ${catkin_LIBRARIES})\n```\n\n完整的`CMakeList.txt`文件如下：\n\n~~~cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(actionlib_tutorials)\n\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n\ninclude_directories(include ${catkin_INCLUDE_DIRS} ${Boost_INCLUDE_DIRS})\n\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server  ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries( fibonacci_client  ${catkin_LIBRARIES})\n~~~\n\n工作空间下执行`catkin_make`命令。\n\n其实还需要在`package.xml`中添加如下信息，只不过在最开始创建程序包的时候`catkin_create_pkg`命令添加了对`actionlib`和`actionlib_msgs`的依赖，生成的程序包文件`package.xml`中已经自动添加了这些信息，不需要手动添加了。完美～\n\n~~~xml\n  <build_depend>actionlib</build_depend>\n  <build_depend>actionlib_msgs</build_depend>\n  <build_export_depend>actionlib</build_export_depend>\n  <build_export_depend>actionlib_msgs</build_export_depend>\n  <exec_depend>actionlib</exec_depend>\n  <exec_depend>actionlib_msgs</exec_depend>\n~~~\n\n# 运行行为－连接服务器和客户端\n\n1. 终端启动ROS：\n\n```shell\nroscore\n```\n\n2. 查看行为反馈：\n\n```shell\nrostopic echo /fibonacci/feedback\n```\n\n会有一系列的输出信息，最后的一条信息为：\n\n~~~shell\n---\nheader: \n  seq: 19\n  stamp: \n    secs: 1522552545\n    nsecs: 242077849\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522552526\n      nsecs: 241284287\n    id: \"/test_fibonacci-1-1522552526.241284287\"\n  status: 1\n  text: \"This goal has been accepted by the simple action server\"\nfeedback: \n  sequence: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946]\n~~~\n\n3. 查看行为结果：\n\n```shell\nrostopic echo /fibonacci/result\n```\n\n执行完成输出信息：\n\n~~~shell\neric@eric:~$ rostopic echo /fibonacci/result\nWARNING: topic [/fibonacci/result] does not appear to be published yet\nheader: \n  seq: 0\n  stamp: \n    secs: 1522552546\n    nsecs: 242312501\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522552526\n      nsecs: 241284287\n    id: \"/test_fibonacci-1-1522552526.241284287\"\n  status: 3\n  text: ''\nresult: \n  sequence: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946]\n---\n~~~\n\n4. 运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials fibonacci_client \n```\n执行完成的输出信息：\n\n~~~shell\neric@eric:~$ rosrun actionlib_tutorials fibonacci_client\n[ INFO] [1522552522.129016184]: Waiting for action server to start.\n[ INFO] [1522552526.241189187]: Action server started, sending goal.\n[ INFO] [1522552546.242949052]: Action finished: SUCCEEDED\n~~~\n\n5. 运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials fibonacci_server\n```\n\n执行完成的输出信息：\n\n~~~shell\neric@eric:~rosrun actionlib_tutorials fibonacci_server\n[ INFO] [1522552526.242112000]: fibonacci: Executing, creating fibonacci sequence of order 20 with seeds 0, 1\n[ INFO] [1522552546.242205514]: fibonacci: Succeeded\n~~~\n\n6. 查看发布的话题列表（检查行为运行是否正常）：\n\n~~~shell\nrostopic list -v\n~~~\n\n得到如下信息：\n\n~~~shell\neric@eric:~$ rostopic list -v\n\nPublished topics:\n * /turtle1/color_sensor [turtlesim/Color] 1 publisher\n * /fibonacci/feedback [actionlib_tutorials/FibonacciActionFeedback] 1 publisher\n * /fibonacci/cancel [actionlib_msgs/GoalID] 1 publisher\n * /rosout [rosgraph_msgs/Log] 5 publishers\n * /fibonacci/goal [actionlib_tutorials/FibonacciActionGoal] 1 publisher\n * /rosout_agg [rosgraph_msgs/Log] 1 publisher\n * /fibonacci/status [actionlib_msgs/GoalStatusArray] 1 publisher\n * /fibonacci/result [actionlib_tutorials/FibonacciActionResult] 1 publisher\n * /turtle1/pose [turtlesim/Pose] 1 publisher\n\nSubscribed topics:\n * /fibonacci/feedback [actionlib_tutorials/FibonacciActionFeedback] 2 subscribers\n * /rosout [rosgraph_msgs/Log] 1 subscriber\n * /fibonacci/cancel [actionlib_msgs/GoalID] 1 subscriber\n * /fibonacci/goal [actionlib_tutorials/FibonacciActionGoal] 1 subscriber\n * /fibonacci/status [actionlib_msgs/GoalStatusArray] 1 subscriber\n * /fibonacci/result [actionlib_tutorials/FibonacciActionResult] 2 subscribers\n * /turtle1/cmd_vel [geometry_msgs/Twist] 1 subscriber\n~~~\n\n7. 查看行为节点图：\n\n~~~shell\nrqt_graph\n~~~\n显式如下节点图：\n\n{% asset_img 节点图.png  %}","slug":"ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器","published":1,"updated":"2019-05-30T12:29:26.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbzg00brqlcrtafj6pf7","content":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"创建行为消息\"><a href=\"#创建行为消息\" class=\"headerlink\" title=\"创建行为消息\"></a>创建行为消息</h1><p>行为消息自动从<code>.action</code>文件生成，该文件放置在程序包的<code>action</code>目录下，它定义行为消息的目标、结果和行为反馈话题的类型和格式。下面是一个例子。</p>\n<p>在程序包中创建文件<code>actionlib_tutorials/action/Fibonacci.action</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#goal definition</span><br><span class=\"line\">int32 order</span><br><span class=\"line\">---</span><br><span class=\"line\">#result definition</span><br><span class=\"line\">int32[] sequence</span><br><span class=\"line\">---</span><br><span class=\"line\">#feedback</span><br><span class=\"line\">int32[] sequence</span><br></pre></td></tr></table></figure>\n<h1 id=\"生成消息文件\"><a href=\"#生成消息文件\" class=\"headerlink\" title=\"生成消息文件\"></a>生成消息文件</h1><p>使用编辑好的<code>.action</code>文件生成<code>.msg</code>消息文件，有两种方式，笔者认为手动生成方式其实不是必须的，只是提供了一种生成消息文件的方式而已，一般实践过程中只需要在<code>CMakeList.txt</code>文件添加必要的信息，自动生成消息文件。</p>\n<ul>\n<li>通过设置<code>CMakeList.txt</code>文件在编译过程中自动生成，生成的<code>.msg</code>消息文件会自动放在 <code>工作空间/devel/share/程序包名/msg/</code> 路径下；</li>\n<li>使用<code>generation.py</code>脚本手动生成，生成的<code>.msg</code>消息文件可以自定义放置的目录，例如可以放在<code>工作空间/src/程序包名/msg/</code> 路径下，这时可以在当前程序包下执行命令<code>rosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action</code>。</li>\n</ul>\n<h2 id=\"手动生成\"><a href=\"#手动生成\" class=\"headerlink\" title=\"手动生成\"></a>手动生成</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscd actionlib_tutorials</span><br><span class=\"line\">rosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action</span><br></pre></td></tr></table></figure>\n<p><code>genaction.py</code>文件位于<code>/opt/ros/kinetic/lib/actionlib_msgs/</code>目录下。</p>\n<p>会出现如下提示信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Generating for action Fibonacci</span><br></pre></td></tr></table></figure>\n<h2 id=\"自动生成\"><a href=\"#自动生成\" class=\"headerlink\" title=\"自动生成\"></a>自动生成</h2><p>在编译过程中自动生成消息需要添加一些内容到<code>CMakeList.txt</code>文件。</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  actionlib</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  message_generation</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_action_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  Fibonacci.action</span><br><span class=\"line\">  DoDishes.action</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>运行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_make #　工作空间下运行</span><br></pre></td></tr></table></figure>\n<p>使用如下命令就可以看到自动生成的<code>.msg</code>和<code>.h</code>文件：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls devel/share/actionlib_tutorials/msg/</span><br><span class=\"line\">ls devel/include/actionlib_tutorials/</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建行为服务器\"><a href=\"#创建行为服务器\" class=\"headerlink\" title=\"创建行为服务器\"></a>创建行为服务器</h1><p>创建文件<code>actionlib_tutorials/src/fibonacci_server.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/server/simple_action_server.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib_tutorials/FibonacciAction.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FibonacciAction</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle nh_;<span class=\"comment\">//　将会传递到行为服务器中</span></span><br><span class=\"line\">  actionlib::SimpleActionServer&lt;actionlib_tutorials::FibonacciAction&gt; as_; <span class=\"comment\">// NodeHandle instance must be created before this line. Otherwise strange error occurs.</span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> action_name_;</span><br><span class=\"line\">  <span class=\"comment\">// create messages that are used to published feedback/result</span></span><br><span class=\"line\">  actionlib_tutorials::FibonacciFeedback feedback_;<span class=\"comment\">//　反馈消息</span></span><br><span class=\"line\">  actionlib_tutorials::FibonacciResult result_;<span class=\"comment\">//　结果消息</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  FibonacciAction(<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> name) :</span><br><span class=\"line\">    as_(nh_, name, boost::bind(&amp;FibonacciAction::executeCB, <span class=\"keyword\">this</span>, _1), <span class=\"literal\">false</span>),</span><br><span class=\"line\">    action_name_(name)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    as_.start();</span><br><span class=\"line\">  &#125;<span class=\"comment\">//　行为构造函数构造行为服务器as_,它会得到一个节点句柄（node handle）、行为名称和选择一个运行回调函数（executeCB）参数。</span></span><br><span class=\"line\"></span><br><span class=\"line\">  ~FibonacciAction(<span class=\"keyword\">void</span>)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">executeCB</span><span class=\"params\">(<span class=\"keyword\">const</span> actionlib_tutorials::FibonacciGoalConstPtr &amp;goal)</span><span class=\"comment\">//　传递一个指向目标消息的指针，它是一个boost共享指针</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// helper variables</span></span><br><span class=\"line\">    ros::<span class=\"function\">Rate <span class=\"title\">r</span><span class=\"params\">(<span class=\"number\">1</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"keyword\">bool</span> success = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// push_back the seeds for the fibonacci sequence</span></span><br><span class=\"line\">    feedback_.sequence.clear();</span><br><span class=\"line\">    feedback_.sequence.push_back(<span class=\"number\">0</span>);</span><br><span class=\"line\">    feedback_.sequence.push_back(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// publish info to the console for the user</span></span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"%s: Executing, creating fibonacci sequence of order %i with seeds %i, %i\"</span>, action_name_.c_str(), goal-&gt;order, feedback_.sequence[<span class=\"number\">0</span>], feedback_.sequence[<span class=\"number\">1</span>]);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 开始执行行为服务器</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=goal-&gt;order; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"comment\">// 检测一个客户端请求是否抢占当前目标。体现行为服务器的一个重要组成部分：允许行为客户端请求取消当前目标执行</span></span><br><span class=\"line\">      <span class=\"keyword\">if</span> (as_.isPreemptRequested() || !ros::ok())</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        ROS_INFO(<span class=\"string\">\"%s: Preempted\"</span>, action_name_.c_str());</span><br><span class=\"line\">        <span class=\"comment\">// set the action state to preempted</span></span><br><span class=\"line\">        as_.setPreempted();<span class=\"comment\">//发出该行为已经被用户请求抢占信号</span></span><br><span class=\"line\">        success = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      feedback_.sequence.push_back(feedback_.sequence[i] + feedback_.sequence[i<span class=\"number\">-1</span>]);<span class=\"comment\">//设置检查抢占请求服务器的等级到服务器系统</span></span><br><span class=\"line\">      <span class=\"comment\">// 发布反馈：Fibonacci序列赋值给feedback变量，然后通过行为服务器提供的反馈频道发布出去</span></span><br><span class=\"line\">      as_.publishFeedback(feedback_);</span><br><span class=\"line\">      <span class=\"comment\">// this sleep is not necessary, the sequence is computed at 1 Hz for demonstration purposes</span></span><br><span class=\"line\">      r.sleep();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(success)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      result_.sequence = feedback_.sequence;</span><br><span class=\"line\">      ROS_INFO(<span class=\"string\">\"%s: Succeeded\"</span>, action_name_.c_str());</span><br><span class=\"line\">      <span class=\"comment\">// set the action state to succeeded</span></span><br><span class=\"line\">      as_.setSucceeded(result_);<span class=\"comment\">//　一旦行为完成计算Fibonacci序列，通知行为客户端操作设置成功</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"fibonacci\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\">FibonacciAction <span class=\"title\">fibonacci</span><span class=\"params\">(<span class=\"string\">\"fibonacci\"</span>)</span></span>;<span class=\"comment\">//创建行为</span></span><br><span class=\"line\">  ros::spin();<span class=\"comment\">//spin节点，行为会运行并等待接收目标</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建行为客户端\"><a href=\"#创建行为客户端\" class=\"headerlink\" title=\"创建行为客户端\"></a>创建行为客户端</h1><p>创建行为客户端文件<code>actionlib_tutorials/src/fibonacci_client.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/simple_action_client.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/terminal_state.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib_tutorials/FibonacciAction.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"test_fibonacci\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 创建行为客户端</span></span><br><span class=\"line\">  <span class=\"comment\">// 成功会开启客户端创建自己的线程</span></span><br><span class=\"line\">  actionlib::SimpleActionClient&lt;actionlib_tutorials::FibonacciAction&gt; ac(<span class=\"string\">\"fibonacci\"</span>, <span class=\"literal\">true</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Waiting for action server to start.\"</span>);</span><br><span class=\"line\">  <span class=\"comment\">//等待行为服务器开启</span></span><br><span class=\"line\">  ac.waitForServer(); <span class=\"comment\">//will wait for infinite time</span></span><br><span class=\"line\"></span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Action server started, sending goal.\"</span>);</span><br><span class=\"line\">  <span class=\"comment\">// 发送目标到行为服务器</span></span><br><span class=\"line\">  actionlib_tutorials::FibonacciGoal goal;</span><br><span class=\"line\">  goal.order = <span class=\"number\">20</span>;</span><br><span class=\"line\">  ac.sendGoal(goal);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//等待行为返回</span></span><br><span class=\"line\">  <span class=\"keyword\">bool</span> finished_before_timeout = ac.waitForResult(ros::Duration(<span class=\"number\">30.0</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (finished_before_timeout)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    actionlib::SimpleClientGoalState state = ac.getState();</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Action finished: %s\"</span>,state.toString().c_str());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">else</span></span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Action did not finish before the time out.\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//exit</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"编译行为\"><a href=\"#编译行为\" class=\"headerlink\" title=\"编译行为\"></a>编译行为</h1><p>在<code>CMakeLists.txt</code>文件末尾添加以下几行： </p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_server src/fibonacci_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(fibonacci_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_client src/fibonacci_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(fibonacci_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>完整的<code>CMakeList.txt</code>文件如下：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.8</span>.<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(actionlib_tutorials)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  actionlib</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  message_generation</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_action_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  Fibonacci.action</span><br><span class=\"line\">  DoDishes.action</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"keyword\">include</span> <span class=\"variable\">$&#123;catkin_INCLUDE_DIRS&#125;</span> <span class=\"variable\">$&#123;Boost_INCLUDE_DIRS&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_server src/fibonacci_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(fibonacci_server  <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_client src/fibonacci_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>( fibonacci_client  <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>工作空间下执行<code>catkin_make</code>命令。</p>\n<p>其实还需要在<code>package.xml</code>中添加如下信息，只不过在最开始创建程序包的时候<code>catkin_create_pkg</code>命令添加了对<code>actionlib</code>和<code>actionlib_msgs</code>的依赖，生成的程序包文件<code>package.xml</code>中已经自动添加了这些信息，不需要手动添加了。完美～</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>actionlib<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>actionlib_msgs<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_export_depend</span>&gt;</span>actionlib<span class=\"tag\">&lt;/<span class=\"name\">build_export_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_export_depend</span>&gt;</span>actionlib_msgs<span class=\"tag\">&lt;/<span class=\"name\">build_export_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">exec_depend</span>&gt;</span>actionlib<span class=\"tag\">&lt;/<span class=\"name\">exec_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">exec_depend</span>&gt;</span>actionlib_msgs<span class=\"tag\">&lt;/<span class=\"name\">exec_depend</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"运行行为－连接服务器和客户端\"><a href=\"#运行行为－连接服务器和客户端\" class=\"headerlink\" title=\"运行行为－连接服务器和客户端\"></a>运行行为－连接服务器和客户端</h1><ol>\n<li>终端启动ROS：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscore</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看行为反馈：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic echo /fibonacci/feedback</span><br></pre></td></tr></table></figure>\n<p>会有一系列的输出信息，最后的一条信息为：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">header: </span><br><span class=\"line\">  seq: 19</span><br><span class=\"line\">  stamp: </span><br><span class=\"line\">    secs: 1522552545</span><br><span class=\"line\">    nsecs: 242077849</span><br><span class=\"line\">  frame_id: ''</span><br><span class=\"line\">status: </span><br><span class=\"line\">  goal_id: </span><br><span class=\"line\">    stamp: </span><br><span class=\"line\">      secs: 1522552526</span><br><span class=\"line\">      nsecs: 241284287</span><br><span class=\"line\">    id: \"/test_fibonacci-1-1522552526.241284287\"</span><br><span class=\"line\">  status: 1</span><br><span class=\"line\">  text: \"This goal has been accepted by the simple action server\"</span><br><span class=\"line\">feedback: </span><br><span class=\"line\">  sequence: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946]</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看行为结果：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic echo /fibonacci/result</span><br></pre></td></tr></table></figure>\n<p>执行完成输出信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~$ rostopic echo /fibonacci/result</span><br><span class=\"line\">WARNING: topic [/fibonacci/result] does not appear to be published yet</span><br><span class=\"line\">header: </span><br><span class=\"line\">  seq: 0</span><br><span class=\"line\">  stamp: </span><br><span class=\"line\">    secs: 1522552546</span><br><span class=\"line\">    nsecs: 242312501</span><br><span class=\"line\">  frame_id: ''</span><br><span class=\"line\">status: </span><br><span class=\"line\">  goal_id: </span><br><span class=\"line\">    stamp: </span><br><span class=\"line\">      secs: 1522552526</span><br><span class=\"line\">      nsecs: 241284287</span><br><span class=\"line\">    id: \"/test_fibonacci-1-1522552526.241284287\"</span><br><span class=\"line\">  status: 3</span><br><span class=\"line\">  text: ''</span><br><span class=\"line\">result: </span><br><span class=\"line\">  sequence: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946]</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<ol>\n<li>运行行为客户端：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials fibonacci_client</span><br></pre></td></tr></table></figure>\n<p>执行完成的输出信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~$ rosrun actionlib_tutorials fibonacci_client</span><br><span class=\"line\">[ INFO] [1522552522.129016184]: Waiting for action server to start.</span><br><span class=\"line\">[ INFO] [1522552526.241189187]: Action server started, sending goal.</span><br><span class=\"line\">[ INFO] [1522552546.242949052]: Action finished: SUCCEEDED</span><br></pre></td></tr></table></figure>\n<ol>\n<li>运行行为服务器：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials fibonacci_server</span><br></pre></td></tr></table></figure>\n<p>执行完成的输出信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~rosrun actionlib_tutorials fibonacci_server</span><br><span class=\"line\">[ INFO] [1522552526.242112000]: fibonacci: Executing, creating fibonacci sequence of order 20 with seeds 0, 1</span><br><span class=\"line\">[ INFO] [1522552546.242205514]: fibonacci: Succeeded</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看发布的话题列表（检查行为运行是否正常）：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic list -v</span><br></pre></td></tr></table></figure>\n<p>得到如下信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~$ rostopic list -v</span><br><span class=\"line\"></span><br><span class=\"line\">Published topics:</span><br><span class=\"line\"> * /turtle1/color_sensor [turtlesim/Color] 1 publisher</span><br><span class=\"line\"> * /fibonacci/feedback [actionlib_tutorials/FibonacciActionFeedback] 1 publisher</span><br><span class=\"line\"> * /fibonacci/cancel [actionlib_msgs/GoalID] 1 publisher</span><br><span class=\"line\"> * /rosout [rosgraph_msgs/Log] 5 publishers</span><br><span class=\"line\"> * /fibonacci/goal [actionlib_tutorials/FibonacciActionGoal] 1 publisher</span><br><span class=\"line\"> * /rosout_agg [rosgraph_msgs/Log] 1 publisher</span><br><span class=\"line\"> * /fibonacci/status [actionlib_msgs/GoalStatusArray] 1 publisher</span><br><span class=\"line\"> * /fibonacci/result [actionlib_tutorials/FibonacciActionResult] 1 publisher</span><br><span class=\"line\"> * /turtle1/pose [turtlesim/Pose] 1 publisher</span><br><span class=\"line\"></span><br><span class=\"line\">Subscribed topics:</span><br><span class=\"line\"> * /fibonacci/feedback [actionlib_tutorials/FibonacciActionFeedback] 2 subscribers</span><br><span class=\"line\"> * /rosout [rosgraph_msgs/Log] 1 subscriber</span><br><span class=\"line\"> * /fibonacci/cancel [actionlib_msgs/GoalID] 1 subscriber</span><br><span class=\"line\"> * /fibonacci/goal [actionlib_tutorials/FibonacciActionGoal] 1 subscriber</span><br><span class=\"line\"> * /fibonacci/status [actionlib_msgs/GoalStatusArray] 1 subscriber</span><br><span class=\"line\"> * /fibonacci/result [actionlib_tutorials/FibonacciActionResult] 2 subscribers</span><br><span class=\"line\"> * /turtle1/cmd_vel [geometry_msgs/Twist] 1 subscriber</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看行为节点图：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rqt_graph</span><br></pre></td></tr></table></figure>\n<p>显式如下节点图：</p>\n<img src=\"/2018/03/30/ROS学习之actionlib库（２）-使用Execute%20Callback编写一个简单的行为服务器/节点图.png\">","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>","more":"<h1 id=\"创建行为消息\"><a href=\"#创建行为消息\" class=\"headerlink\" title=\"创建行为消息\"></a>创建行为消息</h1><p>行为消息自动从<code>.action</code>文件生成，该文件放置在程序包的<code>action</code>目录下，它定义行为消息的目标、结果和行为反馈话题的类型和格式。下面是一个例子。</p>\n<p>在程序包中创建文件<code>actionlib_tutorials/action/Fibonacci.action</code>：</p>\n<!--�192-->\n<h1 id=\"生成消息文件\"><a href=\"#生成消息文件\" class=\"headerlink\" title=\"生成消息文件\"></a>生成消息文件</h1><p>使用编辑好的<code>.action</code>文件生成<code>.msg</code>消息文件，有两种方式，笔者认为手动生成方式其实不是必须的，只是提供了一种生成消息文件的方式而已，一般实践过程中只需要在<code>CMakeList.txt</code>文件添加必要的信息，自动生成消息文件。</p>\n<ul>\n<li>通过设置<code>CMakeList.txt</code>文件在编译过程中自动生成，生成的<code>.msg</code>消息文件会自动放在 <code>工作空间/devel/share/程序包名/msg/</code> 路径下；</li>\n<li>使用<code>generation.py</code>脚本手动生成，生成的<code>.msg</code>消息文件可以自定义放置的目录，例如可以放在<code>工作空间/src/程序包名/msg/</code> 路径下，这时可以在当前程序包下执行命令<code>rosrun actionlib_msgs genaction.py -o msg/ action/Fibonacci.action</code>。</li>\n</ul>\n<h2 id=\"手动生成\"><a href=\"#手动生成\" class=\"headerlink\" title=\"手动生成\"></a>手动生成</h2><!--�193-->\n<p><code>genaction.py</code>文件位于<code>/opt/ros/kinetic/lib/actionlib_msgs/</code>目录下。</p>\n<p>会出现如下提示信息：</p>\n<!--�194-->\n<h2 id=\"自动生成\"><a href=\"#自动生成\" class=\"headerlink\" title=\"自动生成\"></a>自动生成</h2><p>在编译过程中自动生成消息需要添加一些内容到<code>CMakeList.txt</code>文件。</p>\n<!--�195-->\n<p>运行：</p>\n<!--�196-->\n<p>使用如下命令就可以看到自动生成的<code>.msg</code>和<code>.h</code>文件：</p>\n<!--�197-->\n<h1 id=\"创建行为服务器\"><a href=\"#创建行为服务器\" class=\"headerlink\" title=\"创建行为服务器\"></a>创建行为服务器</h1><p>创建文件<code>actionlib_tutorials/src/fibonacci_server.cpp</code>：</p>\n<!--�198-->\n<h1 id=\"创建行为客户端\"><a href=\"#创建行为客户端\" class=\"headerlink\" title=\"创建行为客户端\"></a>创建行为客户端</h1><p>创建行为客户端文件<code>actionlib_tutorials/src/fibonacci_client.cpp</code>：</p>\n<!--�199-->\n<h1 id=\"编译行为\"><a href=\"#编译行为\" class=\"headerlink\" title=\"编译行为\"></a>编译行为</h1><p>在<code>CMakeLists.txt</code>文件末尾添加以下几行： </p>\n<!--�200-->\n<p>完整的<code>CMakeList.txt</code>文件如下：</p>\n<!--�201-->\n<p>工作空间下执行<code>catkin_make</code>命令。</p>\n<p>其实还需要在<code>package.xml</code>中添加如下信息，只不过在最开始创建程序包的时候<code>catkin_create_pkg</code>命令添加了对<code>actionlib</code>和<code>actionlib_msgs</code>的依赖，生成的程序包文件<code>package.xml</code>中已经自动添加了这些信息，不需要手动添加了。完美～</p>\n<!--�202-->\n<h1 id=\"运行行为－连接服务器和客户端\"><a href=\"#运行行为－连接服务器和客户端\" class=\"headerlink\" title=\"运行行为－连接服务器和客户端\"></a>运行行为－连接服务器和客户端</h1><ol>\n<li>终端启动ROS：</li>\n</ol>\n<!--�203-->\n<ol>\n<li>查看行为反馈：</li>\n</ol>\n<!--�204-->\n<p>会有一系列的输出信息，最后的一条信息为：</p>\n<!--�205-->\n<ol>\n<li>查看行为结果：</li>\n</ol>\n<!--�206-->\n<p>执行完成输出信息：</p>\n<!--�207-->\n<ol>\n<li>运行行为客户端：</li>\n</ol>\n<!--�208-->\n<p>执行完成的输出信息：</p>\n<!--�209-->\n<ol>\n<li>运行行为服务器：</li>\n</ol>\n<!--�210-->\n<p>执行完成的输出信息：</p>\n<!--�211-->\n<ol>\n<li>查看发布的话题列表（检查行为运行是否正常）：</li>\n</ol>\n<!--�212-->\n<p>得到如下信息：</p>\n<!--�213-->\n<ol>\n<li>查看行为节点图：</li>\n</ol>\n<!--�214-->\n<p>显式如下节点图：</p>\n<img src=\"/2018/03/30/ROS学习之actionlib库（２）-使用Execute%20Callback编写一个简单的行为服务器/节点图.png\">"},{"title":"ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器","date":"2018-03-30T11:06:02.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more-->\n\n这一节接着上一节的内容，默认已经创建好程序包（和上一节公用一个程序包，即`actionlib_tutorials`），这里将讲述如何使用目标回调方法(Goal Callback Method)编写一个简单的行为服务器。\n\n# 创建行为消息\n\n在程序包中创建文件`actionlib_tutorials/action/Averaging.action`：\n\n~~~\n#goal definition\nint32 samples\n---\n#result definition\nfloat32 mean\nfloat32 std_dev\n---\n#feedback\nint32 sample\nfloat32 data\nfloat32 mean\nfloat32 std_dev\n~~~\n\n<!--more--->\n\n# 生成消息文件\n\n添加一些内容到`CMakeList.txt`文件：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  Averaging.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n~~~\n\n运行：\n\n~~~shell\ncatkin_make #　工作空间下运行\n~~~\n\n# 创建行为服务器\n\n创建文件`actionlib_tutorials/src/averaging_server.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <std_msgs/Float32.h>\n// 行为库\n#include <actionlib/server/simple_action_server.h>\n// 包含从Averaging.action文件中生成的消息\n#include <actionlib_tutorials/AveragingAction.h>\n\nclass AveragingAction\n{\npublic:\n    \n  AveragingAction(std::string name) : \n    as_(nh_, name, false),\n    action_name_(name)\n  {\n    //注册目标和反馈回调函数\n    as_.registerGoalCallback(boost::bind(&AveragingAction::goalCB, this));\n    as_.registerPreemptCallback(boost::bind(&AveragingAction::preemptCB, this));\n\n    //订阅感兴趣的话题数据 建立一个数据回调，该回调会处理行为\n    sub_ = nh_.subscribe(\"/random_number\", 1, &AveragingAction::analysisCB, this);\n    as_.start();//行为服务器开启\n  }\n\n  ~AveragingAction(void)\n  {\n  }\n\n  void goalCB()\n  {\n    // 重置帮助变量\n    data_count_ = 0;\n    sum_ = 0;\n    sum_sq_ = 0;\n    // 接收新目标\n    goal_ = as_.acceptNewGoal()->samples;\n  }\n\n  void preemptCB()\n  {\n    ROS_INFO(\"%s: Preempted\", action_name_.c_str());\n    // 设置行为状态为抢占(preempted)\n    as_.setPreempted();\n  }\n\n  void analysisCB(const std_msgs::Float32::ConstPtr& msg)\n  {\n    // 确保行为还没有被取消\n    if (!as_.isActive())\n      return;\n    \n    data_count_++;\n    feedback_.sample = data_count_;\n    feedback_.data = msg->data;\n    //处理std_dev和数据含义 \n    sum_ += msg->data;\n    feedback_.mean = sum_ / data_count_;\n    sum_sq_ += pow(msg->data, 2);\n    feedback_.std_dev = sqrt(fabs((sum_sq_/data_count_) - pow(feedback_.mean, 2)));\n    as_.publishFeedback(feedback_);\n\n    if(data_count_ > goal_) \n    {\n      result_.mean = feedback_.mean;\n      result_.std_dev = feedback_.std_dev;\n\n      if(result_.mean < 5.0)\n      {\n        ROS_INFO(\"%s: Aborted\", action_name_.c_str());\n        //设置行为状态为崩溃(aborted)\n        as_.setAborted(result_);\n      }\n      else \n      {\n        ROS_INFO(\"%s: Succeeded\", action_name_.c_str());\n        // 设置行为状态为成功(succeeded)\n        as_.setSucceeded(result_);\n      }\n    } \n  }\n\nprotected:\n    \n  ros::NodeHandle nh_;\n  actionlib::SimpleActionServer<actionlib_tutorials::AveragingAction> as_;\n  std::string action_name_;\n  int data_count_, goal_;\n  float sum_, sum_sq_;\n  actionlib_tutorials::AveragingFeedback feedback_;\n  actionlib_tutorials::AveragingResult result_;\n  ros::Subscriber sub_;\n};\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"averaging\");\n\n  AveragingAction averaging(ros::this_node::getName());\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n# 创建行为客户端\n\n创建行为客户端文件`actionlib_tutorials/src/averaging_client.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <actionlib/client/simple_action_client.h>\n#include <actionlib/client/terminal_state.h>\n#include <actionlib_tutorials/AveragingAction.h>\n#include <boost/thread.hpp>\n\nvoid spinThread()\n{\n  ros::spin();\n}\n\nint main (int argc, char **argv)\n{\n  ros::init(argc, argv, \"test_averaging\");\n\n  // 创建一个行为客户端\n  actionlib::SimpleActionClient<actionlib_tutorials::AveragingAction> ac(\"averaging\");\n  boost::thread spin_thread(&spinThread);\n\n  ROS_INFO(\"Waiting for action server to start.\");\n  ac.waitForServer();\n\n  ROS_INFO(\"Action server started, sending goal.\");\n  // 发送目标到行为\n  actionlib_tutorials::AveragingGoal goal;\n  goal.samples = 100;\n  ac.sendGoal(goal);\n\n  //等待行为返回\n  bool finished_before_timeout = ac.waitForResult(ros::Duration(30.0));\n\n  if (finished_before_timeout)\n  {\n    actionlib::SimpleClientGoalState state = ac.getState();\n    ROS_INFO(\"Action finished: %s\",state.toString().c_str());\n  }\n  else\n    ROS_INFO(\"Action did not finish before the time out.\");\n\n  // 关闭节点，在退出前加入线程\n  ros::shutdown();\n  spin_thread.join();\n\n  //exit\n  return 0;\n}\n~~~\n\n# 编译行为\n\n在`CMakeLists.txt`文件末尾添加以下几行： \n\n~~~cmake\nadd_executable(averaging_server src/averaging_server.cpp)\ntarget_link_libraries(averaging_server ${catkin_LIBRARIES})\n\nadd_executable(averaging_client src/averaging_client.cpp)\ntarget_link_libraries(averaging_client ${catkin_LIBRARIES})\n~~~\n\n完整的`CMakeList.txt`文件如下：\n\n```cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(actionlib_tutorials)\n\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  Averaging.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n\ninclude_directories(include ${catkin_INCLUDE_DIRS} ${Boost_INCLUDE_DIRS})\n\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server  ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries( fibonacci_client  ${catkin_LIBRARIES})\n\nadd_executable(averaging_server src/averaging_server.cpp)\ntarget_link_libraries(averaging_server ${catkin_LIBRARIES})\n\nadd_executable(averaging_client src/averaging_client.cpp)\ntarget_link_libraries(averaging_client ${catkin_LIBRARIES})\n```\n\n工作空间下执行`catkin_make`命令。\n\n# 运行行为－使用其他节点连接服务器和客户端\n\n## 编写数据节点\n\n创建文件`actionlib_tutorials/scripts/gen_numbers.py`：\n\n~~~python\n#!/usr/bin/env python\n\nimport rospy\nfrom std_msgs.msg import Float32\nimport random\ndef gen_number():\n    pub = rospy.Publisher('random_number', Float32)\n    rospy.init_node('random_number_generator', log_level=rospy.INFO)\n    rospy.loginfo(\"Generating random numbers\")\n\n    while not rospy.is_shutdown():\n        pub.publish(Float32(random.normalvariate(5, 1)))\n        rospy.sleep(0.05)\n\nif __name__ == '__main__':\n  try:\n    gen_number()\n  except Exception, e:\n    print \"done\"\n~~~\n\n该文件使用一个正态分布生成随机5个数字，并且标准差为1，然后发布数据到/random_number话题。编译该文件节点可运行：`chmod +x gen_numbers.py`。\n\n## 运行行为\n\n1. 终端启动ROS：\n\n```shell\nroscore\n```\n\n2. 运行数据节点：\n\n~~~shell\nrosrun actionlib_tutorials gen_numbers.py \n~~~\n\n3. 查看行为反馈：\n\n```shell\nrostopic echo /averaging/feedback\n```\n\n执行过程会有一系列的信息输出，最后一条消息是：\n\n~~~shell\nheader: \n  seq: 100\n  stamp: \n    secs: 1522553011\n    nsecs: 185810695\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522553006\n      nsecs: 117426116\n    id: \"/test_averaging-1-1522553006.117426116\"\n  status: 1\n  text: \"This goal has been accepted by the simple action server\"\nfeedback: \n  sample: 101\n  data: 6.57791948318\n  mean: 4.95768070221\n  std_dev: 1.06043183804\n---\n~~~\n\n4. 查看行为结果：\n\n```shell\nrostopic echo /averaging/result\n```\n\n执行完成输出信息：\n\n~~~shell\neric@eric:~$ rostopic echo /averaging/result\nheader: \n  seq: 0\n  stamp: \n    secs: 1522553011\n    nsecs: 186018651\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522553006\n      nsecs: 117426116\n    id: \"/test_averaging-1-1522553006.117426116\"\n  status: 4\n  text: ''\nresult: \n  mean: 4.95768070221\n  std_dev: 1.06043183804\n---\n~~~\n\n5. 运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials averaging_client \n```\n\n执行完输出信息：\n\n~~~shell\neric@eric:~$ rosrun actionlib_tutorials averaging_client \n[ INFO] [1522553004.895895005]: Waiting for action server to start.\n[ INFO] [1522553006.117383219]: Action server started, sending goal.\n[ INFO] [1522553011.186401349]: Action finished: ABORTED\n~~~\n\n6. 运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials averaging_server\n```\n\n7. 查看发布的话题列表（检查行为运行是否正常）：\n\n```shell\nrostopic list -v\n```\n\n输出信息：\n\n~~~shell\neric@eric:~$ rostopic list -v\n\nPublished topics:\n * /turtle1/color_sensor [turtlesim/Color] 1 publisher\n * /averaging/status [actionlib_msgs/GoalStatusArray] 1 publisher\n * /random_number [std_msgs/Float32] 1 publisher\n * /averaging/result [actionlib_tutorials/AveragingActionResult] 1 publisher\n * /rosout [rosgraph_msgs/Log] 6 publishers\n * /averaging/feedback [actionlib_tutorials/AveragingActionFeedback] 1 publisher\n * /rosout_agg [rosgraph_msgs/Log] 1 publisher\n * /averaging/goal [actionlib_tutorials/AveragingActionGoal] 1 publisher\n * /averaging/cancel [actionlib_msgs/GoalID] 1 publisher\n * /turtle1/pose [turtlesim/Pose] 1 publisher\n\nSubscribed topics:\n * /averaging/cancel [actionlib_msgs/GoalID] 1 subscriber\n * /averaging/status [actionlib_msgs/GoalStatusArray] 1 subscriber\n * /random_number [std_msgs/Float32] 1 subscriber\n * /averaging/result [actionlib_tutorials/AveragingActionResult] 2 subscribers\n * /rosout [rosgraph_msgs/Log] 1 subscriber\n * /averaging/goal [actionlib_tutorials/AveragingActionGoal] 1 subscriber\n * /averaging/feedback [actionlib_tutorials/AveragingActionFeedback] 2 subscribers\n * /turtle1/cmd_vel [geometry_msgs/Twist] 1 subscriber\n~~~\n\n8. 查看行为节点图：\n\n```shell\nrqt_graph\n```\n显式如下节点图：\n\n{% asset_img 节点图.png  %}","source":"_posts/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器.md","raw":"---\ntitle: ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器\ndate: 2018-03-30 19:06:02\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more-->\n\n这一节接着上一节的内容，默认已经创建好程序包（和上一节公用一个程序包，即`actionlib_tutorials`），这里将讲述如何使用目标回调方法(Goal Callback Method)编写一个简单的行为服务器。\n\n# 创建行为消息\n\n在程序包中创建文件`actionlib_tutorials/action/Averaging.action`：\n\n~~~\n#goal definition\nint32 samples\n---\n#result definition\nfloat32 mean\nfloat32 std_dev\n---\n#feedback\nint32 sample\nfloat32 data\nfloat32 mean\nfloat32 std_dev\n~~~\n\n<!--more--->\n\n# 生成消息文件\n\n添加一些内容到`CMakeList.txt`文件：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  Averaging.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n~~~\n\n运行：\n\n~~~shell\ncatkin_make #　工作空间下运行\n~~~\n\n# 创建行为服务器\n\n创建文件`actionlib_tutorials/src/averaging_server.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <std_msgs/Float32.h>\n// 行为库\n#include <actionlib/server/simple_action_server.h>\n// 包含从Averaging.action文件中生成的消息\n#include <actionlib_tutorials/AveragingAction.h>\n\nclass AveragingAction\n{\npublic:\n    \n  AveragingAction(std::string name) : \n    as_(nh_, name, false),\n    action_name_(name)\n  {\n    //注册目标和反馈回调函数\n    as_.registerGoalCallback(boost::bind(&AveragingAction::goalCB, this));\n    as_.registerPreemptCallback(boost::bind(&AveragingAction::preemptCB, this));\n\n    //订阅感兴趣的话题数据 建立一个数据回调，该回调会处理行为\n    sub_ = nh_.subscribe(\"/random_number\", 1, &AveragingAction::analysisCB, this);\n    as_.start();//行为服务器开启\n  }\n\n  ~AveragingAction(void)\n  {\n  }\n\n  void goalCB()\n  {\n    // 重置帮助变量\n    data_count_ = 0;\n    sum_ = 0;\n    sum_sq_ = 0;\n    // 接收新目标\n    goal_ = as_.acceptNewGoal()->samples;\n  }\n\n  void preemptCB()\n  {\n    ROS_INFO(\"%s: Preempted\", action_name_.c_str());\n    // 设置行为状态为抢占(preempted)\n    as_.setPreempted();\n  }\n\n  void analysisCB(const std_msgs::Float32::ConstPtr& msg)\n  {\n    // 确保行为还没有被取消\n    if (!as_.isActive())\n      return;\n    \n    data_count_++;\n    feedback_.sample = data_count_;\n    feedback_.data = msg->data;\n    //处理std_dev和数据含义 \n    sum_ += msg->data;\n    feedback_.mean = sum_ / data_count_;\n    sum_sq_ += pow(msg->data, 2);\n    feedback_.std_dev = sqrt(fabs((sum_sq_/data_count_) - pow(feedback_.mean, 2)));\n    as_.publishFeedback(feedback_);\n\n    if(data_count_ > goal_) \n    {\n      result_.mean = feedback_.mean;\n      result_.std_dev = feedback_.std_dev;\n\n      if(result_.mean < 5.0)\n      {\n        ROS_INFO(\"%s: Aborted\", action_name_.c_str());\n        //设置行为状态为崩溃(aborted)\n        as_.setAborted(result_);\n      }\n      else \n      {\n        ROS_INFO(\"%s: Succeeded\", action_name_.c_str());\n        // 设置行为状态为成功(succeeded)\n        as_.setSucceeded(result_);\n      }\n    } \n  }\n\nprotected:\n    \n  ros::NodeHandle nh_;\n  actionlib::SimpleActionServer<actionlib_tutorials::AveragingAction> as_;\n  std::string action_name_;\n  int data_count_, goal_;\n  float sum_, sum_sq_;\n  actionlib_tutorials::AveragingFeedback feedback_;\n  actionlib_tutorials::AveragingResult result_;\n  ros::Subscriber sub_;\n};\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"averaging\");\n\n  AveragingAction averaging(ros::this_node::getName());\n  ros::spin();\n\n  return 0;\n}\n~~~\n\n# 创建行为客户端\n\n创建行为客户端文件`actionlib_tutorials/src/averaging_client.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <actionlib/client/simple_action_client.h>\n#include <actionlib/client/terminal_state.h>\n#include <actionlib_tutorials/AveragingAction.h>\n#include <boost/thread.hpp>\n\nvoid spinThread()\n{\n  ros::spin();\n}\n\nint main (int argc, char **argv)\n{\n  ros::init(argc, argv, \"test_averaging\");\n\n  // 创建一个行为客户端\n  actionlib::SimpleActionClient<actionlib_tutorials::AveragingAction> ac(\"averaging\");\n  boost::thread spin_thread(&spinThread);\n\n  ROS_INFO(\"Waiting for action server to start.\");\n  ac.waitForServer();\n\n  ROS_INFO(\"Action server started, sending goal.\");\n  // 发送目标到行为\n  actionlib_tutorials::AveragingGoal goal;\n  goal.samples = 100;\n  ac.sendGoal(goal);\n\n  //等待行为返回\n  bool finished_before_timeout = ac.waitForResult(ros::Duration(30.0));\n\n  if (finished_before_timeout)\n  {\n    actionlib::SimpleClientGoalState state = ac.getState();\n    ROS_INFO(\"Action finished: %s\",state.toString().c_str());\n  }\n  else\n    ROS_INFO(\"Action did not finish before the time out.\");\n\n  // 关闭节点，在退出前加入线程\n  ros::shutdown();\n  spin_thread.join();\n\n  //exit\n  return 0;\n}\n~~~\n\n# 编译行为\n\n在`CMakeLists.txt`文件末尾添加以下几行： \n\n~~~cmake\nadd_executable(averaging_server src/averaging_server.cpp)\ntarget_link_libraries(averaging_server ${catkin_LIBRARIES})\n\nadd_executable(averaging_client src/averaging_client.cpp)\ntarget_link_libraries(averaging_client ${catkin_LIBRARIES})\n~~~\n\n完整的`CMakeList.txt`文件如下：\n\n```cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(actionlib_tutorials)\n\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  Averaging.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs\n)\n\ninclude_directories(include ${catkin_INCLUDE_DIRS} ${Boost_INCLUDE_DIRS})\n\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server  ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries( fibonacci_client  ${catkin_LIBRARIES})\n\nadd_executable(averaging_server src/averaging_server.cpp)\ntarget_link_libraries(averaging_server ${catkin_LIBRARIES})\n\nadd_executable(averaging_client src/averaging_client.cpp)\ntarget_link_libraries(averaging_client ${catkin_LIBRARIES})\n```\n\n工作空间下执行`catkin_make`命令。\n\n# 运行行为－使用其他节点连接服务器和客户端\n\n## 编写数据节点\n\n创建文件`actionlib_tutorials/scripts/gen_numbers.py`：\n\n~~~python\n#!/usr/bin/env python\n\nimport rospy\nfrom std_msgs.msg import Float32\nimport random\ndef gen_number():\n    pub = rospy.Publisher('random_number', Float32)\n    rospy.init_node('random_number_generator', log_level=rospy.INFO)\n    rospy.loginfo(\"Generating random numbers\")\n\n    while not rospy.is_shutdown():\n        pub.publish(Float32(random.normalvariate(5, 1)))\n        rospy.sleep(0.05)\n\nif __name__ == '__main__':\n  try:\n    gen_number()\n  except Exception, e:\n    print \"done\"\n~~~\n\n该文件使用一个正态分布生成随机5个数字，并且标准差为1，然后发布数据到/random_number话题。编译该文件节点可运行：`chmod +x gen_numbers.py`。\n\n## 运行行为\n\n1. 终端启动ROS：\n\n```shell\nroscore\n```\n\n2. 运行数据节点：\n\n~~~shell\nrosrun actionlib_tutorials gen_numbers.py \n~~~\n\n3. 查看行为反馈：\n\n```shell\nrostopic echo /averaging/feedback\n```\n\n执行过程会有一系列的信息输出，最后一条消息是：\n\n~~~shell\nheader: \n  seq: 100\n  stamp: \n    secs: 1522553011\n    nsecs: 185810695\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522553006\n      nsecs: 117426116\n    id: \"/test_averaging-1-1522553006.117426116\"\n  status: 1\n  text: \"This goal has been accepted by the simple action server\"\nfeedback: \n  sample: 101\n  data: 6.57791948318\n  mean: 4.95768070221\n  std_dev: 1.06043183804\n---\n~~~\n\n4. 查看行为结果：\n\n```shell\nrostopic echo /averaging/result\n```\n\n执行完成输出信息：\n\n~~~shell\neric@eric:~$ rostopic echo /averaging/result\nheader: \n  seq: 0\n  stamp: \n    secs: 1522553011\n    nsecs: 186018651\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522553006\n      nsecs: 117426116\n    id: \"/test_averaging-1-1522553006.117426116\"\n  status: 4\n  text: ''\nresult: \n  mean: 4.95768070221\n  std_dev: 1.06043183804\n---\n~~~\n\n5. 运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials averaging_client \n```\n\n执行完输出信息：\n\n~~~shell\neric@eric:~$ rosrun actionlib_tutorials averaging_client \n[ INFO] [1522553004.895895005]: Waiting for action server to start.\n[ INFO] [1522553006.117383219]: Action server started, sending goal.\n[ INFO] [1522553011.186401349]: Action finished: ABORTED\n~~~\n\n6. 运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials averaging_server\n```\n\n7. 查看发布的话题列表（检查行为运行是否正常）：\n\n```shell\nrostopic list -v\n```\n\n输出信息：\n\n~~~shell\neric@eric:~$ rostopic list -v\n\nPublished topics:\n * /turtle1/color_sensor [turtlesim/Color] 1 publisher\n * /averaging/status [actionlib_msgs/GoalStatusArray] 1 publisher\n * /random_number [std_msgs/Float32] 1 publisher\n * /averaging/result [actionlib_tutorials/AveragingActionResult] 1 publisher\n * /rosout [rosgraph_msgs/Log] 6 publishers\n * /averaging/feedback [actionlib_tutorials/AveragingActionFeedback] 1 publisher\n * /rosout_agg [rosgraph_msgs/Log] 1 publisher\n * /averaging/goal [actionlib_tutorials/AveragingActionGoal] 1 publisher\n * /averaging/cancel [actionlib_msgs/GoalID] 1 publisher\n * /turtle1/pose [turtlesim/Pose] 1 publisher\n\nSubscribed topics:\n * /averaging/cancel [actionlib_msgs/GoalID] 1 subscriber\n * /averaging/status [actionlib_msgs/GoalStatusArray] 1 subscriber\n * /random_number [std_msgs/Float32] 1 subscriber\n * /averaging/result [actionlib_tutorials/AveragingActionResult] 2 subscribers\n * /rosout [rosgraph_msgs/Log] 1 subscriber\n * /averaging/goal [actionlib_tutorials/AveragingActionGoal] 1 subscriber\n * /averaging/feedback [actionlib_tutorials/AveragingActionFeedback] 2 subscribers\n * /turtle1/cmd_vel [geometry_msgs/Twist] 1 subscriber\n~~~\n\n8. 查看行为节点图：\n\n```shell\nrqt_graph\n```\n显式如下节点图：\n\n{% asset_img 节点图.png  %}","slug":"ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器","published":1,"updated":"2019-05-30T12:29:26.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbzh00buqlcrp0ot2qrt","content":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>\n<a id=\"more\"></a>\n<p>这一节接着上一节的内容，默认已经创建好程序包（和上一节公用一个程序包，即<code>actionlib_tutorials</code>），这里将讲述如何使用目标回调方法(Goal Callback Method)编写一个简单的行为服务器。</p>\n<h1 id=\"创建行为消息\"><a href=\"#创建行为消息\" class=\"headerlink\" title=\"创建行为消息\"></a>创建行为消息</h1><p>在程序包中创建文件<code>actionlib_tutorials/action/Averaging.action</code>：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#goal definition</span><br><span class=\"line\">int32 samples</span><br><span class=\"line\">---</span><br><span class=\"line\">#result definition</span><br><span class=\"line\">float32 mean</span><br><span class=\"line\">float32 std_dev</span><br><span class=\"line\">---</span><br><span class=\"line\">#feedback</span><br><span class=\"line\">int32 sample</span><br><span class=\"line\">float32 data</span><br><span class=\"line\">float32 mean</span><br><span class=\"line\">float32 std_dev</span><br></pre></td></tr></table></figure>\n<!--more--->\n<h1 id=\"生成消息文件\"><a href=\"#生成消息文件\" class=\"headerlink\" title=\"生成消息文件\"></a>生成消息文件</h1><p>添加一些内容到<code>CMakeList.txt</code>文件：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  actionlib</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  message_generation</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_action_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  Fibonacci.action</span><br><span class=\"line\">  Averaging.action</span><br><span class=\"line\">  DoDishes.action</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>运行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_make #　工作空间下运行</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建行为服务器\"><a href=\"#创建行为服务器\" class=\"headerlink\" title=\"创建行为服务器\"></a>创建行为服务器</h1><p>创建文件<code>actionlib_tutorials/src/averaging_server.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;std_msgs/Float32.h&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\">// 行为库</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/server/simple_action_server.h&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\">// 包含从Averaging.action文件中生成的消息</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib_tutorials/AveragingAction.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AveragingAction</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    </span><br><span class=\"line\">  AveragingAction(<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> name) : </span><br><span class=\"line\">    as_(nh_, name, <span class=\"literal\">false</span>),</span><br><span class=\"line\">    action_name_(name)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    <span class=\"comment\">//注册目标和反馈回调函数</span></span><br><span class=\"line\">    as_.registerGoalCallback(boost::bind(&amp;AveragingAction::goalCB, <span class=\"keyword\">this</span>));</span><br><span class=\"line\">    as_.registerPreemptCallback(boost::bind(&amp;AveragingAction::preemptCB, <span class=\"keyword\">this</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//订阅感兴趣的话题数据 建立一个数据回调，该回调会处理行为</span></span><br><span class=\"line\">    sub_ = nh_.subscribe(<span class=\"string\">\"/random_number\"</span>, <span class=\"number\">1</span>, &amp;AveragingAction::analysisCB, <span class=\"keyword\">this</span>);</span><br><span class=\"line\">    as_.start();<span class=\"comment\">//行为服务器开启</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  ~AveragingAction(<span class=\"keyword\">void</span>)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">goalCB</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 重置帮助变量</span></span><br><span class=\"line\">    data_count_ = <span class=\"number\">0</span>;</span><br><span class=\"line\">    sum_ = <span class=\"number\">0</span>;</span><br><span class=\"line\">    sum_sq_ = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">// 接收新目标</span></span><br><span class=\"line\">    goal_ = as_.acceptNewGoal()-&gt;samples;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preemptCB</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"%s: Preempted\"</span>, action_name_.c_str());</span><br><span class=\"line\">    <span class=\"comment\">// 设置行为状态为抢占(preempted)</span></span><br><span class=\"line\">    as_.setPreempted();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">analysisCB</span><span class=\"params\">(<span class=\"keyword\">const</span> std_msgs::Float32::ConstPtr&amp; msg)</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 确保行为还没有被取消</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!as_.isActive())</span><br><span class=\"line\">      <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    data_count_++;</span><br><span class=\"line\">    feedback_.sample = data_count_;</span><br><span class=\"line\">    feedback_.data = msg-&gt;data;</span><br><span class=\"line\">    <span class=\"comment\">//处理std_dev和数据含义 </span></span><br><span class=\"line\">    sum_ += msg-&gt;data;</span><br><span class=\"line\">    feedback_.mean = sum_ / data_count_;</span><br><span class=\"line\">    sum_sq_ += <span class=\"built_in\">pow</span>(msg-&gt;data, <span class=\"number\">2</span>);</span><br><span class=\"line\">    feedback_.std_dev = <span class=\"built_in\">sqrt</span>(<span class=\"built_in\">fabs</span>((sum_sq_/data_count_) - <span class=\"built_in\">pow</span>(feedback_.mean, <span class=\"number\">2</span>)));</span><br><span class=\"line\">    as_.publishFeedback(feedback_);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(data_count_ &gt; goal_) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      result_.mean = feedback_.mean;</span><br><span class=\"line\">      result_.std_dev = feedback_.std_dev;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">if</span>(result_.mean &lt; <span class=\"number\">5.0</span>)</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        ROS_INFO(<span class=\"string\">\"%s: Aborted\"</span>, action_name_.c_str());</span><br><span class=\"line\">        <span class=\"comment\">//设置行为状态为崩溃(aborted)</span></span><br><span class=\"line\">        as_.setAborted(result_);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      <span class=\"keyword\">else</span> </span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        ROS_INFO(<span class=\"string\">\"%s: Succeeded\"</span>, action_name_.c_str());</span><br><span class=\"line\">        <span class=\"comment\">// 设置行为状态为成功(succeeded)</span></span><br><span class=\"line\">        as_.setSucceeded(result_);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    </span><br><span class=\"line\">  ros::NodeHandle nh_;</span><br><span class=\"line\">  actionlib::SimpleActionServer&lt;actionlib_tutorials::AveragingAction&gt; as_;</span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> action_name_;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> data_count_, goal_;</span><br><span class=\"line\">  <span class=\"keyword\">float</span> sum_, sum_sq_;</span><br><span class=\"line\">  actionlib_tutorials::AveragingFeedback feedback_;</span><br><span class=\"line\">  actionlib_tutorials::AveragingResult result_;</span><br><span class=\"line\">  ros::Subscriber sub_;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"averaging\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  AveragingAction averaging(ros::this_node::getName());</span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建行为客户端\"><a href=\"#创建行为客户端\" class=\"headerlink\" title=\"创建行为客户端\"></a>创建行为客户端</h1><p>创建行为客户端文件<code>actionlib_tutorials/src/averaging_client.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/simple_action_client.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/terminal_state.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib_tutorials/AveragingAction.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;boost/thread.hpp&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">spinThread</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"test_averaging\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 创建一个行为客户端</span></span><br><span class=\"line\">  actionlib::SimpleActionClient&lt;actionlib_tutorials::AveragingAction&gt; ac(<span class=\"string\">\"averaging\"</span>);</span><br><span class=\"line\">  boost::<span class=\"function\">thread <span class=\"title\">spin_thread</span><span class=\"params\">(&amp;spinThread)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Waiting for action server to start.\"</span>);</span><br><span class=\"line\">  ac.waitForServer();</span><br><span class=\"line\"></span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Action server started, sending goal.\"</span>);</span><br><span class=\"line\">  <span class=\"comment\">// 发送目标到行为</span></span><br><span class=\"line\">  actionlib_tutorials::AveragingGoal goal;</span><br><span class=\"line\">  goal.samples = <span class=\"number\">100</span>;</span><br><span class=\"line\">  ac.sendGoal(goal);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//等待行为返回</span></span><br><span class=\"line\">  <span class=\"keyword\">bool</span> finished_before_timeout = ac.waitForResult(ros::Duration(<span class=\"number\">30.0</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (finished_before_timeout)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    actionlib::SimpleClientGoalState state = ac.getState();</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Action finished: %s\"</span>,state.toString().c_str());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">else</span></span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Action did not finish before the time out.\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 关闭节点，在退出前加入线程</span></span><br><span class=\"line\">  ros::shutdown();</span><br><span class=\"line\">  spin_thread.join();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//exit</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"编译行为\"><a href=\"#编译行为\" class=\"headerlink\" title=\"编译行为\"></a>编译行为</h1><p>在<code>CMakeLists.txt</code>文件末尾添加以下几行： </p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(averaging_server src/averaging_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(averaging_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(averaging_client src/averaging_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(averaging_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>完整的<code>CMakeList.txt</code>文件如下：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.8</span>.<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(actionlib_tutorials)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  actionlib</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  message_generation</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_action_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  Fibonacci.action</span><br><span class=\"line\">  Averaging.action</span><br><span class=\"line\">  DoDishes.action</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"keyword\">include</span> <span class=\"variable\">$&#123;catkin_INCLUDE_DIRS&#125;</span> <span class=\"variable\">$&#123;Boost_INCLUDE_DIRS&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_server src/fibonacci_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(fibonacci_server  <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_client src/fibonacci_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>( fibonacci_client  <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(averaging_server src/averaging_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(averaging_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(averaging_client src/averaging_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(averaging_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>工作空间下执行<code>catkin_make</code>命令。</p>\n<h1 id=\"运行行为－使用其他节点连接服务器和客户端\"><a href=\"#运行行为－使用其他节点连接服务器和客户端\" class=\"headerlink\" title=\"运行行为－使用其他节点连接服务器和客户端\"></a>运行行为－使用其他节点连接服务器和客户端</h1><h2 id=\"编写数据节点\"><a href=\"#编写数据节点\" class=\"headerlink\" title=\"编写数据节点\"></a>编写数据节点</h2><p>创建文件<code>actionlib_tutorials/scripts/gen_numbers.py</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> rospy</span><br><span class=\"line\"><span class=\"keyword\">from</span> std_msgs.msg <span class=\"keyword\">import</span> Float32</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">gen_number</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    pub = rospy.Publisher(<span class=\"string\">'random_number'</span>, Float32)</span><br><span class=\"line\">    rospy.init_node(<span class=\"string\">'random_number_generator'</span>, log_level=rospy.INFO)</span><br><span class=\"line\">    rospy.loginfo(<span class=\"string\">\"Generating random numbers\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">not</span> rospy.is_shutdown():</span><br><span class=\"line\">        pub.publish(Float32(random.normalvariate(<span class=\"number\">5</span>, <span class=\"number\">1</span>)))</span><br><span class=\"line\">        rospy.sleep(<span class=\"number\">0.05</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">  <span class=\"keyword\">try</span>:</span><br><span class=\"line\">    gen_number()</span><br><span class=\"line\">  <span class=\"keyword\">except</span> Exception, e:</span><br><span class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">\"done\"</span></span><br></pre></td></tr></table></figure>\n<p>该文件使用一个正态分布生成随机5个数字，并且标准差为1，然后发布数据到/random_number话题。编译该文件节点可运行：<code>chmod +x gen_numbers.py</code>。</p>\n<h2 id=\"运行行为\"><a href=\"#运行行为\" class=\"headerlink\" title=\"运行行为\"></a>运行行为</h2><ol>\n<li>终端启动ROS：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscore</span><br></pre></td></tr></table></figure>\n<ol>\n<li>运行数据节点：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials gen_numbers.py</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看行为反馈：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic echo /averaging/feedback</span><br></pre></td></tr></table></figure>\n<p>执行过程会有一系列的信息输出，最后一条消息是：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">header: </span><br><span class=\"line\">  seq: 100</span><br><span class=\"line\">  stamp: </span><br><span class=\"line\">    secs: 1522553011</span><br><span class=\"line\">    nsecs: 185810695</span><br><span class=\"line\">  frame_id: ''</span><br><span class=\"line\">status: </span><br><span class=\"line\">  goal_id: </span><br><span class=\"line\">    stamp: </span><br><span class=\"line\">      secs: 1522553006</span><br><span class=\"line\">      nsecs: 117426116</span><br><span class=\"line\">    id: \"/test_averaging-1-1522553006.117426116\"</span><br><span class=\"line\">  status: 1</span><br><span class=\"line\">  text: \"This goal has been accepted by the simple action server\"</span><br><span class=\"line\">feedback: </span><br><span class=\"line\">  sample: 101</span><br><span class=\"line\">  data: 6.57791948318</span><br><span class=\"line\">  mean: 4.95768070221</span><br><span class=\"line\">  std_dev: 1.06043183804</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看行为结果：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic echo /averaging/result</span><br></pre></td></tr></table></figure>\n<p>执行完成输出信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~$ rostopic echo /averaging/result</span><br><span class=\"line\">header: </span><br><span class=\"line\">  seq: 0</span><br><span class=\"line\">  stamp: </span><br><span class=\"line\">    secs: 1522553011</span><br><span class=\"line\">    nsecs: 186018651</span><br><span class=\"line\">  frame_id: ''</span><br><span class=\"line\">status: </span><br><span class=\"line\">  goal_id: </span><br><span class=\"line\">    stamp: </span><br><span class=\"line\">      secs: 1522553006</span><br><span class=\"line\">      nsecs: 117426116</span><br><span class=\"line\">    id: \"/test_averaging-1-1522553006.117426116\"</span><br><span class=\"line\">  status: 4</span><br><span class=\"line\">  text: ''</span><br><span class=\"line\">result: </span><br><span class=\"line\">  mean: 4.95768070221</span><br><span class=\"line\">  std_dev: 1.06043183804</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<ol>\n<li>运行行为客户端：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials averaging_client</span><br></pre></td></tr></table></figure>\n<p>执行完输出信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~$ rosrun actionlib_tutorials averaging_client </span><br><span class=\"line\">[ INFO] [1522553004.895895005]: Waiting for action server to start.</span><br><span class=\"line\">[ INFO] [1522553006.117383219]: Action server started, sending goal.</span><br><span class=\"line\">[ INFO] [1522553011.186401349]: Action finished: ABORTED</span><br></pre></td></tr></table></figure>\n<ol>\n<li>运行行为服务器：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials averaging_server</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看发布的话题列表（检查行为运行是否正常）：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic list -v</span><br></pre></td></tr></table></figure>\n<p>输出信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eric@eric:~$ rostopic list -v</span><br><span class=\"line\"></span><br><span class=\"line\">Published topics:</span><br><span class=\"line\"> * /turtle1/color_sensor [turtlesim/Color] 1 publisher</span><br><span class=\"line\"> * /averaging/status [actionlib_msgs/GoalStatusArray] 1 publisher</span><br><span class=\"line\"> * /random_number [std_msgs/Float32] 1 publisher</span><br><span class=\"line\"> * /averaging/result [actionlib_tutorials/AveragingActionResult] 1 publisher</span><br><span class=\"line\"> * /rosout [rosgraph_msgs/Log] 6 publishers</span><br><span class=\"line\"> * /averaging/feedback [actionlib_tutorials/AveragingActionFeedback] 1 publisher</span><br><span class=\"line\"> * /rosout_agg [rosgraph_msgs/Log] 1 publisher</span><br><span class=\"line\"> * /averaging/goal [actionlib_tutorials/AveragingActionGoal] 1 publisher</span><br><span class=\"line\"> * /averaging/cancel [actionlib_msgs/GoalID] 1 publisher</span><br><span class=\"line\"> * /turtle1/pose [turtlesim/Pose] 1 publisher</span><br><span class=\"line\"></span><br><span class=\"line\">Subscribed topics:</span><br><span class=\"line\"> * /averaging/cancel [actionlib_msgs/GoalID] 1 subscriber</span><br><span class=\"line\"> * /averaging/status [actionlib_msgs/GoalStatusArray] 1 subscriber</span><br><span class=\"line\"> * /random_number [std_msgs/Float32] 1 subscriber</span><br><span class=\"line\"> * /averaging/result [actionlib_tutorials/AveragingActionResult] 2 subscribers</span><br><span class=\"line\"> * /rosout [rosgraph_msgs/Log] 1 subscriber</span><br><span class=\"line\"> * /averaging/goal [actionlib_tutorials/AveragingActionGoal] 1 subscriber</span><br><span class=\"line\"> * /averaging/feedback [actionlib_tutorials/AveragingActionFeedback] 2 subscribers</span><br><span class=\"line\"> * /turtle1/cmd_vel [geometry_msgs/Twist] 1 subscriber</span><br></pre></td></tr></table></figure>\n<ol>\n<li>查看行为节点图：</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rqt_graph</span><br></pre></td></tr></table></figure>\n<p>显式如下节点图：</p>\n<img src=\"/2018/03/30/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器/节点图.png\">","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>","more":"<p>这一节接着上一节的内容，默认已经创建好程序包（和上一节公用一个程序包，即<code>actionlib_tutorials</code>），这里将讲述如何使用目标回调方法(Goal Callback Method)编写一个简单的行为服务器。</p>\n<h1 id=\"创建行为消息\"><a href=\"#创建行为消息\" class=\"headerlink\" title=\"创建行为消息\"></a>创建行为消息</h1><p>在程序包中创建文件<code>actionlib_tutorials/action/Averaging.action</code>：</p>\n<!--�215-->\n<!--more--->\n<h1 id=\"生成消息文件\"><a href=\"#生成消息文件\" class=\"headerlink\" title=\"生成消息文件\"></a>生成消息文件</h1><p>添加一些内容到<code>CMakeList.txt</code>文件：</p>\n<!--�216-->\n<p>运行：</p>\n<!--�217-->\n<h1 id=\"创建行为服务器\"><a href=\"#创建行为服务器\" class=\"headerlink\" title=\"创建行为服务器\"></a>创建行为服务器</h1><p>创建文件<code>actionlib_tutorials/src/averaging_server.cpp</code>：</p>\n<!--�218-->\n<h1 id=\"创建行为客户端\"><a href=\"#创建行为客户端\" class=\"headerlink\" title=\"创建行为客户端\"></a>创建行为客户端</h1><p>创建行为客户端文件<code>actionlib_tutorials/src/averaging_client.cpp</code>：</p>\n<!--�219-->\n<h1 id=\"编译行为\"><a href=\"#编译行为\" class=\"headerlink\" title=\"编译行为\"></a>编译行为</h1><p>在<code>CMakeLists.txt</code>文件末尾添加以下几行： </p>\n<!--�220-->\n<p>完整的<code>CMakeList.txt</code>文件如下：</p>\n<!--�221-->\n<p>工作空间下执行<code>catkin_make</code>命令。</p>\n<h1 id=\"运行行为－使用其他节点连接服务器和客户端\"><a href=\"#运行行为－使用其他节点连接服务器和客户端\" class=\"headerlink\" title=\"运行行为－使用其他节点连接服务器和客户端\"></a>运行行为－使用其他节点连接服务器和客户端</h1><h2 id=\"编写数据节点\"><a href=\"#编写数据节点\" class=\"headerlink\" title=\"编写数据节点\"></a>编写数据节点</h2><p>创建文件<code>actionlib_tutorials/scripts/gen_numbers.py</code>：</p>\n<!--�222-->\n<p>该文件使用一个正态分布生成随机5个数字，并且标准差为1，然后发布数据到/random_number话题。编译该文件节点可运行：<code>chmod +x gen_numbers.py</code>。</p>\n<h2 id=\"运行行为\"><a href=\"#运行行为\" class=\"headerlink\" title=\"运行行为\"></a>运行行为</h2><ol>\n<li>终端启动ROS：</li>\n</ol>\n<!--�223-->\n<ol>\n<li>运行数据节点：</li>\n</ol>\n<!--�224-->\n<ol>\n<li>查看行为反馈：</li>\n</ol>\n<!--�225-->\n<p>执行过程会有一系列的信息输出，最后一条消息是：</p>\n<!--�226-->\n<ol>\n<li>查看行为结果：</li>\n</ol>\n<!--�227-->\n<p>执行完成输出信息：</p>\n<!--�228-->\n<ol>\n<li>运行行为客户端：</li>\n</ol>\n<!--�229-->\n<p>执行完输出信息：</p>\n<!--�230-->\n<ol>\n<li>运行行为服务器：</li>\n</ol>\n<!--�231-->\n<ol>\n<li>查看发布的话题列表（检查行为运行是否正常）：</li>\n</ol>\n<!--�232-->\n<p>输出信息：</p>\n<!--�233-->\n<ol>\n<li>查看行为节点图：</li>\n</ol>\n<!--�234-->\n<p>显式如下节点图：</p>\n<img src=\"/2018/03/30/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器/节点图.png\">"},{"title":"ROS学习之pluginlib","date":"2018-04-03T11:23:25.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS pluginlib使用的学习内容。\n\n<!--more--->\n\nROS的pluginlib程序包提供了一种使用ROS构建基础结构编写和**动态加载**插件的工具。为了能够工作，这些工具需要**插件提供者在他们的包的package.xml中注册他们的插件。**\n\n# 概述\n\npluginlib是一个C ++库，用于**从ROS包**中加载和卸载插件。插件是从运行时库（即共享对象，动态链接库）加载的可动态 \t加载的类。使用pluginlib，不需要将应用程序明确地链接到包含类的库。相反，pluginlib可以在任何时候打开包含导出类的库，而无需事先知道库或包含类定义的头文件。 插件对于扩展/修改应用程序行为而不需要应用程序源代码是很有用的。\n\n **pluginlib**利用了**C++多态的特性**，不同的插件只要使用统一的接口（抽象基类）便可以替换使用。这样用户通过调用在插件中实现的统一的接口函数，不需要更改程序，也不需要重新编译，更换插件即可实现功能修正。\n\n利用**pluginlib**编写插件的方法大致包括如下四步：\n\n1. 创建插件基类，定义统一接口（如果为现有接口编写插件，则跳过该步）\n2. 编写插件类，继承插件基类，实现统一接口\n3. 导出插件，并编译为动态库\n4. 将插件加入ROS系统，使其可识别和管理\n\n贴一张自己总结的pluginlib框架图，帮助自己理解：\n\n{% asset_img pluginlib.png  %}\n\n# 例子\n\n首先，假设存在一个包含多边形基类的ROS程序包（“polygon_interface_package”）。系统支持两种不同的多边形：一个是位于“rectangle_plugin”包中的矩形和一个是位于“triangle_plugin”包中的三角形。rectangle_plugin和triangle_plugin包的实现都在其package.xml文件中包含特殊的导出行，告诉rosbuild系统它们可以为polygon_interface_package包中的polygon类提供插件。实际上这些导出行作用是在ROS构建/打包系统中注册这些类。这样使用者如果希望在系统中看到所有的多边形类，它就可以运行一个简单的`rospack`命令查询，得到可以使用的类的清单，在这里是三角形和矩形。\n\n\n\n![pluginlib/plugin_model.png](http://wiki.ros.org/pluginlib?action=AttachFile&do=get&target=plugin_model.png)\n\n# 提供一个插件\n\n## 注册/导出插件\n\n一个可以被动态加载的类必须被标记为导出类，可以使用特殊的宏`PLUGINLIB_EXPORT_CLASS`实现这一点。该宏可以放入任何组成插件库的源（.cpp）文件中，但通常放在导出类的.cpp文件的末尾。对于上述例子，可以在`example_pkg`包中创建`class_list.cpp`文件，并编译该文件，加入librectangle库：\n\n~~~c++\n#include <pluginlib/class_list_macros.h>\n#include <polygon_interface_package/polygon.h>\n#include <rectangle_package/rectangle.h>\n\n//Declare the Rectangle as a Polygon class\nPLUGINLIB_EXPORT_CLASS(rectangle_namespace::Rectangle, polygon_namespace::Polygon)\n~~~\n\n## 插件描述文件\n\n插件描述文件是一个XML文件，它以机器可读的格式存储关于插件的所有信息，包括插件所在的库、插件的名字、插件的类型等等。上述例子的插件描述文件（例如，`rectangle_plugin.xml`）可以写为：\n\n~~~XML\n<library path=\"lib/librectangle\">\n  <class type=\"rectangle_namespace::Rectangle\" base_class_type=\"polygon_namespace::Polygon\">\n  <description>\n  This is a rectangle plugin\n  </description>\n  </class>\n</library>\n~~~\n\n关于插件描述文件的详细信息，[查看这里](http://wiki.ros.org/pluginlib/PluginDescriptionFile)。\n\n### 为什么需要这个文件\n\n除了代码宏之外，我们还需要这个文件来允许ROS系统自动发现、加载和推理插件。 插件描述文件也包含重要的信息，如插件的描述，它不适合在宏中使用。\n\n## 使用ROS Package System注册插件\n\n为了让pluginlib可以通过所有的ROS包查询系统上的所有可用插件，每个包必须明确指定它导出的插件以及哪些包库包含这些插件。插件提供程序必须在其导出标记块内的package.xml中指向其插件描述文件。 请注意，如果有其他出口，它们都必须放在同一个出口字段中。对于上述例子，相关的内容写为：\n\n~~~xml\n<export>\n  <polygon_interface_package plugin=\"${prefix}/rectangle_plugin.xml\" />\n</export>\n~~~\n\n关于导出一个插件的细节学习，[参考这里](http://wiki.ros.org/pluginlib/PluginExport)。\n\n**提醒：**为了使上述导出命令正常工作，提供的包必须直接依赖于包含插件接口的包。 例如，rectangle_plugin的catkin / package.xml中必须包含以下行：\n\n~~~xml\n<build_depend>polygon_interface_package</build_depend>\n<run_depend>polygon_interface_package</run_depend>\n~~~\n\n## 查询ROS包系统中的可用插件\n\n用户可以使用`rospack`命令查看可用的插件，例如：\n\n~~~\nrospack plugins --attrib=plugin nav_core\n~~~\n\n其中nav_cor为包名，该命令将返回所有从nav_core包中导出的插件。\n\n# 使用一个插件\n\npluginlib在class_loader.h头文件中提供了ClassLoader类，使得可以快速方便地使用它提供的类。关于该类细节的描述[参考这里](http://docs.ros.org/api/pluginlib/html/classpluginlib_1_1ClassLoaderBase.html)。下面是一个简单的例子，使用ClassLoader类在使用多边形的代码中创建一个rectangle的实例：\n\n~~~c++\n#include <pluginlib/class_loader.h>\n#include <polygon_interface_package/polygon.h>\n\n//... some code ...\n\npluginlib::ClassLoader<polygon_namespace::Polygon> poly_loader(\"polygon_interface_package\", \"polygon_namespace::Polygon\");\n\ntry\n{\n  boost::shared_ptr<polygon_namespace::Polygon> poly = poly_loader.createInstance(\"rectangle_namespace::Rectangle\");\n\n  //... use the polygon, boost::shared_ptr will automatically delete memory when it goes out of scope\n}\ncatch(pluginlib::PluginlibException& ex)\n{\n  //handle the class failing to load\n  ROS_ERROR(\"The plugin failed to load for some reason. Error: %s\", ex.what());\n}\n~~~\n\n**注意：**在使用插件时，ClassLoader不能超出范围。 所以，如果要在类中加载插件对象，请确保类加载器是该类的成员变量。\n\n# 手动创建并使用一个简单的插件\n\n## 准备工作\n\n安装pluginlib_tutorials pkg：\n\n~~~shell\napt-get install ros-kinetic-common-tutorials\n~~~\n\ncatkin_ws/src目录下创建程序包：\n\n~~~shell\ncatkin_create_pkg pluginlib_tutorials_ roscpp pluginlib\n~~~\n\n## 创建基类\n\n创建文件`pluginlib_tutorials_/include/pluginlib_tutorials_/polygon_base.h`：\n\n~~~c++\n#ifndef PLUGINLIB_TUTORIALS__POLYGON_BASE_H_\n#define PLUGINLIB_TUTORIALS__POLYGON_BASE_H_\n\nnamespace polygon_base\n{\n  class RegularPolygon\n  {\n    public:\n      virtual void initialize(double side_length) = 0;\n      virtual double area() = 0;\n      virtual ~RegularPolygon(){}\n\n    protected:\n      RegularPolygon(){}\n  };\n};\n#endif\n~~~\n\n## 创建插件\n\n创建文件`include/pluginlib_tutorials_/polygon_plugins.h`：\n\n~~~c++\n#ifndef PLUGINLIB_TUTORIALS__POLYGON_PLUGINS_H_\n#define PLUGINLIB_TUTORIALS__POLYGON_PLUGINS_H_\n#include <pluginlib_tutorials_/polygon_base.h>\n#include <cmath>\n\nnamespace polygon_plugins\n{\n  class Triangle : public polygon_base::RegularPolygon\n  {\n    public:\n      Triangle(){}\n\n      void initialize(double side_length)\n      {\n        side_length_ = side_length;\n      }\n\n      double area()\n      {\n        return 0.5 * side_length_ * getHeight();\n      }\n\n      double getHeight()\n      {\n        return sqrt((side_length_ * side_length_) - ((side_length_ / 2) * (side_length_ / 2)));\n      }\n\n    private:\n      double side_length_;\n  };\n\n  class Square : public polygon_base::RegularPolygon\n  {\n    public:\n      Square(){}\n\n      void initialize(double side_length)\n      {\n        side_length_ = side_length;\n      }\n\n      double area()\n      {\n        return side_length_ * side_length_;\n      }\n\n    private:\n      double side_length_;\n\n  };\n};\n#endif\n~~~\n\n## 注册插件\n\n创建文件`src/polygon_plugins.cpp`：\n\n~~~c++\n#include <pluginlib/class_list_macros.h>\n#include <pluginlib_tutorials_/polygon_base.h>\n#include <pluginlib_tutorials_/polygon_plugins.h>\n\nPLUGINLIB_EXPORT_CLASS(polygon_plugins::Triangle, polygon_base::RegularPolygon)\nPLUGINLIB_EXPORT_CLASS(polygon_plugins::Square, polygon_base::RegularPolygon)\n~~~\n\n## 构建插件\n\n`CMakeList.txt`文件中添加内容：\n\n~~~cmake\ninclude_directories(include)\nadd_library(polygon_plugins src/polygon_plugins.cpp)\n~~~\n\n## 使得ROS Toolchain可访问插件\n\n### 创建XML文件\n\n在程序包顶层目录创建文件`polygon_plugins.xml`：\n\n~~~xml\n<library path=\"lib/libpolygon_plugins\">\n  <class type=\"polygon_plugins::Triangle\" base_class_type=\"polygon_base::RegularPolygon\">\n    <description>This is a triangle plugin.</description>\n  </class>\n  <class type=\"polygon_plugins::Square\" base_class_type=\"polygon_base::RegularPolygon\">\n    <description>This is a square plugin.</description>\n  </class>\n</library>\n~~~\n\n### 导入插件\n\n在`package.xml`文件添加信息：\n\n~~~xml\n<export>\n  <pluginlib_tutorials_ plugin=\"${prefix}/polygon_plugins.xml\" />\n</export>\n~~~\n\n### 测试插件\n\n执行`catkin_make`命令编译工作空间，并执行如下命令：\n\n~~~shell\nrospack plugins --attrib=plugin pluginlib_tutorials_\n~~~\n\n输出 `polygon_plugins.xml`文件的路径信息则正确。\n\n## 使用插件\n\n创建文件`src/polygon_loader.cpp`：\n\n~~~c++\n#include <pluginlib/class_loader.h>\n#include <pluginlib_tutorials_/polygon_base.h>\n\nint main(int argc, char** argv)\n{\n  pluginlib::ClassLoader<polygon_base::RegularPolygon> poly_loader(\"pluginlib_tutorials_\", \"polygon_base::RegularPolygon\");\n\n  try\n  {\n    boost::shared_ptr<polygon_base::RegularPolygon> triangle = poly_loader.createInstance(\"polygon_plugins::Triangle\");\n    triangle->initialize(10.0);\n\n    boost::shared_ptr<polygon_base::RegularPolygon> square = poly_loader.createInstance(\"polygon_plugins::Square\");\n    square->initialize(10.0);\n\n    ROS_INFO(\"Triangle area: %.2f\", triangle->area());\n    ROS_INFO(\"Square area: %.2f\", square->area());\n  }\n  catch(pluginlib::PluginlibException& ex)\n  {\n    ROS_ERROR(\"The plugin failed to load for some reason. Error: %s\", ex.what());\n  }\n\n  return 0;\n}\n~~~\n\n## 运行节点\n\n在 `CMakeLists.txt`文件中添加信息：\n\n~~~cmake\nadd_executable(polygon_loader src/polygon_loader.cpp)\ntarget_link_libraries(polygon_loader ${catkin_LIBRARIES})\n~~~\n\n执行`catkin_make`命令。\n\n### 方式一：命令行rosrun方式\n\n运行可执行文件节点：\n\n~~~shell\nrosrun pluginlib_tutorials_ polygon_loader\n~~~\n\n输出如下信息：\n\n~~~shell\n[ INFO] [WallTime: 1279658450.869089666]: Triangle area: 43.30\n[ INFO] [WallTime: 1279658450.869138007]: Square area: 100.00\n~~~\n\n\n\n### 方式二：启动文件方式\n\n在程序包中创建launch文件夹，并创建文件`polygon_loader.launch`，输入：\n\n~~~~xml\n<launch>  \n        <node name=\"polygon_loader\" pkg=\"pluginlib_tutorials_\" type=\"polygon_loader\" output=\"screen\"/>  \n</launch> \n~~~~\n\n执行命令：`roslaunch pluginlib_tutorials_ polygon_loader.launch`\n\n可以看到同样的输出信息。\n\n启动文件（launch file）方式，是ROS提供的一个同时启动节点管理器（master）和多个节点的途径。任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以*.launch*作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。每个XML文件都必须要包含一个根元素。根元素由一对launch标签定义：`<launch> … <launch>`元素都应该包含在这两个标签之内。\n\n节点属性中节点元素的形式：\n\n`<node pkg=”package-name” type=”executable-name” name=”node-name”/>`\n","source":"_posts/ROS学习之pluginlib.md","raw":"---\ntitle: ROS学习之pluginlib\ndate: 2018-04-03 19:23:25\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS pluginlib使用的学习内容。\n\n<!--more--->\n\nROS的pluginlib程序包提供了一种使用ROS构建基础结构编写和**动态加载**插件的工具。为了能够工作，这些工具需要**插件提供者在他们的包的package.xml中注册他们的插件。**\n\n# 概述\n\npluginlib是一个C ++库，用于**从ROS包**中加载和卸载插件。插件是从运行时库（即共享对象，动态链接库）加载的可动态 \t加载的类。使用pluginlib，不需要将应用程序明确地链接到包含类的库。相反，pluginlib可以在任何时候打开包含导出类的库，而无需事先知道库或包含类定义的头文件。 插件对于扩展/修改应用程序行为而不需要应用程序源代码是很有用的。\n\n **pluginlib**利用了**C++多态的特性**，不同的插件只要使用统一的接口（抽象基类）便可以替换使用。这样用户通过调用在插件中实现的统一的接口函数，不需要更改程序，也不需要重新编译，更换插件即可实现功能修正。\n\n利用**pluginlib**编写插件的方法大致包括如下四步：\n\n1. 创建插件基类，定义统一接口（如果为现有接口编写插件，则跳过该步）\n2. 编写插件类，继承插件基类，实现统一接口\n3. 导出插件，并编译为动态库\n4. 将插件加入ROS系统，使其可识别和管理\n\n贴一张自己总结的pluginlib框架图，帮助自己理解：\n\n{% asset_img pluginlib.png  %}\n\n# 例子\n\n首先，假设存在一个包含多边形基类的ROS程序包（“polygon_interface_package”）。系统支持两种不同的多边形：一个是位于“rectangle_plugin”包中的矩形和一个是位于“triangle_plugin”包中的三角形。rectangle_plugin和triangle_plugin包的实现都在其package.xml文件中包含特殊的导出行，告诉rosbuild系统它们可以为polygon_interface_package包中的polygon类提供插件。实际上这些导出行作用是在ROS构建/打包系统中注册这些类。这样使用者如果希望在系统中看到所有的多边形类，它就可以运行一个简单的`rospack`命令查询，得到可以使用的类的清单，在这里是三角形和矩形。\n\n\n\n![pluginlib/plugin_model.png](http://wiki.ros.org/pluginlib?action=AttachFile&do=get&target=plugin_model.png)\n\n# 提供一个插件\n\n## 注册/导出插件\n\n一个可以被动态加载的类必须被标记为导出类，可以使用特殊的宏`PLUGINLIB_EXPORT_CLASS`实现这一点。该宏可以放入任何组成插件库的源（.cpp）文件中，但通常放在导出类的.cpp文件的末尾。对于上述例子，可以在`example_pkg`包中创建`class_list.cpp`文件，并编译该文件，加入librectangle库：\n\n~~~c++\n#include <pluginlib/class_list_macros.h>\n#include <polygon_interface_package/polygon.h>\n#include <rectangle_package/rectangle.h>\n\n//Declare the Rectangle as a Polygon class\nPLUGINLIB_EXPORT_CLASS(rectangle_namespace::Rectangle, polygon_namespace::Polygon)\n~~~\n\n## 插件描述文件\n\n插件描述文件是一个XML文件，它以机器可读的格式存储关于插件的所有信息，包括插件所在的库、插件的名字、插件的类型等等。上述例子的插件描述文件（例如，`rectangle_plugin.xml`）可以写为：\n\n~~~XML\n<library path=\"lib/librectangle\">\n  <class type=\"rectangle_namespace::Rectangle\" base_class_type=\"polygon_namespace::Polygon\">\n  <description>\n  This is a rectangle plugin\n  </description>\n  </class>\n</library>\n~~~\n\n关于插件描述文件的详细信息，[查看这里](http://wiki.ros.org/pluginlib/PluginDescriptionFile)。\n\n### 为什么需要这个文件\n\n除了代码宏之外，我们还需要这个文件来允许ROS系统自动发现、加载和推理插件。 插件描述文件也包含重要的信息，如插件的描述，它不适合在宏中使用。\n\n## 使用ROS Package System注册插件\n\n为了让pluginlib可以通过所有的ROS包查询系统上的所有可用插件，每个包必须明确指定它导出的插件以及哪些包库包含这些插件。插件提供程序必须在其导出标记块内的package.xml中指向其插件描述文件。 请注意，如果有其他出口，它们都必须放在同一个出口字段中。对于上述例子，相关的内容写为：\n\n~~~xml\n<export>\n  <polygon_interface_package plugin=\"${prefix}/rectangle_plugin.xml\" />\n</export>\n~~~\n\n关于导出一个插件的细节学习，[参考这里](http://wiki.ros.org/pluginlib/PluginExport)。\n\n**提醒：**为了使上述导出命令正常工作，提供的包必须直接依赖于包含插件接口的包。 例如，rectangle_plugin的catkin / package.xml中必须包含以下行：\n\n~~~xml\n<build_depend>polygon_interface_package</build_depend>\n<run_depend>polygon_interface_package</run_depend>\n~~~\n\n## 查询ROS包系统中的可用插件\n\n用户可以使用`rospack`命令查看可用的插件，例如：\n\n~~~\nrospack plugins --attrib=plugin nav_core\n~~~\n\n其中nav_cor为包名，该命令将返回所有从nav_core包中导出的插件。\n\n# 使用一个插件\n\npluginlib在class_loader.h头文件中提供了ClassLoader类，使得可以快速方便地使用它提供的类。关于该类细节的描述[参考这里](http://docs.ros.org/api/pluginlib/html/classpluginlib_1_1ClassLoaderBase.html)。下面是一个简单的例子，使用ClassLoader类在使用多边形的代码中创建一个rectangle的实例：\n\n~~~c++\n#include <pluginlib/class_loader.h>\n#include <polygon_interface_package/polygon.h>\n\n//... some code ...\n\npluginlib::ClassLoader<polygon_namespace::Polygon> poly_loader(\"polygon_interface_package\", \"polygon_namespace::Polygon\");\n\ntry\n{\n  boost::shared_ptr<polygon_namespace::Polygon> poly = poly_loader.createInstance(\"rectangle_namespace::Rectangle\");\n\n  //... use the polygon, boost::shared_ptr will automatically delete memory when it goes out of scope\n}\ncatch(pluginlib::PluginlibException& ex)\n{\n  //handle the class failing to load\n  ROS_ERROR(\"The plugin failed to load for some reason. Error: %s\", ex.what());\n}\n~~~\n\n**注意：**在使用插件时，ClassLoader不能超出范围。 所以，如果要在类中加载插件对象，请确保类加载器是该类的成员变量。\n\n# 手动创建并使用一个简单的插件\n\n## 准备工作\n\n安装pluginlib_tutorials pkg：\n\n~~~shell\napt-get install ros-kinetic-common-tutorials\n~~~\n\ncatkin_ws/src目录下创建程序包：\n\n~~~shell\ncatkin_create_pkg pluginlib_tutorials_ roscpp pluginlib\n~~~\n\n## 创建基类\n\n创建文件`pluginlib_tutorials_/include/pluginlib_tutorials_/polygon_base.h`：\n\n~~~c++\n#ifndef PLUGINLIB_TUTORIALS__POLYGON_BASE_H_\n#define PLUGINLIB_TUTORIALS__POLYGON_BASE_H_\n\nnamespace polygon_base\n{\n  class RegularPolygon\n  {\n    public:\n      virtual void initialize(double side_length) = 0;\n      virtual double area() = 0;\n      virtual ~RegularPolygon(){}\n\n    protected:\n      RegularPolygon(){}\n  };\n};\n#endif\n~~~\n\n## 创建插件\n\n创建文件`include/pluginlib_tutorials_/polygon_plugins.h`：\n\n~~~c++\n#ifndef PLUGINLIB_TUTORIALS__POLYGON_PLUGINS_H_\n#define PLUGINLIB_TUTORIALS__POLYGON_PLUGINS_H_\n#include <pluginlib_tutorials_/polygon_base.h>\n#include <cmath>\n\nnamespace polygon_plugins\n{\n  class Triangle : public polygon_base::RegularPolygon\n  {\n    public:\n      Triangle(){}\n\n      void initialize(double side_length)\n      {\n        side_length_ = side_length;\n      }\n\n      double area()\n      {\n        return 0.5 * side_length_ * getHeight();\n      }\n\n      double getHeight()\n      {\n        return sqrt((side_length_ * side_length_) - ((side_length_ / 2) * (side_length_ / 2)));\n      }\n\n    private:\n      double side_length_;\n  };\n\n  class Square : public polygon_base::RegularPolygon\n  {\n    public:\n      Square(){}\n\n      void initialize(double side_length)\n      {\n        side_length_ = side_length;\n      }\n\n      double area()\n      {\n        return side_length_ * side_length_;\n      }\n\n    private:\n      double side_length_;\n\n  };\n};\n#endif\n~~~\n\n## 注册插件\n\n创建文件`src/polygon_plugins.cpp`：\n\n~~~c++\n#include <pluginlib/class_list_macros.h>\n#include <pluginlib_tutorials_/polygon_base.h>\n#include <pluginlib_tutorials_/polygon_plugins.h>\n\nPLUGINLIB_EXPORT_CLASS(polygon_plugins::Triangle, polygon_base::RegularPolygon)\nPLUGINLIB_EXPORT_CLASS(polygon_plugins::Square, polygon_base::RegularPolygon)\n~~~\n\n## 构建插件\n\n`CMakeList.txt`文件中添加内容：\n\n~~~cmake\ninclude_directories(include)\nadd_library(polygon_plugins src/polygon_plugins.cpp)\n~~~\n\n## 使得ROS Toolchain可访问插件\n\n### 创建XML文件\n\n在程序包顶层目录创建文件`polygon_plugins.xml`：\n\n~~~xml\n<library path=\"lib/libpolygon_plugins\">\n  <class type=\"polygon_plugins::Triangle\" base_class_type=\"polygon_base::RegularPolygon\">\n    <description>This is a triangle plugin.</description>\n  </class>\n  <class type=\"polygon_plugins::Square\" base_class_type=\"polygon_base::RegularPolygon\">\n    <description>This is a square plugin.</description>\n  </class>\n</library>\n~~~\n\n### 导入插件\n\n在`package.xml`文件添加信息：\n\n~~~xml\n<export>\n  <pluginlib_tutorials_ plugin=\"${prefix}/polygon_plugins.xml\" />\n</export>\n~~~\n\n### 测试插件\n\n执行`catkin_make`命令编译工作空间，并执行如下命令：\n\n~~~shell\nrospack plugins --attrib=plugin pluginlib_tutorials_\n~~~\n\n输出 `polygon_plugins.xml`文件的路径信息则正确。\n\n## 使用插件\n\n创建文件`src/polygon_loader.cpp`：\n\n~~~c++\n#include <pluginlib/class_loader.h>\n#include <pluginlib_tutorials_/polygon_base.h>\n\nint main(int argc, char** argv)\n{\n  pluginlib::ClassLoader<polygon_base::RegularPolygon> poly_loader(\"pluginlib_tutorials_\", \"polygon_base::RegularPolygon\");\n\n  try\n  {\n    boost::shared_ptr<polygon_base::RegularPolygon> triangle = poly_loader.createInstance(\"polygon_plugins::Triangle\");\n    triangle->initialize(10.0);\n\n    boost::shared_ptr<polygon_base::RegularPolygon> square = poly_loader.createInstance(\"polygon_plugins::Square\");\n    square->initialize(10.0);\n\n    ROS_INFO(\"Triangle area: %.2f\", triangle->area());\n    ROS_INFO(\"Square area: %.2f\", square->area());\n  }\n  catch(pluginlib::PluginlibException& ex)\n  {\n    ROS_ERROR(\"The plugin failed to load for some reason. Error: %s\", ex.what());\n  }\n\n  return 0;\n}\n~~~\n\n## 运行节点\n\n在 `CMakeLists.txt`文件中添加信息：\n\n~~~cmake\nadd_executable(polygon_loader src/polygon_loader.cpp)\ntarget_link_libraries(polygon_loader ${catkin_LIBRARIES})\n~~~\n\n执行`catkin_make`命令。\n\n### 方式一：命令行rosrun方式\n\n运行可执行文件节点：\n\n~~~shell\nrosrun pluginlib_tutorials_ polygon_loader\n~~~\n\n输出如下信息：\n\n~~~shell\n[ INFO] [WallTime: 1279658450.869089666]: Triangle area: 43.30\n[ INFO] [WallTime: 1279658450.869138007]: Square area: 100.00\n~~~\n\n\n\n### 方式二：启动文件方式\n\n在程序包中创建launch文件夹，并创建文件`polygon_loader.launch`，输入：\n\n~~~~xml\n<launch>  \n        <node name=\"polygon_loader\" pkg=\"pluginlib_tutorials_\" type=\"polygon_loader\" output=\"screen\"/>  \n</launch> \n~~~~\n\n执行命令：`roslaunch pluginlib_tutorials_ polygon_loader.launch`\n\n可以看到同样的输出信息。\n\n启动文件（launch file）方式，是ROS提供的一个同时启动节点管理器（master）和多个节点的途径。任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以*.launch*作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。每个XML文件都必须要包含一个根元素。根元素由一对launch标签定义：`<launch> … <launch>`元素都应该包含在这两个标签之内。\n\n节点属性中节点元素的形式：\n\n`<node pkg=”package-name” type=”executable-name” name=”node-name”/>`\n","slug":"ROS学习之pluginlib","published":1,"updated":"2019-05-30T12:29:26.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbzp00bxqlcrkrzzb4wp","content":"<hr>\n<p>这篇文章是有关ROS pluginlib使用的学习内容。</p>\n<a id=\"more\"></a>\n<p>ROS的pluginlib程序包提供了一种使用ROS构建基础结构编写和<strong>动态加载</strong>插件的工具。为了能够工作，这些工具需要<strong>插件提供者在他们的包的package.xml中注册他们的插件。</strong></p>\n<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>pluginlib是一个C ++库，用于<strong>从ROS包</strong>中加载和卸载插件。插件是从运行时库（即共享对象，动态链接库）加载的可动态     加载的类。使用pluginlib，不需要将应用程序明确地链接到包含类的库。相反，pluginlib可以在任何时候打开包含导出类的库，而无需事先知道库或包含类定义的头文件。 插件对于扩展/修改应用程序行为而不需要应用程序源代码是很有用的。</p>\n<p> <strong>pluginlib</strong>利用了<strong>C++多态的特性</strong>，不同的插件只要使用统一的接口（抽象基类）便可以替换使用。这样用户通过调用在插件中实现的统一的接口函数，不需要更改程序，也不需要重新编译，更换插件即可实现功能修正。</p>\n<p>利用<strong>pluginlib</strong>编写插件的方法大致包括如下四步：</p>\n<ol>\n<li>创建插件基类，定义统一接口（如果为现有接口编写插件，则跳过该步）</li>\n<li>编写插件类，继承插件基类，实现统一接口</li>\n<li>导出插件，并编译为动态库</li>\n<li>将插件加入ROS系统，使其可识别和管理</li>\n</ol>\n<p>贴一张自己总结的pluginlib框架图，帮助自己理解：</p>\n<img src=\"/2018/04/03/ROS学习之pluginlib/pluginlib.png\">\n<h1 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h1><p>首先，假设存在一个包含多边形基类的ROS程序包（“polygon_interface_package”）。系统支持两种不同的多边形：一个是位于“rectangle_plugin”包中的矩形和一个是位于“triangle_plugin”包中的三角形。rectangle_plugin和triangle_plugin包的实现都在其package.xml文件中包含特殊的导出行，告诉rosbuild系统它们可以为polygon_interface_package包中的polygon类提供插件。实际上这些导出行作用是在ROS构建/打包系统中注册这些类。这样使用者如果希望在系统中看到所有的多边形类，它就可以运行一个简单的<code>rospack</code>命令查询，得到可以使用的类的清单，在这里是三角形和矩形。</p>\n<p><img src=\"http://wiki.ros.org/pluginlib?action=AttachFile&amp;do=get&amp;target=plugin_model.png\" alt=\"pluginlib/plugin_model.png\"></p>\n<h1 id=\"提供一个插件\"><a href=\"#提供一个插件\" class=\"headerlink\" title=\"提供一个插件\"></a>提供一个插件</h1><h2 id=\"注册-导出插件\"><a href=\"#注册-导出插件\" class=\"headerlink\" title=\"注册/导出插件\"></a>注册/导出插件</h2><p>一个可以被动态加载的类必须被标记为导出类，可以使用特殊的宏<code>PLUGINLIB_EXPORT_CLASS</code>实现这一点。该宏可以放入任何组成插件库的源（.cpp）文件中，但通常放在导出类的.cpp文件的末尾。对于上述例子，可以在<code>example_pkg</code>包中创建<code>class_list.cpp</code>文件，并编译该文件，加入librectangle库：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib/class_list_macros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;polygon_interface_package/polygon.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;rectangle_package/rectangle.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//Declare the Rectangle as a Polygon class</span></span><br><span class=\"line\">PLUGINLIB_EXPORT_CLASS(rectangle_namespace::Rectangle, polygon_namespace::Polygon)</span><br></pre></td></tr></table></figure>\n<h2 id=\"插件描述文件\"><a href=\"#插件描述文件\" class=\"headerlink\" title=\"插件描述文件\"></a>插件描述文件</h2><p>插件描述文件是一个XML文件，它以机器可读的格式存储关于插件的所有信息，包括插件所在的库、插件的名字、插件的类型等等。上述例子的插件描述文件（例如，<code>rectangle_plugin.xml</code>）可以写为：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">library</span> <span class=\"attr\">path</span>=<span class=\"string\">\"lib/librectangle\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">class</span> <span class=\"attr\">type</span>=<span class=\"string\">\"rectangle_namespace::Rectangle\"</span> <span class=\"attr\">base_class_type</span>=<span class=\"string\">\"polygon_namespace::Polygon\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  This is a rectangle plugin</span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">class</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">library</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>关于插件描述文件的详细信息，<a href=\"http://wiki.ros.org/pluginlib/PluginDescriptionFile\" target=\"_blank\" rel=\"noopener\">查看这里</a>。</p>\n<h3 id=\"为什么需要这个文件\"><a href=\"#为什么需要这个文件\" class=\"headerlink\" title=\"为什么需要这个文件\"></a>为什么需要这个文件</h3><p>除了代码宏之外，我们还需要这个文件来允许ROS系统自动发现、加载和推理插件。 插件描述文件也包含重要的信息，如插件的描述，它不适合在宏中使用。</p>\n<h2 id=\"使用ROS-Package-System注册插件\"><a href=\"#使用ROS-Package-System注册插件\" class=\"headerlink\" title=\"使用ROS Package System注册插件\"></a>使用ROS Package System注册插件</h2><p>为了让pluginlib可以通过所有的ROS包查询系统上的所有可用插件，每个包必须明确指定它导出的插件以及哪些包库包含这些插件。插件提供程序必须在其导出标记块内的package.xml中指向其插件描述文件。 请注意，如果有其他出口，它们都必须放在同一个出口字段中。对于上述例子，相关的内容写为：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">export</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">polygon_interface_package</span> <span class=\"attr\">plugin</span>=<span class=\"string\">\"$&#123;prefix&#125;/rectangle_plugin.xml\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">export</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>关于导出一个插件的细节学习，<a href=\"http://wiki.ros.org/pluginlib/PluginExport\" target=\"_blank\" rel=\"noopener\">参考这里</a>。</p>\n<p><strong>提醒：</strong>为了使上述导出命令正常工作，提供的包必须直接依赖于包含插件接口的包。 例如，rectangle_plugin的catkin / package.xml中必须包含以下行：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>polygon_interface_package<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">run_depend</span>&gt;</span>polygon_interface_package<span class=\"tag\">&lt;/<span class=\"name\">run_depend</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"查询ROS包系统中的可用插件\"><a href=\"#查询ROS包系统中的可用插件\" class=\"headerlink\" title=\"查询ROS包系统中的可用插件\"></a>查询ROS包系统中的可用插件</h2><p>用户可以使用<code>rospack</code>命令查看可用的插件，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rospack plugins --attrib=plugin nav_core</span><br></pre></td></tr></table></figure>\n<p>其中nav_cor为包名，该命令将返回所有从nav_core包中导出的插件。</p>\n<h1 id=\"使用一个插件\"><a href=\"#使用一个插件\" class=\"headerlink\" title=\"使用一个插件\"></a>使用一个插件</h1><p>pluginlib在class_loader.h头文件中提供了ClassLoader类，使得可以快速方便地使用它提供的类。关于该类细节的描述<a href=\"http://docs.ros.org/api/pluginlib/html/classpluginlib_1_1ClassLoaderBase.html\" target=\"_blank\" rel=\"noopener\">参考这里</a>。下面是一个简单的例子，使用ClassLoader类在使用多边形的代码中创建一个rectangle的实例：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib/class_loader.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;polygon_interface_package/polygon.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//... some code ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">pluginlib::ClassLoader&lt;polygon_namespace::Polygon&gt; poly_loader(<span class=\"string\">\"polygon_interface_package\"</span>, <span class=\"string\">\"polygon_namespace::Polygon\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">try</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  boost::<span class=\"built_in\">shared_ptr</span>&lt;polygon_namespace::Polygon&gt; poly = poly_loader.createInstance(<span class=\"string\">\"rectangle_namespace::Rectangle\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//... use the polygon, boost::shared_ptr will automatically delete memory when it goes out of scope</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">catch</span>(pluginlib::PluginlibException&amp; ex)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"comment\">//handle the class failing to load</span></span><br><span class=\"line\">  ROS_ERROR(<span class=\"string\">\"The plugin failed to load for some reason. Error: %s\"</span>, ex.what());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>注意：</strong>在使用插件时，ClassLoader不能超出范围。 所以，如果要在类中加载插件对象，请确保类加载器是该类的成员变量。</p>\n<h1 id=\"手动创建并使用一个简单的插件\"><a href=\"#手动创建并使用一个简单的插件\" class=\"headerlink\" title=\"手动创建并使用一个简单的插件\"></a>手动创建并使用一个简单的插件</h1><h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><p>安装pluginlib_tutorials pkg：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get install ros-kinetic-common-tutorials</span><br></pre></td></tr></table></figure>\n<p>catkin_ws/src目录下创建程序包：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_create_pkg pluginlib_tutorials_ roscpp pluginlib</span><br></pre></td></tr></table></figure>\n<h2 id=\"创建基类\"><a href=\"#创建基类\" class=\"headerlink\" title=\"创建基类\"></a>创建基类</h2><p>创建文件<code>pluginlib_tutorials_/include/pluginlib_tutorials_/polygon_base.h</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> PLUGINLIB_TUTORIALS__POLYGON_BASE_H_</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PLUGINLIB_TUTORIALS__POLYGON_BASE_H_</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> polygon_base</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RegularPolygon</span></span></span><br><span class=\"line\"><span class=\"class\">  &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">initialize</span><span class=\"params\">(<span class=\"keyword\">double</span> side_length)</span> </span>= <span class=\"number\">0</span>;</span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">double</span> <span class=\"title\">area</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;</span><br><span class=\"line\">      <span class=\"keyword\">virtual</span> ~RegularPolygon()&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">protected</span>:</span><br><span class=\"line\">      RegularPolygon()&#123;&#125;</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br></pre></td></tr></table></figure>\n<h2 id=\"创建插件\"><a href=\"#创建插件\" class=\"headerlink\" title=\"创建插件\"></a>创建插件</h2><p>创建文件<code>include/pluginlib_tutorials_/polygon_plugins.h</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> PLUGINLIB_TUTORIALS__POLYGON_PLUGINS_H_</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PLUGINLIB_TUTORIALS__POLYGON_PLUGINS_H_</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib_tutorials_/polygon_base.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> polygon_plugins</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Triangle</span> :</span> <span class=\"keyword\">public</span> polygon_base::RegularPolygon</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">      Triangle()&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">initialize</span><span class=\"params\">(<span class=\"keyword\">double</span> side_length)</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">        side_length_ = side_length;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">area</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0.5</span> * side_length_ * getHeight();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">getHeight</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">sqrt</span>((side_length_ * side_length_) - ((side_length_ / <span class=\"number\">2</span>) * (side_length_ / <span class=\"number\">2</span>)));</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span>:</span><br><span class=\"line\">      <span class=\"keyword\">double</span> side_length_;</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Square</span> :</span> <span class=\"keyword\">public</span> polygon_base::RegularPolygon</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span>:</span><br><span class=\"line\">      Square()&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">initialize</span><span class=\"params\">(<span class=\"keyword\">double</span> side_length)</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">        side_length_ = side_length;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">area</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">      </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> side_length_ * side_length_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span>:</span><br><span class=\"line\">      <span class=\"keyword\">double</span> side_length_;</span><br><span class=\"line\"></span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br></pre></td></tr></table></figure>\n<h2 id=\"注册插件\"><a href=\"#注册插件\" class=\"headerlink\" title=\"注册插件\"></a>注册插件</h2><p>创建文件<code>src/polygon_plugins.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib/class_list_macros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib_tutorials_/polygon_base.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib_tutorials_/polygon_plugins.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">PLUGINLIB_EXPORT_CLASS(polygon_plugins::Triangle, polygon_base::RegularPolygon)</span><br><span class=\"line\">PLUGINLIB_EXPORT_CLASS(polygon_plugins::Square, polygon_base::RegularPolygon)</span><br></pre></td></tr></table></figure>\n<h2 id=\"构建插件\"><a href=\"#构建插件\" class=\"headerlink\" title=\"构建插件\"></a>构建插件</h2><p><code>CMakeList.txt</code>文件中添加内容：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"keyword\">include</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(polygon_plugins src/polygon_plugins.cpp)</span><br></pre></td></tr></table></figure>\n<h2 id=\"使得ROS-Toolchain可访问插件\"><a href=\"#使得ROS-Toolchain可访问插件\" class=\"headerlink\" title=\"使得ROS Toolchain可访问插件\"></a>使得ROS Toolchain可访问插件</h2><h3 id=\"创建XML文件\"><a href=\"#创建XML文件\" class=\"headerlink\" title=\"创建XML文件\"></a>创建XML文件</h3><p>在程序包顶层目录创建文件<code>polygon_plugins.xml</code>：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">library</span> <span class=\"attr\">path</span>=<span class=\"string\">\"lib/libpolygon_plugins\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">class</span> <span class=\"attr\">type</span>=<span class=\"string\">\"polygon_plugins::Triangle\"</span> <span class=\"attr\">base_class_type</span>=<span class=\"string\">\"polygon_base::RegularPolygon\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>This is a triangle plugin.<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">class</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">class</span> <span class=\"attr\">type</span>=<span class=\"string\">\"polygon_plugins::Square\"</span> <span class=\"attr\">base_class_type</span>=<span class=\"string\">\"polygon_base::RegularPolygon\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>This is a square plugin.<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">class</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">library</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"导入插件\"><a href=\"#导入插件\" class=\"headerlink\" title=\"导入插件\"></a>导入插件</h3><p>在<code>package.xml</code>文件添加信息：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">export</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">pluginlib_tutorials_</span> <span class=\"attr\">plugin</span>=<span class=\"string\">\"$&#123;prefix&#125;/polygon_plugins.xml\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">export</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"测试插件\"><a href=\"#测试插件\" class=\"headerlink\" title=\"测试插件\"></a>测试插件</h3><p>执行<code>catkin_make</code>命令编译工作空间，并执行如下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rospack plugins --attrib=plugin pluginlib_tutorials_</span><br></pre></td></tr></table></figure>\n<p>输出 <code>polygon_plugins.xml</code>文件的路径信息则正确。</p>\n<h2 id=\"使用插件\"><a href=\"#使用插件\" class=\"headerlink\" title=\"使用插件\"></a>使用插件</h2><p>创建文件<code>src/polygon_loader.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib/class_loader.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;pluginlib_tutorials_/polygon_base.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  pluginlib::ClassLoader&lt;polygon_base::RegularPolygon&gt; poly_loader(<span class=\"string\">\"pluginlib_tutorials_\"</span>, <span class=\"string\">\"polygon_base::RegularPolygon\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">try</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    boost::<span class=\"built_in\">shared_ptr</span>&lt;polygon_base::RegularPolygon&gt; triangle = poly_loader.createInstance(<span class=\"string\">\"polygon_plugins::Triangle\"</span>);</span><br><span class=\"line\">    triangle-&gt;initialize(<span class=\"number\">10.0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    boost::<span class=\"built_in\">shared_ptr</span>&lt;polygon_base::RegularPolygon&gt; square = poly_loader.createInstance(<span class=\"string\">\"polygon_plugins::Square\"</span>);</span><br><span class=\"line\">    square-&gt;initialize(<span class=\"number\">10.0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Triangle area: %.2f\"</span>, triangle-&gt;area());</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Square area: %.2f\"</span>, square-&gt;area());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">catch</span>(pluginlib::PluginlibException&amp; ex)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    ROS_ERROR(<span class=\"string\">\"The plugin failed to load for some reason. Error: %s\"</span>, ex.what());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h2><p>在 <code>CMakeLists.txt</code>文件中添加信息：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(polygon_loader src/polygon_loader.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(polygon_loader <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>执行<code>catkin_make</code>命令。</p>\n<h3 id=\"方式一：命令行rosrun方式\"><a href=\"#方式一：命令行rosrun方式\" class=\"headerlink\" title=\"方式一：命令行rosrun方式\"></a>方式一：命令行rosrun方式</h3><p>运行可执行文件节点：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun pluginlib_tutorials_ polygon_loader</span><br></pre></td></tr></table></figure>\n<p>输出如下信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ INFO] [WallTime: 1279658450.869089666]: Triangle area: 43.30</span><br><span class=\"line\">[ INFO] [WallTime: 1279658450.869138007]: Square area: 100.00</span><br></pre></td></tr></table></figure>\n<h3 id=\"方式二：启动文件方式\"><a href=\"#方式二：启动文件方式\" class=\"headerlink\" title=\"方式二：启动文件方式\"></a>方式二：启动文件方式</h3><p>在程序包中创建launch文件夹，并创建文件<code>polygon_loader.launch</code>，输入：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">launch</span>&gt;</span>  </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"polygon_loader\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"pluginlib_tutorials_\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"polygon_loader\"</span> <span class=\"attr\">output</span>=<span class=\"string\">\"screen\"</span>/&gt;</span>  </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">launch</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>执行命令：<code>roslaunch pluginlib_tutorials_ polygon_loader.launch</code></p>\n<p>可以看到同样的输出信息。</p>\n<p>启动文件（launch file）方式，是ROS提供的一个同时启动节点管理器（master）和多个节点的途径。任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以<em>.launch</em>作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。每个XML文件都必须要包含一个根元素。根元素由一对launch标签定义：<code>&lt;launch&gt; … &lt;launch&gt;</code>元素都应该包含在这两个标签之内。</p>\n<p>节点属性中节点元素的形式：</p>\n<p><code>&lt;node pkg=”package-name” type=”executable-name” name=”node-name”/&gt;</code></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS pluginlib使用的学习内容。</p>","more":"<p>ROS的pluginlib程序包提供了一种使用ROS构建基础结构编写和<strong>动态加载</strong>插件的工具。为了能够工作，这些工具需要<strong>插件提供者在他们的包的package.xml中注册他们的插件。</strong></p>\n<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>pluginlib是一个C ++库，用于<strong>从ROS包</strong>中加载和卸载插件。插件是从运行时库（即共享对象，动态链接库）加载的可动态     加载的类。使用pluginlib，不需要将应用程序明确地链接到包含类的库。相反，pluginlib可以在任何时候打开包含导出类的库，而无需事先知道库或包含类定义的头文件。 插件对于扩展/修改应用程序行为而不需要应用程序源代码是很有用的。</p>\n<p> <strong>pluginlib</strong>利用了<strong>C++多态的特性</strong>，不同的插件只要使用统一的接口（抽象基类）便可以替换使用。这样用户通过调用在插件中实现的统一的接口函数，不需要更改程序，也不需要重新编译，更换插件即可实现功能修正。</p>\n<p>利用<strong>pluginlib</strong>编写插件的方法大致包括如下四步：</p>\n<ol>\n<li>创建插件基类，定义统一接口（如果为现有接口编写插件，则跳过该步）</li>\n<li>编写插件类，继承插件基类，实现统一接口</li>\n<li>导出插件，并编译为动态库</li>\n<li>将插件加入ROS系统，使其可识别和管理</li>\n</ol>\n<p>贴一张自己总结的pluginlib框架图，帮助自己理解：</p>\n<img src=\"/2018/04/03/ROS学习之pluginlib/pluginlib.png\">\n<h1 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h1><p>首先，假设存在一个包含多边形基类的ROS程序包（“polygon_interface_package”）。系统支持两种不同的多边形：一个是位于“rectangle_plugin”包中的矩形和一个是位于“triangle_plugin”包中的三角形。rectangle_plugin和triangle_plugin包的实现都在其package.xml文件中包含特殊的导出行，告诉rosbuild系统它们可以为polygon_interface_package包中的polygon类提供插件。实际上这些导出行作用是在ROS构建/打包系统中注册这些类。这样使用者如果希望在系统中看到所有的多边形类，它就可以运行一个简单的<code>rospack</code>命令查询，得到可以使用的类的清单，在这里是三角形和矩形。</p>\n<p><img src=\"http://wiki.ros.org/pluginlib?action=AttachFile&amp;do=get&amp;target=plugin_model.png\" alt=\"pluginlib/plugin_model.png\"></p>\n<h1 id=\"提供一个插件\"><a href=\"#提供一个插件\" class=\"headerlink\" title=\"提供一个插件\"></a>提供一个插件</h1><h2 id=\"注册-导出插件\"><a href=\"#注册-导出插件\" class=\"headerlink\" title=\"注册/导出插件\"></a>注册/导出插件</h2><p>一个可以被动态加载的类必须被标记为导出类，可以使用特殊的宏<code>PLUGINLIB_EXPORT_CLASS</code>实现这一点。该宏可以放入任何组成插件库的源（.cpp）文件中，但通常放在导出类的.cpp文件的末尾。对于上述例子，可以在<code>example_pkg</code>包中创建<code>class_list.cpp</code>文件，并编译该文件，加入librectangle库：</p>\n<!--�235-->\n<h2 id=\"插件描述文件\"><a href=\"#插件描述文件\" class=\"headerlink\" title=\"插件描述文件\"></a>插件描述文件</h2><p>插件描述文件是一个XML文件，它以机器可读的格式存储关于插件的所有信息，包括插件所在的库、插件的名字、插件的类型等等。上述例子的插件描述文件（例如，<code>rectangle_plugin.xml</code>）可以写为：</p>\n<!--�236-->\n<p>关于插件描述文件的详细信息，<a href=\"http://wiki.ros.org/pluginlib/PluginDescriptionFile\" target=\"_blank\" rel=\"noopener\">查看这里</a>。</p>\n<h3 id=\"为什么需要这个文件\"><a href=\"#为什么需要这个文件\" class=\"headerlink\" title=\"为什么需要这个文件\"></a>为什么需要这个文件</h3><p>除了代码宏之外，我们还需要这个文件来允许ROS系统自动发现、加载和推理插件。 插件描述文件也包含重要的信息，如插件的描述，它不适合在宏中使用。</p>\n<h2 id=\"使用ROS-Package-System注册插件\"><a href=\"#使用ROS-Package-System注册插件\" class=\"headerlink\" title=\"使用ROS Package System注册插件\"></a>使用ROS Package System注册插件</h2><p>为了让pluginlib可以通过所有的ROS包查询系统上的所有可用插件，每个包必须明确指定它导出的插件以及哪些包库包含这些插件。插件提供程序必须在其导出标记块内的package.xml中指向其插件描述文件。 请注意，如果有其他出口，它们都必须放在同一个出口字段中。对于上述例子，相关的内容写为：</p>\n<!--�237-->\n<p>关于导出一个插件的细节学习，<a href=\"http://wiki.ros.org/pluginlib/PluginExport\" target=\"_blank\" rel=\"noopener\">参考这里</a>。</p>\n<p><strong>提醒：</strong>为了使上述导出命令正常工作，提供的包必须直接依赖于包含插件接口的包。 例如，rectangle_plugin的catkin / package.xml中必须包含以下行：</p>\n<!--�238-->\n<h2 id=\"查询ROS包系统中的可用插件\"><a href=\"#查询ROS包系统中的可用插件\" class=\"headerlink\" title=\"查询ROS包系统中的可用插件\"></a>查询ROS包系统中的可用插件</h2><p>用户可以使用<code>rospack</code>命令查看可用的插件，例如：</p>\n<!--�239-->\n<p>其中nav_cor为包名，该命令将返回所有从nav_core包中导出的插件。</p>\n<h1 id=\"使用一个插件\"><a href=\"#使用一个插件\" class=\"headerlink\" title=\"使用一个插件\"></a>使用一个插件</h1><p>pluginlib在class_loader.h头文件中提供了ClassLoader类，使得可以快速方便地使用它提供的类。关于该类细节的描述<a href=\"http://docs.ros.org/api/pluginlib/html/classpluginlib_1_1ClassLoaderBase.html\" target=\"_blank\" rel=\"noopener\">参考这里</a>。下面是一个简单的例子，使用ClassLoader类在使用多边形的代码中创建一个rectangle的实例：</p>\n<!--�240-->\n<p><strong>注意：</strong>在使用插件时，ClassLoader不能超出范围。 所以，如果要在类中加载插件对象，请确保类加载器是该类的成员变量。</p>\n<h1 id=\"手动创建并使用一个简单的插件\"><a href=\"#手动创建并使用一个简单的插件\" class=\"headerlink\" title=\"手动创建并使用一个简单的插件\"></a>手动创建并使用一个简单的插件</h1><h2 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\"准备工作\"></a>准备工作</h2><p>安装pluginlib_tutorials pkg：</p>\n<!--�241-->\n<p>catkin_ws/src目录下创建程序包：</p>\n<!--�242-->\n<h2 id=\"创建基类\"><a href=\"#创建基类\" class=\"headerlink\" title=\"创建基类\"></a>创建基类</h2><p>创建文件<code>pluginlib_tutorials_/include/pluginlib_tutorials_/polygon_base.h</code>：</p>\n<!--�243-->\n<h2 id=\"创建插件\"><a href=\"#创建插件\" class=\"headerlink\" title=\"创建插件\"></a>创建插件</h2><p>创建文件<code>include/pluginlib_tutorials_/polygon_plugins.h</code>：</p>\n<!--�244-->\n<h2 id=\"注册插件\"><a href=\"#注册插件\" class=\"headerlink\" title=\"注册插件\"></a>注册插件</h2><p>创建文件<code>src/polygon_plugins.cpp</code>：</p>\n<!--�245-->\n<h2 id=\"构建插件\"><a href=\"#构建插件\" class=\"headerlink\" title=\"构建插件\"></a>构建插件</h2><p><code>CMakeList.txt</code>文件中添加内容：</p>\n<!--�246-->\n<h2 id=\"使得ROS-Toolchain可访问插件\"><a href=\"#使得ROS-Toolchain可访问插件\" class=\"headerlink\" title=\"使得ROS Toolchain可访问插件\"></a>使得ROS Toolchain可访问插件</h2><h3 id=\"创建XML文件\"><a href=\"#创建XML文件\" class=\"headerlink\" title=\"创建XML文件\"></a>创建XML文件</h3><p>在程序包顶层目录创建文件<code>polygon_plugins.xml</code>：</p>\n<!--�247-->\n<h3 id=\"导入插件\"><a href=\"#导入插件\" class=\"headerlink\" title=\"导入插件\"></a>导入插件</h3><p>在<code>package.xml</code>文件添加信息：</p>\n<!--�248-->\n<h3 id=\"测试插件\"><a href=\"#测试插件\" class=\"headerlink\" title=\"测试插件\"></a>测试插件</h3><p>执行<code>catkin_make</code>命令编译工作空间，并执行如下命令：</p>\n<!--�249-->\n<p>输出 <code>polygon_plugins.xml</code>文件的路径信息则正确。</p>\n<h2 id=\"使用插件\"><a href=\"#使用插件\" class=\"headerlink\" title=\"使用插件\"></a>使用插件</h2><p>创建文件<code>src/polygon_loader.cpp</code>：</p>\n<!--�250-->\n<h2 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h2><p>在 <code>CMakeLists.txt</code>文件中添加信息：</p>\n<!--�251-->\n<p>执行<code>catkin_make</code>命令。</p>\n<h3 id=\"方式一：命令行rosrun方式\"><a href=\"#方式一：命令行rosrun方式\" class=\"headerlink\" title=\"方式一：命令行rosrun方式\"></a>方式一：命令行rosrun方式</h3><p>运行可执行文件节点：</p>\n<!--�252-->\n<p>输出如下信息：</p>\n<!--�253-->\n<h3 id=\"方式二：启动文件方式\"><a href=\"#方式二：启动文件方式\" class=\"headerlink\" title=\"方式二：启动文件方式\"></a>方式二：启动文件方式</h3><p>在程序包中创建launch文件夹，并创建文件<code>polygon_loader.launch</code>，输入：</p>\n<!--�254-->\n<p>执行命令：<code>roslaunch pluginlib_tutorials_ polygon_loader.launch</code></p>\n<p>可以看到同样的输出信息。</p>\n<p>启动文件（launch file）方式，是ROS提供的一个同时启动节点管理器（master）和多个节点的途径。任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以<em>.launch</em>作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。每个XML文件都必须要包含一个根元素。根元素由一对launch标签定义：<code>&lt;launch&gt; … &lt;launch&gt;</code>元素都应该包含在这两个标签之内。</p>\n<p>节点属性中节点元素的形式：</p>\n<p><code>&lt;node pkg=”package-name” type=”executable-name” name=”node-name”/&gt;</code></p>"},{"title":"ROS学习之actionlib库（４）-实践之小乌龟画五边形","date":"2018-03-31T03:19:47.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more-->\n\n本例程并没有创建`.action`文件生成消息，在安装ROS时，在`opt/ros/kinetic/`路径中已经包含了我们需要的文件，其实就是一个依赖库`turtle_actionlib`。这一点不同就需要在`CMakeList.txt`和`package.xml`文件中手动添加一些信息，后续的内容会提到。\n\n# 创建行为服务器\n\n创建文件`actionlib_tutorials/src/shape_server.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <turtlesim/Pose.h>\n#include <actionlib/server/simple_action_server.h>\n#include <cmath>\n#include <math.h>\n#include <angles/angles.h>\n\n#include <geometry_msgs/Twist.h>\n#include <turtle_actionlib/ShapeAction.h>\n\n// This class computes the command_velocities of the turtle to draw regular polygons \nclass ShapeAction\n{\npublic:\n  ShapeAction(std::string name) : \n    as_(nh_, name, false),\n    action_name_(name)\n  {\n    //register the goal and feeback callbacks\n    as_.registerGoalCallback(boost::bind(&ShapeAction::goalCB, this));\n    as_.registerPreemptCallback(boost::bind(&ShapeAction::preemptCB, this));\n\n    //subscribe to the data topic of interest\n    sub_ = nh_.subscribe(\"/turtle1/pose\", 1, &ShapeAction::controlCB, this);\n    pub_ = nh_.advertise<geometry_msgs::Twist>(\"/turtle1/cmd_vel\", 1);\n\n    as_.start();\n  }\n\n  ~ShapeAction(void)\n  {\n  }\n\n  void goalCB()\n  {\n    // accept the new goal\n    turtle_actionlib::ShapeGoal goal = *as_.acceptNewGoal();\n    //save the goal as private variables\n    edges_ = goal.edges;\n    radius_ = goal.radius;\n\n    // reset helper variables\n    interior_angle_ = ((edges_-2)*M_PI)/edges_;\n    apothem_ = radius_*cos(M_PI/edges_);\n    //compute the side length of the polygon\n    side_len_ = apothem_ * 2* tan( M_PI/edges_);\n    //store the result values\n    result_.apothem = apothem_;\n    result_.interior_angle = interior_angle_;\n    edge_progress_ =0;\n    start_edge_ = true;\n  }\n\n  void preemptCB()\n  {\n    ROS_INFO(\"%s: Preempted\", action_name_.c_str());\n    // set the action state to preempted\n    as_.setPreempted();\n  }\n\n  void controlCB(const turtlesim::Pose::ConstPtr& msg)\n  {\n    // make sure that the action hasn't been canceled\n    if (!as_.isActive())\n      return;\n  \n    if (edge_progress_ < edges_)\n    {\n      // scalar values for drive the turtle faster and straighter\n      double l_scale = 6.0;\n      double a_scale = 6.0;\n      double error_tol = 0.00001;\n\n      if (start_edge_)\n      {\n        start_x_ = msg->x;\n        start_y_ = msg->y;\n        start_theta_ = msg->theta;\n        start_edge_ = false;\n      }\n\n      // compute the distance and theta error for the shape\n      dis_error_ = side_len_ - fabs(sqrt((start_x_- msg->x)*(start_x_-msg->x) + (start_y_-msg->y)*(start_y_-msg->y)));\n      theta_error_ = angles::normalize_angle_positive(M_PI - interior_angle_ - (msg->theta - start_theta_));\n     \n      if (dis_error_ > error_tol)\n      {\n        command_.linear.x = l_scale*dis_error_;\n        command_.angular.z = 0;\n      }\n      else if (dis_error_ < error_tol && fabs(theta_error_)> error_tol)\n      { \n        command_.linear.x = 0;\n        command_.angular.z = a_scale*theta_error_;\n      }\n      else if (dis_error_ < error_tol && fabs(theta_error_)< error_tol)\n      {\n        command_.linear.x = 0;\n        command_.angular.z = 0;\n        start_edge_ = true;\n        edge_progress_++;\n      }  \n      else\n      {\n        command_.linear.x = l_scale*dis_error_;\n        command_.angular.z = a_scale*theta_error_;\n      } \n      // publish the velocity command\n      pub_.publish(command_);\n      \n    } \n    else\n    {          \n      ROS_INFO(\"%s: Succeeded\", action_name_.c_str());\n      // set the action state to succeeded\n      as_.setSucceeded(result_);\n    }   \n  }\n\nprotected:\n  ros::NodeHandle nh_;\n  actionlib::SimpleActionServer<turtle_actionlib::ShapeAction> as_;\n  std::string action_name_;\n  double radius_, apothem_, interior_angle_, side_len_;\n  double start_x_, start_y_, start_theta_;\n  double dis_error_, theta_error_;\n  int edges_ , edge_progress_;\n  bool start_edge_;\n  geometry_msgs::Twist command_;\n  turtle_actionlib::ShapeResult result_;\n  ros::Subscriber sub_;\n  ros::Publisher pub_;\n};\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"turtle_shape\");\n\n  ShapeAction shape(ros::this_node::getName());\n  ros::spin();\n\n  return 0;\n}\n```\n\n# 创建行为客户端\n\n创建行为客户端文件`actionlib_tutorials/src/shape_client.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <actionlib/client/simple_action_client.h>\n#include <actionlib/client/terminal_state.h>\n#include <turtle_actionlib/ShapeAction.h>\n\nint main (int argc, char **argv)\n{\n  ros::init(argc, argv, \"test_shape\"); \n\n  // create the action client\n  // true causes the client to spin it's own thread\n  actionlib::SimpleActionClient<turtle_actionlib::ShapeAction> ac(\"turtle_shape\", true); \n\n  ROS_INFO(\"Waiting for action server to start.\");\n  // wait for the action server to start\n  ac.waitForServer(); //will wait for infinite time\n \n  ROS_INFO(\"Action server started, sending goal.\");\n  // send a goal to the action \n  turtle_actionlib::ShapeGoal goal;\n  goal.edges = 5;\n  goal.radius = 1.3;\n  ac.sendGoal(goal);\n  \n  //wait for the action to return\n  bool finished_before_timeout = ac.waitForResult(ros::Duration(40.0));\n\n  if (finished_before_timeout)\n    {\n      actionlib::SimpleClientGoalState state = ac.getState();\n      ROS_INFO(\"Action finished: %s\",state.toString().c_str());\n    }\n  else  \n    ROS_INFO(\"Action did not finish before the time out.\");\n\n  //exit\n  return 0;\n}\n```\n\n# 编译行为\n\n**注意**：\n\n本例程并没有创建`.action`文件生成消息，而是使用安装ROS时就有的`opt/ros/kinetic/share/turtle_actionlib`目录下的库文件，所以在`CMakeLists.txt`文件中需要添加如下信息：\n\n~~~cmake\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs turtle_actionlib #turtle_actionlib是新添加的依赖库\n)\n~~~\n\n在`CMakeLists.txt`文件末尾添加以下几行： \n\n```cmake\nadd_executable(shape_server src/shape_server.cpp)\ntarget_link_libraries(shape_server ${catkin_LIBRARIES})\n\nadd_executable(shape_client src/shape_client.cpp)\ntarget_link_libraries(shape_client ${catkin_LIBRARIES})\n```\n\n完整的`CMakeList.txt`文件如下：\n\n```cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(actionlib_tutorials)\n\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  Averaging.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs turtle_actionlib\n)\n\n\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries(fibonacci_client ${catkin_LIBRARIES})\n\nadd_executable(averaging_server src/averaging_server.cpp)\ntarget_link_libraries(averaging_server ${catkin_LIBRARIES})\n\nadd_executable(averaging_client src/averaging_client.cpp)\ntarget_link_libraries(averaging_client ${catkin_LIBRARIES})\n\nadd_executable(do_dishes_server src/do_dishes_server.cpp)\ntarget_link_libraries(do_dishes_server ${catkin_LIBRARIES})\n\nadd_executable(do_dishes_client src/do_dishes_client.cpp)\ntarget_link_libraries(do_dishes_client ${catkin_LIBRARIES})\n\nadd_executable(shape_server src/shape_server.cpp)\ntarget_link_libraries(shape_server ${catkin_LIBRARIES})\n\nadd_executable(shape_client src/shape_client.cpp)\ntarget_link_libraries(shape_client ${catkin_LIBRARIES})\n```\n\n接着记得在`package.xml`文件中加入如下信息：\n\n~~~xml\n<build_depend>turtle_actionlib</build_depend><build_export_depend>turtle_actionlib</build_export_depend><exec_depend>turtle_actionlib</exec_depend>\n~~~\n\n工作空间下执行`catkin_make`命令。\n\n# 运行行为\n\n终端启动ROS：\n\n```shell\nroscore\n```\n\n运行小乌龟：\n\n~~~\nrosrun turtlesim turtlesim_node \n~~~\n\n运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials shape_client \n```\n\n运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials shape_server\n```\n执行命令查看反馈信息：\n\n~~~\nrostopic echo /turtle_shape/feedback\n~~~\n\n程序执行完并没有反馈信息输出，因为没有涉及到反馈信息。\n\n执行命令查看结果信息：\n\n~~~\nrostopic echo /turtle_shape/result\n~~~\n\n小乌龟画完五边形，会有信息输出：\n\n~~~\nheader: \n  seq: 0\n  stamp: \n    secs: 1522547343\n    nsecs: 139139044\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522547324\n      nsecs: 173274728\n    id: \"/test_shape-1-1522547324.173274728\"\n  status: 3\n  text: ''\nresult: \n  interior_angle: 1.88495564461\n  apothem: 1.05172204971\n---\n~~~\n\n小乌龟画图的效果：\n\n{% asset_img 五边形.png  %}\n\n执行命令`rqt_graph`查看节点图如下所示：\n\n{% asset_img 节点图.png  %}\n\n理解分析：\n\n服务器是作为ROS中的一个节点存在的，该节点名称为`/turtle_shape`，它会发布消息到话题`/turtle_shape/feedback`、　`/turtle_shape/result`、`/turtle_shape/status`，客户端通过订阅这些话题获取到服务器执行客户端赋予的任务的完成进度信息；服务器还发布消息到`/turtle1/cmd_vel`话题，`/turtlesim`订阅了该话题，以此来控制小乌龟运动。同时，服务器订阅了`turtle_shape/goal`、`/turtle_shape/cancel`、`/turtle/pose`三个话题，服务器通过话题`turtle_shape/goal`获取到客户端发布的目标信息，通过`turtle_shape/cancel`话题获取到客户端发布的中断消息。\n\n客户端也是一个节点`test_shape`，该节点订阅了`/turtle_shape/feedback`、　`/turtle_shape/result`、`/turtle_shape/status`三个话题，并发布消息到`/turtle_shape/goal`和`/turtle_shape/cancel`话题，前者使的服务器获取到客户端发布的任务目标，后者是客户端告知服务器中断任务停止执行的途径。\n\n根据上面的节点图，笔者总结了一下actionlib SimpleAction的简单交互图，帮助自己理解。笔者理解的是`feedback`、`result`、`status`、`goal`、`cancel`，这些话题由于actionlib机制的存在会自动创建，并且ActionServer和ActionClient会自动发布或者订阅这些话题，这也许就是actionlib的作用了。仔细想想，其实和简单的消息发布器、接收器的核心思想是一样的。（这一点理解在官网的介绍中得到验证，“action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息”）\n\n{% asset_img 交互图.png  %}\n\n如果要画其他多边形，将客户端文件中的`goal`对象的`edges`值设为相应的边数即可。","source":"_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形.md","raw":"---\ntitle: ROS学习之actionlib库（４）-实践之小乌龟画五边形\ndate: 2018-03-31 11:19:47\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中actionlib使用的学习内容。\n\n<!--more-->\n\n本例程并没有创建`.action`文件生成消息，在安装ROS时，在`opt/ros/kinetic/`路径中已经包含了我们需要的文件，其实就是一个依赖库`turtle_actionlib`。这一点不同就需要在`CMakeList.txt`和`package.xml`文件中手动添加一些信息，后续的内容会提到。\n\n# 创建行为服务器\n\n创建文件`actionlib_tutorials/src/shape_server.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <turtlesim/Pose.h>\n#include <actionlib/server/simple_action_server.h>\n#include <cmath>\n#include <math.h>\n#include <angles/angles.h>\n\n#include <geometry_msgs/Twist.h>\n#include <turtle_actionlib/ShapeAction.h>\n\n// This class computes the command_velocities of the turtle to draw regular polygons \nclass ShapeAction\n{\npublic:\n  ShapeAction(std::string name) : \n    as_(nh_, name, false),\n    action_name_(name)\n  {\n    //register the goal and feeback callbacks\n    as_.registerGoalCallback(boost::bind(&ShapeAction::goalCB, this));\n    as_.registerPreemptCallback(boost::bind(&ShapeAction::preemptCB, this));\n\n    //subscribe to the data topic of interest\n    sub_ = nh_.subscribe(\"/turtle1/pose\", 1, &ShapeAction::controlCB, this);\n    pub_ = nh_.advertise<geometry_msgs::Twist>(\"/turtle1/cmd_vel\", 1);\n\n    as_.start();\n  }\n\n  ~ShapeAction(void)\n  {\n  }\n\n  void goalCB()\n  {\n    // accept the new goal\n    turtle_actionlib::ShapeGoal goal = *as_.acceptNewGoal();\n    //save the goal as private variables\n    edges_ = goal.edges;\n    radius_ = goal.radius;\n\n    // reset helper variables\n    interior_angle_ = ((edges_-2)*M_PI)/edges_;\n    apothem_ = radius_*cos(M_PI/edges_);\n    //compute the side length of the polygon\n    side_len_ = apothem_ * 2* tan( M_PI/edges_);\n    //store the result values\n    result_.apothem = apothem_;\n    result_.interior_angle = interior_angle_;\n    edge_progress_ =0;\n    start_edge_ = true;\n  }\n\n  void preemptCB()\n  {\n    ROS_INFO(\"%s: Preempted\", action_name_.c_str());\n    // set the action state to preempted\n    as_.setPreempted();\n  }\n\n  void controlCB(const turtlesim::Pose::ConstPtr& msg)\n  {\n    // make sure that the action hasn't been canceled\n    if (!as_.isActive())\n      return;\n  \n    if (edge_progress_ < edges_)\n    {\n      // scalar values for drive the turtle faster and straighter\n      double l_scale = 6.0;\n      double a_scale = 6.0;\n      double error_tol = 0.00001;\n\n      if (start_edge_)\n      {\n        start_x_ = msg->x;\n        start_y_ = msg->y;\n        start_theta_ = msg->theta;\n        start_edge_ = false;\n      }\n\n      // compute the distance and theta error for the shape\n      dis_error_ = side_len_ - fabs(sqrt((start_x_- msg->x)*(start_x_-msg->x) + (start_y_-msg->y)*(start_y_-msg->y)));\n      theta_error_ = angles::normalize_angle_positive(M_PI - interior_angle_ - (msg->theta - start_theta_));\n     \n      if (dis_error_ > error_tol)\n      {\n        command_.linear.x = l_scale*dis_error_;\n        command_.angular.z = 0;\n      }\n      else if (dis_error_ < error_tol && fabs(theta_error_)> error_tol)\n      { \n        command_.linear.x = 0;\n        command_.angular.z = a_scale*theta_error_;\n      }\n      else if (dis_error_ < error_tol && fabs(theta_error_)< error_tol)\n      {\n        command_.linear.x = 0;\n        command_.angular.z = 0;\n        start_edge_ = true;\n        edge_progress_++;\n      }  \n      else\n      {\n        command_.linear.x = l_scale*dis_error_;\n        command_.angular.z = a_scale*theta_error_;\n      } \n      // publish the velocity command\n      pub_.publish(command_);\n      \n    } \n    else\n    {          \n      ROS_INFO(\"%s: Succeeded\", action_name_.c_str());\n      // set the action state to succeeded\n      as_.setSucceeded(result_);\n    }   \n  }\n\nprotected:\n  ros::NodeHandle nh_;\n  actionlib::SimpleActionServer<turtle_actionlib::ShapeAction> as_;\n  std::string action_name_;\n  double radius_, apothem_, interior_angle_, side_len_;\n  double start_x_, start_y_, start_theta_;\n  double dis_error_, theta_error_;\n  int edges_ , edge_progress_;\n  bool start_edge_;\n  geometry_msgs::Twist command_;\n  turtle_actionlib::ShapeResult result_;\n  ros::Subscriber sub_;\n  ros::Publisher pub_;\n};\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"turtle_shape\");\n\n  ShapeAction shape(ros::this_node::getName());\n  ros::spin();\n\n  return 0;\n}\n```\n\n# 创建行为客户端\n\n创建行为客户端文件`actionlib_tutorials/src/shape_client.cpp`：\n\n```c++\n#include <ros/ros.h>\n#include <actionlib/client/simple_action_client.h>\n#include <actionlib/client/terminal_state.h>\n#include <turtle_actionlib/ShapeAction.h>\n\nint main (int argc, char **argv)\n{\n  ros::init(argc, argv, \"test_shape\"); \n\n  // create the action client\n  // true causes the client to spin it's own thread\n  actionlib::SimpleActionClient<turtle_actionlib::ShapeAction> ac(\"turtle_shape\", true); \n\n  ROS_INFO(\"Waiting for action server to start.\");\n  // wait for the action server to start\n  ac.waitForServer(); //will wait for infinite time\n \n  ROS_INFO(\"Action server started, sending goal.\");\n  // send a goal to the action \n  turtle_actionlib::ShapeGoal goal;\n  goal.edges = 5;\n  goal.radius = 1.3;\n  ac.sendGoal(goal);\n  \n  //wait for the action to return\n  bool finished_before_timeout = ac.waitForResult(ros::Duration(40.0));\n\n  if (finished_before_timeout)\n    {\n      actionlib::SimpleClientGoalState state = ac.getState();\n      ROS_INFO(\"Action finished: %s\",state.toString().c_str());\n    }\n  else  \n    ROS_INFO(\"Action did not finish before the time out.\");\n\n  //exit\n  return 0;\n}\n```\n\n# 编译行为\n\n**注意**：\n\n本例程并没有创建`.action`文件生成消息，而是使用安装ROS时就有的`opt/ros/kinetic/share/turtle_actionlib`目录下的库文件，所以在`CMakeLists.txt`文件中需要添加如下信息：\n\n~~~cmake\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs turtle_actionlib #turtle_actionlib是新添加的依赖库\n)\n~~~\n\n在`CMakeLists.txt`文件末尾添加以下几行： \n\n```cmake\nadd_executable(shape_server src/shape_server.cpp)\ntarget_link_libraries(shape_server ${catkin_LIBRARIES})\n\nadd_executable(shape_client src/shape_client.cpp)\ntarget_link_libraries(shape_client ${catkin_LIBRARIES})\n```\n\n完整的`CMakeList.txt`文件如下：\n\n```cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(actionlib_tutorials)\n\nfind_package(catkin REQUIRED COMPONENTS\n  actionlib\n  actionlib_msgs\n  message_generation\n  roscpp\n  rospy\n  std_msgs\n)\n\nadd_action_files(\n  FILES\n  Fibonacci.action\n  Averaging.action\n  DoDishes.action\n)\n\ngenerate_messages(\n  DEPENDENCIES\n  actionlib_msgs\n  std_msgs\n)\n\ncatkin_package(\n   CATKIN_DEPENDS actionlib_msgs turtle_actionlib\n)\n\n\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\nadd_executable(fibonacci_server src/fibonacci_server.cpp)\ntarget_link_libraries(fibonacci_server ${catkin_LIBRARIES})\n\nadd_executable(fibonacci_client src/fibonacci_client.cpp)\ntarget_link_libraries(fibonacci_client ${catkin_LIBRARIES})\n\nadd_executable(averaging_server src/averaging_server.cpp)\ntarget_link_libraries(averaging_server ${catkin_LIBRARIES})\n\nadd_executable(averaging_client src/averaging_client.cpp)\ntarget_link_libraries(averaging_client ${catkin_LIBRARIES})\n\nadd_executable(do_dishes_server src/do_dishes_server.cpp)\ntarget_link_libraries(do_dishes_server ${catkin_LIBRARIES})\n\nadd_executable(do_dishes_client src/do_dishes_client.cpp)\ntarget_link_libraries(do_dishes_client ${catkin_LIBRARIES})\n\nadd_executable(shape_server src/shape_server.cpp)\ntarget_link_libraries(shape_server ${catkin_LIBRARIES})\n\nadd_executable(shape_client src/shape_client.cpp)\ntarget_link_libraries(shape_client ${catkin_LIBRARIES})\n```\n\n接着记得在`package.xml`文件中加入如下信息：\n\n~~~xml\n<build_depend>turtle_actionlib</build_depend><build_export_depend>turtle_actionlib</build_export_depend><exec_depend>turtle_actionlib</exec_depend>\n~~~\n\n工作空间下执行`catkin_make`命令。\n\n# 运行行为\n\n终端启动ROS：\n\n```shell\nroscore\n```\n\n运行小乌龟：\n\n~~~\nrosrun turtlesim turtlesim_node \n~~~\n\n运行行为客户端：\n\n```shell\nrosrun actionlib_tutorials shape_client \n```\n\n运行行为服务器：\n\n```shell\nrosrun actionlib_tutorials shape_server\n```\n执行命令查看反馈信息：\n\n~~~\nrostopic echo /turtle_shape/feedback\n~~~\n\n程序执行完并没有反馈信息输出，因为没有涉及到反馈信息。\n\n执行命令查看结果信息：\n\n~~~\nrostopic echo /turtle_shape/result\n~~~\n\n小乌龟画完五边形，会有信息输出：\n\n~~~\nheader: \n  seq: 0\n  stamp: \n    secs: 1522547343\n    nsecs: 139139044\n  frame_id: ''\nstatus: \n  goal_id: \n    stamp: \n      secs: 1522547324\n      nsecs: 173274728\n    id: \"/test_shape-1-1522547324.173274728\"\n  status: 3\n  text: ''\nresult: \n  interior_angle: 1.88495564461\n  apothem: 1.05172204971\n---\n~~~\n\n小乌龟画图的效果：\n\n{% asset_img 五边形.png  %}\n\n执行命令`rqt_graph`查看节点图如下所示：\n\n{% asset_img 节点图.png  %}\n\n理解分析：\n\n服务器是作为ROS中的一个节点存在的，该节点名称为`/turtle_shape`，它会发布消息到话题`/turtle_shape/feedback`、　`/turtle_shape/result`、`/turtle_shape/status`，客户端通过订阅这些话题获取到服务器执行客户端赋予的任务的完成进度信息；服务器还发布消息到`/turtle1/cmd_vel`话题，`/turtlesim`订阅了该话题，以此来控制小乌龟运动。同时，服务器订阅了`turtle_shape/goal`、`/turtle_shape/cancel`、`/turtle/pose`三个话题，服务器通过话题`turtle_shape/goal`获取到客户端发布的目标信息，通过`turtle_shape/cancel`话题获取到客户端发布的中断消息。\n\n客户端也是一个节点`test_shape`，该节点订阅了`/turtle_shape/feedback`、　`/turtle_shape/result`、`/turtle_shape/status`三个话题，并发布消息到`/turtle_shape/goal`和`/turtle_shape/cancel`话题，前者使的服务器获取到客户端发布的任务目标，后者是客户端告知服务器中断任务停止执行的途径。\n\n根据上面的节点图，笔者总结了一下actionlib SimpleAction的简单交互图，帮助自己理解。笔者理解的是`feedback`、`result`、`status`、`goal`、`cancel`，这些话题由于actionlib机制的存在会自动创建，并且ActionServer和ActionClient会自动发布或者订阅这些话题，这也许就是actionlib的作用了。仔细想想，其实和简单的消息发布器、接收器的核心思想是一样的。（这一点理解在官网的介绍中得到验证，“action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息”）\n\n{% asset_img 交互图.png  %}\n\n如果要画其他多边形，将客户端文件中的`goal`对象的`edges`值设为相应的边数即可。","slug":"ROS学习之actionlib库（４）-实践之小乌龟画五边形","published":1,"updated":"2019-05-30T12:29:26.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedbzw00c0qlcrc64a54zr","content":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>\n<a id=\"more\"></a>\n<p>本例程并没有创建<code>.action</code>文件生成消息，在安装ROS时，在<code>opt/ros/kinetic/</code>路径中已经包含了我们需要的文件，其实就是一个依赖库<code>turtle_actionlib</code>。这一点不同就需要在<code>CMakeList.txt</code>和<code>package.xml</code>文件中手动添加一些信息，后续的内容会提到。</p>\n<h1 id=\"创建行为服务器\"><a href=\"#创建行为服务器\" class=\"headerlink\" title=\"创建行为服务器\"></a>创建行为服务器</h1><p>创建文件<code>actionlib_tutorials/src/shape_server.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;turtlesim/Pose.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/server/simple_action_server.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;math.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;angles/angles.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;geometry_msgs/Twist.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;turtle_actionlib/ShapeAction.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This class computes the command_velocities of the turtle to draw regular polygons </span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ShapeAction</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">  ShapeAction(<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> name) : </span><br><span class=\"line\">    as_(nh_, name, <span class=\"literal\">false</span>),</span><br><span class=\"line\">    action_name_(name)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    <span class=\"comment\">//register the goal and feeback callbacks</span></span><br><span class=\"line\">    as_.registerGoalCallback(boost::bind(&amp;ShapeAction::goalCB, <span class=\"keyword\">this</span>));</span><br><span class=\"line\">    as_.registerPreemptCallback(boost::bind(&amp;ShapeAction::preemptCB, <span class=\"keyword\">this</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//subscribe to the data topic of interest</span></span><br><span class=\"line\">    sub_ = nh_.subscribe(<span class=\"string\">\"/turtle1/pose\"</span>, <span class=\"number\">1</span>, &amp;ShapeAction::controlCB, <span class=\"keyword\">this</span>);</span><br><span class=\"line\">    pub_ = nh_.advertise&lt;geometry_msgs::Twist&gt;(<span class=\"string\">\"/turtle1/cmd_vel\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    as_.start();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  ~ShapeAction(<span class=\"keyword\">void</span>)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">goalCB</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// accept the new goal</span></span><br><span class=\"line\">    turtle_actionlib::ShapeGoal goal = *as_.acceptNewGoal();</span><br><span class=\"line\">    <span class=\"comment\">//save the goal as private variables</span></span><br><span class=\"line\">    edges_ = goal.edges;</span><br><span class=\"line\">    radius_ = goal.radius;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// reset helper variables</span></span><br><span class=\"line\">    interior_angle_ = ((edges_<span class=\"number\">-2</span>)*M_PI)/edges_;</span><br><span class=\"line\">    apothem_ = radius_*<span class=\"built_in\">cos</span>(M_PI/edges_);</span><br><span class=\"line\">    <span class=\"comment\">//compute the side length of the polygon</span></span><br><span class=\"line\">    side_len_ = apothem_ * <span class=\"number\">2</span>* <span class=\"built_in\">tan</span>( M_PI/edges_);</span><br><span class=\"line\">    <span class=\"comment\">//store the result values</span></span><br><span class=\"line\">    result_.apothem = apothem_;</span><br><span class=\"line\">    result_.interior_angle = interior_angle_;</span><br><span class=\"line\">    edge_progress_ =<span class=\"number\">0</span>;</span><br><span class=\"line\">    start_edge_ = <span class=\"literal\">true</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preemptCB</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"%s: Preempted\"</span>, action_name_.c_str());</span><br><span class=\"line\">    <span class=\"comment\">// set the action state to preempted</span></span><br><span class=\"line\">    as_.setPreempted();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">controlCB</span><span class=\"params\">(<span class=\"keyword\">const</span> turtlesim::Pose::ConstPtr&amp; msg)</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// make sure that the action hasn't been canceled</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!as_.isActive())</span><br><span class=\"line\">      <span class=\"keyword\">return</span>;</span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"keyword\">if</span> (edge_progress_ &lt; edges_)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"comment\">// scalar values for drive the turtle faster and straighter</span></span><br><span class=\"line\">      <span class=\"keyword\">double</span> l_scale = <span class=\"number\">6.0</span>;</span><br><span class=\"line\">      <span class=\"keyword\">double</span> a_scale = <span class=\"number\">6.0</span>;</span><br><span class=\"line\">      <span class=\"keyword\">double</span> error_tol = <span class=\"number\">0.00001</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">if</span> (start_edge_)</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        start_x_ = msg-&gt;x;</span><br><span class=\"line\">        start_y_ = msg-&gt;y;</span><br><span class=\"line\">        start_theta_ = msg-&gt;theta;</span><br><span class=\"line\">        start_edge_ = <span class=\"literal\">false</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// compute the distance and theta error for the shape</span></span><br><span class=\"line\">      dis_error_ = side_len_ - <span class=\"built_in\">fabs</span>(<span class=\"built_in\">sqrt</span>((start_x_- msg-&gt;x)*(start_x_-msg-&gt;x) + (start_y_-msg-&gt;y)*(start_y_-msg-&gt;y)));</span><br><span class=\"line\">      theta_error_ = angles::normalize_angle_positive(M_PI - interior_angle_ - (msg-&gt;theta - start_theta_));</span><br><span class=\"line\">     </span><br><span class=\"line\">      <span class=\"keyword\">if</span> (dis_error_ &gt; error_tol)</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        command_.linear.x = l_scale*dis_error_;</span><br><span class=\"line\">        command_.angular.z = <span class=\"number\">0</span>;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (dis_error_ &lt; error_tol &amp;&amp; <span class=\"built_in\">fabs</span>(theta_error_)&gt; error_tol)</span><br><span class=\"line\">      &#123; </span><br><span class=\"line\">        command_.linear.x = <span class=\"number\">0</span>;</span><br><span class=\"line\">        command_.angular.z = a_scale*theta_error_;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (dis_error_ &lt; error_tol &amp;&amp; <span class=\"built_in\">fabs</span>(theta_error_)&lt; error_tol)</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        command_.linear.x = <span class=\"number\">0</span>;</span><br><span class=\"line\">        command_.angular.z = <span class=\"number\">0</span>;</span><br><span class=\"line\">        start_edge_ = <span class=\"literal\">true</span>;</span><br><span class=\"line\">        edge_progress_++;</span><br><span class=\"line\">      &#125;  </span><br><span class=\"line\">      <span class=\"keyword\">else</span></span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        command_.linear.x = l_scale*dis_error_;</span><br><span class=\"line\">        command_.angular.z = a_scale*theta_error_;</span><br><span class=\"line\">      &#125; </span><br><span class=\"line\">      <span class=\"comment\">// publish the velocity command</span></span><br><span class=\"line\">      pub_.publish(command_);</span><br><span class=\"line\">      </span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">    &#123;          </span><br><span class=\"line\">      ROS_INFO(<span class=\"string\">\"%s: Succeeded\"</span>, action_name_.c_str());</span><br><span class=\"line\">      <span class=\"comment\">// set the action state to succeeded</span></span><br><span class=\"line\">      as_.setSucceeded(result_);</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">  ros::NodeHandle nh_;</span><br><span class=\"line\">  actionlib::SimpleActionServer&lt;turtle_actionlib::ShapeAction&gt; as_;</span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> action_name_;</span><br><span class=\"line\">  <span class=\"keyword\">double</span> radius_, apothem_, interior_angle_, side_len_;</span><br><span class=\"line\">  <span class=\"keyword\">double</span> start_x_, start_y_, start_theta_;</span><br><span class=\"line\">  <span class=\"keyword\">double</span> dis_error_, theta_error_;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> edges_ , edge_progress_;</span><br><span class=\"line\">  <span class=\"keyword\">bool</span> start_edge_;</span><br><span class=\"line\">  geometry_msgs::Twist command_;</span><br><span class=\"line\">  turtle_actionlib::ShapeResult result_;</span><br><span class=\"line\">  ros::Subscriber sub_;</span><br><span class=\"line\">  ros::Publisher pub_;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"turtle_shape\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  ShapeAction shape(ros::this_node::getName());</span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"创建行为客户端\"><a href=\"#创建行为客户端\" class=\"headerlink\" title=\"创建行为客户端\"></a>创建行为客户端</h1><p>创建行为客户端文件<code>actionlib_tutorials/src/shape_client.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/simple_action_client.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;actionlib/client/terminal_state.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;turtle_actionlib/ShapeAction.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"test_shape\"</span>); </span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// create the action client</span></span><br><span class=\"line\">  <span class=\"comment\">// true causes the client to spin it's own thread</span></span><br><span class=\"line\">  actionlib::SimpleActionClient&lt;turtle_actionlib::ShapeAction&gt; ac(<span class=\"string\">\"turtle_shape\"</span>, <span class=\"literal\">true</span>); </span><br><span class=\"line\"></span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Waiting for action server to start.\"</span>);</span><br><span class=\"line\">  <span class=\"comment\">// wait for the action server to start</span></span><br><span class=\"line\">  ac.waitForServer(); <span class=\"comment\">//will wait for infinite time</span></span><br><span class=\"line\"> </span><br><span class=\"line\">  ROS_INFO(<span class=\"string\">\"Action server started, sending goal.\"</span>);</span><br><span class=\"line\">  <span class=\"comment\">// send a goal to the action </span></span><br><span class=\"line\">  turtle_actionlib::ShapeGoal goal;</span><br><span class=\"line\">  goal.edges = <span class=\"number\">5</span>;</span><br><span class=\"line\">  goal.radius = <span class=\"number\">1.3</span>;</span><br><span class=\"line\">  ac.sendGoal(goal);</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\">//wait for the action to return</span></span><br><span class=\"line\">  <span class=\"keyword\">bool</span> finished_before_timeout = ac.waitForResult(ros::Duration(<span class=\"number\">40.0</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (finished_before_timeout)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      actionlib::SimpleClientGoalState state = ac.getState();</span><br><span class=\"line\">      ROS_INFO(<span class=\"string\">\"Action finished: %s\"</span>,state.toString().c_str());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  <span class=\"keyword\">else</span>  </span><br><span class=\"line\">    ROS_INFO(<span class=\"string\">\"Action did not finish before the time out.\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//exit</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"编译行为\"><a href=\"#编译行为\" class=\"headerlink\" title=\"编译行为\"></a>编译行为</h1><p><strong>注意</strong>：</p>\n<p>本例程并没有创建<code>.action</code>文件生成消息，而是使用安装ROS时就有的<code>opt/ros/kinetic/share/turtle_actionlib</code>目录下的库文件，所以在<code>CMakeLists.txt</code>文件中需要添加如下信息：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs turtle_actionlib <span class=\"comment\">#turtle_actionlib是新添加的依赖库</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>在<code>CMakeLists.txt</code>文件末尾添加以下几行： </p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(shape_server src/shape_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(shape_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(shape_client src/shape_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(shape_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>完整的<code>CMakeList.txt</code>文件如下：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.8</span>.<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(actionlib_tutorials)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  actionlib</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  message_generation</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_action_files(</span><br><span class=\"line\">  FILES</span><br><span class=\"line\">  Fibonacci.action</span><br><span class=\"line\">  Averaging.action</span><br><span class=\"line\">  DoDishes.action</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">generate_messages(</span><br><span class=\"line\">  DEPENDENCIES</span><br><span class=\"line\">  actionlib_msgs</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\">   CATKIN_DEPENDS actionlib_msgs turtle_actionlib</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(</span><br><span class=\"line\"><span class=\"comment\"># include</span></span><br><span class=\"line\">  <span class=\"variable\">$&#123;catkin_INCLUDE_DIRS&#125;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_server src/fibonacci_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(fibonacci_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(fibonacci_client src/fibonacci_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(fibonacci_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(averaging_server src/averaging_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(averaging_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(averaging_client src/averaging_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(averaging_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(do_dishes_server src/do_dishes_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(do_dishes_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(do_dishes_client src/do_dishes_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(do_dishes_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(shape_server src/shape_server.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(shape_server <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(shape_client src/shape_client.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(shape_client <span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>接着记得在<code>package.xml</code>文件中加入如下信息：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>turtle_actionlib<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">build_export_depend</span>&gt;</span>turtle_actionlib<span class=\"tag\">&lt;/<span class=\"name\">build_export_depend</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">exec_depend</span>&gt;</span>turtle_actionlib<span class=\"tag\">&lt;/<span class=\"name\">exec_depend</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>工作空间下执行<code>catkin_make</code>命令。</p>\n<h1 id=\"运行行为\"><a href=\"#运行行为\" class=\"headerlink\" title=\"运行行为\"></a>运行行为</h1><p>终端启动ROS：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roscore</span><br></pre></td></tr></table></figure>\n<p>运行小乌龟：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun turtlesim turtlesim_node</span><br></pre></td></tr></table></figure>\n<p>运行行为客户端：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials shape_client</span><br></pre></td></tr></table></figure>\n<p>运行行为服务器：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun actionlib_tutorials shape_server</span><br></pre></td></tr></table></figure>\n<p>执行命令查看反馈信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic echo /turtle_shape/feedback</span><br></pre></td></tr></table></figure>\n<p>程序执行完并没有反馈信息输出，因为没有涉及到反馈信息。</p>\n<p>执行命令查看结果信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rostopic echo /turtle_shape/result</span><br></pre></td></tr></table></figure>\n<p>小乌龟画完五边形，会有信息输出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">header: </span><br><span class=\"line\">  seq: 0</span><br><span class=\"line\">  stamp: </span><br><span class=\"line\">    secs: 1522547343</span><br><span class=\"line\">    nsecs: 139139044</span><br><span class=\"line\">  frame_id: &apos;&apos;</span><br><span class=\"line\">status: </span><br><span class=\"line\">  goal_id: </span><br><span class=\"line\">    stamp: </span><br><span class=\"line\">      secs: 1522547324</span><br><span class=\"line\">      nsecs: 173274728</span><br><span class=\"line\">    id: &quot;/test_shape-1-1522547324.173274728&quot;</span><br><span class=\"line\">  status: 3</span><br><span class=\"line\">  text: &apos;&apos;</span><br><span class=\"line\">result: </span><br><span class=\"line\">  interior_angle: 1.88495564461</span><br><span class=\"line\">  apothem: 1.05172204971</span><br><span class=\"line\">---</span><br></pre></td></tr></table></figure>\n<p>小乌龟画图的效果：</p>\n<img src=\"/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/五边形.png\">\n<p>执行命令<code>rqt_graph</code>查看节点图如下所示：</p>\n<img src=\"/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/节点图.png\">\n<p>理解分析：</p>\n<p>服务器是作为ROS中的一个节点存在的，该节点名称为<code>/turtle_shape</code>，它会发布消息到话题<code>/turtle_shape/feedback</code>、　<code>/turtle_shape/result</code>、<code>/turtle_shape/status</code>，客户端通过订阅这些话题获取到服务器执行客户端赋予的任务的完成进度信息；服务器还发布消息到<code>/turtle1/cmd_vel</code>话题，<code>/turtlesim</code>订阅了该话题，以此来控制小乌龟运动。同时，服务器订阅了<code>turtle_shape/goal</code>、<code>/turtle_shape/cancel</code>、<code>/turtle/pose</code>三个话题，服务器通过话题<code>turtle_shape/goal</code>获取到客户端发布的目标信息，通过<code>turtle_shape/cancel</code>话题获取到客户端发布的中断消息。</p>\n<p>客户端也是一个节点<code>test_shape</code>，该节点订阅了<code>/turtle_shape/feedback</code>、　<code>/turtle_shape/result</code>、<code>/turtle_shape/status</code>三个话题，并发布消息到<code>/turtle_shape/goal</code>和<code>/turtle_shape/cancel</code>话题，前者使的服务器获取到客户端发布的任务目标，后者是客户端告知服务器中断任务停止执行的途径。</p>\n<p>根据上面的节点图，笔者总结了一下actionlib SimpleAction的简单交互图，帮助自己理解。笔者理解的是<code>feedback</code>、<code>result</code>、<code>status</code>、<code>goal</code>、<code>cancel</code>，这些话题由于actionlib机制的存在会自动创建，并且ActionServer和ActionClient会自动发布或者订阅这些话题，这也许就是actionlib的作用了。仔细想想，其实和简单的消息发布器、接收器的核心思想是一样的。（这一点理解在官网的介绍中得到验证，“action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息”）</p>\n<img src=\"/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/交互图.png\">\n<p>如果要画其他多边形，将客户端文件中的<code>goal</code>对象的<code>edges</code>值设为相应的边数即可。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中actionlib使用的学习内容。</p>","more":"<p>本例程并没有创建<code>.action</code>文件生成消息，在安装ROS时，在<code>opt/ros/kinetic/</code>路径中已经包含了我们需要的文件，其实就是一个依赖库<code>turtle_actionlib</code>。这一点不同就需要在<code>CMakeList.txt</code>和<code>package.xml</code>文件中手动添加一些信息，后续的内容会提到。</p>\n<h1 id=\"创建行为服务器\"><a href=\"#创建行为服务器\" class=\"headerlink\" title=\"创建行为服务器\"></a>创建行为服务器</h1><p>创建文件<code>actionlib_tutorials/src/shape_server.cpp</code>：</p>\n<!--�255-->\n<h1 id=\"创建行为客户端\"><a href=\"#创建行为客户端\" class=\"headerlink\" title=\"创建行为客户端\"></a>创建行为客户端</h1><p>创建行为客户端文件<code>actionlib_tutorials/src/shape_client.cpp</code>：</p>\n<!--�256-->\n<h1 id=\"编译行为\"><a href=\"#编译行为\" class=\"headerlink\" title=\"编译行为\"></a>编译行为</h1><p><strong>注意</strong>：</p>\n<p>本例程并没有创建<code>.action</code>文件生成消息，而是使用安装ROS时就有的<code>opt/ros/kinetic/share/turtle_actionlib</code>目录下的库文件，所以在<code>CMakeLists.txt</code>文件中需要添加如下信息：</p>\n<!--�257-->\n<p>在<code>CMakeLists.txt</code>文件末尾添加以下几行： </p>\n<!--�258-->\n<p>完整的<code>CMakeList.txt</code>文件如下：</p>\n<!--�259-->\n<p>接着记得在<code>package.xml</code>文件中加入如下信息：</p>\n<!--�260-->\n<p>工作空间下执行<code>catkin_make</code>命令。</p>\n<h1 id=\"运行行为\"><a href=\"#运行行为\" class=\"headerlink\" title=\"运行行为\"></a>运行行为</h1><p>终端启动ROS：</p>\n<!--�261-->\n<p>运行小乌龟：</p>\n<!--�262-->\n<p>运行行为客户端：</p>\n<!--�263-->\n<p>运行行为服务器：</p>\n<!--�264-->\n<p>执行命令查看反馈信息：</p>\n<!--�265-->\n<p>程序执行完并没有反馈信息输出，因为没有涉及到反馈信息。</p>\n<p>执行命令查看结果信息：</p>\n<!--�266-->\n<p>小乌龟画完五边形，会有信息输出：</p>\n<!--�267-->\n<p>小乌龟画图的效果：</p>\n<img src=\"/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/五边形.png\">\n<p>执行命令<code>rqt_graph</code>查看节点图如下所示：</p>\n<img src=\"/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/节点图.png\">\n<p>理解分析：</p>\n<p>服务器是作为ROS中的一个节点存在的，该节点名称为<code>/turtle_shape</code>，它会发布消息到话题<code>/turtle_shape/feedback</code>、　<code>/turtle_shape/result</code>、<code>/turtle_shape/status</code>，客户端通过订阅这些话题获取到服务器执行客户端赋予的任务的完成进度信息；服务器还发布消息到<code>/turtle1/cmd_vel</code>话题，<code>/turtlesim</code>订阅了该话题，以此来控制小乌龟运动。同时，服务器订阅了<code>turtle_shape/goal</code>、<code>/turtle_shape/cancel</code>、<code>/turtle/pose</code>三个话题，服务器通过话题<code>turtle_shape/goal</code>获取到客户端发布的目标信息，通过<code>turtle_shape/cancel</code>话题获取到客户端发布的中断消息。</p>\n<p>客户端也是一个节点<code>test_shape</code>，该节点订阅了<code>/turtle_shape/feedback</code>、　<code>/turtle_shape/result</code>、<code>/turtle_shape/status</code>三个话题，并发布消息到<code>/turtle_shape/goal</code>和<code>/turtle_shape/cancel</code>话题，前者使的服务器获取到客户端发布的任务目标，后者是客户端告知服务器中断任务停止执行的途径。</p>\n<p>根据上面的节点图，笔者总结了一下actionlib SimpleAction的简单交互图，帮助自己理解。笔者理解的是<code>feedback</code>、<code>result</code>、<code>status</code>、<code>goal</code>、<code>cancel</code>，这些话题由于actionlib机制的存在会自动创建，并且ActionServer和ActionClient会自动发布或者订阅这些话题，这也许就是actionlib的作用了。仔细想想，其实和简单的消息发布器、接收器的核心思想是一样的。（这一点理解在官网的介绍中得到验证，“action客户端和服务端通过预定义的ROS Action协议通信，该通信机制基于ROS消息”）</p>\n<img src=\"/2018/03/31/ROS学习之actionlib库（４）-实践之小乌龟画五边形/交互图.png\">\n<p>如果要画其他多边形，将客户端文件中的<code>goal</code>对象的<code>edges</code>值设为相应的边数即可。</p>"},{"title":"ROS学习之roslaunch","date":"2018-05-24T12:43:34.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中roslaunch使用的学习内容。\n\n<!--more--->\n\n### wiki官方文档\n\nroslaunch命令：http://wiki.ros.org/roslaunch/Commandline%20Tools\n\nlaunch文件格式：http://wiki.ros.org/roslaunch/XML\n\n### 介绍\n\nrosrun只能运行一个node，roslaunch可以同时运行多个nodes。roslaunch工具是ros中python实现的程序启动工具，可以通过读取启动文件（launch file）中的参数配置、属性配置等，同时启动节点管理器（master）和多个节点，在启动任何一个节点前，`roslaunch` 将会确定 **roscore节点（节点管理器）** 是否已经在运行，如果没有，自动启动它；可以在本地或者远程（使用SSH）启动ROS节点，要通过参数服务器设置参数。\n\n`roscore`会做三件事： \n\n- 启动master节点，该节点是隐藏的，用于通过消息名查询目标节点，实现消息、服务在各个节点之间的连接 \n- 启动参数服务器parameter server，用于设置与查询参数 \n- 启动日志节点，记录所有消息收发和stdout、stderr，目前roscore暂不会加入其他功能\n\n|     任务名称     |                          任务功能                          | 特性 |\n| :--------------: | :--------------------------------------------------------: | :--: |\n|      master      | 通过消息名查询目标节点，实现消息、服务在各个节点之间的连接 | 隐藏 |\n| parameter server |                       设置与查询参数                       |  -   |\n|     日志节点     |              记录所有消息收发和stdout、stderr              |  -   |\n\n任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以*.launch*作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。\n\nroslaunch命令执行launch文件的命令格式：\n\n~~~shell\nroslaunch [package] [filename.launch]\n~~~\n\n###  launch文件编写\n\n一般格式：\n\n~~~xml\n<launch>\n    <node .../>\n    <rosparam ..../>\n    <param .../>\n    <include .../>\n    <env .../>\n    <remap .../>\n    <arg .../>\n    <group> \n        ... \n    </group>\n</launch>\n~~~\n\n- `<launch>...</launch>`：根元素，作为放置其他元素的容器，其他元素必须在该标记之间。\n\n- `<node .../>`：标记用于定义一个希望启动的ROS节点。格式：\n\n  ```xml\n  <node name=\"bar1\" pkg=\"foo_pkg\" type=\"bar\" />\n  ```\n\n  > 三个必须的属性：pkg, type, name。\n  >\n  > - pkg是节点所在的程序包名字；\n  > - type是节点的类型，是可执行文件的名字；\n  > - name是节点名字，不能包含namespace，可以任意给出的，它覆盖了原有文件中ros::init指定的node name；\n  > - 在默认状态下，从启动文件启动节点的标准输出被重定向到一个日志文件中，而不是像 `rosrun` 命令那样，将 **log** 信息显示在终端(**console**)。该日志文件的名称是：` ~/.ros/log/run_id/node_name-number-stout.log` 其中，run_id 是节点管理器（master）启动时生成的一个唯一标示符；\n  > - 如果需要将标准输出信息输出到终端，使用属性`output`，即`output=screen`；\n  > - 其他属性：args（可以通过命令行启动参数赋值，将参数传递给节点）、ns（节点定义为某个namespace下）等。\n\n- `<param .../>`：定义一个设置在参数服务器中的参数，该标记可以放在`<node .../>`标记内部，作为私有参数。格式：\n\n  ~~~xml\n  <param name=\"publish_frequency\" type=\"double\" value=\"10.0\" />\n  ~~~\n\n  name是参数名，可以给出参数所在namesapce；value是可选属性，用于定义参数值，省略时要通过其他方式（命令行或者binfile、testfile文件）指定参数值；type定义参数的数据类型，也是可选属性，省略时roslaunch会尝试自动定义参数的类型（根据参数的形式进行判断）。\n\n- `<include .../>`：允许当前launch文件包含（调用）其他launch文件，包括该文件中的所有nodes和parameters。格式：\n\n  ~~~xml\n  <include file=”$(find package_name)/launch_file_name”/>\n  ~~~\n\n  需要写出该launch文件的绝对路径，比较繁琐，一般使用上述方式。roslaunch会搜索package下的所有子目录；因此，必须给出package_name。另外，include也支持ns属性，将它的内容放进指定的namespace，格式：\n\n  ~~~xml\n  <include file=”...” ns=”namespace_name”/>\n  ~~~\n\n- `<arg .../>`：启动参数，是局部的，只能在一个launch文件中使用，类似于局部变量，声明格式：\n\n  ~~~xml\n  <arg name=”arg_name”>\n  ~~~\n\n  launch文件中的每个argument必须有指定值。指定argument的值有多种方式，包括命令行赋值、声明argument时赋值。\n\n  - 还支持启动参数，有时也简称为参数甚至args。\n\n  - 命令行赋值。命令格式：\n\n    ```shell\n    roslaunch package_name launch_file_name arg_name:=arg_value\n    ```\n\n  - 声明时赋值（两种形式）。格式：\n\n    ```xml\n    <arg name=”arg_name” default=”arg_name”/>\n    <arg name=”arg_name” value=”arg_name”/>\n    ```\n\n    两种形式的区别在于，命令行参数可以覆盖default，但是不能重写value的值。\n\n  可以通过arg获取变量的值，格式：\n\n  ~~~xml\n  $(arg arg_name)\n  ~~~\n\n  另外，还可以将变量值传给included launch文件，格式：\n\n  ~~~xml\n  <include file=”path-to-file”>\n      <arg name=”arg_name” value=”arg_value”/>\n      ...\n  </include>\n  ~~~\n\n  若在launch文件中，launch文件及其包含的launch文件出现出现相同的arguments，则需在launch文件及included launch文件中同时写：\n\n  ~~~xml\n  <arg name=”arg_name” value=”$(arg arg_name)”/>\n  ~~~\n\n  第一个arg_name表示included launch文件中的argument，第二个arg_name表示launch文件中的argument。其结果是指定的argument在launch文件及included launch文件中都有相同的值。\n\n  在ROS中prarmeter和argument是不同的，虽然翻译一样。parameter是运行中的ROS系统使用的数值，存储在参数服务器（parameter server）中，每个活跃的节点都可以通过 ros::param::get 函数来获取parameter的值，用户也可以通过rosparam来获得parameter的值。而argument只在启动文件内才有意义，它们的值是不能被节点直接获取的。\n\n- `<remap .../>`：重映射。重映射是基于替换的思想，每个重映射包含一个原始名称和一个新名称。每当节点使用重映射中的原始名称时，ROS客户端库就会将它默默地替换成其对应的新名称。例如，运行一个 turtlesim 的实例，如果想要把海龟的姿态数据发布到话题/tim 而不是/turtle1/pose，就可以使用如下命令：\n\n  ~~~shell\n  rosrun turtlesim turtlesim_node turtle1/pose:=tim \n  ~~~\n\n  通过启动文件的方式，只需在启动文件内使用重映射（remap）元素即可：\n\n  ~~~xml\n  <remap from=”turtle1/pose” to ”tim”/>\n  ~~~\n\n  例如，节点`mono`订阅了`/camera/image_raw`话题，但是现在只有`/camera_node/image_raw`话题在发布和`/camera/image_raw`话题一样的数据，可以使用重映射完成数据的订阅，这样就可以使得节点`mono`能够订阅`/camera_node/image_raw`话题的数据：\n\n  ~~~xml\n  <remap from=\"/camera/image_raw\" to=\"/camera_node/image_raw\"/>\n  ~~~\n\n- `<group> ... </group>`：可以将指定的nodes组织起来，只能使用ns、if、unless三个属性。group有两个作用/好处：\n\n  - 可以将几个nodes放进同一个namespace，从而使该组标签有独立的名称空间，格式：\n\n    ~~~xml\n    <group ns=”namespace”>\n        <node pkg=”..” .../>\n        <node pkg=”..” .../>\n        ......\n    </group>\n    ~~~\n\n    如果grouped node已经有它自己的namespace，并且是relative name，那么该node的namespace是其relative name，并以group namespace为后缀。\n\n  - 可以同时启动或者终止一组nodes，格式：\n\n    ~~~xml\n    <group if=”$(arg arg_name)”>\n    \t......\n    </group>\n    <group unless=”$(arg arg_name)”>\n    \t......\n    </group>\n    ~~~\n\n    其中arg_name的值只有0或1，若真，则包含group标签，其中的nodes都可运行；否则其中的nodes都不会运行。​\n\n  ​\n\n\n参考链接：\n\nhttps://blog.csdn.net/fengmengdan/article/details/42984429（启动文件的编写）\n\nhttp://www.cnblogs.com/zjiaxing/p/5542614.html（启动文件的编写）\n\nhttps://www.cnblogs.com/zjiaxing/p/5541841.html（ros命名空间的解释）\n","source":"_posts/ROS学习之roslaunch.md","raw":"---\ntitle: ROS学习之roslaunch\ndate: 2018-05-24 20:43:34\ntags:\n  - roslaunch\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中roslaunch使用的学习内容。\n\n<!--more--->\n\n### wiki官方文档\n\nroslaunch命令：http://wiki.ros.org/roslaunch/Commandline%20Tools\n\nlaunch文件格式：http://wiki.ros.org/roslaunch/XML\n\n### 介绍\n\nrosrun只能运行一个node，roslaunch可以同时运行多个nodes。roslaunch工具是ros中python实现的程序启动工具，可以通过读取启动文件（launch file）中的参数配置、属性配置等，同时启动节点管理器（master）和多个节点，在启动任何一个节点前，`roslaunch` 将会确定 **roscore节点（节点管理器）** 是否已经在运行，如果没有，自动启动它；可以在本地或者远程（使用SSH）启动ROS节点，要通过参数服务器设置参数。\n\n`roscore`会做三件事： \n\n- 启动master节点，该节点是隐藏的，用于通过消息名查询目标节点，实现消息、服务在各个节点之间的连接 \n- 启动参数服务器parameter server，用于设置与查询参数 \n- 启动日志节点，记录所有消息收发和stdout、stderr，目前roscore暂不会加入其他功能\n\n|     任务名称     |                          任务功能                          | 特性 |\n| :--------------: | :--------------------------------------------------------: | :--: |\n|      master      | 通过消息名查询目标节点，实现消息、服务在各个节点之间的连接 | 隐藏 |\n| parameter server |                       设置与查询参数                       |  -   |\n|     日志节点     |              记录所有消息收发和stdout、stderr              |  -   |\n\n任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以*.launch*作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。\n\nroslaunch命令执行launch文件的命令格式：\n\n~~~shell\nroslaunch [package] [filename.launch]\n~~~\n\n###  launch文件编写\n\n一般格式：\n\n~~~xml\n<launch>\n    <node .../>\n    <rosparam ..../>\n    <param .../>\n    <include .../>\n    <env .../>\n    <remap .../>\n    <arg .../>\n    <group> \n        ... \n    </group>\n</launch>\n~~~\n\n- `<launch>...</launch>`：根元素，作为放置其他元素的容器，其他元素必须在该标记之间。\n\n- `<node .../>`：标记用于定义一个希望启动的ROS节点。格式：\n\n  ```xml\n  <node name=\"bar1\" pkg=\"foo_pkg\" type=\"bar\" />\n  ```\n\n  > 三个必须的属性：pkg, type, name。\n  >\n  > - pkg是节点所在的程序包名字；\n  > - type是节点的类型，是可执行文件的名字；\n  > - name是节点名字，不能包含namespace，可以任意给出的，它覆盖了原有文件中ros::init指定的node name；\n  > - 在默认状态下，从启动文件启动节点的标准输出被重定向到一个日志文件中，而不是像 `rosrun` 命令那样，将 **log** 信息显示在终端(**console**)。该日志文件的名称是：` ~/.ros/log/run_id/node_name-number-stout.log` 其中，run_id 是节点管理器（master）启动时生成的一个唯一标示符；\n  > - 如果需要将标准输出信息输出到终端，使用属性`output`，即`output=screen`；\n  > - 其他属性：args（可以通过命令行启动参数赋值，将参数传递给节点）、ns（节点定义为某个namespace下）等。\n\n- `<param .../>`：定义一个设置在参数服务器中的参数，该标记可以放在`<node .../>`标记内部，作为私有参数。格式：\n\n  ~~~xml\n  <param name=\"publish_frequency\" type=\"double\" value=\"10.0\" />\n  ~~~\n\n  name是参数名，可以给出参数所在namesapce；value是可选属性，用于定义参数值，省略时要通过其他方式（命令行或者binfile、testfile文件）指定参数值；type定义参数的数据类型，也是可选属性，省略时roslaunch会尝试自动定义参数的类型（根据参数的形式进行判断）。\n\n- `<include .../>`：允许当前launch文件包含（调用）其他launch文件，包括该文件中的所有nodes和parameters。格式：\n\n  ~~~xml\n  <include file=”$(find package_name)/launch_file_name”/>\n  ~~~\n\n  需要写出该launch文件的绝对路径，比较繁琐，一般使用上述方式。roslaunch会搜索package下的所有子目录；因此，必须给出package_name。另外，include也支持ns属性，将它的内容放进指定的namespace，格式：\n\n  ~~~xml\n  <include file=”...” ns=”namespace_name”/>\n  ~~~\n\n- `<arg .../>`：启动参数，是局部的，只能在一个launch文件中使用，类似于局部变量，声明格式：\n\n  ~~~xml\n  <arg name=”arg_name”>\n  ~~~\n\n  launch文件中的每个argument必须有指定值。指定argument的值有多种方式，包括命令行赋值、声明argument时赋值。\n\n  - 还支持启动参数，有时也简称为参数甚至args。\n\n  - 命令行赋值。命令格式：\n\n    ```shell\n    roslaunch package_name launch_file_name arg_name:=arg_value\n    ```\n\n  - 声明时赋值（两种形式）。格式：\n\n    ```xml\n    <arg name=”arg_name” default=”arg_name”/>\n    <arg name=”arg_name” value=”arg_name”/>\n    ```\n\n    两种形式的区别在于，命令行参数可以覆盖default，但是不能重写value的值。\n\n  可以通过arg获取变量的值，格式：\n\n  ~~~xml\n  $(arg arg_name)\n  ~~~\n\n  另外，还可以将变量值传给included launch文件，格式：\n\n  ~~~xml\n  <include file=”path-to-file”>\n      <arg name=”arg_name” value=”arg_value”/>\n      ...\n  </include>\n  ~~~\n\n  若在launch文件中，launch文件及其包含的launch文件出现出现相同的arguments，则需在launch文件及included launch文件中同时写：\n\n  ~~~xml\n  <arg name=”arg_name” value=”$(arg arg_name)”/>\n  ~~~\n\n  第一个arg_name表示included launch文件中的argument，第二个arg_name表示launch文件中的argument。其结果是指定的argument在launch文件及included launch文件中都有相同的值。\n\n  在ROS中prarmeter和argument是不同的，虽然翻译一样。parameter是运行中的ROS系统使用的数值，存储在参数服务器（parameter server）中，每个活跃的节点都可以通过 ros::param::get 函数来获取parameter的值，用户也可以通过rosparam来获得parameter的值。而argument只在启动文件内才有意义，它们的值是不能被节点直接获取的。\n\n- `<remap .../>`：重映射。重映射是基于替换的思想，每个重映射包含一个原始名称和一个新名称。每当节点使用重映射中的原始名称时，ROS客户端库就会将它默默地替换成其对应的新名称。例如，运行一个 turtlesim 的实例，如果想要把海龟的姿态数据发布到话题/tim 而不是/turtle1/pose，就可以使用如下命令：\n\n  ~~~shell\n  rosrun turtlesim turtlesim_node turtle1/pose:=tim \n  ~~~\n\n  通过启动文件的方式，只需在启动文件内使用重映射（remap）元素即可：\n\n  ~~~xml\n  <remap from=”turtle1/pose” to ”tim”/>\n  ~~~\n\n  例如，节点`mono`订阅了`/camera/image_raw`话题，但是现在只有`/camera_node/image_raw`话题在发布和`/camera/image_raw`话题一样的数据，可以使用重映射完成数据的订阅，这样就可以使得节点`mono`能够订阅`/camera_node/image_raw`话题的数据：\n\n  ~~~xml\n  <remap from=\"/camera/image_raw\" to=\"/camera_node/image_raw\"/>\n  ~~~\n\n- `<group> ... </group>`：可以将指定的nodes组织起来，只能使用ns、if、unless三个属性。group有两个作用/好处：\n\n  - 可以将几个nodes放进同一个namespace，从而使该组标签有独立的名称空间，格式：\n\n    ~~~xml\n    <group ns=”namespace”>\n        <node pkg=”..” .../>\n        <node pkg=”..” .../>\n        ......\n    </group>\n    ~~~\n\n    如果grouped node已经有它自己的namespace，并且是relative name，那么该node的namespace是其relative name，并以group namespace为后缀。\n\n  - 可以同时启动或者终止一组nodes，格式：\n\n    ~~~xml\n    <group if=”$(arg arg_name)”>\n    \t......\n    </group>\n    <group unless=”$(arg arg_name)”>\n    \t......\n    </group>\n    ~~~\n\n    其中arg_name的值只有0或1，若真，则包含group标签，其中的nodes都可运行；否则其中的nodes都不会运行。​\n\n  ​\n\n\n参考链接：\n\nhttps://blog.csdn.net/fengmengdan/article/details/42984429（启动文件的编写）\n\nhttp://www.cnblogs.com/zjiaxing/p/5542614.html（启动文件的编写）\n\nhttps://www.cnblogs.com/zjiaxing/p/5541841.html（ros命名空间的解释）\n","slug":"ROS学习之roslaunch","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0400c3qlcrifvh6oky","content":"<hr>\n<p>这篇文章是有关ROS中roslaunch使用的学习内容。</p>\n<a id=\"more\"></a>\n<h3 id=\"wiki官方文档\"><a href=\"#wiki官方文档\" class=\"headerlink\" title=\"wiki官方文档\"></a>wiki官方文档</h3><p>roslaunch命令：<a href=\"http://wiki.ros.org/roslaunch/Commandline%20Tools\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/roslaunch/Commandline%20Tools</a></p>\n<p>launch文件格式：<a href=\"http://wiki.ros.org/roslaunch/XML\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/roslaunch/XML</a></p>\n<h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><p>rosrun只能运行一个node，roslaunch可以同时运行多个nodes。roslaunch工具是ros中python实现的程序启动工具，可以通过读取启动文件（launch file）中的参数配置、属性配置等，同时启动节点管理器（master）和多个节点，在启动任何一个节点前，<code>roslaunch</code> 将会确定 <strong>roscore节点（节点管理器）</strong> 是否已经在运行，如果没有，自动启动它；可以在本地或者远程（使用SSH）启动ROS节点，要通过参数服务器设置参数。</p>\n<p><code>roscore</code>会做三件事： </p>\n<ul>\n<li>启动master节点，该节点是隐藏的，用于通过消息名查询目标节点，实现消息、服务在各个节点之间的连接 </li>\n<li>启动参数服务器parameter server，用于设置与查询参数 </li>\n<li>启动日志节点，记录所有消息收发和stdout、stderr，目前roscore暂不会加入其他功能</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">任务名称</th>\n<th style=\"text-align:center\">任务功能</th>\n<th style=\"text-align:center\">特性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">master</td>\n<td style=\"text-align:center\">通过消息名查询目标节点，实现消息、服务在各个节点之间的连接</td>\n<td style=\"text-align:center\">隐藏</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">parameter server</td>\n<td style=\"text-align:center\">设置与查询参数</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">日志节点</td>\n<td style=\"text-align:center\">记录所有消息收发和stdout、stderr</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以<em>.launch</em>作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。</p>\n<p>roslaunch命令执行launch文件的命令格式：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roslaunch [package] [filename.launch]</span><br></pre></td></tr></table></figure>\n<h3 id=\"launch文件编写\"><a href=\"#launch文件编写\" class=\"headerlink\" title=\"launch文件编写\"></a>launch文件编写</h3><p>一般格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">launch</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">rosparam</span> <span class=\"attr\">....</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">param</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">include</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">env</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">remap</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">arg</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">group</span>&gt;</span> </span><br><span class=\"line\">        ... </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">group</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">launch</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li><p><code>&lt;launch&gt;...&lt;/launch&gt;</code>：根元素，作为放置其他元素的容器，其他元素必须在该标记之间。</p>\n</li>\n<li><p><code>&lt;node .../&gt;</code>：标记用于定义一个希望启动的ROS节点。格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"bar1\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"foo_pkg\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"bar\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>三个必须的属性：pkg, type, name。</p>\n<ul>\n<li>pkg是节点所在的程序包名字；</li>\n<li>type是节点的类型，是可执行文件的名字；</li>\n<li>name是节点名字，不能包含namespace，可以任意给出的，它覆盖了原有文件中ros::init指定的node name；</li>\n<li>在默认状态下，从启动文件启动节点的标准输出被重定向到一个日志文件中，而不是像 <code>rosrun</code> 命令那样，将 <strong>log</strong> 信息显示在终端(<strong>console</strong>)。该日志文件的名称是：<code>~/.ros/log/run_id/node_name-number-stout.log</code> 其中，run_id 是节点管理器（master）启动时生成的一个唯一标示符；</li>\n<li>如果需要将标准输出信息输出到终端，使用属性<code>output</code>，即<code>output=screen</code>；</li>\n<li>其他属性：args（可以通过命令行启动参数赋值，将参数传递给节点）、ns（节点定义为某个namespace下）等。</li>\n</ul>\n</blockquote>\n</li>\n<li><p><code>&lt;param .../&gt;</code>：定义一个设置在参数服务器中的参数，该标记可以放在<code>&lt;node .../&gt;</code>标记内部，作为私有参数。格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">param</span> <span class=\"attr\">name</span>=<span class=\"string\">\"publish_frequency\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"double\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"10.0\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<p>name是参数名，可以给出参数所在namesapce；value是可选属性，用于定义参数值，省略时要通过其他方式（命令行或者binfile、testfile文件）指定参数值；type定义参数的数据类型，也是可选属性，省略时roslaunch会尝试自动定义参数的类型（根据参数的形式进行判断）。</p>\n</li>\n<li><p><code>&lt;include .../&gt;</code>：允许当前launch文件包含（调用）其他launch文件，包括该文件中的所有nodes和parameters。格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">include</span> <span class=\"attr\">file</span>=<span class=\"string\">”$(find</span> <span class=\"attr\">package_name</span>)/<span class=\"attr\">launch_file_name</span>”/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>需要写出该launch文件的绝对路径，比较繁琐，一般使用上述方式。roslaunch会搜索package下的所有子目录；因此，必须给出package_name。另外，include也支持ns属性，将它的内容放进指定的namespace，格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">include</span> <span class=\"attr\">file</span>=<span class=\"string\">”...”</span> <span class=\"attr\">ns</span>=<span class=\"string\">”namespace_name”/</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>&lt;arg .../&gt;</code>：启动参数，是局部的，只能在一个launch文件中使用，类似于局部变量，声明格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">arg</span> <span class=\"attr\">name</span>=<span class=\"string\">”arg_name”</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>launch文件中的每个argument必须有指定值。指定argument的值有多种方式，包括命令行赋值、声明argument时赋值。</p>\n<ul>\n<li><p>还支持启动参数，有时也简称为参数甚至args。</p>\n</li>\n<li><p>命令行赋值。命令格式：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roslaunch package_name launch_file_name arg_name:=arg_value</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>声明时赋值（两种形式）。格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">arg</span> <span class=\"attr\">name</span>=<span class=\"string\">”arg_name”</span> <span class=\"attr\">default</span>=<span class=\"string\">”arg_name”/</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">arg</span> <span class=\"attr\">name</span>=<span class=\"string\">”arg_name”</span> <span class=\"attr\">value</span>=<span class=\"string\">”arg_name”/</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>两种形式的区别在于，命令行参数可以覆盖default，但是不能重写value的值。</p>\n</li>\n</ul>\n<p>可以通过arg获取变量的值，格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(arg arg_name)</span><br></pre></td></tr></table></figure>\n<p>另外，还可以将变量值传给included launch文件，格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">include</span> <span class=\"attr\">file</span>=<span class=\"string\">”path-to-file”</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">arg</span> <span class=\"attr\">name</span>=<span class=\"string\">”arg_name”</span> <span class=\"attr\">value</span>=<span class=\"string\">”arg_value”/</span>&gt;</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>若在launch文件中，launch文件及其包含的launch文件出现出现相同的arguments，则需在launch文件及included launch文件中同时写：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">arg</span> <span class=\"attr\">name</span>=<span class=\"string\">”arg_name”</span> <span class=\"attr\">value</span>=<span class=\"string\">”$(arg</span> <span class=\"attr\">arg_name</span>)”/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>第一个arg_name表示included launch文件中的argument，第二个arg_name表示launch文件中的argument。其结果是指定的argument在launch文件及included launch文件中都有相同的值。</p>\n<p>在ROS中prarmeter和argument是不同的，虽然翻译一样。parameter是运行中的ROS系统使用的数值，存储在参数服务器（parameter server）中，每个活跃的节点都可以通过 ros::param::get 函数来获取parameter的值，用户也可以通过rosparam来获得parameter的值。而argument只在启动文件内才有意义，它们的值是不能被节点直接获取的。</p>\n</li>\n<li><p><code>&lt;remap .../&gt;</code>：重映射。重映射是基于替换的思想，每个重映射包含一个原始名称和一个新名称。每当节点使用重映射中的原始名称时，ROS客户端库就会将它默默地替换成其对应的新名称。例如，运行一个 turtlesim 的实例，如果想要把海龟的姿态数据发布到话题/tim 而不是/turtle1/pose，就可以使用如下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun turtlesim turtlesim_node turtle1/pose:=tim</span><br></pre></td></tr></table></figure>\n<p>通过启动文件的方式，只需在启动文件内使用重映射（remap）元素即可：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">remap</span> <span class=\"attr\">from</span>=<span class=\"string\">”turtle1/pose”</span> <span class=\"attr\">to</span> ”<span class=\"attr\">tim</span>”/&gt;</span></span><br></pre></td></tr></table></figure>\n<p>例如，节点<code>mono</code>订阅了<code>/camera/image_raw</code>话题，但是现在只有<code>/camera_node/image_raw</code>话题在发布和<code>/camera/image_raw</code>话题一样的数据，可以使用重映射完成数据的订阅，这样就可以使得节点<code>mono</code>能够订阅<code>/camera_node/image_raw</code>话题的数据：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">remap</span> <span class=\"attr\">from</span>=<span class=\"string\">\"/camera/image_raw\"</span> <span class=\"attr\">to</span>=<span class=\"string\">\"/camera_node/image_raw\"</span>/&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>&lt;group&gt; ... &lt;/group&gt;</code>：可以将指定的nodes组织起来，只能使用ns、if、unless三个属性。group有两个作用/好处：</p>\n<ul>\n<li><p>可以将几个nodes放进同一个namespace，从而使该组标签有独立的名称空间，格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">group</span> <span class=\"attr\">ns</span>=<span class=\"string\">”namespace”</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">pkg</span>=<span class=\"string\">”..”</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">pkg</span>=<span class=\"string\">”..”</span> <span class=\"attr\">...</span>/&gt;</span></span><br><span class=\"line\">    ......</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">group</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>如果grouped node已经有它自己的namespace，并且是relative name，那么该node的namespace是其relative name，并以group namespace为后缀。</p>\n</li>\n<li><p>可以同时启动或者终止一组nodes，格式：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">group</span> <span class=\"attr\">if</span>=<span class=\"string\">”$(arg</span> <span class=\"attr\">arg_name</span>)”&gt;</span></span><br><span class=\"line\">\t......</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">group</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">group</span> <span class=\"attr\">unless</span>=<span class=\"string\">”$(arg</span> <span class=\"attr\">arg_name</span>)”&gt;</span></span><br><span class=\"line\">\t......</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">group</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>其中arg_name的值只有0或1，若真，则包含group标签，其中的nodes都可运行；否则其中的nodes都不会运行。​</p>\n</li>\n</ul>\n<p>​</p>\n</li>\n</ul>\n<p>参考链接：</p>\n<p><a href=\"https://blog.csdn.net/fengmengdan/article/details/42984429（启动文件的编写）\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fengmengdan/article/details/42984429（启动文件的编写）</a></p>\n<p><a href=\"http://www.cnblogs.com/zjiaxing/p/5542614.html（启动文件的编写）\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/zjiaxing/p/5542614.html（启动文件的编写）</a></p>\n<p><a href=\"https://www.cnblogs.com/zjiaxing/p/5541841.html（ros命名空间的解释）\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zjiaxing/p/5541841.html（ros命名空间的解释）</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中roslaunch使用的学习内容。</p>","more":"<h3 id=\"wiki官方文档\"><a href=\"#wiki官方文档\" class=\"headerlink\" title=\"wiki官方文档\"></a>wiki官方文档</h3><p>roslaunch命令：<a href=\"http://wiki.ros.org/roslaunch/Commandline%20Tools\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/roslaunch/Commandline%20Tools</a></p>\n<p>launch文件格式：<a href=\"http://wiki.ros.org/roslaunch/XML\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/roslaunch/XML</a></p>\n<h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><p>rosrun只能运行一个node，roslaunch可以同时运行多个nodes。roslaunch工具是ros中python实现的程序启动工具，可以通过读取启动文件（launch file）中的参数配置、属性配置等，同时启动节点管理器（master）和多个节点，在启动任何一个节点前，<code>roslaunch</code> 将会确定 <strong>roscore节点（节点管理器）</strong> 是否已经在运行，如果没有，自动启动它；可以在本地或者远程（使用SSH）启动ROS节点，要通过参数服务器设置参数。</p>\n<p><code>roscore</code>会做三件事： </p>\n<ul>\n<li>启动master节点，该节点是隐藏的，用于通过消息名查询目标节点，实现消息、服务在各个节点之间的连接 </li>\n<li>启动参数服务器parameter server，用于设置与查询参数 </li>\n<li>启动日志节点，记录所有消息收发和stdout、stderr，目前roscore暂不会加入其他功能</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">任务名称</th>\n<th style=\"text-align:center\">任务功能</th>\n<th style=\"text-align:center\">特性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">master</td>\n<td style=\"text-align:center\">通过消息名查询目标节点，实现消息、服务在各个节点之间的连接</td>\n<td style=\"text-align:center\">隐藏</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">parameter server</td>\n<td style=\"text-align:center\">设置与查询参数</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">日志节点</td>\n<td style=\"text-align:center\">记录所有消息收发和stdout、stderr</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>任何包含两个或两个以上节点的系统都可以利用启动文件来指定和配置需要使用的节点。通常的命名方案是以<em>.launch</em>作为启动文件的后缀，启动文件是XML文件。一般把启动文件存储在取名为launch的目录中。</p>\n<p>roslaunch命令执行launch文件的命令格式：</p>\n<!--�268-->\n<h3 id=\"launch文件编写\"><a href=\"#launch文件编写\" class=\"headerlink\" title=\"launch文件编写\"></a>launch文件编写</h3><p>一般格式：</p>\n<!--�269-->\n<ul>\n<li><p><code>&lt;launch&gt;...&lt;/launch&gt;</code>：根元素，作为放置其他元素的容器，其他元素必须在该标记之间。</p>\n</li>\n<li><p><code>&lt;node .../&gt;</code>：标记用于定义一个希望启动的ROS节点。格式：</p>\n<!--�270-->\n<blockquote>\n<p>三个必须的属性：pkg, type, name。</p>\n<ul>\n<li>pkg是节点所在的程序包名字；</li>\n<li>type是节点的类型，是可执行文件的名字；</li>\n<li>name是节点名字，不能包含namespace，可以任意给出的，它覆盖了原有文件中ros::init指定的node name；</li>\n<li>在默认状态下，从启动文件启动节点的标准输出被重定向到一个日志文件中，而不是像 <code>rosrun</code> 命令那样，将 <strong>log</strong> 信息显示在终端(<strong>console</strong>)。该日志文件的名称是：<code>~/.ros/log/run_id/node_name-number-stout.log</code> 其中，run_id 是节点管理器（master）启动时生成的一个唯一标示符；</li>\n<li>如果需要将标准输出信息输出到终端，使用属性<code>output</code>，即<code>output=screen</code>；</li>\n<li>其他属性：args（可以通过命令行启动参数赋值，将参数传递给节点）、ns（节点定义为某个namespace下）等。</li>\n</ul>\n</blockquote>\n</li>\n<li><p><code>&lt;param .../&gt;</code>：定义一个设置在参数服务器中的参数，该标记可以放在<code>&lt;node .../&gt;</code>标记内部，作为私有参数。格式：</p>\n<!--�271-->\n<p>name是参数名，可以给出参数所在namesapce；value是可选属性，用于定义参数值，省略时要通过其他方式（命令行或者binfile、testfile文件）指定参数值；type定义参数的数据类型，也是可选属性，省略时roslaunch会尝试自动定义参数的类型（根据参数的形式进行判断）。</p>\n</li>\n<li><p><code>&lt;include .../&gt;</code>：允许当前launch文件包含（调用）其他launch文件，包括该文件中的所有nodes和parameters。格式：</p>\n<!--�272-->\n<p>需要写出该launch文件的绝对路径，比较繁琐，一般使用上述方式。roslaunch会搜索package下的所有子目录；因此，必须给出package_name。另外，include也支持ns属性，将它的内容放进指定的namespace，格式：</p>\n<!--�273-->\n</li>\n<li><p><code>&lt;arg .../&gt;</code>：启动参数，是局部的，只能在一个launch文件中使用，类似于局部变量，声明格式：</p>\n<!--�274-->\n<p>launch文件中的每个argument必须有指定值。指定argument的值有多种方式，包括命令行赋值、声明argument时赋值。</p>\n<ul>\n<li><p>还支持启动参数，有时也简称为参数甚至args。</p>\n</li>\n<li><p>命令行赋值。命令格式：</p>\n<!--�275-->\n</li>\n<li><p>声明时赋值（两种形式）。格式：</p>\n<!--�276-->\n<p>两种形式的区别在于，命令行参数可以覆盖default，但是不能重写value的值。</p>\n</li>\n</ul>\n<p>可以通过arg获取变量的值，格式：</p>\n<!--�277-->\n<p>另外，还可以将变量值传给included launch文件，格式：</p>\n<!--�278-->\n<p>若在launch文件中，launch文件及其包含的launch文件出现出现相同的arguments，则需在launch文件及included launch文件中同时写：</p>\n<!--�279-->\n<p>第一个arg_name表示included launch文件中的argument，第二个arg_name表示launch文件中的argument。其结果是指定的argument在launch文件及included launch文件中都有相同的值。</p>\n<p>在ROS中prarmeter和argument是不同的，虽然翻译一样。parameter是运行中的ROS系统使用的数值，存储在参数服务器（parameter server）中，每个活跃的节点都可以通过 ros::param::get 函数来获取parameter的值，用户也可以通过rosparam来获得parameter的值。而argument只在启动文件内才有意义，它们的值是不能被节点直接获取的。</p>\n</li>\n<li><p><code>&lt;remap .../&gt;</code>：重映射。重映射是基于替换的思想，每个重映射包含一个原始名称和一个新名称。每当节点使用重映射中的原始名称时，ROS客户端库就会将它默默地替换成其对应的新名称。例如，运行一个 turtlesim 的实例，如果想要把海龟的姿态数据发布到话题/tim 而不是/turtle1/pose，就可以使用如下命令：</p>\n<!--�280-->\n<p>通过启动文件的方式，只需在启动文件内使用重映射（remap）元素即可：</p>\n<!--�281-->\n<p>例如，节点<code>mono</code>订阅了<code>/camera/image_raw</code>话题，但是现在只有<code>/camera_node/image_raw</code>话题在发布和<code>/camera/image_raw</code>话题一样的数据，可以使用重映射完成数据的订阅，这样就可以使得节点<code>mono</code>能够订阅<code>/camera_node/image_raw</code>话题的数据：</p>\n<!--�282-->\n</li>\n<li><p><code>&lt;group&gt; ... &lt;/group&gt;</code>：可以将指定的nodes组织起来，只能使用ns、if、unless三个属性。group有两个作用/好处：</p>\n<ul>\n<li><p>可以将几个nodes放进同一个namespace，从而使该组标签有独立的名称空间，格式：</p>\n<!--�283-->\n<p>如果grouped node已经有它自己的namespace，并且是relative name，那么该node的namespace是其relative name，并以group namespace为后缀。</p>\n</li>\n<li><p>可以同时启动或者终止一组nodes，格式：</p>\n<!--�284-->\n<p>其中arg_name的值只有0或1，若真，则包含group标签，其中的nodes都可运行；否则其中的nodes都不会运行。​</p>\n</li>\n</ul>\n<p>​</p>\n</li>\n</ul>\n<p>参考链接：</p>\n<p><a href=\"https://blog.csdn.net/fengmengdan/article/details/42984429（启动文件的编写）\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fengmengdan/article/details/42984429（启动文件的编写）</a></p>\n<p><a href=\"http://www.cnblogs.com/zjiaxing/p/5542614.html（启动文件的编写）\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/zjiaxing/p/5542614.html（启动文件的编写）</a></p>\n<p><a href=\"https://www.cnblogs.com/zjiaxing/p/5541841.html（ros命名空间的解释）\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zjiaxing/p/5541841.html（ros命名空间的解释）</a></p>"},{"title":"ROS学习之基本概念和命令","date":"2018-03-22T05:27:48.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关ROS中基本概念和命令的学习内容。\n\n<!--more--->\n\n# ROS命令**\n\n`source /devel/setup.bash`：刷新`setup.bash`文件，这个自动生成的脚本文件设置了若干环境变量，从而使ROS能够找到创建的功能包和新生成的可执行文件，类似与下面所述的全局脚本文件，但该文件是专门为自己的工作区量身定做的。\n\n`source /opt/ros/kinetic/setup.bash`：全局的脚本文件\n\n`ros··· -h`：查看ros命令格式\n\n`roscore`：运行所有ROS程序前首先要运行的命令\n\n`roswtf`：进行全面深入的检测，包括检测环境变量、安装的文件以及运行的节点\n\n`rosnode list`：列出活跃的节点\n\n`rosnode info /[node_name]`：返回关于一个特定节点的信息\n\n`rosrun [package_name] [node_name]`：允许使用包名直接运行一个包内的节点\n\n`rosrun rqt_graph rqt_graph`：以图的形式显示正在运行的节点和话题之间的消息\n\n`roscp [package_name] [file_to_copy_path] [copy_path]`：将文件从一个package复制到另一个package\n\n`rospack`：允许用户获取软件包的有关信息，用法：`rospack find [package_name]`\n\n`roscd`：切换工作目录到某个软件包或软件包集中\n\n`rosls`：直接按软件包的名称而不是绝对路径执行ls命令，罗列命令。\n\n`catkin_create_pkg <package_name> [depend1] [depend2] [depend3]`：创建程序包\n\n`rospack depends1 <package_name>`：一级依赖\n\n`rospcak depends <package_name>`：间接依赖\n\n`catkin_make [make_targets] [-DCMAKE_VARIABLES=...]`：编译程序包\n\n`rosnode list`：列出正在运行的活跃的节点\n\n`rosnode info [node_name]`：返回关于一个特定节点的信息\n\n`rosnode kill [node_name]`：终止节点运行\n\n`rosnode cleanup`：将节点从rosnode列表中删除\n\n`rosrun [package_name][node_name]`：允许使用包名直接运行一个包内的节点\n\n`rostopic echo [topic]`：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。\n\n`rostopic hz [topic]`：订阅指定的话题，显示该话题的数据发布速率，每秒发布的消息数量\n\n`rostopic bw [topic]`：订阅指定的话题，显示话题使用的宽带，即每秒发布消息所占的字节量\n\n`rostopic list`：列出所有当前订阅和发布的话题，运行`rostopic list -h`可查看其子命令。\n\n`rostopic pub -r rate-in-hz [topic]　[msg_type] [args]`：向当前某个正在广播的话题重复地按照指定频率发布指定的消息，使用`rostopic pub -h`查看该命令参数，例子：\n\n`rostopic pub –r 1 /turtle1/cmd_vel geometry_msgs/Twist ’[2,0,0]’ ’[0,0,0]’`\n\n子参数说明：\n\n * -r：指定话题以频率模式发布消息，即以一定的时间周期发布消息\n * -1(数字1)：一次性发布模式\n * -l(小写L)：默认的模式，即特别的锁存模式，也是发布一次消息，但会确保该话题的新订阅者也会收到消息\n * -f：从文件中读取消息或从标准的输入中读取\n\n`rostopic type [topic]`：显示所发布话题的消息类型\n\n`rostopic info [topic]`：获取关于话题的信息（消息类型、发布者、订阅者）\n\n`rosmsg show [message type]`：查看消息的详细情况，即消息类型的基本数据类型组成\n\n`rosmsg users`：Find files that use message  \n\n`rosmsg md5`：Display message md5sum  \n\n`rosmsg package`：List messages in a package \n\n`rosmsg packages`：List packages that contain messages\n\n\n\nrosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：\n\n`rosservice list`：输出可用服务的信息\n\n`rosservice call [service`] [args]：调用带参数的服务\n\n`rosservice type [service]`：输出服务类型\n\n`rosservice find`：依据类型寻找服务\n\n`rosservice uri`：输出服务的`ROSRPC uri`\n\n`rosparam set [param_name]`：设置参数\n\n`rosparam get [param_name]`：获取参数\n\n`rosparam load`：从文件读取参数\n\n`rosparam dump`：向文件中写入参数\n\n`rosparam delete`：删除参数\n\n`rosparam list`：列出参数名\n\n`rosdep install [package]`：下载并安装ROS package所需要的系统依赖项\n\n \n\n- Roslaunch xml文件标签说明：<http://wiki.ros.org/roslaunch/XML>\n- Urdf xml 文件标签说明：<http://wiki.ros.org/urdf/XML>\n- Roscpp api 文档：<http://docs.ros.org/jade/api/roscpp/html/>\n- Rospy api 文档：http://docs.ros.org/jade/api/rospy/html/\n\n# **ROS概念**\n\n## **ROS文件系统**\n\n文件系统层概念主要指在硬盘里能看到的ROS目录和文件，包括：\n\n- Packages：软件包，ROS应用程序代码的组织单元，每个软件包都可包含程序库、可执行文件、脚本或其他手动创建的文件。\n- Manifest（package.xml）：清单是对于“软件包”相关信息的描述，用于定义软件包相关元信息之间的依赖关系，这些信息包括版本、维护者和许可协议等。\n- Message (msg) types: 存储在`my_package/msg/MyMessageType.msg`的Message文件，主要定义了ROS系统的messages传输的数据结构。 \n- Service (srv) types: 存储在 `my_package/srv/MyServiceType.srv`的服务services文件，定义了ROS的服务通信时的请求（request ）和响应（response ）相关的数据结构。 \n\n## ROS计算图层\n\n计算图是ROS在点对点网络里整合并处理数据的过程。基本计算图概念是 *节点*, *主机*, *参数服务器*, *消息*, *服务*, *话题*, and *数据包*，它们通过不同的方式提供数据给图层。 这些概念是在ros_comm库里实现的。\n\n- **Nodes**: 节点主要执行计算处理 。ROS被设计为细粒度的模块化的系统：一个机器人控制系统通常有很多节点组成 。例如，一个节点控制激光测距仪，一个节点控制轮电机，一个节点执行定位，一个节点执行路径规划，一个节点提供系统图形界面，等等。一个ROS节点通过ROS客户端库 [client library](http://wiki.ros.org/Client%20Libraries)编写，例如 [roscpp](http://wiki.ros.org/roscpp) o或[rospy](http://wiki.ros.org/rospy) 。\n- **Master**: The ROS Master provides name registration and lookup to the rest of the Computation Graph. Without the Master, nodes would not be able to find each other, exchange messages, or invoke services.  \n- **Parameter Server**: The Parameter Server allows data to be stored by key in a central location. It is currently part of the Master. \n- **Messages**: 节点之间使用messages信息互相通信。 一个消息就是一个由类型域组成的简单的数据结构，支持标准的原始数据类型（integer, floating point, boolean等等）和数组 。消息可以包含任意嵌套的结构和数组（很像C结构）。\n- **Topics**: Messages are routed via a transport system with publish / subscribe semantics.  A node sends out a message by *publishing* it to a given [topic](http://wiki.ros.org/Topics). The topic is a [name](http://wiki.ros.org/Names) that is used to identify the content of the message.  A node that is interested in a certain kind of data will *subscribe* to the appropriate topic.  There may be multiple concurrent publishers and subscribers for a single topic, and a single node may publish and/or subscribe to multiple topics.  In general, publishers and subscribers are not aware of each others' existence.  The idea is to decouple the production of information from its consumption. Logically, one can think of a topic as a strongly typed message bus.  Each bus has a name, and anyone can connect to the bus to send or receive messages as long as they are the right type. \n- **Services**: The publish / subscribe model is a very flexible communication paradigm, but its many-to-many, one-way transport is not appropriate for request / reply interactions, which are often required in a distributed system.  Request / reply is done via [services](http://wiki.ros.org/Services), which are defined by a pair of message structures: one for the request and one for the reply. A providing node offers a service under a [name](http://wiki.ros.org/Names) and a client uses the service by sending the request message and awaiting the reply.  ROS client libraries generally present this interaction to the programmer as if it were a remote procedure call. \n- **Bags**: Bags are a format for saving and playing back ROS message data. Bags are an important mechanism for storing data, such as sensor data, that can be difficult to collect but is necessary for developing and testing algorithms. \n\n## 工作空间结构\n\n- build：build space默认的所在位置，同时也是cmake 和 make被调用来配置并编译程序包的地方\n- devel：devel space默认的所在位置，也是安装程序包之前存放可执行文件和库文件的地方\n- src：存放软件包的位置\n\n## **文件系统工具**\n\n`rospack`：允许用户获取软件包的有关信息，用法：`rospack find [package_name] `\n\n`roscd`：是rosbash命令集中的一部分，允许用户切换工作目录到某个软件包或软件包集中；和ROS中其他工具一样，只能切换到那些路径已经包含在`ROS_PACKAGE_PATH`环境变量中的软件包，可以使用`echo $ROS_PACKAGE_PATH`查看其中包含的路径。`ROS_PACKAGE_PATH`环境变量应该包含那些保存有ROS软件包的路径，并且每个路径之间用冒号分隔开。\n\n`rosls`：rosbash命令集中的一部分，允许用户直接按软件包的名称而不是绝对路径执行`ls`命令，罗列命令。\n\n## **ROS catkin程序包**\n\n组成：`package.xml`文件+`CMakeLists.txt`文件。\n\n每个目录下只能有一个程序包，同一目录下不能有嵌套的或多个程序包存在。\n\n## **创建程序包的命令**\n\n`catkin_create_pkg <package_name> [depend1] [depend2] [depend3]`\n\n该命令需要在工作空间/src目录下执行，`<package_name>`是要创建的软件包的名字，`depend1..3`是创建的程序包依赖的其他程序包,执行完该命令后,就会在src目录下生成一个文件夹，包含`package.xml`和`CMakeLists.txt`文件。\n\n程序包依赖关系查看命令:\n\n一级依赖：`rospack depends1 <package_name>`\n\n间接依赖：`rospcak depends <package_name>`\n\n## **编译程序包**\n\n`catkin_make [make_targets] [-DCMAKE_VARIABLES=...]`\n\n`catkin_make install ` # (可选)\n\n编译工作空间下的某个软件包：\n\n~~~shell\ncatkin_make  -DCATKIN_WHITELIST_PACKAGES=\"package1;package2\"\n~~~\n\n\n\n在工作空间下执行上述命令，会编译src文件夹下的所有catkin工程。\n\n## **ROS图概念**\n\nNodes：节点，ROS网络中的可执行文件，可通过ROS客户库与其他节点通信,节点可以发布或接收一个话题，节点也可以提供或使用某种服务。\n\nMessages：消息，一种ROS数据类型，用于订阅或发布到一个话题\n\nTopics：话题，节点可以发布消息到话题，也可以订阅话题以接受消息\n\nMaster：节点管理器，ROS名称服务（如帮助节点找到彼此）\n\nROS客户端库允许使用不同编程语言编写的节点之间互相通信：\n\nrospy = python客户端\n\nroscpp = c++ 客户端\n\n \n\n`rosout`：ROS中相当于stdout/stderr，用于收集和记录节点调试输出信息，它总是运行的。\n\n`roscore`：主机+rosout+参数服务器；运行所有ROS程序前首先要运行的命令;启动节点管理器（The Master）\n\n`rosnode list`：列出活跃的节点\n\n`rosnode info /[node_name]`：返回关于一个特定节点的信息\n\n`rosrun [package_name] [node_name]`：允许使用包名直接运行一个包内的节点（不需要知道包的路径）\n\n## **ROS话题**(topic)\n\n节点和节点之间是通过一个ROS话题来互相通信的，某一个节点在一个话题上发布特定的消息，其他节点可以订阅该话题以接收该消息。\n\nrostopic命令工具可以获取有关ROS话题的信息，运行rostopic -h可以查看所有的rostopic子命令。\n\n`rostopic bw`：显示话题使用的宽带。\n\n`rostopic echo [topic]`：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。\n\n`rostopic hz [topic]`：显示话题的数据发布速率\n\n`rostopic list`：列出所有当前订阅和发布的话题，运行rostopic list -h可查看其子命令。\n\n`rostopic pub [topic] [msg_type] [args]`：向当前某个正在广播的话题发布数据，使用`rostopic pub -h`查看该命令参数\n\n`rostopic type [topic]`：显示所发布话题的消息类型，可以根据显示的话题类型，再继续执行`rosmsg show [message type]`：查看消息的详细情况\n\n## **ROS消息(msg)**\n\n话题之间的通信是通过节点之间发送ROS消息实现的，发布器和订阅器之间的通信，必须发送和接收相同类型的消息，意味着话题的类型是由发布在它上面的消息类型决定的。\n\nmsg文件存放在package的msg目录下，它是一个描述ROS中所使用消息类型的简单文本，实际是每行声明一个数据类型和变量名，会被用于生成不同语言的源代码。\n\n`rostopic type [topic]`：用来显示所发布话题的消息类型\n\n`rosmsg show [message type]`：查看消息的详细情况，即消息类型的基本数据类型组成\n\n`rosmsg users`：Find files that use message  \n\n`rosmsg md5`：Display message md5sum  \n\n`rosmsg package`：List messages in a package  \n\n`rosmsg packages`：List packages that contain messages\n\n## **ROS服务(srv)**\n\n服务（services）是节点之间通信的另一种方式，服务允许节点发送请求（request）并获得一个响应（response）。srv文件存放在srv目录下，一个srv文件描述一项服务，包含请求和响应两个部分，在srv文件中由'---'分隔。\n\n rosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：\n\n`rosservice list`：输出可用服务的信息\n\n`rosservice call [service] [args]`：调用带参数的服务\n\n`rosservice type [service]`：输出服务类型\n\n`rosservice find`：依据类型寻找服务\n\n`rosservice uri`：输出服务的ROSRPC uri\n\n## **ROS参数**\n\n`rosparam`使得能够存储并操作ROS参数服务器（Parameter Server）上的数据，参数服务器能够存储整型、浮点、布尔、字符串、字典和列表等数据类型，使用YAML标记语言的语法，其子命令如下：\n\n`rosparam set [param_name]`：设置参数\n\n`rosparam get [param_name]`：获取参数\n\n`rosparam load`：从文件读取参数\n\n`rosparam dump`：向文件中写入参数\n\n`rosparam delete`：删除参数\n\n`rosparam list`：列出参数名\n\n## **消息发布器（节点）**\n\n创建过程：\n\n- 初始化 ROS 系统 \n- 在 ROS 网络内广播将要在话题上发布的某一类型的消息 \n- 以某一频率在话题上发布消息 \n\n\n\n## **消息订阅器（节点）**\n\n创建过程：\n\n- 初始化ROS系统\n- 订阅话题\n- 进入自循环，等待消息的到达\n- 当消息到达，调用回调函数 \n\n## **服务器（Service）节点、客户端（Client）节点**\n\n## **录制与回放数据**\n\n只有消息已经发布了才可以被录制。\n\n使用`rostopic list -v`命令查看当前系统中发布的所有话题。\n\n在一个保存录制的目录下运行`rosbag record -a`命令，附加的-a选项表示将当前发布的所有话题数据都录制保存到一个bag文件中，该文件会自动以年份、日期和时间命名并以.bag作为后缀，它包含了rosbag record运行期间所有节点发布的话题。\n\nbag文件可以使用`rosbag info`检查其内容，使用`rosbag play`命令回放出来。\n\n \n\n## **常见错误**\n\n执行`roscd`命令时，出现no such packag的情况，解决方案执行：\n\n~~~yaml\necho \"export ROS_PACKAGE_PATH\"=~/catkin_ws:\"$ROS_PACKAGE_PATH \" >> ~/.bashrc\n~~~\n\n在新的终端执行：`roscd ...`成功。\n\n ","source":"_posts/ROS学习之基本概念和命令.md","raw":"---\ntitle: ROS学习之基本概念和命令\ndate: 2018-03-22 13:27:48\ntags:\n  - ROS\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n-----\n\n这篇文章是有关ROS中基本概念和命令的学习内容。\n\n<!--more--->\n\n# ROS命令**\n\n`source /devel/setup.bash`：刷新`setup.bash`文件，这个自动生成的脚本文件设置了若干环境变量，从而使ROS能够找到创建的功能包和新生成的可执行文件，类似与下面所述的全局脚本文件，但该文件是专门为自己的工作区量身定做的。\n\n`source /opt/ros/kinetic/setup.bash`：全局的脚本文件\n\n`ros··· -h`：查看ros命令格式\n\n`roscore`：运行所有ROS程序前首先要运行的命令\n\n`roswtf`：进行全面深入的检测，包括检测环境变量、安装的文件以及运行的节点\n\n`rosnode list`：列出活跃的节点\n\n`rosnode info /[node_name]`：返回关于一个特定节点的信息\n\n`rosrun [package_name] [node_name]`：允许使用包名直接运行一个包内的节点\n\n`rosrun rqt_graph rqt_graph`：以图的形式显示正在运行的节点和话题之间的消息\n\n`roscp [package_name] [file_to_copy_path] [copy_path]`：将文件从一个package复制到另一个package\n\n`rospack`：允许用户获取软件包的有关信息，用法：`rospack find [package_name]`\n\n`roscd`：切换工作目录到某个软件包或软件包集中\n\n`rosls`：直接按软件包的名称而不是绝对路径执行ls命令，罗列命令。\n\n`catkin_create_pkg <package_name> [depend1] [depend2] [depend3]`：创建程序包\n\n`rospack depends1 <package_name>`：一级依赖\n\n`rospcak depends <package_name>`：间接依赖\n\n`catkin_make [make_targets] [-DCMAKE_VARIABLES=...]`：编译程序包\n\n`rosnode list`：列出正在运行的活跃的节点\n\n`rosnode info [node_name]`：返回关于一个特定节点的信息\n\n`rosnode kill [node_name]`：终止节点运行\n\n`rosnode cleanup`：将节点从rosnode列表中删除\n\n`rosrun [package_name][node_name]`：允许使用包名直接运行一个包内的节点\n\n`rostopic echo [topic]`：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。\n\n`rostopic hz [topic]`：订阅指定的话题，显示该话题的数据发布速率，每秒发布的消息数量\n\n`rostopic bw [topic]`：订阅指定的话题，显示话题使用的宽带，即每秒发布消息所占的字节量\n\n`rostopic list`：列出所有当前订阅和发布的话题，运行`rostopic list -h`可查看其子命令。\n\n`rostopic pub -r rate-in-hz [topic]　[msg_type] [args]`：向当前某个正在广播的话题重复地按照指定频率发布指定的消息，使用`rostopic pub -h`查看该命令参数，例子：\n\n`rostopic pub –r 1 /turtle1/cmd_vel geometry_msgs/Twist ’[2,0,0]’ ’[0,0,0]’`\n\n子参数说明：\n\n * -r：指定话题以频率模式发布消息，即以一定的时间周期发布消息\n * -1(数字1)：一次性发布模式\n * -l(小写L)：默认的模式，即特别的锁存模式，也是发布一次消息，但会确保该话题的新订阅者也会收到消息\n * -f：从文件中读取消息或从标准的输入中读取\n\n`rostopic type [topic]`：显示所发布话题的消息类型\n\n`rostopic info [topic]`：获取关于话题的信息（消息类型、发布者、订阅者）\n\n`rosmsg show [message type]`：查看消息的详细情况，即消息类型的基本数据类型组成\n\n`rosmsg users`：Find files that use message  \n\n`rosmsg md5`：Display message md5sum  \n\n`rosmsg package`：List messages in a package \n\n`rosmsg packages`：List packages that contain messages\n\n\n\nrosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：\n\n`rosservice list`：输出可用服务的信息\n\n`rosservice call [service`] [args]：调用带参数的服务\n\n`rosservice type [service]`：输出服务类型\n\n`rosservice find`：依据类型寻找服务\n\n`rosservice uri`：输出服务的`ROSRPC uri`\n\n`rosparam set [param_name]`：设置参数\n\n`rosparam get [param_name]`：获取参数\n\n`rosparam load`：从文件读取参数\n\n`rosparam dump`：向文件中写入参数\n\n`rosparam delete`：删除参数\n\n`rosparam list`：列出参数名\n\n`rosdep install [package]`：下载并安装ROS package所需要的系统依赖项\n\n \n\n- Roslaunch xml文件标签说明：<http://wiki.ros.org/roslaunch/XML>\n- Urdf xml 文件标签说明：<http://wiki.ros.org/urdf/XML>\n- Roscpp api 文档：<http://docs.ros.org/jade/api/roscpp/html/>\n- Rospy api 文档：http://docs.ros.org/jade/api/rospy/html/\n\n# **ROS概念**\n\n## **ROS文件系统**\n\n文件系统层概念主要指在硬盘里能看到的ROS目录和文件，包括：\n\n- Packages：软件包，ROS应用程序代码的组织单元，每个软件包都可包含程序库、可执行文件、脚本或其他手动创建的文件。\n- Manifest（package.xml）：清单是对于“软件包”相关信息的描述，用于定义软件包相关元信息之间的依赖关系，这些信息包括版本、维护者和许可协议等。\n- Message (msg) types: 存储在`my_package/msg/MyMessageType.msg`的Message文件，主要定义了ROS系统的messages传输的数据结构。 \n- Service (srv) types: 存储在 `my_package/srv/MyServiceType.srv`的服务services文件，定义了ROS的服务通信时的请求（request ）和响应（response ）相关的数据结构。 \n\n## ROS计算图层\n\n计算图是ROS在点对点网络里整合并处理数据的过程。基本计算图概念是 *节点*, *主机*, *参数服务器*, *消息*, *服务*, *话题*, and *数据包*，它们通过不同的方式提供数据给图层。 这些概念是在ros_comm库里实现的。\n\n- **Nodes**: 节点主要执行计算处理 。ROS被设计为细粒度的模块化的系统：一个机器人控制系统通常有很多节点组成 。例如，一个节点控制激光测距仪，一个节点控制轮电机，一个节点执行定位，一个节点执行路径规划，一个节点提供系统图形界面，等等。一个ROS节点通过ROS客户端库 [client library](http://wiki.ros.org/Client%20Libraries)编写，例如 [roscpp](http://wiki.ros.org/roscpp) o或[rospy](http://wiki.ros.org/rospy) 。\n- **Master**: The ROS Master provides name registration and lookup to the rest of the Computation Graph. Without the Master, nodes would not be able to find each other, exchange messages, or invoke services.  \n- **Parameter Server**: The Parameter Server allows data to be stored by key in a central location. It is currently part of the Master. \n- **Messages**: 节点之间使用messages信息互相通信。 一个消息就是一个由类型域组成的简单的数据结构，支持标准的原始数据类型（integer, floating point, boolean等等）和数组 。消息可以包含任意嵌套的结构和数组（很像C结构）。\n- **Topics**: Messages are routed via a transport system with publish / subscribe semantics.  A node sends out a message by *publishing* it to a given [topic](http://wiki.ros.org/Topics). The topic is a [name](http://wiki.ros.org/Names) that is used to identify the content of the message.  A node that is interested in a certain kind of data will *subscribe* to the appropriate topic.  There may be multiple concurrent publishers and subscribers for a single topic, and a single node may publish and/or subscribe to multiple topics.  In general, publishers and subscribers are not aware of each others' existence.  The idea is to decouple the production of information from its consumption. Logically, one can think of a topic as a strongly typed message bus.  Each bus has a name, and anyone can connect to the bus to send or receive messages as long as they are the right type. \n- **Services**: The publish / subscribe model is a very flexible communication paradigm, but its many-to-many, one-way transport is not appropriate for request / reply interactions, which are often required in a distributed system.  Request / reply is done via [services](http://wiki.ros.org/Services), which are defined by a pair of message structures: one for the request and one for the reply. A providing node offers a service under a [name](http://wiki.ros.org/Names) and a client uses the service by sending the request message and awaiting the reply.  ROS client libraries generally present this interaction to the programmer as if it were a remote procedure call. \n- **Bags**: Bags are a format for saving and playing back ROS message data. Bags are an important mechanism for storing data, such as sensor data, that can be difficult to collect but is necessary for developing and testing algorithms. \n\n## 工作空间结构\n\n- build：build space默认的所在位置，同时也是cmake 和 make被调用来配置并编译程序包的地方\n- devel：devel space默认的所在位置，也是安装程序包之前存放可执行文件和库文件的地方\n- src：存放软件包的位置\n\n## **文件系统工具**\n\n`rospack`：允许用户获取软件包的有关信息，用法：`rospack find [package_name] `\n\n`roscd`：是rosbash命令集中的一部分，允许用户切换工作目录到某个软件包或软件包集中；和ROS中其他工具一样，只能切换到那些路径已经包含在`ROS_PACKAGE_PATH`环境变量中的软件包，可以使用`echo $ROS_PACKAGE_PATH`查看其中包含的路径。`ROS_PACKAGE_PATH`环境变量应该包含那些保存有ROS软件包的路径，并且每个路径之间用冒号分隔开。\n\n`rosls`：rosbash命令集中的一部分，允许用户直接按软件包的名称而不是绝对路径执行`ls`命令，罗列命令。\n\n## **ROS catkin程序包**\n\n组成：`package.xml`文件+`CMakeLists.txt`文件。\n\n每个目录下只能有一个程序包，同一目录下不能有嵌套的或多个程序包存在。\n\n## **创建程序包的命令**\n\n`catkin_create_pkg <package_name> [depend1] [depend2] [depend3]`\n\n该命令需要在工作空间/src目录下执行，`<package_name>`是要创建的软件包的名字，`depend1..3`是创建的程序包依赖的其他程序包,执行完该命令后,就会在src目录下生成一个文件夹，包含`package.xml`和`CMakeLists.txt`文件。\n\n程序包依赖关系查看命令:\n\n一级依赖：`rospack depends1 <package_name>`\n\n间接依赖：`rospcak depends <package_name>`\n\n## **编译程序包**\n\n`catkin_make [make_targets] [-DCMAKE_VARIABLES=...]`\n\n`catkin_make install ` # (可选)\n\n编译工作空间下的某个软件包：\n\n~~~shell\ncatkin_make  -DCATKIN_WHITELIST_PACKAGES=\"package1;package2\"\n~~~\n\n\n\n在工作空间下执行上述命令，会编译src文件夹下的所有catkin工程。\n\n## **ROS图概念**\n\nNodes：节点，ROS网络中的可执行文件，可通过ROS客户库与其他节点通信,节点可以发布或接收一个话题，节点也可以提供或使用某种服务。\n\nMessages：消息，一种ROS数据类型，用于订阅或发布到一个话题\n\nTopics：话题，节点可以发布消息到话题，也可以订阅话题以接受消息\n\nMaster：节点管理器，ROS名称服务（如帮助节点找到彼此）\n\nROS客户端库允许使用不同编程语言编写的节点之间互相通信：\n\nrospy = python客户端\n\nroscpp = c++ 客户端\n\n \n\n`rosout`：ROS中相当于stdout/stderr，用于收集和记录节点调试输出信息，它总是运行的。\n\n`roscore`：主机+rosout+参数服务器；运行所有ROS程序前首先要运行的命令;启动节点管理器（The Master）\n\n`rosnode list`：列出活跃的节点\n\n`rosnode info /[node_name]`：返回关于一个特定节点的信息\n\n`rosrun [package_name] [node_name]`：允许使用包名直接运行一个包内的节点（不需要知道包的路径）\n\n## **ROS话题**(topic)\n\n节点和节点之间是通过一个ROS话题来互相通信的，某一个节点在一个话题上发布特定的消息，其他节点可以订阅该话题以接收该消息。\n\nrostopic命令工具可以获取有关ROS话题的信息，运行rostopic -h可以查看所有的rostopic子命令。\n\n`rostopic bw`：显示话题使用的宽带。\n\n`rostopic echo [topic]`：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。\n\n`rostopic hz [topic]`：显示话题的数据发布速率\n\n`rostopic list`：列出所有当前订阅和发布的话题，运行rostopic list -h可查看其子命令。\n\n`rostopic pub [topic] [msg_type] [args]`：向当前某个正在广播的话题发布数据，使用`rostopic pub -h`查看该命令参数\n\n`rostopic type [topic]`：显示所发布话题的消息类型，可以根据显示的话题类型，再继续执行`rosmsg show [message type]`：查看消息的详细情况\n\n## **ROS消息(msg)**\n\n话题之间的通信是通过节点之间发送ROS消息实现的，发布器和订阅器之间的通信，必须发送和接收相同类型的消息，意味着话题的类型是由发布在它上面的消息类型决定的。\n\nmsg文件存放在package的msg目录下，它是一个描述ROS中所使用消息类型的简单文本，实际是每行声明一个数据类型和变量名，会被用于生成不同语言的源代码。\n\n`rostopic type [topic]`：用来显示所发布话题的消息类型\n\n`rosmsg show [message type]`：查看消息的详细情况，即消息类型的基本数据类型组成\n\n`rosmsg users`：Find files that use message  \n\n`rosmsg md5`：Display message md5sum  \n\n`rosmsg package`：List messages in a package  \n\n`rosmsg packages`：List packages that contain messages\n\n## **ROS服务(srv)**\n\n服务（services）是节点之间通信的另一种方式，服务允许节点发送请求（request）并获得一个响应（response）。srv文件存放在srv目录下，一个srv文件描述一项服务，包含请求和响应两个部分，在srv文件中由'---'分隔。\n\n rosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：\n\n`rosservice list`：输出可用服务的信息\n\n`rosservice call [service] [args]`：调用带参数的服务\n\n`rosservice type [service]`：输出服务类型\n\n`rosservice find`：依据类型寻找服务\n\n`rosservice uri`：输出服务的ROSRPC uri\n\n## **ROS参数**\n\n`rosparam`使得能够存储并操作ROS参数服务器（Parameter Server）上的数据，参数服务器能够存储整型、浮点、布尔、字符串、字典和列表等数据类型，使用YAML标记语言的语法，其子命令如下：\n\n`rosparam set [param_name]`：设置参数\n\n`rosparam get [param_name]`：获取参数\n\n`rosparam load`：从文件读取参数\n\n`rosparam dump`：向文件中写入参数\n\n`rosparam delete`：删除参数\n\n`rosparam list`：列出参数名\n\n## **消息发布器（节点）**\n\n创建过程：\n\n- 初始化 ROS 系统 \n- 在 ROS 网络内广播将要在话题上发布的某一类型的消息 \n- 以某一频率在话题上发布消息 \n\n\n\n## **消息订阅器（节点）**\n\n创建过程：\n\n- 初始化ROS系统\n- 订阅话题\n- 进入自循环，等待消息的到达\n- 当消息到达，调用回调函数 \n\n## **服务器（Service）节点、客户端（Client）节点**\n\n## **录制与回放数据**\n\n只有消息已经发布了才可以被录制。\n\n使用`rostopic list -v`命令查看当前系统中发布的所有话题。\n\n在一个保存录制的目录下运行`rosbag record -a`命令，附加的-a选项表示将当前发布的所有话题数据都录制保存到一个bag文件中，该文件会自动以年份、日期和时间命名并以.bag作为后缀，它包含了rosbag record运行期间所有节点发布的话题。\n\nbag文件可以使用`rosbag info`检查其内容，使用`rosbag play`命令回放出来。\n\n \n\n## **常见错误**\n\n执行`roscd`命令时，出现no such packag的情况，解决方案执行：\n\n~~~yaml\necho \"export ROS_PACKAGE_PATH\"=~/catkin_ws:\"$ROS_PACKAGE_PATH \" >> ~/.bashrc\n~~~\n\n在新的终端执行：`roscd ...`成功。\n\n ","slug":"ROS学习之基本概念和命令","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0500c6qlcrtop5fjy5","content":"<hr>\n<p>这篇文章是有关ROS中基本概念和命令的学习内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"ROS命令\"><a href=\"#ROS命令\" class=\"headerlink\" title=\"ROS命令**\"></a>ROS命令**</h1><p><code>source /devel/setup.bash</code>：刷新<code>setup.bash</code>文件，这个自动生成的脚本文件设置了若干环境变量，从而使ROS能够找到创建的功能包和新生成的可执行文件，类似与下面所述的全局脚本文件，但该文件是专门为自己的工作区量身定做的。</p>\n<p><code>source /opt/ros/kinetic/setup.bash</code>：全局的脚本文件</p>\n<p><code>ros··· -h</code>：查看ros命令格式</p>\n<p><code>roscore</code>：运行所有ROS程序前首先要运行的命令</p>\n<p><code>roswtf</code>：进行全面深入的检测，包括检测环境变量、安装的文件以及运行的节点</p>\n<p><code>rosnode list</code>：列出活跃的节点</p>\n<p><code>rosnode info /[node_name]</code>：返回关于一个特定节点的信息</p>\n<p><code>rosrun [package_name] [node_name]</code>：允许使用包名直接运行一个包内的节点</p>\n<p><code>rosrun rqt_graph rqt_graph</code>：以图的形式显示正在运行的节点和话题之间的消息</p>\n<p><code>roscp [package_name] [file_to_copy_path] [copy_path]</code>：将文件从一个package复制到另一个package</p>\n<p><code>rospack</code>：允许用户获取软件包的有关信息，用法：<code>rospack find [package_name]</code></p>\n<p><code>roscd</code>：切换工作目录到某个软件包或软件包集中</p>\n<p><code>rosls</code>：直接按软件包的名称而不是绝对路径执行ls命令，罗列命令。</p>\n<p><code>catkin_create_pkg &lt;package_name&gt; [depend1] [depend2] [depend3]</code>：创建程序包</p>\n<p><code>rospack depends1 &lt;package_name&gt;</code>：一级依赖</p>\n<p><code>rospcak depends &lt;package_name&gt;</code>：间接依赖</p>\n<p><code>catkin_make [make_targets] [-DCMAKE_VARIABLES=...]</code>：编译程序包</p>\n<p><code>rosnode list</code>：列出正在运行的活跃的节点</p>\n<p><code>rosnode info [node_name]</code>：返回关于一个特定节点的信息</p>\n<p><code>rosnode kill [node_name]</code>：终止节点运行</p>\n<p><code>rosnode cleanup</code>：将节点从rosnode列表中删除</p>\n<p><code>rosrun [package_name][node_name]</code>：允许使用包名直接运行一个包内的节点</p>\n<p><code>rostopic echo [topic]</code>：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。</p>\n<p><code>rostopic hz [topic]</code>：订阅指定的话题，显示该话题的数据发布速率，每秒发布的消息数量</p>\n<p><code>rostopic bw [topic]</code>：订阅指定的话题，显示话题使用的宽带，即每秒发布消息所占的字节量</p>\n<p><code>rostopic list</code>：列出所有当前订阅和发布的话题，运行<code>rostopic list -h</code>可查看其子命令。</p>\n<p><code>rostopic pub -r rate-in-hz [topic]　[msg_type] [args]</code>：向当前某个正在广播的话题重复地按照指定频率发布指定的消息，使用<code>rostopic pub -h</code>查看该命令参数，例子：</p>\n<p><code>rostopic pub –r 1 /turtle1/cmd_vel geometry_msgs/Twist ’[2,0,0]’ ’[0,0,0]’</code></p>\n<p>子参数说明：</p>\n<ul>\n<li>-r：指定话题以频率模式发布消息，即以一定的时间周期发布消息</li>\n<li>-1(数字1)：一次性发布模式</li>\n<li>-l(小写L)：默认的模式，即特别的锁存模式，也是发布一次消息，但会确保该话题的新订阅者也会收到消息</li>\n<li>-f：从文件中读取消息或从标准的输入中读取</li>\n</ul>\n<p><code>rostopic type [topic]</code>：显示所发布话题的消息类型</p>\n<p><code>rostopic info [topic]</code>：获取关于话题的信息（消息类型、发布者、订阅者）</p>\n<p><code>rosmsg show [message type]</code>：查看消息的详细情况，即消息类型的基本数据类型组成</p>\n<p><code>rosmsg users</code>：Find files that use message  </p>\n<p><code>rosmsg md5</code>：Display message md5sum  </p>\n<p><code>rosmsg package</code>：List messages in a package </p>\n<p><code>rosmsg packages</code>：List packages that contain messages</p>\n<p>rosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：</p>\n<p><code>rosservice list</code>：输出可用服务的信息</p>\n<p><code>rosservice call [service</code>] [args]：调用带参数的服务</p>\n<p><code>rosservice type [service]</code>：输出服务类型</p>\n<p><code>rosservice find</code>：依据类型寻找服务</p>\n<p><code>rosservice uri</code>：输出服务的<code>ROSRPC uri</code></p>\n<p><code>rosparam set [param_name]</code>：设置参数</p>\n<p><code>rosparam get [param_name]</code>：获取参数</p>\n<p><code>rosparam load</code>：从文件读取参数</p>\n<p><code>rosparam dump</code>：向文件中写入参数</p>\n<p><code>rosparam delete</code>：删除参数</p>\n<p><code>rosparam list</code>：列出参数名</p>\n<p><code>rosdep install [package]</code>：下载并安装ROS package所需要的系统依赖项</p>\n<ul>\n<li>Roslaunch xml文件标签说明：<a href=\"http://wiki.ros.org/roslaunch/XML\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/roslaunch/XML</a></li>\n<li>Urdf xml 文件标签说明：<a href=\"http://wiki.ros.org/urdf/XML\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/urdf/XML</a></li>\n<li>Roscpp api 文档：<a href=\"http://docs.ros.org/jade/api/roscpp/html/\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/jade/api/roscpp/html/</a></li>\n<li>Rospy api 文档：<a href=\"http://docs.ros.org/jade/api/rospy/html/\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/jade/api/rospy/html/</a></li>\n</ul>\n<h1 id=\"ROS概念\"><a href=\"#ROS概念\" class=\"headerlink\" title=\"ROS概念\"></a><strong>ROS概念</strong></h1><h2 id=\"ROS文件系统\"><a href=\"#ROS文件系统\" class=\"headerlink\" title=\"ROS文件系统\"></a><strong>ROS文件系统</strong></h2><p>文件系统层概念主要指在硬盘里能看到的ROS目录和文件，包括：</p>\n<ul>\n<li>Packages：软件包，ROS应用程序代码的组织单元，每个软件包都可包含程序库、可执行文件、脚本或其他手动创建的文件。</li>\n<li>Manifest（package.xml）：清单是对于“软件包”相关信息的描述，用于定义软件包相关元信息之间的依赖关系，这些信息包括版本、维护者和许可协议等。</li>\n<li>Message (msg) types: 存储在<code>my_package/msg/MyMessageType.msg</code>的Message文件，主要定义了ROS系统的messages传输的数据结构。 </li>\n<li>Service (srv) types: 存储在 <code>my_package/srv/MyServiceType.srv</code>的服务services文件，定义了ROS的服务通信时的请求（request ）和响应（response ）相关的数据结构。 </li>\n</ul>\n<h2 id=\"ROS计算图层\"><a href=\"#ROS计算图层\" class=\"headerlink\" title=\"ROS计算图层\"></a>ROS计算图层</h2><p>计算图是ROS在点对点网络里整合并处理数据的过程。基本计算图概念是 <em>节点</em>, <em>主机</em>, <em>参数服务器</em>, <em>消息</em>, <em>服务</em>, <em>话题</em>, and <em>数据包</em>，它们通过不同的方式提供数据给图层。 这些概念是在ros_comm库里实现的。</p>\n<ul>\n<li><strong>Nodes</strong>: 节点主要执行计算处理 。ROS被设计为细粒度的模块化的系统：一个机器人控制系统通常有很多节点组成 。例如，一个节点控制激光测距仪，一个节点控制轮电机，一个节点执行定位，一个节点执行路径规划，一个节点提供系统图形界面，等等。一个ROS节点通过ROS客户端库 <a href=\"http://wiki.ros.org/Client%20Libraries\" target=\"_blank\" rel=\"noopener\">client library</a>编写，例如 <a href=\"http://wiki.ros.org/roscpp\" target=\"_blank\" rel=\"noopener\">roscpp</a> o或<a href=\"http://wiki.ros.org/rospy\" target=\"_blank\" rel=\"noopener\">rospy</a> 。</li>\n<li><strong>Master</strong>: The ROS Master provides name registration and lookup to the rest of the Computation Graph. Without the Master, nodes would not be able to find each other, exchange messages, or invoke services.  </li>\n<li><strong>Parameter Server</strong>: The Parameter Server allows data to be stored by key in a central location. It is currently part of the Master. </li>\n<li><strong>Messages</strong>: 节点之间使用messages信息互相通信。 一个消息就是一个由类型域组成的简单的数据结构，支持标准的原始数据类型（integer, floating point, boolean等等）和数组 。消息可以包含任意嵌套的结构和数组（很像C结构）。</li>\n<li><strong>Topics</strong>: Messages are routed via a transport system with publish / subscribe semantics.  A node sends out a message by <em>publishing</em> it to a given <a href=\"http://wiki.ros.org/Topics\" target=\"_blank\" rel=\"noopener\">topic</a>. The topic is a <a href=\"http://wiki.ros.org/Names\" target=\"_blank\" rel=\"noopener\">name</a> that is used to identify the content of the message.  A node that is interested in a certain kind of data will <em>subscribe</em> to the appropriate topic.  There may be multiple concurrent publishers and subscribers for a single topic, and a single node may publish and/or subscribe to multiple topics.  In general, publishers and subscribers are not aware of each others’ existence.  The idea is to decouple the production of information from its consumption. Logically, one can think of a topic as a strongly typed message bus.  Each bus has a name, and anyone can connect to the bus to send or receive messages as long as they are the right type. </li>\n<li><strong>Services</strong>: The publish / subscribe model is a very flexible communication paradigm, but its many-to-many, one-way transport is not appropriate for request / reply interactions, which are often required in a distributed system.  Request / reply is done via <a href=\"http://wiki.ros.org/Services\" target=\"_blank\" rel=\"noopener\">services</a>, which are defined by a pair of message structures: one for the request and one for the reply. A providing node offers a service under a <a href=\"http://wiki.ros.org/Names\" target=\"_blank\" rel=\"noopener\">name</a> and a client uses the service by sending the request message and awaiting the reply.  ROS client libraries generally present this interaction to the programmer as if it were a remote procedure call. </li>\n<li><strong>Bags</strong>: Bags are a format for saving and playing back ROS message data. Bags are an important mechanism for storing data, such as sensor data, that can be difficult to collect but is necessary for developing and testing algorithms. </li>\n</ul>\n<h2 id=\"工作空间结构\"><a href=\"#工作空间结构\" class=\"headerlink\" title=\"工作空间结构\"></a>工作空间结构</h2><ul>\n<li>build：build space默认的所在位置，同时也是cmake 和 make被调用来配置并编译程序包的地方</li>\n<li>devel：devel space默认的所在位置，也是安装程序包之前存放可执行文件和库文件的地方</li>\n<li>src：存放软件包的位置</li>\n</ul>\n<h2 id=\"文件系统工具\"><a href=\"#文件系统工具\" class=\"headerlink\" title=\"文件系统工具\"></a><strong>文件系统工具</strong></h2><p><code>rospack</code>：允许用户获取软件包的有关信息，用法：<code>rospack find [package_name]</code></p>\n<p><code>roscd</code>：是rosbash命令集中的一部分，允许用户切换工作目录到某个软件包或软件包集中；和ROS中其他工具一样，只能切换到那些路径已经包含在<code>ROS_PACKAGE_PATH</code>环境变量中的软件包，可以使用<code>echo $ROS_PACKAGE_PATH</code>查看其中包含的路径。<code>ROS_PACKAGE_PATH</code>环境变量应该包含那些保存有ROS软件包的路径，并且每个路径之间用冒号分隔开。</p>\n<p><code>rosls</code>：rosbash命令集中的一部分，允许用户直接按软件包的名称而不是绝对路径执行<code>ls</code>命令，罗列命令。</p>\n<h2 id=\"ROS-catkin程序包\"><a href=\"#ROS-catkin程序包\" class=\"headerlink\" title=\"ROS catkin程序包\"></a><strong>ROS catkin程序包</strong></h2><p>组成：<code>package.xml</code>文件+<code>CMakeLists.txt</code>文件。</p>\n<p>每个目录下只能有一个程序包，同一目录下不能有嵌套的或多个程序包存在。</p>\n<h2 id=\"创建程序包的命令\"><a href=\"#创建程序包的命令\" class=\"headerlink\" title=\"创建程序包的命令\"></a><strong>创建程序包的命令</strong></h2><p><code>catkin_create_pkg &lt;package_name&gt; [depend1] [depend2] [depend3]</code></p>\n<p>该命令需要在工作空间/src目录下执行，<code>&lt;package_name&gt;</code>是要创建的软件包的名字，<code>depend1..3</code>是创建的程序包依赖的其他程序包,执行完该命令后,就会在src目录下生成一个文件夹，包含<code>package.xml</code>和<code>CMakeLists.txt</code>文件。</p>\n<p>程序包依赖关系查看命令:</p>\n<p>一级依赖：<code>rospack depends1 &lt;package_name&gt;</code></p>\n<p>间接依赖：<code>rospcak depends &lt;package_name&gt;</code></p>\n<h2 id=\"编译程序包\"><a href=\"#编译程序包\" class=\"headerlink\" title=\"编译程序包\"></a><strong>编译程序包</strong></h2><p><code>catkin_make [make_targets] [-DCMAKE_VARIABLES=...]</code></p>\n<p><code>catkin_make install</code> # (可选)</p>\n<p>编译工作空间下的某个软件包：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_make  -DCATKIN_WHITELIST_PACKAGES=\"package1;package2\"</span><br></pre></td></tr></table></figure>\n<p>在工作空间下执行上述命令，会编译src文件夹下的所有catkin工程。</p>\n<h2 id=\"ROS图概念\"><a href=\"#ROS图概念\" class=\"headerlink\" title=\"ROS图概念\"></a><strong>ROS图概念</strong></h2><p>Nodes：节点，ROS网络中的可执行文件，可通过ROS客户库与其他节点通信,节点可以发布或接收一个话题，节点也可以提供或使用某种服务。</p>\n<p>Messages：消息，一种ROS数据类型，用于订阅或发布到一个话题</p>\n<p>Topics：话题，节点可以发布消息到话题，也可以订阅话题以接受消息</p>\n<p>Master：节点管理器，ROS名称服务（如帮助节点找到彼此）</p>\n<p>ROS客户端库允许使用不同编程语言编写的节点之间互相通信：</p>\n<p>rospy = python客户端</p>\n<p>roscpp = c++ 客户端</p>\n<p><code>rosout</code>：ROS中相当于stdout/stderr，用于收集和记录节点调试输出信息，它总是运行的。</p>\n<p><code>roscore</code>：主机+rosout+参数服务器；运行所有ROS程序前首先要运行的命令;启动节点管理器（The Master）</p>\n<p><code>rosnode list</code>：列出活跃的节点</p>\n<p><code>rosnode info /[node_name]</code>：返回关于一个特定节点的信息</p>\n<p><code>rosrun [package_name] [node_name]</code>：允许使用包名直接运行一个包内的节点（不需要知道包的路径）</p>\n<h2 id=\"ROS话题-topic\"><a href=\"#ROS话题-topic\" class=\"headerlink\" title=\"ROS话题(topic)\"></a><strong>ROS话题</strong>(topic)</h2><p>节点和节点之间是通过一个ROS话题来互相通信的，某一个节点在一个话题上发布特定的消息，其他节点可以订阅该话题以接收该消息。</p>\n<p>rostopic命令工具可以获取有关ROS话题的信息，运行rostopic -h可以查看所有的rostopic子命令。</p>\n<p><code>rostopic bw</code>：显示话题使用的宽带。</p>\n<p><code>rostopic echo [topic]</code>：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。</p>\n<p><code>rostopic hz [topic]</code>：显示话题的数据发布速率</p>\n<p><code>rostopic list</code>：列出所有当前订阅和发布的话题，运行rostopic list -h可查看其子命令。</p>\n<p><code>rostopic pub [topic] [msg_type] [args]</code>：向当前某个正在广播的话题发布数据，使用<code>rostopic pub -h</code>查看该命令参数</p>\n<p><code>rostopic type [topic]</code>：显示所发布话题的消息类型，可以根据显示的话题类型，再继续执行<code>rosmsg show [message type]</code>：查看消息的详细情况</p>\n<h2 id=\"ROS消息-msg\"><a href=\"#ROS消息-msg\" class=\"headerlink\" title=\"ROS消息(msg)\"></a><strong>ROS消息(msg)</strong></h2><p>话题之间的通信是通过节点之间发送ROS消息实现的，发布器和订阅器之间的通信，必须发送和接收相同类型的消息，意味着话题的类型是由发布在它上面的消息类型决定的。</p>\n<p>msg文件存放在package的msg目录下，它是一个描述ROS中所使用消息类型的简单文本，实际是每行声明一个数据类型和变量名，会被用于生成不同语言的源代码。</p>\n<p><code>rostopic type [topic]</code>：用来显示所发布话题的消息类型</p>\n<p><code>rosmsg show [message type]</code>：查看消息的详细情况，即消息类型的基本数据类型组成</p>\n<p><code>rosmsg users</code>：Find files that use message  </p>\n<p><code>rosmsg md5</code>：Display message md5sum  </p>\n<p><code>rosmsg package</code>：List messages in a package  </p>\n<p><code>rosmsg packages</code>：List packages that contain messages</p>\n<h2 id=\"ROS服务-srv\"><a href=\"#ROS服务-srv\" class=\"headerlink\" title=\"ROS服务(srv)\"></a><strong>ROS服务(srv)</strong></h2><p>服务（services）是节点之间通信的另一种方式，服务允许节点发送请求（request）并获得一个响应（response）。srv文件存放在srv目录下，一个srv文件描述一项服务，包含请求和响应两个部分，在srv文件中由’—-‘分隔。</p>\n<p> rosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：</p>\n<p><code>rosservice list</code>：输出可用服务的信息</p>\n<p><code>rosservice call [service] [args]</code>：调用带参数的服务</p>\n<p><code>rosservice type [service]</code>：输出服务类型</p>\n<p><code>rosservice find</code>：依据类型寻找服务</p>\n<p><code>rosservice uri</code>：输出服务的ROSRPC uri</p>\n<h2 id=\"ROS参数\"><a href=\"#ROS参数\" class=\"headerlink\" title=\"ROS参数\"></a><strong>ROS参数</strong></h2><p><code>rosparam</code>使得能够存储并操作ROS参数服务器（Parameter Server）上的数据，参数服务器能够存储整型、浮点、布尔、字符串、字典和列表等数据类型，使用YAML标记语言的语法，其子命令如下：</p>\n<p><code>rosparam set [param_name]</code>：设置参数</p>\n<p><code>rosparam get [param_name]</code>：获取参数</p>\n<p><code>rosparam load</code>：从文件读取参数</p>\n<p><code>rosparam dump</code>：向文件中写入参数</p>\n<p><code>rosparam delete</code>：删除参数</p>\n<p><code>rosparam list</code>：列出参数名</p>\n<h2 id=\"消息发布器（节点）\"><a href=\"#消息发布器（节点）\" class=\"headerlink\" title=\"消息发布器（节点）\"></a><strong>消息发布器（节点）</strong></h2><p>创建过程：</p>\n<ul>\n<li>初始化 ROS 系统 </li>\n<li>在 ROS 网络内广播将要在话题上发布的某一类型的消息 </li>\n<li>以某一频率在话题上发布消息 </li>\n</ul>\n<h2 id=\"消息订阅器（节点）\"><a href=\"#消息订阅器（节点）\" class=\"headerlink\" title=\"消息订阅器（节点）\"></a><strong>消息订阅器（节点）</strong></h2><p>创建过程：</p>\n<ul>\n<li>初始化ROS系统</li>\n<li>订阅话题</li>\n<li>进入自循环，等待消息的到达</li>\n<li>当消息到达，调用回调函数 </li>\n</ul>\n<h2 id=\"服务器（Service）节点、客户端（Client）节点\"><a href=\"#服务器（Service）节点、客户端（Client）节点\" class=\"headerlink\" title=\"服务器（Service）节点、客户端（Client）节点\"></a><strong>服务器（Service）节点、客户端（Client）节点</strong></h2><h2 id=\"录制与回放数据\"><a href=\"#录制与回放数据\" class=\"headerlink\" title=\"录制与回放数据\"></a><strong>录制与回放数据</strong></h2><p>只有消息已经发布了才可以被录制。</p>\n<p>使用<code>rostopic list -v</code>命令查看当前系统中发布的所有话题。</p>\n<p>在一个保存录制的目录下运行<code>rosbag record -a</code>命令，附加的-a选项表示将当前发布的所有话题数据都录制保存到一个bag文件中，该文件会自动以年份、日期和时间命名并以.bag作为后缀，它包含了rosbag record运行期间所有节点发布的话题。</p>\n<p>bag文件可以使用<code>rosbag info</code>检查其内容，使用<code>rosbag play</code>命令回放出来。</p>\n<h2 id=\"常见错误\"><a href=\"#常见错误\" class=\"headerlink\" title=\"常见错误\"></a><strong>常见错误</strong></h2><p>执行<code>roscd</code>命令时，出现no such packag的情况，解决方案执行：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">echo</span> <span class=\"string\">\"export ROS_PACKAGE_PATH\"</span><span class=\"string\">=~/catkin_ws:\"$ROS_PACKAGE_PATH</span> <span class=\"string\">\" &gt;&gt; ~/.bashrc</span></span><br></pre></td></tr></table></figure>\n<p>在新的终端执行：<code>roscd ...</code>成功。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中基本概念和命令的学习内容。</p>","more":"<h1 id=\"ROS命令\"><a href=\"#ROS命令\" class=\"headerlink\" title=\"ROS命令**\"></a>ROS命令**</h1><p><code>source /devel/setup.bash</code>：刷新<code>setup.bash</code>文件，这个自动生成的脚本文件设置了若干环境变量，从而使ROS能够找到创建的功能包和新生成的可执行文件，类似与下面所述的全局脚本文件，但该文件是专门为自己的工作区量身定做的。</p>\n<p><code>source /opt/ros/kinetic/setup.bash</code>：全局的脚本文件</p>\n<p><code>ros··· -h</code>：查看ros命令格式</p>\n<p><code>roscore</code>：运行所有ROS程序前首先要运行的命令</p>\n<p><code>roswtf</code>：进行全面深入的检测，包括检测环境变量、安装的文件以及运行的节点</p>\n<p><code>rosnode list</code>：列出活跃的节点</p>\n<p><code>rosnode info /[node_name]</code>：返回关于一个特定节点的信息</p>\n<p><code>rosrun [package_name] [node_name]</code>：允许使用包名直接运行一个包内的节点</p>\n<p><code>rosrun rqt_graph rqt_graph</code>：以图的形式显示正在运行的节点和话题之间的消息</p>\n<p><code>roscp [package_name] [file_to_copy_path] [copy_path]</code>：将文件从一个package复制到另一个package</p>\n<p><code>rospack</code>：允许用户获取软件包的有关信息，用法：<code>rospack find [package_name]</code></p>\n<p><code>roscd</code>：切换工作目录到某个软件包或软件包集中</p>\n<p><code>rosls</code>：直接按软件包的名称而不是绝对路径执行ls命令，罗列命令。</p>\n<p><code>catkin_create_pkg &lt;package_name&gt; [depend1] [depend2] [depend3]</code>：创建程序包</p>\n<p><code>rospack depends1 &lt;package_name&gt;</code>：一级依赖</p>\n<p><code>rospcak depends &lt;package_name&gt;</code>：间接依赖</p>\n<p><code>catkin_make [make_targets] [-DCMAKE_VARIABLES=...]</code>：编译程序包</p>\n<p><code>rosnode list</code>：列出正在运行的活跃的节点</p>\n<p><code>rosnode info [node_name]</code>：返回关于一个特定节点的信息</p>\n<p><code>rosnode kill [node_name]</code>：终止节点运行</p>\n<p><code>rosnode cleanup</code>：将节点从rosnode列表中删除</p>\n<p><code>rosrun [package_name][node_name]</code>：允许使用包名直接运行一个包内的节点</p>\n<p><code>rostopic echo [topic]</code>：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。</p>\n<p><code>rostopic hz [topic]</code>：订阅指定的话题，显示该话题的数据发布速率，每秒发布的消息数量</p>\n<p><code>rostopic bw [topic]</code>：订阅指定的话题，显示话题使用的宽带，即每秒发布消息所占的字节量</p>\n<p><code>rostopic list</code>：列出所有当前订阅和发布的话题，运行<code>rostopic list -h</code>可查看其子命令。</p>\n<p><code>rostopic pub -r rate-in-hz [topic]　[msg_type] [args]</code>：向当前某个正在广播的话题重复地按照指定频率发布指定的消息，使用<code>rostopic pub -h</code>查看该命令参数，例子：</p>\n<p><code>rostopic pub –r 1 /turtle1/cmd_vel geometry_msgs/Twist ’[2,0,0]’ ’[0,0,0]’</code></p>\n<p>子参数说明：</p>\n<ul>\n<li>-r：指定话题以频率模式发布消息，即以一定的时间周期发布消息</li>\n<li>-1(数字1)：一次性发布模式</li>\n<li>-l(小写L)：默认的模式，即特别的锁存模式，也是发布一次消息，但会确保该话题的新订阅者也会收到消息</li>\n<li>-f：从文件中读取消息或从标准的输入中读取</li>\n</ul>\n<p><code>rostopic type [topic]</code>：显示所发布话题的消息类型</p>\n<p><code>rostopic info [topic]</code>：获取关于话题的信息（消息类型、发布者、订阅者）</p>\n<p><code>rosmsg show [message type]</code>：查看消息的详细情况，即消息类型的基本数据类型组成</p>\n<p><code>rosmsg users</code>：Find files that use message  </p>\n<p><code>rosmsg md5</code>：Display message md5sum  </p>\n<p><code>rosmsg package</code>：List messages in a package </p>\n<p><code>rosmsg packages</code>：List packages that contain messages</p>\n<p>rosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：</p>\n<p><code>rosservice list</code>：输出可用服务的信息</p>\n<p><code>rosservice call [service</code>] [args]：调用带参数的服务</p>\n<p><code>rosservice type [service]</code>：输出服务类型</p>\n<p><code>rosservice find</code>：依据类型寻找服务</p>\n<p><code>rosservice uri</code>：输出服务的<code>ROSRPC uri</code></p>\n<p><code>rosparam set [param_name]</code>：设置参数</p>\n<p><code>rosparam get [param_name]</code>：获取参数</p>\n<p><code>rosparam load</code>：从文件读取参数</p>\n<p><code>rosparam dump</code>：向文件中写入参数</p>\n<p><code>rosparam delete</code>：删除参数</p>\n<p><code>rosparam list</code>：列出参数名</p>\n<p><code>rosdep install [package]</code>：下载并安装ROS package所需要的系统依赖项</p>\n<ul>\n<li>Roslaunch xml文件标签说明：<a href=\"http://wiki.ros.org/roslaunch/XML\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/roslaunch/XML</a></li>\n<li>Urdf xml 文件标签说明：<a href=\"http://wiki.ros.org/urdf/XML\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/urdf/XML</a></li>\n<li>Roscpp api 文档：<a href=\"http://docs.ros.org/jade/api/roscpp/html/\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/jade/api/roscpp/html/</a></li>\n<li>Rospy api 文档：<a href=\"http://docs.ros.org/jade/api/rospy/html/\" target=\"_blank\" rel=\"noopener\">http://docs.ros.org/jade/api/rospy/html/</a></li>\n</ul>\n<h1 id=\"ROS概念\"><a href=\"#ROS概念\" class=\"headerlink\" title=\"ROS概念\"></a><strong>ROS概念</strong></h1><h2 id=\"ROS文件系统\"><a href=\"#ROS文件系统\" class=\"headerlink\" title=\"ROS文件系统\"></a><strong>ROS文件系统</strong></h2><p>文件系统层概念主要指在硬盘里能看到的ROS目录和文件，包括：</p>\n<ul>\n<li>Packages：软件包，ROS应用程序代码的组织单元，每个软件包都可包含程序库、可执行文件、脚本或其他手动创建的文件。</li>\n<li>Manifest（package.xml）：清单是对于“软件包”相关信息的描述，用于定义软件包相关元信息之间的依赖关系，这些信息包括版本、维护者和许可协议等。</li>\n<li>Message (msg) types: 存储在<code>my_package/msg/MyMessageType.msg</code>的Message文件，主要定义了ROS系统的messages传输的数据结构。 </li>\n<li>Service (srv) types: 存储在 <code>my_package/srv/MyServiceType.srv</code>的服务services文件，定义了ROS的服务通信时的请求（request ）和响应（response ）相关的数据结构。 </li>\n</ul>\n<h2 id=\"ROS计算图层\"><a href=\"#ROS计算图层\" class=\"headerlink\" title=\"ROS计算图层\"></a>ROS计算图层</h2><p>计算图是ROS在点对点网络里整合并处理数据的过程。基本计算图概念是 <em>节点</em>, <em>主机</em>, <em>参数服务器</em>, <em>消息</em>, <em>服务</em>, <em>话题</em>, and <em>数据包</em>，它们通过不同的方式提供数据给图层。 这些概念是在ros_comm库里实现的。</p>\n<ul>\n<li><strong>Nodes</strong>: 节点主要执行计算处理 。ROS被设计为细粒度的模块化的系统：一个机器人控制系统通常有很多节点组成 。例如，一个节点控制激光测距仪，一个节点控制轮电机，一个节点执行定位，一个节点执行路径规划，一个节点提供系统图形界面，等等。一个ROS节点通过ROS客户端库 <a href=\"http://wiki.ros.org/Client%20Libraries\" target=\"_blank\" rel=\"noopener\">client library</a>编写，例如 <a href=\"http://wiki.ros.org/roscpp\" target=\"_blank\" rel=\"noopener\">roscpp</a> o或<a href=\"http://wiki.ros.org/rospy\" target=\"_blank\" rel=\"noopener\">rospy</a> 。</li>\n<li><strong>Master</strong>: The ROS Master provides name registration and lookup to the rest of the Computation Graph. Without the Master, nodes would not be able to find each other, exchange messages, or invoke services.  </li>\n<li><strong>Parameter Server</strong>: The Parameter Server allows data to be stored by key in a central location. It is currently part of the Master. </li>\n<li><strong>Messages</strong>: 节点之间使用messages信息互相通信。 一个消息就是一个由类型域组成的简单的数据结构，支持标准的原始数据类型（integer, floating point, boolean等等）和数组 。消息可以包含任意嵌套的结构和数组（很像C结构）。</li>\n<li><strong>Topics</strong>: Messages are routed via a transport system with publish / subscribe semantics.  A node sends out a message by <em>publishing</em> it to a given <a href=\"http://wiki.ros.org/Topics\" target=\"_blank\" rel=\"noopener\">topic</a>. The topic is a <a href=\"http://wiki.ros.org/Names\" target=\"_blank\" rel=\"noopener\">name</a> that is used to identify the content of the message.  A node that is interested in a certain kind of data will <em>subscribe</em> to the appropriate topic.  There may be multiple concurrent publishers and subscribers for a single topic, and a single node may publish and/or subscribe to multiple topics.  In general, publishers and subscribers are not aware of each others’ existence.  The idea is to decouple the production of information from its consumption. Logically, one can think of a topic as a strongly typed message bus.  Each bus has a name, and anyone can connect to the bus to send or receive messages as long as they are the right type. </li>\n<li><strong>Services</strong>: The publish / subscribe model is a very flexible communication paradigm, but its many-to-many, one-way transport is not appropriate for request / reply interactions, which are often required in a distributed system.  Request / reply is done via <a href=\"http://wiki.ros.org/Services\" target=\"_blank\" rel=\"noopener\">services</a>, which are defined by a pair of message structures: one for the request and one for the reply. A providing node offers a service under a <a href=\"http://wiki.ros.org/Names\" target=\"_blank\" rel=\"noopener\">name</a> and a client uses the service by sending the request message and awaiting the reply.  ROS client libraries generally present this interaction to the programmer as if it were a remote procedure call. </li>\n<li><strong>Bags</strong>: Bags are a format for saving and playing back ROS message data. Bags are an important mechanism for storing data, such as sensor data, that can be difficult to collect but is necessary for developing and testing algorithms. </li>\n</ul>\n<h2 id=\"工作空间结构\"><a href=\"#工作空间结构\" class=\"headerlink\" title=\"工作空间结构\"></a>工作空间结构</h2><ul>\n<li>build：build space默认的所在位置，同时也是cmake 和 make被调用来配置并编译程序包的地方</li>\n<li>devel：devel space默认的所在位置，也是安装程序包之前存放可执行文件和库文件的地方</li>\n<li>src：存放软件包的位置</li>\n</ul>\n<h2 id=\"文件系统工具\"><a href=\"#文件系统工具\" class=\"headerlink\" title=\"文件系统工具\"></a><strong>文件系统工具</strong></h2><p><code>rospack</code>：允许用户获取软件包的有关信息，用法：<code>rospack find [package_name]</code></p>\n<p><code>roscd</code>：是rosbash命令集中的一部分，允许用户切换工作目录到某个软件包或软件包集中；和ROS中其他工具一样，只能切换到那些路径已经包含在<code>ROS_PACKAGE_PATH</code>环境变量中的软件包，可以使用<code>echo $ROS_PACKAGE_PATH</code>查看其中包含的路径。<code>ROS_PACKAGE_PATH</code>环境变量应该包含那些保存有ROS软件包的路径，并且每个路径之间用冒号分隔开。</p>\n<p><code>rosls</code>：rosbash命令集中的一部分，允许用户直接按软件包的名称而不是绝对路径执行<code>ls</code>命令，罗列命令。</p>\n<h2 id=\"ROS-catkin程序包\"><a href=\"#ROS-catkin程序包\" class=\"headerlink\" title=\"ROS catkin程序包\"></a><strong>ROS catkin程序包</strong></h2><p>组成：<code>package.xml</code>文件+<code>CMakeLists.txt</code>文件。</p>\n<p>每个目录下只能有一个程序包，同一目录下不能有嵌套的或多个程序包存在。</p>\n<h2 id=\"创建程序包的命令\"><a href=\"#创建程序包的命令\" class=\"headerlink\" title=\"创建程序包的命令\"></a><strong>创建程序包的命令</strong></h2><p><code>catkin_create_pkg &lt;package_name&gt; [depend1] [depend2] [depend3]</code></p>\n<p>该命令需要在工作空间/src目录下执行，<code>&lt;package_name&gt;</code>是要创建的软件包的名字，<code>depend1..3</code>是创建的程序包依赖的其他程序包,执行完该命令后,就会在src目录下生成一个文件夹，包含<code>package.xml</code>和<code>CMakeLists.txt</code>文件。</p>\n<p>程序包依赖关系查看命令:</p>\n<p>一级依赖：<code>rospack depends1 &lt;package_name&gt;</code></p>\n<p>间接依赖：<code>rospcak depends &lt;package_name&gt;</code></p>\n<h2 id=\"编译程序包\"><a href=\"#编译程序包\" class=\"headerlink\" title=\"编译程序包\"></a><strong>编译程序包</strong></h2><p><code>catkin_make [make_targets] [-DCMAKE_VARIABLES=...]</code></p>\n<p><code>catkin_make install</code> # (可选)</p>\n<p>编译工作空间下的某个软件包：</p>\n<!--�285-->\n<p>在工作空间下执行上述命令，会编译src文件夹下的所有catkin工程。</p>\n<h2 id=\"ROS图概念\"><a href=\"#ROS图概念\" class=\"headerlink\" title=\"ROS图概念\"></a><strong>ROS图概念</strong></h2><p>Nodes：节点，ROS网络中的可执行文件，可通过ROS客户库与其他节点通信,节点可以发布或接收一个话题，节点也可以提供或使用某种服务。</p>\n<p>Messages：消息，一种ROS数据类型，用于订阅或发布到一个话题</p>\n<p>Topics：话题，节点可以发布消息到话题，也可以订阅话题以接受消息</p>\n<p>Master：节点管理器，ROS名称服务（如帮助节点找到彼此）</p>\n<p>ROS客户端库允许使用不同编程语言编写的节点之间互相通信：</p>\n<p>rospy = python客户端</p>\n<p>roscpp = c++ 客户端</p>\n<p><code>rosout</code>：ROS中相当于stdout/stderr，用于收集和记录节点调试输出信息，它总是运行的。</p>\n<p><code>roscore</code>：主机+rosout+参数服务器；运行所有ROS程序前首先要运行的命令;启动节点管理器（The Master）</p>\n<p><code>rosnode list</code>：列出活跃的节点</p>\n<p><code>rosnode info /[node_name]</code>：返回关于一个特定节点的信息</p>\n<p><code>rosrun [package_name] [node_name]</code>：允许使用包名直接运行一个包内的节点（不需要知道包的路径）</p>\n<h2 id=\"ROS话题-topic\"><a href=\"#ROS话题-topic\" class=\"headerlink\" title=\"ROS话题(topic)\"></a><strong>ROS话题</strong>(topic)</h2><p>节点和节点之间是通过一个ROS话题来互相通信的，某一个节点在一个话题上发布特定的消息，其他节点可以订阅该话题以接收该消息。</p>\n<p>rostopic命令工具可以获取有关ROS话题的信息，运行rostopic -h可以查看所有的rostopic子命令。</p>\n<p><code>rostopic bw</code>：显示话题使用的宽带。</p>\n<p><code>rostopic echo [topic]</code>：显示在某个话题上发布的数据，本质是生成rostopic echo节点，订阅该话题以接收该话题上发布的消息并显示。</p>\n<p><code>rostopic hz [topic]</code>：显示话题的数据发布速率</p>\n<p><code>rostopic list</code>：列出所有当前订阅和发布的话题，运行rostopic list -h可查看其子命令。</p>\n<p><code>rostopic pub [topic] [msg_type] [args]</code>：向当前某个正在广播的话题发布数据，使用<code>rostopic pub -h</code>查看该命令参数</p>\n<p><code>rostopic type [topic]</code>：显示所发布话题的消息类型，可以根据显示的话题类型，再继续执行<code>rosmsg show [message type]</code>：查看消息的详细情况</p>\n<h2 id=\"ROS消息-msg\"><a href=\"#ROS消息-msg\" class=\"headerlink\" title=\"ROS消息(msg)\"></a><strong>ROS消息(msg)</strong></h2><p>话题之间的通信是通过节点之间发送ROS消息实现的，发布器和订阅器之间的通信，必须发送和接收相同类型的消息，意味着话题的类型是由发布在它上面的消息类型决定的。</p>\n<p>msg文件存放在package的msg目录下，它是一个描述ROS中所使用消息类型的简单文本，实际是每行声明一个数据类型和变量名，会被用于生成不同语言的源代码。</p>\n<p><code>rostopic type [topic]</code>：用来显示所发布话题的消息类型</p>\n<p><code>rosmsg show [message type]</code>：查看消息的详细情况，即消息类型的基本数据类型组成</p>\n<p><code>rosmsg users</code>：Find files that use message  </p>\n<p><code>rosmsg md5</code>：Display message md5sum  </p>\n<p><code>rosmsg package</code>：List messages in a package  </p>\n<p><code>rosmsg packages</code>：List packages that contain messages</p>\n<h2 id=\"ROS服务-srv\"><a href=\"#ROS服务-srv\" class=\"headerlink\" title=\"ROS服务(srv)\"></a><strong>ROS服务(srv)</strong></h2><p>服务（services）是节点之间通信的另一种方式，服务允许节点发送请求（request）并获得一个响应（response）。srv文件存放在srv目录下，一个srv文件描述一项服务，包含请求和响应两个部分，在srv文件中由’—-‘分隔。</p>\n<p> rosservice命令可以使用ROS客户端/服务器框架提供的服务，其子命令如下：</p>\n<p><code>rosservice list</code>：输出可用服务的信息</p>\n<p><code>rosservice call [service] [args]</code>：调用带参数的服务</p>\n<p><code>rosservice type [service]</code>：输出服务类型</p>\n<p><code>rosservice find</code>：依据类型寻找服务</p>\n<p><code>rosservice uri</code>：输出服务的ROSRPC uri</p>\n<h2 id=\"ROS参数\"><a href=\"#ROS参数\" class=\"headerlink\" title=\"ROS参数\"></a><strong>ROS参数</strong></h2><p><code>rosparam</code>使得能够存储并操作ROS参数服务器（Parameter Server）上的数据，参数服务器能够存储整型、浮点、布尔、字符串、字典和列表等数据类型，使用YAML标记语言的语法，其子命令如下：</p>\n<p><code>rosparam set [param_name]</code>：设置参数</p>\n<p><code>rosparam get [param_name]</code>：获取参数</p>\n<p><code>rosparam load</code>：从文件读取参数</p>\n<p><code>rosparam dump</code>：向文件中写入参数</p>\n<p><code>rosparam delete</code>：删除参数</p>\n<p><code>rosparam list</code>：列出参数名</p>\n<h2 id=\"消息发布器（节点）\"><a href=\"#消息发布器（节点）\" class=\"headerlink\" title=\"消息发布器（节点）\"></a><strong>消息发布器（节点）</strong></h2><p>创建过程：</p>\n<ul>\n<li>初始化 ROS 系统 </li>\n<li>在 ROS 网络内广播将要在话题上发布的某一类型的消息 </li>\n<li>以某一频率在话题上发布消息 </li>\n</ul>\n<h2 id=\"消息订阅器（节点）\"><a href=\"#消息订阅器（节点）\" class=\"headerlink\" title=\"消息订阅器（节点）\"></a><strong>消息订阅器（节点）</strong></h2><p>创建过程：</p>\n<ul>\n<li>初始化ROS系统</li>\n<li>订阅话题</li>\n<li>进入自循环，等待消息的到达</li>\n<li>当消息到达，调用回调函数 </li>\n</ul>\n<h2 id=\"服务器（Service）节点、客户端（Client）节点\"><a href=\"#服务器（Service）节点、客户端（Client）节点\" class=\"headerlink\" title=\"服务器（Service）节点、客户端（Client）节点\"></a><strong>服务器（Service）节点、客户端（Client）节点</strong></h2><h2 id=\"录制与回放数据\"><a href=\"#录制与回放数据\" class=\"headerlink\" title=\"录制与回放数据\"></a><strong>录制与回放数据</strong></h2><p>只有消息已经发布了才可以被录制。</p>\n<p>使用<code>rostopic list -v</code>命令查看当前系统中发布的所有话题。</p>\n<p>在一个保存录制的目录下运行<code>rosbag record -a</code>命令，附加的-a选项表示将当前发布的所有话题数据都录制保存到一个bag文件中，该文件会自动以年份、日期和时间命名并以.bag作为后缀，它包含了rosbag record运行期间所有节点发布的话题。</p>\n<p>bag文件可以使用<code>rosbag info</code>检查其内容，使用<code>rosbag play</code>命令回放出来。</p>\n<h2 id=\"常见错误\"><a href=\"#常见错误\" class=\"headerlink\" title=\"常见错误\"></a><strong>常见错误</strong></h2><p>执行<code>roscd</code>命令时，出现no such packag的情况，解决方案执行：</p>\n<!--�286-->\n<p>在新的终端执行：<code>roscd ...</code>成功。</p>"},{"title":"ubuntu16.04 Hexo+github+Typora搭建博客","date":"2018-03-21T14:22:50.000Z","copyright":true,"_content":"\n------\n\n这篇文章是Hexo博客搭建有关的内容。\n\n<!--more-->\n\n# 预备知识\n\nHexo是一个基于Node.js的静态博客程序，可以方便的生成静态网页托管在github、gitcafe和Heroku上。博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，hexo所做的就是将这些md文件都放在本地，更新博文目录和相关链接信息，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n\nHexo依赖Node.js和Git。nvm（node version manager）是nodejs版本管理工具，管理nodejs和npm的版本；npm是随同nodeJs一起安装的包管理工具，npm管理对应nodeJs的第三方插件；nvm管理构建nodejs和对应的npm，npm管理对应的nodejs的第三方插件。\n\n# **本地搭建**\n\n## 安装Git\n\n~~~shell\nsudo apt-get install git-core\n~~~\n\n## 安装Node.js\n\n最好的方式是使用NVM（Node Version Manager）安装，在终端安装nvm执行命令：\n\ncURL：\n\n~~~sh\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash\n~~~\n\nWget：\n\n~~~shelll\nwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash\n~~~\n\n重启终端安装Node.js：\n\n~~~shell\nnvm install stable\n~~~\n\n## 安装Hexo\n\n~~~shell\nnpm install -g hexo-cli\n~~~\n\n## 初始化Hexo\n\n~~~shell\nmkdir git\ncd git\nhexo init hexo   #自定义的文件夹\ncd hexo\nnpm install \n~~~\n\n## 设置Hexo\n\n执行命令：\n\n~~~shell\nhexo g/generate  #生成静态网页\nhexo s/server    #运行本地服务器\n~~~\n\n如果出现提示：\n\n~~~shell\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.\n~~~\n\n说明安装成功，在浏览器地址栏输入http://localhost:4000 就可以看到默认主题的博客界面了。\n\n## 博客主题更改\n\n安装主题next或yillia，在～/git/hexo/目录下执行命令：\n\n~~~shell\nhexo clean\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n~~~\n\n或\n\n~~~shell\ngit clone git@github.com:litten/hexo-theme-yilia.git themes/yilia\n~~~\n\n更新主题，修改hexo目录下的`_config.yml`，将`theme`属性设置为`next`或`yilia`，默认是landscape。\n\n执行命令查看本地效果：\n\n~~~shell\nhexo g\nhexo s\n~~~\n\n到此为止已经完成了Hexo博客的本地安装和查看，下一步是将博客部署到github上面，这样就可以通过网络远程访问自己的博客了。\n\n目前使用的是next主题，完整的安装配置过程可以参考[这里](http://theme-next.iissnan.com/getting-started.html)。\n\nnext主题优化推荐文章：https://www.jianshu.com/p/1f8107a8778c\n\n# **部署到github**\n\n- 首先到github上面注册自己的账号。\n- 配置github\n\n命令行输入命令：\n\n~~~shell\ngit config --global user.name \"username\" #ruoxiangli\ngit config --global user.eamil \"email@example.com\" #981968690@qq.com\n~~~\n\n其中`yourname `是输入你自己的用户名，`email@example.com`输入你自己的注册邮箱。\n\n这里可以使用`git config --list`命令查看配置好的内容（保存在home/.gitconfig文件中），如果需要修改用户名或邮箱，执行如下命令（也可以直接修改文件）：\n\n~~~shell\ngit config --global --replace-all user.name “username”\ngit config --global --replace-all user.email “email@example.com”\n~~~\n\n- 创建公钥，命令行输入命令：\n\n~~~shell\nssh-keygen -C 'you email address@gmail.com' -t rsa\n~~~\n\n**说明：C必须大写，改为自己的注册邮箱，然后一直回车，直到出现`“The key’s randomart image is：”`的提示。**\n\n之后用户目录` ~/.ssh/ `下建立了相应的密钥文件`id_rsa.pub `，打开该文件。\n\n- 添加公钥：github首页右上角点击头像，选择`Settings`，再选择`New SSH KEY`，把上一步`id_rsa.pub`文件的秘钥复制进去生成公钥。\n\n\n- 创建项目仓库：github首页点击右上角的`+`，选择`New repository`。在页面里输入`username.github.io`，必须这么写。填完后点击`Create repository`。\n\n\n- 部署博客：修改hexo目录下的`_config.yml`文件，最后面修改为：\n\n~~~yaml\ndeploy:\n  type: git\n  repository: git@github.com:username/username.github.io.git\n  branch: master\n~~~\n\n安装hexo的插件：\n\n~~~shell\nnpm install hexo-deployer-git --save\n~~~\n\n然后：\n\n~~~shell\nhexo clean\nhexo generate\nhexo deploy #可以使用hexo g -d命令代替上面两个命令\n~~~\n\n在浏览器输入`yourname.github.io`就可以访问的自己的博客啦。\n# 绑定自己的域名\n绑定域名分2种情况：带www和不带www的。\n\n域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下`yourname.github.io`的IP，然后到域名DNS设置页，将A记录指向ping出来的IP，将CNAME指向`username.github.io`，这样可以保证无论是否添加www都可以访问，如下：\n\n![img](http://image.liuxianan.com/201608/20160823_191336_238_8683.png)\n\n然后到github项目根目录新建一个名为CNAME的文件（无后缀），里面填写自己的域名。在绑定了新域名之后，原来的`username.github.io`并没有失效，还是会自动跳转到新域名。\n\n# 编辑.md文件工具推荐\n\n笔者使用的是Typora，[官网](https://typora.io/)，网页最下面是下载入口，根据自己的系统选择，ubuntu的方式如下：\n\n~~~shell\n# optional, but recommended\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE\n# add Typora's repository\nsudo add-apt-repository 'deb http://typora.io linux/'\nsudo apt-get update\n# install typora\nsudo apt-get install typora\n~~~\n\nTypora的Markdown语法的学习可以参考[博客](http://blog.csdn.net/tzs_1041218129/article/details/54728799)。\n\n配置Hexo渲染MathJax数学公式，推荐文章：https://www.jianshu.com/p/7ab21c7f0674\n\n# 多机更新\n\n## 方案一（不好用）\n\n使用坚果云同步hexo文件夹文件。坚果云同步hexo中文件时，有些文件会一直处于分析状态，上传不上去，影响其他文件的上传，so放弃坚果云。\n\n## 方案二\n\n使用GitHub进行同步\n\n### 旧设备操作\n\n> 假设已经按照前面的步骤在旧设备上搭建好了Hexo并部署到了GitHub。\n\n在旧设备部署博客到Github以后，我们可以在Github仓库的master分支上看到上传的博客文件。但是这个博客文件不包含hexo配置文件，所以需要新建分支，使用git指令将带hexo的配置文件上传到新建的分支上。在本地博客根目录下使用git指令上传项目到GitHub，按如下进行操作：\n\n~~~\n// git初始化 \ngit init \n// 添加仓库地址 \ngit remote add origin https://github.com/用户名/仓库名.git \n// 新建分支hexo并切换到新建的分支 \ngit checkout -b hexo \n// 添加所有本地文件到git\ngit add . \n// git提交 \ngit commit -m \"...\" \n// 文件推送到hexo分支 \ngit push origin hexo\n~~~\n\n至此，旧设备上需要进行的操作完成。\n\n### 新设备操作\n\n1. Github上新建的分支的文件git clone到本地\n\n   ~~~\n   git clone -b hexo https://github.com/用户名/仓库名.git\n   ~~~\n\n2. 安装Git、Node.js\n\n3. 安装依赖库\n\n   ~~~\n   #hexo-renderer-kramed markdown渲染引擎\n   npm uninstall hexo-renderer-marked --save\n   npm install hexo-renderer-kramed --save\n   #rss\n   npm install --save hexo-generator-feed\n   #hexo-word count\n   npm install hexo-wordcount --save\n   ~~~\n\n   安装过程中会提示没有/home/eric/package.json文件的提示（但应该已经安装完成了），不过对后面的过程没有影响。\n\n4. 安装hexo（到git clone的目录下操作命令）\n\n   ~~~\n   npm install -g hexo-cli\n   npm install\n   npm install hexo-deployer-git\n   ~~~\n\n   这个过程应该会在当前目录下产生`package.json`文件，执行`hexo clean`，应该可以顺利执行，说明配置成功。\n\n5. 添加SSH key\n\n   - 命令行输入`ssh-keygen -t rsa -C “邮箱地址”`\n\n   - 按三次回车（密码为空），生成密匙。 在`home/username/.ssh`目录下找到`id_rsa.pub`，打开复制内容到GitHub添加新的SSH key。\n\n   - 终端输入`ssh - T git@github.com`回车，提示认证成功即可。\n\n   - 在终端输入命令(和旧设备中的相同)：\n\n     ```\n     git config --global user.name \"username\" #ruoxiangli\n     git config --global user.eamil \"email@example.com\" #981968690@qq.com\n     ```\n\n     执行`hexo g -d`，顺利执行则说明配置成功。\n\n6. [配置Hexo渲染MathJax数学公式](https://www.jianshu.com/p/7ab21c7f0674)\n\n\n### 新旧设备的日常维护\n\n**注意：在当前设备上进行所有操作之前，一定要现将本地的配置文件（包括添加的新博文、修改内容样式等等）进行更新，因为在此之前另一台设备可能向GitHub推送了更新，但是本地的内容还是旧版，若不更新进行操作，之后提交的会是旧版的内容修改后的效果。**\n\n> 为了保证本地内容为最新，所有操作前的操作：git pull origin hexo \n\n本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理： \n\n1. 配置文件的更新：依次执行`git add .`、`git commit -m “…”`、`git push origin hexo`指令将改动推送到GitHub（此时当前分支应为hexo） \n\n   **补充：**如果不想每次push都输入用户名和密码。查看到传输协议，终端执行：\n\n   ~~~\n   git remote -v\n   ~~~\n\n   可以看到：\n\n   ~~~\n   origin\thttps://github.com/ruoxiangli/ruoxiangli.github.io.git (fetch)\n   origin\thttps://github.com/ruoxiangli/ruoxiangli.github.io.git (push)\n   ~~~\n\n   重新设置成ssh的方式：\n\n   ~~~\n   git remote rm origin\n   git remote add origin git@github.com:username/repository.git\n   git push -u origin master\n   ~~~\n\n   再查看当前传输协议：\n\n   ~~~\n   origin\tgit@github.com:ruoxiangli/ruoxiangli.github.io.git (fetch)\n   origin\tgit@github.com:ruoxiangli/ruoxiangli.github.io.git (push)\n   ~~~\n\n   到此操作成功。\n\n2. 静态网页的更新：执行`hexo g -d`发布网站到master分支\n\n参考文章：https://www.jianshu.com/p/6fb0b287f950\n\nhttps://blog.csdn.net/crazy_scott/article/details/79342303\n\n# 遇到的错误解决方法\n\n发现执行时nvm install stable时出现未找到‘nvm’命令的错误提示，解决方式，分别执行下面两行指令：\n\n~~~shell\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"NVM_DIR/nvm.sh\" ] && \\. \"NVM_DIR/nvm.sh\"  # This loads nvm\n~~~\n\n执行`hexo server`后访问`http://localhost:4000`，出现`Cannot Get /`提示，打不开网页，可能是由于端口号4000被占用，可以使用其他端口号打开。解决方式：`hexo server -p 5000`\n","source":"_posts/ubuntu16.04 Hexo+github+Typora搭建博客.md","raw":"---\ntitle: ubuntu16.04 Hexo+github+Typora搭建博客\ndate: 2018-03-21 22:22:50\ntags: \n  - ubuntu16.04\n  - Hexo \n  - Github\n  - Typora\ncategories: 工具\ncopyright: true\n---\n\n------\n\n这篇文章是Hexo博客搭建有关的内容。\n\n<!--more-->\n\n# 预备知识\n\nHexo是一个基于Node.js的静态博客程序，可以方便的生成静态网页托管在github、gitcafe和Heroku上。博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，hexo所做的就是将这些md文件都放在本地，更新博文目录和相关链接信息，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n\nHexo依赖Node.js和Git。nvm（node version manager）是nodejs版本管理工具，管理nodejs和npm的版本；npm是随同nodeJs一起安装的包管理工具，npm管理对应nodeJs的第三方插件；nvm管理构建nodejs和对应的npm，npm管理对应的nodejs的第三方插件。\n\n# **本地搭建**\n\n## 安装Git\n\n~~~shell\nsudo apt-get install git-core\n~~~\n\n## 安装Node.js\n\n最好的方式是使用NVM（Node Version Manager）安装，在终端安装nvm执行命令：\n\ncURL：\n\n~~~sh\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash\n~~~\n\nWget：\n\n~~~shelll\nwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash\n~~~\n\n重启终端安装Node.js：\n\n~~~shell\nnvm install stable\n~~~\n\n## 安装Hexo\n\n~~~shell\nnpm install -g hexo-cli\n~~~\n\n## 初始化Hexo\n\n~~~shell\nmkdir git\ncd git\nhexo init hexo   #自定义的文件夹\ncd hexo\nnpm install \n~~~\n\n## 设置Hexo\n\n执行命令：\n\n~~~shell\nhexo g/generate  #生成静态网页\nhexo s/server    #运行本地服务器\n~~~\n\n如果出现提示：\n\n~~~shell\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.\n~~~\n\n说明安装成功，在浏览器地址栏输入http://localhost:4000 就可以看到默认主题的博客界面了。\n\n## 博客主题更改\n\n安装主题next或yillia，在～/git/hexo/目录下执行命令：\n\n~~~shell\nhexo clean\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n~~~\n\n或\n\n~~~shell\ngit clone git@github.com:litten/hexo-theme-yilia.git themes/yilia\n~~~\n\n更新主题，修改hexo目录下的`_config.yml`，将`theme`属性设置为`next`或`yilia`，默认是landscape。\n\n执行命令查看本地效果：\n\n~~~shell\nhexo g\nhexo s\n~~~\n\n到此为止已经完成了Hexo博客的本地安装和查看，下一步是将博客部署到github上面，这样就可以通过网络远程访问自己的博客了。\n\n目前使用的是next主题，完整的安装配置过程可以参考[这里](http://theme-next.iissnan.com/getting-started.html)。\n\nnext主题优化推荐文章：https://www.jianshu.com/p/1f8107a8778c\n\n# **部署到github**\n\n- 首先到github上面注册自己的账号。\n- 配置github\n\n命令行输入命令：\n\n~~~shell\ngit config --global user.name \"username\" #ruoxiangli\ngit config --global user.eamil \"email@example.com\" #981968690@qq.com\n~~~\n\n其中`yourname `是输入你自己的用户名，`email@example.com`输入你自己的注册邮箱。\n\n这里可以使用`git config --list`命令查看配置好的内容（保存在home/.gitconfig文件中），如果需要修改用户名或邮箱，执行如下命令（也可以直接修改文件）：\n\n~~~shell\ngit config --global --replace-all user.name “username”\ngit config --global --replace-all user.email “email@example.com”\n~~~\n\n- 创建公钥，命令行输入命令：\n\n~~~shell\nssh-keygen -C 'you email address@gmail.com' -t rsa\n~~~\n\n**说明：C必须大写，改为自己的注册邮箱，然后一直回车，直到出现`“The key’s randomart image is：”`的提示。**\n\n之后用户目录` ~/.ssh/ `下建立了相应的密钥文件`id_rsa.pub `，打开该文件。\n\n- 添加公钥：github首页右上角点击头像，选择`Settings`，再选择`New SSH KEY`，把上一步`id_rsa.pub`文件的秘钥复制进去生成公钥。\n\n\n- 创建项目仓库：github首页点击右上角的`+`，选择`New repository`。在页面里输入`username.github.io`，必须这么写。填完后点击`Create repository`。\n\n\n- 部署博客：修改hexo目录下的`_config.yml`文件，最后面修改为：\n\n~~~yaml\ndeploy:\n  type: git\n  repository: git@github.com:username/username.github.io.git\n  branch: master\n~~~\n\n安装hexo的插件：\n\n~~~shell\nnpm install hexo-deployer-git --save\n~~~\n\n然后：\n\n~~~shell\nhexo clean\nhexo generate\nhexo deploy #可以使用hexo g -d命令代替上面两个命令\n~~~\n\n在浏览器输入`yourname.github.io`就可以访问的自己的博客啦。\n# 绑定自己的域名\n绑定域名分2种情况：带www和不带www的。\n\n域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下`yourname.github.io`的IP，然后到域名DNS设置页，将A记录指向ping出来的IP，将CNAME指向`username.github.io`，这样可以保证无论是否添加www都可以访问，如下：\n\n![img](http://image.liuxianan.com/201608/20160823_191336_238_8683.png)\n\n然后到github项目根目录新建一个名为CNAME的文件（无后缀），里面填写自己的域名。在绑定了新域名之后，原来的`username.github.io`并没有失效，还是会自动跳转到新域名。\n\n# 编辑.md文件工具推荐\n\n笔者使用的是Typora，[官网](https://typora.io/)，网页最下面是下载入口，根据自己的系统选择，ubuntu的方式如下：\n\n~~~shell\n# optional, but recommended\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE\n# add Typora's repository\nsudo add-apt-repository 'deb http://typora.io linux/'\nsudo apt-get update\n# install typora\nsudo apt-get install typora\n~~~\n\nTypora的Markdown语法的学习可以参考[博客](http://blog.csdn.net/tzs_1041218129/article/details/54728799)。\n\n配置Hexo渲染MathJax数学公式，推荐文章：https://www.jianshu.com/p/7ab21c7f0674\n\n# 多机更新\n\n## 方案一（不好用）\n\n使用坚果云同步hexo文件夹文件。坚果云同步hexo中文件时，有些文件会一直处于分析状态，上传不上去，影响其他文件的上传，so放弃坚果云。\n\n## 方案二\n\n使用GitHub进行同步\n\n### 旧设备操作\n\n> 假设已经按照前面的步骤在旧设备上搭建好了Hexo并部署到了GitHub。\n\n在旧设备部署博客到Github以后，我们可以在Github仓库的master分支上看到上传的博客文件。但是这个博客文件不包含hexo配置文件，所以需要新建分支，使用git指令将带hexo的配置文件上传到新建的分支上。在本地博客根目录下使用git指令上传项目到GitHub，按如下进行操作：\n\n~~~\n// git初始化 \ngit init \n// 添加仓库地址 \ngit remote add origin https://github.com/用户名/仓库名.git \n// 新建分支hexo并切换到新建的分支 \ngit checkout -b hexo \n// 添加所有本地文件到git\ngit add . \n// git提交 \ngit commit -m \"...\" \n// 文件推送到hexo分支 \ngit push origin hexo\n~~~\n\n至此，旧设备上需要进行的操作完成。\n\n### 新设备操作\n\n1. Github上新建的分支的文件git clone到本地\n\n   ~~~\n   git clone -b hexo https://github.com/用户名/仓库名.git\n   ~~~\n\n2. 安装Git、Node.js\n\n3. 安装依赖库\n\n   ~~~\n   #hexo-renderer-kramed markdown渲染引擎\n   npm uninstall hexo-renderer-marked --save\n   npm install hexo-renderer-kramed --save\n   #rss\n   npm install --save hexo-generator-feed\n   #hexo-word count\n   npm install hexo-wordcount --save\n   ~~~\n\n   安装过程中会提示没有/home/eric/package.json文件的提示（但应该已经安装完成了），不过对后面的过程没有影响。\n\n4. 安装hexo（到git clone的目录下操作命令）\n\n   ~~~\n   npm install -g hexo-cli\n   npm install\n   npm install hexo-deployer-git\n   ~~~\n\n   这个过程应该会在当前目录下产生`package.json`文件，执行`hexo clean`，应该可以顺利执行，说明配置成功。\n\n5. 添加SSH key\n\n   - 命令行输入`ssh-keygen -t rsa -C “邮箱地址”`\n\n   - 按三次回车（密码为空），生成密匙。 在`home/username/.ssh`目录下找到`id_rsa.pub`，打开复制内容到GitHub添加新的SSH key。\n\n   - 终端输入`ssh - T git@github.com`回车，提示认证成功即可。\n\n   - 在终端输入命令(和旧设备中的相同)：\n\n     ```\n     git config --global user.name \"username\" #ruoxiangli\n     git config --global user.eamil \"email@example.com\" #981968690@qq.com\n     ```\n\n     执行`hexo g -d`，顺利执行则说明配置成功。\n\n6. [配置Hexo渲染MathJax数学公式](https://www.jianshu.com/p/7ab21c7f0674)\n\n\n### 新旧设备的日常维护\n\n**注意：在当前设备上进行所有操作之前，一定要现将本地的配置文件（包括添加的新博文、修改内容样式等等）进行更新，因为在此之前另一台设备可能向GitHub推送了更新，但是本地的内容还是旧版，若不更新进行操作，之后提交的会是旧版的内容修改后的效果。**\n\n> 为了保证本地内容为最新，所有操作前的操作：git pull origin hexo \n\n本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理： \n\n1. 配置文件的更新：依次执行`git add .`、`git commit -m “…”`、`git push origin hexo`指令将改动推送到GitHub（此时当前分支应为hexo） \n\n   **补充：**如果不想每次push都输入用户名和密码。查看到传输协议，终端执行：\n\n   ~~~\n   git remote -v\n   ~~~\n\n   可以看到：\n\n   ~~~\n   origin\thttps://github.com/ruoxiangli/ruoxiangli.github.io.git (fetch)\n   origin\thttps://github.com/ruoxiangli/ruoxiangli.github.io.git (push)\n   ~~~\n\n   重新设置成ssh的方式：\n\n   ~~~\n   git remote rm origin\n   git remote add origin git@github.com:username/repository.git\n   git push -u origin master\n   ~~~\n\n   再查看当前传输协议：\n\n   ~~~\n   origin\tgit@github.com:ruoxiangli/ruoxiangli.github.io.git (fetch)\n   origin\tgit@github.com:ruoxiangli/ruoxiangli.github.io.git (push)\n   ~~~\n\n   到此操作成功。\n\n2. 静态网页的更新：执行`hexo g -d`发布网站到master分支\n\n参考文章：https://www.jianshu.com/p/6fb0b287f950\n\nhttps://blog.csdn.net/crazy_scott/article/details/79342303\n\n# 遇到的错误解决方法\n\n发现执行时nvm install stable时出现未找到‘nvm’命令的错误提示，解决方式，分别执行下面两行指令：\n\n~~~shell\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"NVM_DIR/nvm.sh\" ] && \\. \"NVM_DIR/nvm.sh\"  # This loads nvm\n~~~\n\n执行`hexo server`后访问`http://localhost:4000`，出现`Cannot Get /`提示，打不开网页，可能是由于端口号4000被占用，可以使用其他端口号打开。解决方式：`hexo server -p 5000`\n","slug":"ubuntu16.04 Hexo+github+Typora搭建博客","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0600caqlcr65vxhlaq","content":"<hr>\n<p>这篇文章是Hexo博客搭建有关的内容。</p>\n<a id=\"more\"></a>\n<h1 id=\"预备知识\"><a href=\"#预备知识\" class=\"headerlink\" title=\"预备知识\"></a>预备知识</h1><p>Hexo是一个基于Node.js的静态博客程序，可以方便的生成静态网页托管在github、gitcafe和Heroku上。博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，hexo所做的就是将这些md文件都放在本地，更新博文目录和相关链接信息，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。</p>\n<p>Hexo依赖Node.js和Git。nvm（node version manager）是nodejs版本管理工具，管理nodejs和npm的版本；npm是随同nodeJs一起安装的包管理工具，npm管理对应nodeJs的第三方插件；nvm管理构建nodejs和对应的npm，npm管理对应的nodejs的第三方插件。</p>\n<h1 id=\"本地搭建\"><a href=\"#本地搭建\" class=\"headerlink\" title=\"本地搭建\"></a><strong>本地搭建</strong></h1><h2 id=\"安装Git\"><a href=\"#安装Git\" class=\"headerlink\" title=\"安装Git\"></a>安装Git</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install git-core</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Node-js\"><a href=\"#安装Node-js\" class=\"headerlink\" title=\"安装Node.js\"></a>安装Node.js</h2><p>最好的方式是使用NVM（Node Version Manager）安装，在终端安装nvm执行命令：</p>\n<p>cURL：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash</span><br></pre></td></tr></table></figure>\n<p>Wget：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash</span><br></pre></td></tr></table></figure>\n<p>重启终端安装Node.js：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvm install stable</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Hexo\"><a href=\"#安装Hexo\" class=\"headerlink\" title=\"安装Hexo\"></a>安装Hexo</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>\n<h2 id=\"初始化Hexo\"><a href=\"#初始化Hexo\" class=\"headerlink\" title=\"初始化Hexo\"></a>初始化Hexo</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir git</span><br><span class=\"line\">cd git</span><br><span class=\"line\">hexo init hexo   #自定义的文件夹</span><br><span class=\"line\">cd hexo</span><br><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n<h2 id=\"设置Hexo\"><a href=\"#设置Hexo\" class=\"headerlink\" title=\"设置Hexo\"></a>设置Hexo</h2><p>执行命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g/generate  #生成静态网页</span><br><span class=\"line\">hexo s/server    #运行本地服务器</span><br></pre></td></tr></table></figure>\n<p>如果出现提示：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INFO  Start processing</span><br><span class=\"line\">INFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>\n<p>说明安装成功，在浏览器地址栏输入<a href=\"http://localhost:4000\" target=\"_blank\" rel=\"noopener\">http://localhost:4000</a> 就可以看到默认主题的博客界面了。</p>\n<h2 id=\"博客主题更改\"><a href=\"#博客主题更改\" class=\"headerlink\" title=\"博客主题更改\"></a>博客主题更改</h2><p>安装主题next或yillia，在～/git/hexo/目录下执行命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br><span class=\"line\">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<p>或</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone git@github.com:litten/hexo-theme-yilia.git themes/yilia</span><br></pre></td></tr></table></figure>\n<p>更新主题，修改hexo目录下的<code>_config.yml</code>，将<code>theme</code>属性设置为<code>next</code>或<code>yilia</code>，默认是landscape。</p>\n<p>执行命令查看本地效果：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br><span class=\"line\">hexo s</span><br></pre></td></tr></table></figure>\n<p>到此为止已经完成了Hexo博客的本地安装和查看，下一步是将博客部署到github上面，这样就可以通过网络远程访问自己的博客了。</p>\n<p>目前使用的是next主题，完整的安装配置过程可以参考<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"noopener\">这里</a>。</p>\n<p>next主题优化推荐文章：<a href=\"https://www.jianshu.com/p/1f8107a8778c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/1f8107a8778c</a></p>\n<h1 id=\"部署到github\"><a href=\"#部署到github\" class=\"headerlink\" title=\"部署到github\"></a><strong>部署到github</strong></h1><ul>\n<li>首先到github上面注册自己的账号。</li>\n<li>配置github</li>\n</ul>\n<p>命令行输入命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global user.name \"username\" #ruoxiangli</span><br><span class=\"line\">git config --global user.eamil \"email@example.com\" #981968690@qq.com</span><br></pre></td></tr></table></figure>\n<p>其中<code>yourname</code>是输入你自己的用户名，<code>email@example.com</code>输入你自己的注册邮箱。</p>\n<p>这里可以使用<code>git config --list</code>命令查看配置好的内容（保存在home/.gitconfig文件中），如果需要修改用户名或邮箱，执行如下命令（也可以直接修改文件）：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global --replace-all user.name “username”</span><br><span class=\"line\">git config --global --replace-all user.email “email@example.com”</span><br></pre></td></tr></table></figure>\n<ul>\n<li>创建公钥，命令行输入命令：</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen -C 'you email address@gmail.com' -t rsa</span><br></pre></td></tr></table></figure>\n<p><strong>说明：C必须大写，改为自己的注册邮箱，然后一直回车，直到出现<code>“The key’s randomart image is：”</code>的提示。</strong></p>\n<p>之后用户目录<code>~/.ssh/</code>下建立了相应的密钥文件<code>id_rsa.pub</code>，打开该文件。</p>\n<ul>\n<li>添加公钥：github首页右上角点击头像，选择<code>Settings</code>，再选择<code>New SSH KEY</code>，把上一步<code>id_rsa.pub</code>文件的秘钥复制进去生成公钥。</li>\n</ul>\n<ul>\n<li>创建项目仓库：github首页点击右上角的<code>+</code>，选择<code>New repository</code>。在页面里输入<code>username.github.io</code>，必须这么写。填完后点击<code>Create repository</code>。</li>\n</ul>\n<ul>\n<li>部署博客：修改hexo目录下的<code>_config.yml</code>文件，最后面修改为：</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repository:</span> <span class=\"string\">git@github.com:username/username.github.io.git</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">master</span></span><br></pre></td></tr></table></figure>\n<p>安装hexo的插件：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>\n<p>然后：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br><span class=\"line\">hexo generate</span><br><span class=\"line\">hexo deploy #可以使用hexo g -d命令代替上面两个命令</span><br></pre></td></tr></table></figure>\n<p>在浏览器输入<code>yourname.github.io</code>就可以访问的自己的博客啦。</p>\n<h1 id=\"绑定自己的域名\"><a href=\"#绑定自己的域名\" class=\"headerlink\" title=\"绑定自己的域名\"></a>绑定自己的域名</h1><p>绑定域名分2种情况：带www和不带www的。</p>\n<p>域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下<code>yourname.github.io</code>的IP，然后到域名DNS设置页，将A记录指向ping出来的IP，将CNAME指向<code>username.github.io</code>，这样可以保证无论是否添加www都可以访问，如下：</p>\n<p><img src=\"http://image.liuxianan.com/201608/20160823_191336_238_8683.png\" alt=\"img\"></p>\n<p>然后到github项目根目录新建一个名为CNAME的文件（无后缀），里面填写自己的域名。在绑定了新域名之后，原来的<code>username.github.io</code>并没有失效，还是会自动跳转到新域名。</p>\n<h1 id=\"编辑-md文件工具推荐\"><a href=\"#编辑-md文件工具推荐\" class=\"headerlink\" title=\"编辑.md文件工具推荐\"></a>编辑.md文件工具推荐</h1><p>笔者使用的是Typora，<a href=\"https://typora.io/\" target=\"_blank\" rel=\"noopener\">官网</a>，网页最下面是下载入口，根据自己的系统选择，ubuntu的方式如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> optional, but recommended</span></span><br><span class=\"line\">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> add Typora<span class=\"string\">'s repository</span></span></span><br><span class=\"line\">sudo add-apt-repository 'deb http://typora.io linux/'</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> install typora</span></span><br><span class=\"line\">sudo apt-get install typora</span><br></pre></td></tr></table></figure>\n<p>Typora的Markdown语法的学习可以参考<a href=\"http://blog.csdn.net/tzs_1041218129/article/details/54728799\" target=\"_blank\" rel=\"noopener\">博客</a>。</p>\n<p>配置Hexo渲染MathJax数学公式，推荐文章：<a href=\"https://www.jianshu.com/p/7ab21c7f0674\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/7ab21c7f0674</a></p>\n<h1 id=\"多机更新\"><a href=\"#多机更新\" class=\"headerlink\" title=\"多机更新\"></a>多机更新</h1><h2 id=\"方案一（不好用）\"><a href=\"#方案一（不好用）\" class=\"headerlink\" title=\"方案一（不好用）\"></a>方案一（不好用）</h2><p>使用坚果云同步hexo文件夹文件。坚果云同步hexo中文件时，有些文件会一直处于分析状态，上传不上去，影响其他文件的上传，so放弃坚果云。</p>\n<h2 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h2><p>使用GitHub进行同步</p>\n<h3 id=\"旧设备操作\"><a href=\"#旧设备操作\" class=\"headerlink\" title=\"旧设备操作\"></a>旧设备操作</h3><blockquote>\n<p>假设已经按照前面的步骤在旧设备上搭建好了Hexo并部署到了GitHub。</p>\n</blockquote>\n<p>在旧设备部署博客到Github以后，我们可以在Github仓库的master分支上看到上传的博客文件。但是这个博客文件不包含hexo配置文件，所以需要新建分支，使用git指令将带hexo的配置文件上传到新建的分支上。在本地博客根目录下使用git指令上传项目到GitHub，按如下进行操作：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// git初始化 </span><br><span class=\"line\">git init </span><br><span class=\"line\">// 添加仓库地址 </span><br><span class=\"line\">git remote add origin https://github.com/用户名/仓库名.git </span><br><span class=\"line\">// 新建分支hexo并切换到新建的分支 </span><br><span class=\"line\">git checkout -b hexo </span><br><span class=\"line\">// 添加所有本地文件到git</span><br><span class=\"line\">git add . </span><br><span class=\"line\">// git提交 </span><br><span class=\"line\">git commit -m &quot;...&quot; </span><br><span class=\"line\">// 文件推送到hexo分支 </span><br><span class=\"line\">git push origin hexo</span><br></pre></td></tr></table></figure>\n<p>至此，旧设备上需要进行的操作完成。</p>\n<h3 id=\"新设备操作\"><a href=\"#新设备操作\" class=\"headerlink\" title=\"新设备操作\"></a>新设备操作</h3><ol>\n<li><p>Github上新建的分支的文件git clone到本地</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone -b hexo https://github.com/用户名/仓库名.git</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装Git、Node.js</p>\n</li>\n<li><p>安装依赖库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#hexo-renderer-kramed markdown渲染引擎</span><br><span class=\"line\">npm uninstall hexo-renderer-marked --save</span><br><span class=\"line\">npm install hexo-renderer-kramed --save</span><br><span class=\"line\">#rss</span><br><span class=\"line\">npm install --save hexo-generator-feed</span><br><span class=\"line\">#hexo-word count</span><br><span class=\"line\">npm install hexo-wordcount --save</span><br></pre></td></tr></table></figure>\n<p>安装过程中会提示没有/home/eric/package.json文件的提示（但应该已经安装完成了），不过对后面的过程没有影响。</p>\n</li>\n<li><p>安装hexo（到git clone的目录下操作命令）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g hexo-cli</span><br><span class=\"line\">npm install</span><br><span class=\"line\">npm install hexo-deployer-git</span><br></pre></td></tr></table></figure>\n<p>这个过程应该会在当前目录下产生<code>package.json</code>文件，执行<code>hexo clean</code>，应该可以顺利执行，说明配置成功。</p>\n</li>\n<li><p>添加SSH key</p>\n<ul>\n<li><p>命令行输入<code>ssh-keygen -t rsa -C “邮箱地址”</code></p>\n</li>\n<li><p>按三次回车（密码为空），生成密匙。 在<code>home/username/.ssh</code>目录下找到<code>id_rsa.pub</code>，打开复制内容到GitHub添加新的SSH key。</p>\n</li>\n<li><p>终端输入<code>ssh - T git@github.com</code>回车，提示认证成功即可。</p>\n</li>\n<li><p>在终端输入命令(和旧设备中的相同)：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global user.name &quot;username&quot; #ruoxiangli</span><br><span class=\"line\">git config --global user.eamil &quot;email@example.com&quot; #981968690@qq.com</span><br></pre></td></tr></table></figure>\n<p>执行<code>hexo g -d</code>，顺利执行则说明配置成功。</p>\n</li>\n</ul>\n</li>\n<li><p><a href=\"https://www.jianshu.com/p/7ab21c7f0674\" target=\"_blank\" rel=\"noopener\">配置Hexo渲染MathJax数学公式</a></p>\n</li>\n</ol>\n<h3 id=\"新旧设备的日常维护\"><a href=\"#新旧设备的日常维护\" class=\"headerlink\" title=\"新旧设备的日常维护\"></a>新旧设备的日常维护</h3><p><strong>注意：在当前设备上进行所有操作之前，一定要现将本地的配置文件（包括添加的新博文、修改内容样式等等）进行更新，因为在此之前另一台设备可能向GitHub推送了更新，但是本地的内容还是旧版，若不更新进行操作，之后提交的会是旧版的内容修改后的效果。</strong></p>\n<blockquote>\n<p>为了保证本地内容为最新，所有操作前的操作：git pull origin hexo </p>\n</blockquote>\n<p>本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理： </p>\n<ol>\n<li><p>配置文件的更新：依次执行<code>git add .</code>、<code>git commit -m “…”</code>、<code>git push origin hexo</code>指令将改动推送到GitHub（此时当前分支应为hexo） </p>\n<p><strong>补充：</strong>如果不想每次push都输入用户名和密码。查看到传输协议，终端执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git remote -v</span><br></pre></td></tr></table></figure>\n<p>可以看到：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">origin\thttps://github.com/ruoxiangli/ruoxiangli.github.io.git (fetch)</span><br><span class=\"line\">origin\thttps://github.com/ruoxiangli/ruoxiangli.github.io.git (push)</span><br></pre></td></tr></table></figure>\n<p>重新设置成ssh的方式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git remote rm origin</span><br><span class=\"line\">git remote add origin git@github.com:username/repository.git</span><br><span class=\"line\">git push -u origin master</span><br></pre></td></tr></table></figure>\n<p>再查看当前传输协议：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">origin\tgit@github.com:ruoxiangli/ruoxiangli.github.io.git (fetch)</span><br><span class=\"line\">origin\tgit@github.com:ruoxiangli/ruoxiangli.github.io.git (push)</span><br></pre></td></tr></table></figure>\n<p>到此操作成功。</p>\n</li>\n<li><p>静态网页的更新：执行<code>hexo g -d</code>发布网站到master分支</p>\n</li>\n</ol>\n<p>参考文章：<a href=\"https://www.jianshu.com/p/6fb0b287f950\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/6fb0b287f950</a></p>\n<p><a href=\"https://blog.csdn.net/crazy_scott/article/details/79342303\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/crazy_scott/article/details/79342303</a></p>\n<h1 id=\"遇到的错误解决方法\"><a href=\"#遇到的错误解决方法\" class=\"headerlink\" title=\"遇到的错误解决方法\"></a>遇到的错误解决方法</h1><p>发现执行时nvm install stable时出现未找到‘nvm’命令的错误提示，解决方式，分别执行下面两行指令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export NVM_DIR=\"$HOME/.nvm\"</span><br><span class=\"line\">[ -s \"NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"NVM_DIR/nvm.sh\"  # This loads nvm</span><br></pre></td></tr></table></figure>\n<p>执行<code>hexo server</code>后访问<code>http://localhost:4000</code>，出现<code>Cannot Get /</code>提示，打不开网页，可能是由于端口号4000被占用，可以使用其他端口号打开。解决方式：<code>hexo server -p 5000</code></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是Hexo博客搭建有关的内容。</p>","more":"<h1 id=\"预备知识\"><a href=\"#预备知识\" class=\"headerlink\" title=\"预备知识\"></a>预备知识</h1><p>Hexo是一个基于Node.js的静态博客程序，可以方便的生成静态网页托管在github、gitcafe和Heroku上。博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，hexo所做的就是将这些md文件都放在本地，更新博文目录和相关链接信息，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。</p>\n<p>Hexo依赖Node.js和Git。nvm（node version manager）是nodejs版本管理工具，管理nodejs和npm的版本；npm是随同nodeJs一起安装的包管理工具，npm管理对应nodeJs的第三方插件；nvm管理构建nodejs和对应的npm，npm管理对应的nodejs的第三方插件。</p>\n<h1 id=\"本地搭建\"><a href=\"#本地搭建\" class=\"headerlink\" title=\"本地搭建\"></a><strong>本地搭建</strong></h1><h2 id=\"安装Git\"><a href=\"#安装Git\" class=\"headerlink\" title=\"安装Git\"></a>安装Git</h2><!--�287-->\n<h2 id=\"安装Node-js\"><a href=\"#安装Node-js\" class=\"headerlink\" title=\"安装Node.js\"></a>安装Node.js</h2><p>最好的方式是使用NVM（Node Version Manager）安装，在终端安装nvm执行命令：</p>\n<p>cURL：</p>\n<!--�288-->\n<p>Wget：</p>\n<!--�289-->\n<p>重启终端安装Node.js：</p>\n<!--�290-->\n<h2 id=\"安装Hexo\"><a href=\"#安装Hexo\" class=\"headerlink\" title=\"安装Hexo\"></a>安装Hexo</h2><!--�291-->\n<h2 id=\"初始化Hexo\"><a href=\"#初始化Hexo\" class=\"headerlink\" title=\"初始化Hexo\"></a>初始化Hexo</h2><!--�292-->\n<h2 id=\"设置Hexo\"><a href=\"#设置Hexo\" class=\"headerlink\" title=\"设置Hexo\"></a>设置Hexo</h2><p>执行命令：</p>\n<!--�293-->\n<p>如果出现提示：</p>\n<!--�294-->\n<p>说明安装成功，在浏览器地址栏输入<a href=\"http://localhost:4000\" target=\"_blank\" rel=\"noopener\">http://localhost:4000</a> 就可以看到默认主题的博客界面了。</p>\n<h2 id=\"博客主题更改\"><a href=\"#博客主题更改\" class=\"headerlink\" title=\"博客主题更改\"></a>博客主题更改</h2><p>安装主题next或yillia，在～/git/hexo/目录下执行命令：</p>\n<!--�295-->\n<p>或</p>\n<!--�296-->\n<p>更新主题，修改hexo目录下的<code>_config.yml</code>，将<code>theme</code>属性设置为<code>next</code>或<code>yilia</code>，默认是landscape。</p>\n<p>执行命令查看本地效果：</p>\n<!--�297-->\n<p>到此为止已经完成了Hexo博客的本地安装和查看，下一步是将博客部署到github上面，这样就可以通过网络远程访问自己的博客了。</p>\n<p>目前使用的是next主题，完整的安装配置过程可以参考<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"noopener\">这里</a>。</p>\n<p>next主题优化推荐文章：<a href=\"https://www.jianshu.com/p/1f8107a8778c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/1f8107a8778c</a></p>\n<h1 id=\"部署到github\"><a href=\"#部署到github\" class=\"headerlink\" title=\"部署到github\"></a><strong>部署到github</strong></h1><ul>\n<li>首先到github上面注册自己的账号。</li>\n<li>配置github</li>\n</ul>\n<p>命令行输入命令：</p>\n<!--�298-->\n<p>其中<code>yourname</code>是输入你自己的用户名，<code>email@example.com</code>输入你自己的注册邮箱。</p>\n<p>这里可以使用<code>git config --list</code>命令查看配置好的内容（保存在home/.gitconfig文件中），如果需要修改用户名或邮箱，执行如下命令（也可以直接修改文件）：</p>\n<!--�299-->\n<ul>\n<li>创建公钥，命令行输入命令：</li>\n</ul>\n<!--�300-->\n<p><strong>说明：C必须大写，改为自己的注册邮箱，然后一直回车，直到出现<code>“The key’s randomart image is：”</code>的提示。</strong></p>\n<p>之后用户目录<code>~/.ssh/</code>下建立了相应的密钥文件<code>id_rsa.pub</code>，打开该文件。</p>\n<ul>\n<li>添加公钥：github首页右上角点击头像，选择<code>Settings</code>，再选择<code>New SSH KEY</code>，把上一步<code>id_rsa.pub</code>文件的秘钥复制进去生成公钥。</li>\n</ul>\n<ul>\n<li>创建项目仓库：github首页点击右上角的<code>+</code>，选择<code>New repository</code>。在页面里输入<code>username.github.io</code>，必须这么写。填完后点击<code>Create repository</code>。</li>\n</ul>\n<ul>\n<li>部署博客：修改hexo目录下的<code>_config.yml</code>文件，最后面修改为：</li>\n</ul>\n<!--�301-->\n<p>安装hexo的插件：</p>\n<!--�302-->\n<p>然后：</p>\n<!--�303-->\n<p>在浏览器输入<code>yourname.github.io</code>就可以访问的自己的博客啦。</p>\n<h1 id=\"绑定自己的域名\"><a href=\"#绑定自己的域名\" class=\"headerlink\" title=\"绑定自己的域名\"></a>绑定自己的域名</h1><p>绑定域名分2种情况：带www和不带www的。</p>\n<p>域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下<code>yourname.github.io</code>的IP，然后到域名DNS设置页，将A记录指向ping出来的IP，将CNAME指向<code>username.github.io</code>，这样可以保证无论是否添加www都可以访问，如下：</p>\n<p><img src=\"http://image.liuxianan.com/201608/20160823_191336_238_8683.png\" alt=\"img\"></p>\n<p>然后到github项目根目录新建一个名为CNAME的文件（无后缀），里面填写自己的域名。在绑定了新域名之后，原来的<code>username.github.io</code>并没有失效，还是会自动跳转到新域名。</p>\n<h1 id=\"编辑-md文件工具推荐\"><a href=\"#编辑-md文件工具推荐\" class=\"headerlink\" title=\"编辑.md文件工具推荐\"></a>编辑.md文件工具推荐</h1><p>笔者使用的是Typora，<a href=\"https://typora.io/\" target=\"_blank\" rel=\"noopener\">官网</a>，网页最下面是下载入口，根据自己的系统选择，ubuntu的方式如下：</p>\n<!--�304-->\n<p>Typora的Markdown语法的学习可以参考<a href=\"http://blog.csdn.net/tzs_1041218129/article/details/54728799\" target=\"_blank\" rel=\"noopener\">博客</a>。</p>\n<p>配置Hexo渲染MathJax数学公式，推荐文章：<a href=\"https://www.jianshu.com/p/7ab21c7f0674\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/7ab21c7f0674</a></p>\n<h1 id=\"多机更新\"><a href=\"#多机更新\" class=\"headerlink\" title=\"多机更新\"></a>多机更新</h1><h2 id=\"方案一（不好用）\"><a href=\"#方案一（不好用）\" class=\"headerlink\" title=\"方案一（不好用）\"></a>方案一（不好用）</h2><p>使用坚果云同步hexo文件夹文件。坚果云同步hexo中文件时，有些文件会一直处于分析状态，上传不上去，影响其他文件的上传，so放弃坚果云。</p>\n<h2 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h2><p>使用GitHub进行同步</p>\n<h3 id=\"旧设备操作\"><a href=\"#旧设备操作\" class=\"headerlink\" title=\"旧设备操作\"></a>旧设备操作</h3><blockquote>\n<p>假设已经按照前面的步骤在旧设备上搭建好了Hexo并部署到了GitHub。</p>\n</blockquote>\n<p>在旧设备部署博客到Github以后，我们可以在Github仓库的master分支上看到上传的博客文件。但是这个博客文件不包含hexo配置文件，所以需要新建分支，使用git指令将带hexo的配置文件上传到新建的分支上。在本地博客根目录下使用git指令上传项目到GitHub，按如下进行操作：</p>\n<!--�305-->\n<p>至此，旧设备上需要进行的操作完成。</p>\n<h3 id=\"新设备操作\"><a href=\"#新设备操作\" class=\"headerlink\" title=\"新设备操作\"></a>新设备操作</h3><ol>\n<li><p>Github上新建的分支的文件git clone到本地</p>\n<!--�306-->\n</li>\n<li><p>安装Git、Node.js</p>\n</li>\n<li><p>安装依赖库</p>\n<!--�307-->\n<p>安装过程中会提示没有/home/eric/package.json文件的提示（但应该已经安装完成了），不过对后面的过程没有影响。</p>\n</li>\n<li><p>安装hexo（到git clone的目录下操作命令）</p>\n<!--�308-->\n<p>这个过程应该会在当前目录下产生<code>package.json</code>文件，执行<code>hexo clean</code>，应该可以顺利执行，说明配置成功。</p>\n</li>\n<li><p>添加SSH key</p>\n<ul>\n<li><p>命令行输入<code>ssh-keygen -t rsa -C “邮箱地址”</code></p>\n</li>\n<li><p>按三次回车（密码为空），生成密匙。 在<code>home/username/.ssh</code>目录下找到<code>id_rsa.pub</code>，打开复制内容到GitHub添加新的SSH key。</p>\n</li>\n<li><p>终端输入<code>ssh - T git@github.com</code>回车，提示认证成功即可。</p>\n</li>\n<li><p>在终端输入命令(和旧设备中的相同)：</p>\n<!--�309-->\n<p>执行<code>hexo g -d</code>，顺利执行则说明配置成功。</p>\n</li>\n</ul>\n</li>\n<li><p><a href=\"https://www.jianshu.com/p/7ab21c7f0674\" target=\"_blank\" rel=\"noopener\">配置Hexo渲染MathJax数学公式</a></p>\n</li>\n</ol>\n<h3 id=\"新旧设备的日常维护\"><a href=\"#新旧设备的日常维护\" class=\"headerlink\" title=\"新旧设备的日常维护\"></a>新旧设备的日常维护</h3><p><strong>注意：在当前设备上进行所有操作之前，一定要现将本地的配置文件（包括添加的新博文、修改内容样式等等）进行更新，因为在此之前另一台设备可能向GitHub推送了更新，但是本地的内容还是旧版，若不更新进行操作，之后提交的会是旧版的内容修改后的效果。</strong></p>\n<blockquote>\n<p>为了保证本地内容为最新，所有操作前的操作：git pull origin hexo </p>\n</blockquote>\n<p>本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理： </p>\n<ol>\n<li><p>配置文件的更新：依次执行<code>git add .</code>、<code>git commit -m “…”</code>、<code>git push origin hexo</code>指令将改动推送到GitHub（此时当前分支应为hexo） </p>\n<p><strong>补充：</strong>如果不想每次push都输入用户名和密码。查看到传输协议，终端执行：</p>\n<!--�310-->\n<p>可以看到：</p>\n<!--�311-->\n<p>重新设置成ssh的方式：</p>\n<!--�312-->\n<p>再查看当前传输协议：</p>\n<!--�313-->\n<p>到此操作成功。</p>\n</li>\n<li><p>静态网页的更新：执行<code>hexo g -d</code>发布网站到master分支</p>\n</li>\n</ol>\n<p>参考文章：<a href=\"https://www.jianshu.com/p/6fb0b287f950\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/6fb0b287f950</a></p>\n<p><a href=\"https://blog.csdn.net/crazy_scott/article/details/79342303\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/crazy_scott/article/details/79342303</a></p>\n<h1 id=\"遇到的错误解决方法\"><a href=\"#遇到的错误解决方法\" class=\"headerlink\" title=\"遇到的错误解决方法\"></a>遇到的错误解决方法</h1><p>发现执行时nvm install stable时出现未找到‘nvm’命令的错误提示，解决方式，分别执行下面两行指令：</p>\n<!--�314-->\n<p>执行<code>hexo server</code>后访问<code>http://localhost:4000</code>，出现<code>Cannot Get /</code>提示，打不开网页，可能是由于端口号4000被占用，可以使用其他端口号打开。解决方式：<code>hexo server -p 5000</code></p>"},{"title":"lightweight_mapping学习之LocalMeshing","date":"2018-09-04T14:59:48.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录LocalMesshing模块，该模块涉及CGAL库Delauary三角剖分的知识。\n\n<!---more--->\n\n## 概述\n\nLocalMeshing线程主要任务是使用SLAM优化后的稀疏特征（优化的稀疏三维点云）转化为稠密体积表示。具体来说，SLAM模块提供优化后的稀疏三维点云，LocalMeshing线程使用Delaunay三角剖分算法将三维空间进行细分，使用可视化约束刻画空间。LocalMeshing线程的输入是来自LoopClosing线程传送的关键帧（其实这些关键帧都是在Tracking线程创建的），输出是一系列的三维空间中的点、三角形、边结构，这些信息由可视化线程展示在窗口。\n\n## 疑问\n\n1. 关键帧约束和非关键帧约束区别何在？为何要区分？顶点细化的最后为何要添加这两种约束？？\n2. 顶点删除过程，会对新产生的空洞重新三角剖分？？\n\n## 关于Delaunay三角剖分\n\n### Triangulation\n\n三角剖分是代数拓扑学最基本的研究方法。以曲面三角剖分为例，三角剖分需要满足一些条件：\n\n（1）每一块碎片都是曲边三角形（曲边三角形就是以等边三角形的三个顶点为圆心，边长为半径画出的图形，曲面的宽度是等长的）\n\n（2）曲面上任何两个这样的曲边三角形，不能同时相交两条或两条以上的边，只能不相交或者是相切于一条公共边\n\n（3）曲面中所有的都是三角面，且所有三角面的合集是所有点集合的凸包\n\n### Delaunay Triangulation\n\n假设边的集合E中的一条边e（两个端点为a，b）,e如果满足下列条件，则称之为Delaunay边：\n\n存在一个圆经过a,b两点，圆内不包含点集中的任何点，这一特性称为空圆特性。\n\n如果一个曲面的点集的一个三角剖分只包含Delaunay边，那么这样的三角剖分就称为Delaunay三角剖分。\n\n关于Delaunay三角剖分更为直观的定义是：三角剖分中的每个三角形的外接圆的内部都不包含点集中的任何点。\n\nDelaunay三角剖分的算法有翻边算法、逐点插入算法、分割合并算法以及Bowyer-Watson算法等。\n\n下图是Delaunay三角剖分的一个直观示意图：\n\n{% asset_img Delanunay三角剖分.png %}\n\n## LocalMeshing.h\n\n新增文件：\n\n```\ndelaunay文件夹：FreespaceDelaunayAlgorithm相关的文件\ndataStructure.h\nFColorMap.h/FColorMap.cpp\nLocalMeshing.h/LocalMeshing.cpp\n```\n\n增添内容文件：\n\n```\nMapDrawer.h MapDrawer.cpp\n```\n\n### 重要的数据结构\n\n1. Class `Delaunay3CellInfo`：Delaunay三维剖分四面体信息\n2. Class `pointInfo`：顶点信息\n3. Class `constraintInfo`：约束信息类，成员包括约束类型、关联的Cell集合\n\n### 约束\n\n约束定义为相机中心与地图点（顶点）之间的线段。每个约束有一个ID，并且保存定义该约束的顶点的ID。\n\n三种类型：\n\n- `CON_KF`：关键帧约束\n- `CON_NONKF`：非关键帧约束\n- `CON_INFINITY`：deleted 约束（无穷约束？？），程序中并没有用到。\n\n关于添加约束的函数：（分别在什么情况下使用？在后面约束插入函数的介绍中说明）\n\n```\naddSetOfConstraints( int vertexID, float pose_x, float pose_y, float pose_z, float time )：直接与点关联的约束\naddConstraintKF(int vertexID, KeyFrame *kF)：与关键帧关联的约束\naddConstraintNonKF()\n```\n\n## LocalMeshing::buildMesh2\n\n该函数是LocalMeshing线程实现功能的主要函数，构建三角剖分过程在该函数中完成。函数主要过程如下：\n\n1. 检查关键帧队列是否为空，不为空则弹出队列头的关键帧，并设置当前关键帧禁止被设为`bad`；\n2. 检查当前关键帧的数据可用性、是否为`bad`；\n3. 获取当前关键帧的位姿的逆，即`Twc`，由此得到旋转矩阵、平移向量；\n4. 获取当前关键帧观测到的地图点`vpMapPoints`；\n5. 关键帧图像转成BGR彩色图；\n6. 删除外点\n   - 从`outlierVertexList`集合获取LocalMapping线程截至目前剔除的外点，保存在`currentOutlierVertexList`，并将`outlierVertexList`（它是LocalMapping线程地图点剔除过程保存外点的接口）外点清空，重新收集；\n   - 遍历获取到的外点（也没进行什么有实质内容的操作啊，有什么作用？会在全局顶点集合中查找每一个外点）；\n   - 调用顶点集合删除算法删除外点，并得到与外点关联的约束集合。\n7. 根据4获取到的`vpMapPoints`收集地图点和约束；\n8. 更新地图点和约束\n   - 调用顶点插入函数插入顶点，并得到与顶点相关联的约束集合；\n   - 处理上一步得到的约束集合；\n   - 插入关键帧约束。\n9. 检查关键帧变化\n   - 获取当前关键帧的临近关键帧集合，对于每一个关键帧进行如下操作：\n     - 获取当前关键帧匹配到的地图点；\n     - 检查地图点，并收集所有地图点到集合；\n   - 检查收集到的地图点变化，如果变化大于阈值则需要更新，将地图点放入待更新集合；\n   - 对于待更新集合中的地图点，调用顶点细化函数更新地图点；\n   - 对于临近关键帧集合中的每一个关键帧进行如下操作：\n     - 如果关键帧是`bad`，则将该关键帧关联的所有约束删除，处理下一个关键帧，否则，继续后面的操作；\n     - 获取当前关键帧的位姿；\n     - 对于当前关键帧关联的所有约束，进行如下操作： \n       - 获取当前约束关联的顶点，得到其坐标信息；\n       - 检查位姿和三维点的变化确定是否需要更新约束，如需要更新则删除当前约束，重新添加关键帧约束。\n10. 发布网格地图`tetsToTris_naive2`，创建三维空间点、三角形、边集合，主要过程如下：\n    - 初始化三维空间点、三角形、边集合为空；\n    - 创建顶点句柄列表，关联到边界顶点（边界顶点与无线远处连接）；\n    - 填充顶点列表，创建有限的非边界顶点句柄列表，并创建有用的句柄与顶点的关联映射；\n    - 遍历有限面集合，并在网格上添加三角形，创建三角形、边。\n\n## 顶点插入算法\n\n该算法输入是一个顶点的信息，输出是由该顶点引起的冲突Cell关联的约束的集合，由于顶点的插入可能会产生新的四面体，所以还需要重新检查该集合中的约束，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。\n\n### 对应函数\n\n```c++\naddVertex(int vertexID, float x, float y, float z, set<int>& setUnionedConstraints )\n```\n\n### 函数参数\n\n- vertexID：顶点ID\n- x,y,z：顶点三维坐标\n- setUnionedConstraints：顶点关联的约束集合\n\n### 算法过程\n\n1. 使用传入的参数创建待处理的顶点；\n2. 定位顶点的位置；\n3. 找到由此顶点引起的冲突Cell集合；\n4. 对于每一个冲突Cell，将其从关联的约束的关联Cell列表中删除，同时得到所有冲突Cell关联的约束集合（作为算法输出）；\n5. 删除冲突的Cell、插入新顶点并重新三角化空洞产生新的Cell；\n6. 将顶点保存到全局顶点集合。\n\n## 约束插入算法\n\n插入约束的函数有三种，分别适用于不同的情况。\n\n1. `addConstraintNonKF()`：适用于没有和关键帧关联的顶点，函数直接输入顶点坐标信息；\n2. `addConstraintKF()`：适用于和关键帧关联的顶点，通过关键帧的位姿获取顶点的坐标信息，约束的插入过程与第一种类似，只是增加了和关键帧相关的一些操作，例如该约束分类为`CON_KF`、当前关键帧的约束列表会添加该约束；\n3. `addSetOfConstraints`：适用于插入已有的约束，函数输入约束集合，使用约束关联的顶点获取顶点坐标信息。\n\n顶点插入的过程大体类似，只介绍第一种插入函数。\n\n### 对应函数\n\n```c++\naddConstraintNonKF( int vertexID, float pose_x, float pose_y, float pose_z, float time )\n```\n\n### 函数参数\n\n- vertexID：顶点ID\n- pose_x,pose_y,pose_z：顶点三维坐标\n- time：时间戳\n\n### 算法过程\n\n1. 通过顶点ID获取顶点信息、顶点操作手柄；\n2. 使用传入的参数创建待处理的约束，设为`CON_NONKF`类型；\n3. 将约束保存到全局约束集合；\n4. 将约束关联到当前顶点；\n5. 将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。\n\n## 约束删除算法\n\n### 对应函数\n\n```c++\nremoveConstraint( int constraintID )\n```\n\n### 函数参数\n\n- constraintID：函数输入，要删除的约束ID\n\n### 算法过程\n\n1. 获取与该约束关联的所有Cell，将该约束与所有Cell消除关联；\n2. 获取与该约束关联的顶点，将该约束从顶点的约束列表中删除；\n3. 获取该约束关联的关键帧（如果是`CON_KF`类型的约束），将该约束从关键帧的约束列表中删除；\n4. 从全局约束集合中删除该约束。\n\n## 顶点删除算法\n\n包括单个顶点的删除和顶点集合的删除两个函数。顶点删除的过程大致可以分为四个步骤：\n\n- 删除与该外点关联的约束\n- 收集外点附带的四面体关联的约束集合；\n- 删除外点及其附带的四面体，并对产生的空洞重新三角剖分；\n- 检查约束集合，约束可能会关联到新产生的四面体。\n\n### 删除顶点\n\n#### 对应函数\n\n```c++\nremoveVertex_origin( int vertexID )\n```\n\n#### 函数参数\n\n- vertexID：函数输入，要删除的外点ID\n\n#### 算法过程\n\n1. 获取该点相关的约束集合（约束ID），调用约束删除算法剔除每一个约束；\n2. 获取与该外点相关的所有四面体的`Cell_hande`，对于每一个执行如下操作：\n   - 获取与该Cell关联的约束集合；\n   - 对于每一个约束，将当前Cell从约束的Cell列表中删除，并收集该约束到集合。\n3. 剔除该外点（同时会对新产生的空洞重新三角剖分）；\n4. 处理前面收集的约束集合，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。\n\n### 删除顶点集合\n\n#### 对应函数\n\n```c++\nremoveVertexSet(list<int>& currentOutlierVertexList, std::set<int>& setUnionedConstraints)\n```\n\n#### 函数参数\n\n- currentOutlierVertexList：函数输入，要删除的外点集合\n- setUnionedConstraints：函数输出，与删除外点相关联的约束集合，同顶点插入函数一样，也需要检查约束集合。\n\n#### 算法过程\n\n与顶点删除过程类似，只是多了访问待删除外点集合的循环。\n\n## 顶点细化算法\n\n### 对应函数\n\n```c++\nmoveVertexSet( const list<int>& moveVertexList )\n```\n\n### 函数参数\n\n- moveVertexList：函数输入，待细化（更新坐标）的顶点集合\n\n### 算法过程\n\n1. 对于待细化顶点集合中的每一个顶点，进行如下操作：\n   - 获取该顶点的ID、坐标信息（新值），构造`tmp`顶点（这些顶点具备足够的信息，在后续过程进行更新）；\n   - 获取该顶点的约束集合，对于集合中的每一个约束进行如下操作：\n     - 如果该约束类型为`CON_KF`，则在`tmp`顶点中添加该顶点关联的关键帧位姿信息；\n     - 如果该约束类新为`CON_NONKF`，则用该顶点的坐标值（旧值）为`tmp`顶点赋值。\n   - 将`tmp`顶点加入`moveList`集合；\n2. 调用顶点集合删除函数，将待细化顶点集合中的顶点全部删除，并得到与删除顶点关联的约束集合；\n3. 调用顶点添加函数，添加`moveList`集合中的顶点（这一步和上一步会产生新的四面体）；\n4. 调用`addSetOfConstraints`函数，处理2中得到的约束集合，与新生成的四面体关联；\n5. 添加与`moveList`集合中的顶点关联的关键帧约束；\n6. 添加与`moveList`集合中的顶点关联的非关键帧约束。\n\n## 参考资料\n\n1. 论文：Building maps for autonomous navigation using sparse visual SLAM features\n2. [CGAL手册](https://doc.cgal.org/latest/Triangulation_3/index.html)\n3. 书籍：Computational Geometry Algorithms and Applications(third edition)","source":"_posts/lightweight_mapping学习之LocalMeshing.md","raw":"---\ntitle: lightweight_mapping学习之LocalMeshing\ndate: 2018-09-04 22:59:48\ntags: \n  - lightweight_mapping\n  - Delaunay三角剖分\ncategories: \n  - 机器人\n  - SLAM\n  - navigation\ncopyright: true\n---\n\n---\n\n这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录LocalMesshing模块，该模块涉及CGAL库Delauary三角剖分的知识。\n\n<!---more--->\n\n## 概述\n\nLocalMeshing线程主要任务是使用SLAM优化后的稀疏特征（优化的稀疏三维点云）转化为稠密体积表示。具体来说，SLAM模块提供优化后的稀疏三维点云，LocalMeshing线程使用Delaunay三角剖分算法将三维空间进行细分，使用可视化约束刻画空间。LocalMeshing线程的输入是来自LoopClosing线程传送的关键帧（其实这些关键帧都是在Tracking线程创建的），输出是一系列的三维空间中的点、三角形、边结构，这些信息由可视化线程展示在窗口。\n\n## 疑问\n\n1. 关键帧约束和非关键帧约束区别何在？为何要区分？顶点细化的最后为何要添加这两种约束？？\n2. 顶点删除过程，会对新产生的空洞重新三角剖分？？\n\n## 关于Delaunay三角剖分\n\n### Triangulation\n\n三角剖分是代数拓扑学最基本的研究方法。以曲面三角剖分为例，三角剖分需要满足一些条件：\n\n（1）每一块碎片都是曲边三角形（曲边三角形就是以等边三角形的三个顶点为圆心，边长为半径画出的图形，曲面的宽度是等长的）\n\n（2）曲面上任何两个这样的曲边三角形，不能同时相交两条或两条以上的边，只能不相交或者是相切于一条公共边\n\n（3）曲面中所有的都是三角面，且所有三角面的合集是所有点集合的凸包\n\n### Delaunay Triangulation\n\n假设边的集合E中的一条边e（两个端点为a，b）,e如果满足下列条件，则称之为Delaunay边：\n\n存在一个圆经过a,b两点，圆内不包含点集中的任何点，这一特性称为空圆特性。\n\n如果一个曲面的点集的一个三角剖分只包含Delaunay边，那么这样的三角剖分就称为Delaunay三角剖分。\n\n关于Delaunay三角剖分更为直观的定义是：三角剖分中的每个三角形的外接圆的内部都不包含点集中的任何点。\n\nDelaunay三角剖分的算法有翻边算法、逐点插入算法、分割合并算法以及Bowyer-Watson算法等。\n\n下图是Delaunay三角剖分的一个直观示意图：\n\n{% asset_img Delanunay三角剖分.png %}\n\n## LocalMeshing.h\n\n新增文件：\n\n```\ndelaunay文件夹：FreespaceDelaunayAlgorithm相关的文件\ndataStructure.h\nFColorMap.h/FColorMap.cpp\nLocalMeshing.h/LocalMeshing.cpp\n```\n\n增添内容文件：\n\n```\nMapDrawer.h MapDrawer.cpp\n```\n\n### 重要的数据结构\n\n1. Class `Delaunay3CellInfo`：Delaunay三维剖分四面体信息\n2. Class `pointInfo`：顶点信息\n3. Class `constraintInfo`：约束信息类，成员包括约束类型、关联的Cell集合\n\n### 约束\n\n约束定义为相机中心与地图点（顶点）之间的线段。每个约束有一个ID，并且保存定义该约束的顶点的ID。\n\n三种类型：\n\n- `CON_KF`：关键帧约束\n- `CON_NONKF`：非关键帧约束\n- `CON_INFINITY`：deleted 约束（无穷约束？？），程序中并没有用到。\n\n关于添加约束的函数：（分别在什么情况下使用？在后面约束插入函数的介绍中说明）\n\n```\naddSetOfConstraints( int vertexID, float pose_x, float pose_y, float pose_z, float time )：直接与点关联的约束\naddConstraintKF(int vertexID, KeyFrame *kF)：与关键帧关联的约束\naddConstraintNonKF()\n```\n\n## LocalMeshing::buildMesh2\n\n该函数是LocalMeshing线程实现功能的主要函数，构建三角剖分过程在该函数中完成。函数主要过程如下：\n\n1. 检查关键帧队列是否为空，不为空则弹出队列头的关键帧，并设置当前关键帧禁止被设为`bad`；\n2. 检查当前关键帧的数据可用性、是否为`bad`；\n3. 获取当前关键帧的位姿的逆，即`Twc`，由此得到旋转矩阵、平移向量；\n4. 获取当前关键帧观测到的地图点`vpMapPoints`；\n5. 关键帧图像转成BGR彩色图；\n6. 删除外点\n   - 从`outlierVertexList`集合获取LocalMapping线程截至目前剔除的外点，保存在`currentOutlierVertexList`，并将`outlierVertexList`（它是LocalMapping线程地图点剔除过程保存外点的接口）外点清空，重新收集；\n   - 遍历获取到的外点（也没进行什么有实质内容的操作啊，有什么作用？会在全局顶点集合中查找每一个外点）；\n   - 调用顶点集合删除算法删除外点，并得到与外点关联的约束集合。\n7. 根据4获取到的`vpMapPoints`收集地图点和约束；\n8. 更新地图点和约束\n   - 调用顶点插入函数插入顶点，并得到与顶点相关联的约束集合；\n   - 处理上一步得到的约束集合；\n   - 插入关键帧约束。\n9. 检查关键帧变化\n   - 获取当前关键帧的临近关键帧集合，对于每一个关键帧进行如下操作：\n     - 获取当前关键帧匹配到的地图点；\n     - 检查地图点，并收集所有地图点到集合；\n   - 检查收集到的地图点变化，如果变化大于阈值则需要更新，将地图点放入待更新集合；\n   - 对于待更新集合中的地图点，调用顶点细化函数更新地图点；\n   - 对于临近关键帧集合中的每一个关键帧进行如下操作：\n     - 如果关键帧是`bad`，则将该关键帧关联的所有约束删除，处理下一个关键帧，否则，继续后面的操作；\n     - 获取当前关键帧的位姿；\n     - 对于当前关键帧关联的所有约束，进行如下操作： \n       - 获取当前约束关联的顶点，得到其坐标信息；\n       - 检查位姿和三维点的变化确定是否需要更新约束，如需要更新则删除当前约束，重新添加关键帧约束。\n10. 发布网格地图`tetsToTris_naive2`，创建三维空间点、三角形、边集合，主要过程如下：\n    - 初始化三维空间点、三角形、边集合为空；\n    - 创建顶点句柄列表，关联到边界顶点（边界顶点与无线远处连接）；\n    - 填充顶点列表，创建有限的非边界顶点句柄列表，并创建有用的句柄与顶点的关联映射；\n    - 遍历有限面集合，并在网格上添加三角形，创建三角形、边。\n\n## 顶点插入算法\n\n该算法输入是一个顶点的信息，输出是由该顶点引起的冲突Cell关联的约束的集合，由于顶点的插入可能会产生新的四面体，所以还需要重新检查该集合中的约束，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。\n\n### 对应函数\n\n```c++\naddVertex(int vertexID, float x, float y, float z, set<int>& setUnionedConstraints )\n```\n\n### 函数参数\n\n- vertexID：顶点ID\n- x,y,z：顶点三维坐标\n- setUnionedConstraints：顶点关联的约束集合\n\n### 算法过程\n\n1. 使用传入的参数创建待处理的顶点；\n2. 定位顶点的位置；\n3. 找到由此顶点引起的冲突Cell集合；\n4. 对于每一个冲突Cell，将其从关联的约束的关联Cell列表中删除，同时得到所有冲突Cell关联的约束集合（作为算法输出）；\n5. 删除冲突的Cell、插入新顶点并重新三角化空洞产生新的Cell；\n6. 将顶点保存到全局顶点集合。\n\n## 约束插入算法\n\n插入约束的函数有三种，分别适用于不同的情况。\n\n1. `addConstraintNonKF()`：适用于没有和关键帧关联的顶点，函数直接输入顶点坐标信息；\n2. `addConstraintKF()`：适用于和关键帧关联的顶点，通过关键帧的位姿获取顶点的坐标信息，约束的插入过程与第一种类似，只是增加了和关键帧相关的一些操作，例如该约束分类为`CON_KF`、当前关键帧的约束列表会添加该约束；\n3. `addSetOfConstraints`：适用于插入已有的约束，函数输入约束集合，使用约束关联的顶点获取顶点坐标信息。\n\n顶点插入的过程大体类似，只介绍第一种插入函数。\n\n### 对应函数\n\n```c++\naddConstraintNonKF( int vertexID, float pose_x, float pose_y, float pose_z, float time )\n```\n\n### 函数参数\n\n- vertexID：顶点ID\n- pose_x,pose_y,pose_z：顶点三维坐标\n- time：时间戳\n\n### 算法过程\n\n1. 通过顶点ID获取顶点信息、顶点操作手柄；\n2. 使用传入的参数创建待处理的约束，设为`CON_NONKF`类型；\n3. 将约束保存到全局约束集合；\n4. 将约束关联到当前顶点；\n5. 将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。\n\n## 约束删除算法\n\n### 对应函数\n\n```c++\nremoveConstraint( int constraintID )\n```\n\n### 函数参数\n\n- constraintID：函数输入，要删除的约束ID\n\n### 算法过程\n\n1. 获取与该约束关联的所有Cell，将该约束与所有Cell消除关联；\n2. 获取与该约束关联的顶点，将该约束从顶点的约束列表中删除；\n3. 获取该约束关联的关键帧（如果是`CON_KF`类型的约束），将该约束从关键帧的约束列表中删除；\n4. 从全局约束集合中删除该约束。\n\n## 顶点删除算法\n\n包括单个顶点的删除和顶点集合的删除两个函数。顶点删除的过程大致可以分为四个步骤：\n\n- 删除与该外点关联的约束\n- 收集外点附带的四面体关联的约束集合；\n- 删除外点及其附带的四面体，并对产生的空洞重新三角剖分；\n- 检查约束集合，约束可能会关联到新产生的四面体。\n\n### 删除顶点\n\n#### 对应函数\n\n```c++\nremoveVertex_origin( int vertexID )\n```\n\n#### 函数参数\n\n- vertexID：函数输入，要删除的外点ID\n\n#### 算法过程\n\n1. 获取该点相关的约束集合（约束ID），调用约束删除算法剔除每一个约束；\n2. 获取与该外点相关的所有四面体的`Cell_hande`，对于每一个执行如下操作：\n   - 获取与该Cell关联的约束集合；\n   - 对于每一个约束，将当前Cell从约束的Cell列表中删除，并收集该约束到集合。\n3. 剔除该外点（同时会对新产生的空洞重新三角剖分）；\n4. 处理前面收集的约束集合，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。\n\n### 删除顶点集合\n\n#### 对应函数\n\n```c++\nremoveVertexSet(list<int>& currentOutlierVertexList, std::set<int>& setUnionedConstraints)\n```\n\n#### 函数参数\n\n- currentOutlierVertexList：函数输入，要删除的外点集合\n- setUnionedConstraints：函数输出，与删除外点相关联的约束集合，同顶点插入函数一样，也需要检查约束集合。\n\n#### 算法过程\n\n与顶点删除过程类似，只是多了访问待删除外点集合的循环。\n\n## 顶点细化算法\n\n### 对应函数\n\n```c++\nmoveVertexSet( const list<int>& moveVertexList )\n```\n\n### 函数参数\n\n- moveVertexList：函数输入，待细化（更新坐标）的顶点集合\n\n### 算法过程\n\n1. 对于待细化顶点集合中的每一个顶点，进行如下操作：\n   - 获取该顶点的ID、坐标信息（新值），构造`tmp`顶点（这些顶点具备足够的信息，在后续过程进行更新）；\n   - 获取该顶点的约束集合，对于集合中的每一个约束进行如下操作：\n     - 如果该约束类型为`CON_KF`，则在`tmp`顶点中添加该顶点关联的关键帧位姿信息；\n     - 如果该约束类新为`CON_NONKF`，则用该顶点的坐标值（旧值）为`tmp`顶点赋值。\n   - 将`tmp`顶点加入`moveList`集合；\n2. 调用顶点集合删除函数，将待细化顶点集合中的顶点全部删除，并得到与删除顶点关联的约束集合；\n3. 调用顶点添加函数，添加`moveList`集合中的顶点（这一步和上一步会产生新的四面体）；\n4. 调用`addSetOfConstraints`函数，处理2中得到的约束集合，与新生成的四面体关联；\n5. 添加与`moveList`集合中的顶点关联的关键帧约束；\n6. 添加与`moveList`集合中的顶点关联的非关键帧约束。\n\n## 参考资料\n\n1. 论文：Building maps for autonomous navigation using sparse visual SLAM features\n2. [CGAL手册](https://doc.cgal.org/latest/Triangulation_3/index.html)\n3. 书籍：Computational Geometry Algorithms and Applications(third edition)","slug":"lightweight_mapping学习之LocalMeshing","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0700cdqlcrg753r2gp","content":"<hr>\n<p>这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录LocalMesshing模块，该模块涉及CGAL库Delauary三角剖分的知识。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>LocalMeshing线程主要任务是使用SLAM优化后的稀疏特征（优化的稀疏三维点云）转化为稠密体积表示。具体来说，SLAM模块提供优化后的稀疏三维点云，LocalMeshing线程使用Delaunay三角剖分算法将三维空间进行细分，使用可视化约束刻画空间。LocalMeshing线程的输入是来自LoopClosing线程传送的关键帧（其实这些关键帧都是在Tracking线程创建的），输出是一系列的三维空间中的点、三角形、边结构，这些信息由可视化线程展示在窗口。</p>\n<h2 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h2><ol>\n<li>关键帧约束和非关键帧约束区别何在？为何要区分？顶点细化的最后为何要添加这两种约束？？</li>\n<li>顶点删除过程，会对新产生的空洞重新三角剖分？？</li>\n</ol>\n<h2 id=\"关于Delaunay三角剖分\"><a href=\"#关于Delaunay三角剖分\" class=\"headerlink\" title=\"关于Delaunay三角剖分\"></a>关于Delaunay三角剖分</h2><h3 id=\"Triangulation\"><a href=\"#Triangulation\" class=\"headerlink\" title=\"Triangulation\"></a>Triangulation</h3><p>三角剖分是代数拓扑学最基本的研究方法。以曲面三角剖分为例，三角剖分需要满足一些条件：</p>\n<p>（1）每一块碎片都是曲边三角形（曲边三角形就是以等边三角形的三个顶点为圆心，边长为半径画出的图形，曲面的宽度是等长的）</p>\n<p>（2）曲面上任何两个这样的曲边三角形，不能同时相交两条或两条以上的边，只能不相交或者是相切于一条公共边</p>\n<p>（3）曲面中所有的都是三角面，且所有三角面的合集是所有点集合的凸包</p>\n<h3 id=\"Delaunay-Triangulation\"><a href=\"#Delaunay-Triangulation\" class=\"headerlink\" title=\"Delaunay Triangulation\"></a>Delaunay Triangulation</h3><p>假设边的集合E中的一条边e（两个端点为a，b）,e如果满足下列条件，则称之为Delaunay边：</p>\n<p>存在一个圆经过a,b两点，圆内不包含点集中的任何点，这一特性称为空圆特性。</p>\n<p>如果一个曲面的点集的一个三角剖分只包含Delaunay边，那么这样的三角剖分就称为Delaunay三角剖分。</p>\n<p>关于Delaunay三角剖分更为直观的定义是：三角剖分中的每个三角形的外接圆的内部都不包含点集中的任何点。</p>\n<p>Delaunay三角剖分的算法有翻边算法、逐点插入算法、分割合并算法以及Bowyer-Watson算法等。</p>\n<p>下图是Delaunay三角剖分的一个直观示意图：</p>\n<img src=\"/2018/09/04/lightweight_mapping学习之LocalMeshing/Delanunay三角剖分.png\">\n<h2 id=\"LocalMeshing-h\"><a href=\"#LocalMeshing-h\" class=\"headerlink\" title=\"LocalMeshing.h\"></a>LocalMeshing.h</h2><p>新增文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delaunay文件夹：FreespaceDelaunayAlgorithm相关的文件</span><br><span class=\"line\">dataStructure.h</span><br><span class=\"line\">FColorMap.h/FColorMap.cpp</span><br><span class=\"line\">LocalMeshing.h/LocalMeshing.cpp</span><br></pre></td></tr></table></figure>\n<p>增添内容文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MapDrawer.h MapDrawer.cpp</span><br></pre></td></tr></table></figure>\n<h3 id=\"重要的数据结构\"><a href=\"#重要的数据结构\" class=\"headerlink\" title=\"重要的数据结构\"></a>重要的数据结构</h3><ol>\n<li>Class <code>Delaunay3CellInfo</code>：Delaunay三维剖分四面体信息</li>\n<li>Class <code>pointInfo</code>：顶点信息</li>\n<li>Class <code>constraintInfo</code>：约束信息类，成员包括约束类型、关联的Cell集合</li>\n</ol>\n<h3 id=\"约束\"><a href=\"#约束\" class=\"headerlink\" title=\"约束\"></a>约束</h3><p>约束定义为相机中心与地图点（顶点）之间的线段。每个约束有一个ID，并且保存定义该约束的顶点的ID。</p>\n<p>三种类型：</p>\n<ul>\n<li><code>CON_KF</code>：关键帧约束</li>\n<li><code>CON_NONKF</code>：非关键帧约束</li>\n<li><code>CON_INFINITY</code>：deleted 约束（无穷约束？？），程序中并没有用到。</li>\n</ul>\n<p>关于添加约束的函数：（分别在什么情况下使用？在后面约束插入函数的介绍中说明）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addSetOfConstraints( int vertexID, float pose_x, float pose_y, float pose_z, float time )：直接与点关联的约束</span><br><span class=\"line\">addConstraintKF(int vertexID, KeyFrame *kF)：与关键帧关联的约束</span><br><span class=\"line\">addConstraintNonKF()</span><br></pre></td></tr></table></figure>\n<h2 id=\"LocalMeshing-buildMesh2\"><a href=\"#LocalMeshing-buildMesh2\" class=\"headerlink\" title=\"LocalMeshing::buildMesh2\"></a>LocalMeshing::buildMesh2</h2><p>该函数是LocalMeshing线程实现功能的主要函数，构建三角剖分过程在该函数中完成。函数主要过程如下：</p>\n<ol>\n<li>检查关键帧队列是否为空，不为空则弹出队列头的关键帧，并设置当前关键帧禁止被设为<code>bad</code>；</li>\n<li>检查当前关键帧的数据可用性、是否为<code>bad</code>；</li>\n<li>获取当前关键帧的位姿的逆，即<code>Twc</code>，由此得到旋转矩阵、平移向量；</li>\n<li>获取当前关键帧观测到的地图点<code>vpMapPoints</code>；</li>\n<li>关键帧图像转成BGR彩色图；</li>\n<li>删除外点<ul>\n<li>从<code>outlierVertexList</code>集合获取LocalMapping线程截至目前剔除的外点，保存在<code>currentOutlierVertexList</code>，并将<code>outlierVertexList</code>（它是LocalMapping线程地图点剔除过程保存外点的接口）外点清空，重新收集；</li>\n<li>遍历获取到的外点（也没进行什么有实质内容的操作啊，有什么作用？会在全局顶点集合中查找每一个外点）；</li>\n<li>调用顶点集合删除算法删除外点，并得到与外点关联的约束集合。</li>\n</ul>\n</li>\n<li>根据4获取到的<code>vpMapPoints</code>收集地图点和约束；</li>\n<li>更新地图点和约束<ul>\n<li>调用顶点插入函数插入顶点，并得到与顶点相关联的约束集合；</li>\n<li>处理上一步得到的约束集合；</li>\n<li>插入关键帧约束。</li>\n</ul>\n</li>\n<li>检查关键帧变化<ul>\n<li>获取当前关键帧的临近关键帧集合，对于每一个关键帧进行如下操作：<ul>\n<li>获取当前关键帧匹配到的地图点；</li>\n<li>检查地图点，并收集所有地图点到集合；</li>\n</ul>\n</li>\n<li>检查收集到的地图点变化，如果变化大于阈值则需要更新，将地图点放入待更新集合；</li>\n<li>对于待更新集合中的地图点，调用顶点细化函数更新地图点；</li>\n<li>对于临近关键帧集合中的每一个关键帧进行如下操作：<ul>\n<li>如果关键帧是<code>bad</code>，则将该关键帧关联的所有约束删除，处理下一个关键帧，否则，继续后面的操作；</li>\n<li>获取当前关键帧的位姿；</li>\n<li>对于当前关键帧关联的所有约束，进行如下操作： <ul>\n<li>获取当前约束关联的顶点，得到其坐标信息；</li>\n<li>检查位姿和三维点的变化确定是否需要更新约束，如需要更新则删除当前约束，重新添加关键帧约束。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>发布网格地图<code>tetsToTris_naive2</code>，创建三维空间点、三角形、边集合，主要过程如下：<ul>\n<li>初始化三维空间点、三角形、边集合为空；</li>\n<li>创建顶点句柄列表，关联到边界顶点（边界顶点与无线远处连接）；</li>\n<li>填充顶点列表，创建有限的非边界顶点句柄列表，并创建有用的句柄与顶点的关联映射；</li>\n<li>遍历有限面集合，并在网格上添加三角形，创建三角形、边。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"顶点插入算法\"><a href=\"#顶点插入算法\" class=\"headerlink\" title=\"顶点插入算法\"></a>顶点插入算法</h2><p>该算法输入是一个顶点的信息，输出是由该顶点引起的冲突Cell关联的约束的集合，由于顶点的插入可能会产生新的四面体，所以还需要重新检查该集合中的约束，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。</p>\n<h3 id=\"对应函数\"><a href=\"#对应函数\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addVertex(<span class=\"keyword\">int</span> vertexID, <span class=\"keyword\">float</span> x, <span class=\"keyword\">float</span> y, <span class=\"keyword\">float</span> z, <span class=\"built_in\">set</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; setUnionedConstraints )</span><br></pre></td></tr></table></figure>\n<h3 id=\"函数参数\"><a href=\"#函数参数\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>vertexID：顶点ID</li>\n<li>x,y,z：顶点三维坐标</li>\n<li>setUnionedConstraints：顶点关联的约束集合</li>\n</ul>\n<h3 id=\"算法过程\"><a href=\"#算法过程\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>使用传入的参数创建待处理的顶点；</li>\n<li>定位顶点的位置；</li>\n<li>找到由此顶点引起的冲突Cell集合；</li>\n<li>对于每一个冲突Cell，将其从关联的约束的关联Cell列表中删除，同时得到所有冲突Cell关联的约束集合（作为算法输出）；</li>\n<li>删除冲突的Cell、插入新顶点并重新三角化空洞产生新的Cell；</li>\n<li>将顶点保存到全局顶点集合。</li>\n</ol>\n<h2 id=\"约束插入算法\"><a href=\"#约束插入算法\" class=\"headerlink\" title=\"约束插入算法\"></a>约束插入算法</h2><p>插入约束的函数有三种，分别适用于不同的情况。</p>\n<ol>\n<li><code>addConstraintNonKF()</code>：适用于没有和关键帧关联的顶点，函数直接输入顶点坐标信息；</li>\n<li><code>addConstraintKF()</code>：适用于和关键帧关联的顶点，通过关键帧的位姿获取顶点的坐标信息，约束的插入过程与第一种类似，只是增加了和关键帧相关的一些操作，例如该约束分类为<code>CON_KF</code>、当前关键帧的约束列表会添加该约束；</li>\n<li><code>addSetOfConstraints</code>：适用于插入已有的约束，函数输入约束集合，使用约束关联的顶点获取顶点坐标信息。</li>\n</ol>\n<p>顶点插入的过程大体类似，只介绍第一种插入函数。</p>\n<h3 id=\"对应函数-1\"><a href=\"#对应函数-1\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addConstraintNonKF( <span class=\"keyword\">int</span> vertexID, <span class=\"keyword\">float</span> pose_x, <span class=\"keyword\">float</span> pose_y, <span class=\"keyword\">float</span> pose_z, <span class=\"keyword\">float</span> time )</span><br></pre></td></tr></table></figure>\n<h3 id=\"函数参数-1\"><a href=\"#函数参数-1\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>vertexID：顶点ID</li>\n<li>pose_x,pose_y,pose_z：顶点三维坐标</li>\n<li>time：时间戳</li>\n</ul>\n<h3 id=\"算法过程-1\"><a href=\"#算法过程-1\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>通过顶点ID获取顶点信息、顶点操作手柄；</li>\n<li>使用传入的参数创建待处理的约束，设为<code>CON_NONKF</code>类型；</li>\n<li>将约束保存到全局约束集合；</li>\n<li>将约束关联到当前顶点；</li>\n<li>将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。</li>\n</ol>\n<h2 id=\"约束删除算法\"><a href=\"#约束删除算法\" class=\"headerlink\" title=\"约束删除算法\"></a>约束删除算法</h2><h3 id=\"对应函数-2\"><a href=\"#对应函数-2\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">removeConstraint( <span class=\"keyword\">int</span> constraintID )</span><br></pre></td></tr></table></figure>\n<h3 id=\"函数参数-2\"><a href=\"#函数参数-2\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>constraintID：函数输入，要删除的约束ID</li>\n</ul>\n<h3 id=\"算法过程-2\"><a href=\"#算法过程-2\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>获取与该约束关联的所有Cell，将该约束与所有Cell消除关联；</li>\n<li>获取与该约束关联的顶点，将该约束从顶点的约束列表中删除；</li>\n<li>获取该约束关联的关键帧（如果是<code>CON_KF</code>类型的约束），将该约束从关键帧的约束列表中删除；</li>\n<li>从全局约束集合中删除该约束。</li>\n</ol>\n<h2 id=\"顶点删除算法\"><a href=\"#顶点删除算法\" class=\"headerlink\" title=\"顶点删除算法\"></a>顶点删除算法</h2><p>包括单个顶点的删除和顶点集合的删除两个函数。顶点删除的过程大致可以分为四个步骤：</p>\n<ul>\n<li>删除与该外点关联的约束</li>\n<li>收集外点附带的四面体关联的约束集合；</li>\n<li>删除外点及其附带的四面体，并对产生的空洞重新三角剖分；</li>\n<li>检查约束集合，约束可能会关联到新产生的四面体。</li>\n</ul>\n<h3 id=\"删除顶点\"><a href=\"#删除顶点\" class=\"headerlink\" title=\"删除顶点\"></a>删除顶点</h3><h4 id=\"对应函数-3\"><a href=\"#对应函数-3\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">removeVertex_origin( <span class=\"keyword\">int</span> vertexID )</span><br></pre></td></tr></table></figure>\n<h4 id=\"函数参数-3\"><a href=\"#函数参数-3\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h4><ul>\n<li>vertexID：函数输入，要删除的外点ID</li>\n</ul>\n<h4 id=\"算法过程-3\"><a href=\"#算法过程-3\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h4><ol>\n<li>获取该点相关的约束集合（约束ID），调用约束删除算法剔除每一个约束；</li>\n<li>获取与该外点相关的所有四面体的<code>Cell_hande</code>，对于每一个执行如下操作：<ul>\n<li>获取与该Cell关联的约束集合；</li>\n<li>对于每一个约束，将当前Cell从约束的Cell列表中删除，并收集该约束到集合。</li>\n</ul>\n</li>\n<li>剔除该外点（同时会对新产生的空洞重新三角剖分）；</li>\n<li>处理前面收集的约束集合，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。</li>\n</ol>\n<h3 id=\"删除顶点集合\"><a href=\"#删除顶点集合\" class=\"headerlink\" title=\"删除顶点集合\"></a>删除顶点集合</h3><h4 id=\"对应函数-4\"><a href=\"#对应函数-4\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">removeVertexSet(<span class=\"built_in\">list</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; currentOutlierVertexList, <span class=\"built_in\">std</span>::<span class=\"built_in\">set</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; setUnionedConstraints)</span><br></pre></td></tr></table></figure>\n<h4 id=\"函数参数-4\"><a href=\"#函数参数-4\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h4><ul>\n<li>currentOutlierVertexList：函数输入，要删除的外点集合</li>\n<li>setUnionedConstraints：函数输出，与删除外点相关联的约束集合，同顶点插入函数一样，也需要检查约束集合。</li>\n</ul>\n<h4 id=\"算法过程-4\"><a href=\"#算法过程-4\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h4><p>与顶点删除过程类似，只是多了访问待删除外点集合的循环。</p>\n<h2 id=\"顶点细化算法\"><a href=\"#顶点细化算法\" class=\"headerlink\" title=\"顶点细化算法\"></a>顶点细化算法</h2><h3 id=\"对应函数-5\"><a href=\"#对应函数-5\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">moveVertexSet( <span class=\"keyword\">const</span> <span class=\"built_in\">list</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; moveVertexList )</span><br></pre></td></tr></table></figure>\n<h3 id=\"函数参数-5\"><a href=\"#函数参数-5\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>moveVertexList：函数输入，待细化（更新坐标）的顶点集合</li>\n</ul>\n<h3 id=\"算法过程-5\"><a href=\"#算法过程-5\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>对于待细化顶点集合中的每一个顶点，进行如下操作：<ul>\n<li>获取该顶点的ID、坐标信息（新值），构造<code>tmp</code>顶点（这些顶点具备足够的信息，在后续过程进行更新）；</li>\n<li>获取该顶点的约束集合，对于集合中的每一个约束进行如下操作：<ul>\n<li>如果该约束类型为<code>CON_KF</code>，则在<code>tmp</code>顶点中添加该顶点关联的关键帧位姿信息；</li>\n<li>如果该约束类新为<code>CON_NONKF</code>，则用该顶点的坐标值（旧值）为<code>tmp</code>顶点赋值。</li>\n</ul>\n</li>\n<li>将<code>tmp</code>顶点加入<code>moveList</code>集合；</li>\n</ul>\n</li>\n<li>调用顶点集合删除函数，将待细化顶点集合中的顶点全部删除，并得到与删除顶点关联的约束集合；</li>\n<li>调用顶点添加函数，添加<code>moveList</code>集合中的顶点（这一步和上一步会产生新的四面体）；</li>\n<li>调用<code>addSetOfConstraints</code>函数，处理2中得到的约束集合，与新生成的四面体关联；</li>\n<li>添加与<code>moveList</code>集合中的顶点关联的关键帧约束；</li>\n<li>添加与<code>moveList</code>集合中的顶点关联的非关键帧约束。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>论文：Building maps for autonomous navigation using sparse visual SLAM features</li>\n<li><a href=\"https://doc.cgal.org/latest/Triangulation_3/index.html\" target=\"_blank\" rel=\"noopener\">CGAL手册</a></li>\n<li>书籍：Computational Geometry Algorithms and Applications(third edition)</li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关lightwight_mapping项目源码分析的内容，主要记录LocalMesshing模块，该模块涉及CGAL库Delauary三角剖分的知识。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>LocalMeshing线程主要任务是使用SLAM优化后的稀疏特征（优化的稀疏三维点云）转化为稠密体积表示。具体来说，SLAM模块提供优化后的稀疏三维点云，LocalMeshing线程使用Delaunay三角剖分算法将三维空间进行细分，使用可视化约束刻画空间。LocalMeshing线程的输入是来自LoopClosing线程传送的关键帧（其实这些关键帧都是在Tracking线程创建的），输出是一系列的三维空间中的点、三角形、边结构，这些信息由可视化线程展示在窗口。</p>\n<h2 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h2><ol>\n<li>关键帧约束和非关键帧约束区别何在？为何要区分？顶点细化的最后为何要添加这两种约束？？</li>\n<li>顶点删除过程，会对新产生的空洞重新三角剖分？？</li>\n</ol>\n<h2 id=\"关于Delaunay三角剖分\"><a href=\"#关于Delaunay三角剖分\" class=\"headerlink\" title=\"关于Delaunay三角剖分\"></a>关于Delaunay三角剖分</h2><h3 id=\"Triangulation\"><a href=\"#Triangulation\" class=\"headerlink\" title=\"Triangulation\"></a>Triangulation</h3><p>三角剖分是代数拓扑学最基本的研究方法。以曲面三角剖分为例，三角剖分需要满足一些条件：</p>\n<p>（1）每一块碎片都是曲边三角形（曲边三角形就是以等边三角形的三个顶点为圆心，边长为半径画出的图形，曲面的宽度是等长的）</p>\n<p>（2）曲面上任何两个这样的曲边三角形，不能同时相交两条或两条以上的边，只能不相交或者是相切于一条公共边</p>\n<p>（3）曲面中所有的都是三角面，且所有三角面的合集是所有点集合的凸包</p>\n<h3 id=\"Delaunay-Triangulation\"><a href=\"#Delaunay-Triangulation\" class=\"headerlink\" title=\"Delaunay Triangulation\"></a>Delaunay Triangulation</h3><p>假设边的集合E中的一条边e（两个端点为a，b）,e如果满足下列条件，则称之为Delaunay边：</p>\n<p>存在一个圆经过a,b两点，圆内不包含点集中的任何点，这一特性称为空圆特性。</p>\n<p>如果一个曲面的点集的一个三角剖分只包含Delaunay边，那么这样的三角剖分就称为Delaunay三角剖分。</p>\n<p>关于Delaunay三角剖分更为直观的定义是：三角剖分中的每个三角形的外接圆的内部都不包含点集中的任何点。</p>\n<p>Delaunay三角剖分的算法有翻边算法、逐点插入算法、分割合并算法以及Bowyer-Watson算法等。</p>\n<p>下图是Delaunay三角剖分的一个直观示意图：</p>\n<img src=\"/2018/09/04/lightweight_mapping学习之LocalMeshing/Delanunay三角剖分.png\">\n<h2 id=\"LocalMeshing-h\"><a href=\"#LocalMeshing-h\" class=\"headerlink\" title=\"LocalMeshing.h\"></a>LocalMeshing.h</h2><p>新增文件：</p>\n<!--�315-->\n<p>增添内容文件：</p>\n<!--�316-->\n<h3 id=\"重要的数据结构\"><a href=\"#重要的数据结构\" class=\"headerlink\" title=\"重要的数据结构\"></a>重要的数据结构</h3><ol>\n<li>Class <code>Delaunay3CellInfo</code>：Delaunay三维剖分四面体信息</li>\n<li>Class <code>pointInfo</code>：顶点信息</li>\n<li>Class <code>constraintInfo</code>：约束信息类，成员包括约束类型、关联的Cell集合</li>\n</ol>\n<h3 id=\"约束\"><a href=\"#约束\" class=\"headerlink\" title=\"约束\"></a>约束</h3><p>约束定义为相机中心与地图点（顶点）之间的线段。每个约束有一个ID，并且保存定义该约束的顶点的ID。</p>\n<p>三种类型：</p>\n<ul>\n<li><code>CON_KF</code>：关键帧约束</li>\n<li><code>CON_NONKF</code>：非关键帧约束</li>\n<li><code>CON_INFINITY</code>：deleted 约束（无穷约束？？），程序中并没有用到。</li>\n</ul>\n<p>关于添加约束的函数：（分别在什么情况下使用？在后面约束插入函数的介绍中说明）</p>\n<!--�317-->\n<h2 id=\"LocalMeshing-buildMesh2\"><a href=\"#LocalMeshing-buildMesh2\" class=\"headerlink\" title=\"LocalMeshing::buildMesh2\"></a>LocalMeshing::buildMesh2</h2><p>该函数是LocalMeshing线程实现功能的主要函数，构建三角剖分过程在该函数中完成。函数主要过程如下：</p>\n<ol>\n<li>检查关键帧队列是否为空，不为空则弹出队列头的关键帧，并设置当前关键帧禁止被设为<code>bad</code>；</li>\n<li>检查当前关键帧的数据可用性、是否为<code>bad</code>；</li>\n<li>获取当前关键帧的位姿的逆，即<code>Twc</code>，由此得到旋转矩阵、平移向量；</li>\n<li>获取当前关键帧观测到的地图点<code>vpMapPoints</code>；</li>\n<li>关键帧图像转成BGR彩色图；</li>\n<li>删除外点<ul>\n<li>从<code>outlierVertexList</code>集合获取LocalMapping线程截至目前剔除的外点，保存在<code>currentOutlierVertexList</code>，并将<code>outlierVertexList</code>（它是LocalMapping线程地图点剔除过程保存外点的接口）外点清空，重新收集；</li>\n<li>遍历获取到的外点（也没进行什么有实质内容的操作啊，有什么作用？会在全局顶点集合中查找每一个外点）；</li>\n<li>调用顶点集合删除算法删除外点，并得到与外点关联的约束集合。</li>\n</ul>\n</li>\n<li>根据4获取到的<code>vpMapPoints</code>收集地图点和约束；</li>\n<li>更新地图点和约束<ul>\n<li>调用顶点插入函数插入顶点，并得到与顶点相关联的约束集合；</li>\n<li>处理上一步得到的约束集合；</li>\n<li>插入关键帧约束。</li>\n</ul>\n</li>\n<li>检查关键帧变化<ul>\n<li>获取当前关键帧的临近关键帧集合，对于每一个关键帧进行如下操作：<ul>\n<li>获取当前关键帧匹配到的地图点；</li>\n<li>检查地图点，并收集所有地图点到集合；</li>\n</ul>\n</li>\n<li>检查收集到的地图点变化，如果变化大于阈值则需要更新，将地图点放入待更新集合；</li>\n<li>对于待更新集合中的地图点，调用顶点细化函数更新地图点；</li>\n<li>对于临近关键帧集合中的每一个关键帧进行如下操作：<ul>\n<li>如果关键帧是<code>bad</code>，则将该关键帧关联的所有约束删除，处理下一个关键帧，否则，继续后面的操作；</li>\n<li>获取当前关键帧的位姿；</li>\n<li>对于当前关键帧关联的所有约束，进行如下操作： <ul>\n<li>获取当前约束关联的顶点，得到其坐标信息；</li>\n<li>检查位姿和三维点的变化确定是否需要更新约束，如需要更新则删除当前约束，重新添加关键帧约束。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>发布网格地图<code>tetsToTris_naive2</code>，创建三维空间点、三角形、边集合，主要过程如下：<ul>\n<li>初始化三维空间点、三角形、边集合为空；</li>\n<li>创建顶点句柄列表，关联到边界顶点（边界顶点与无线远处连接）；</li>\n<li>填充顶点列表，创建有限的非边界顶点句柄列表，并创建有用的句柄与顶点的关联映射；</li>\n<li>遍历有限面集合，并在网格上添加三角形，创建三角形、边。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"顶点插入算法\"><a href=\"#顶点插入算法\" class=\"headerlink\" title=\"顶点插入算法\"></a>顶点插入算法</h2><p>该算法输入是一个顶点的信息，输出是由该顶点引起的冲突Cell关联的约束的集合，由于顶点的插入可能会产生新的四面体，所以还需要重新检查该集合中的约束，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。</p>\n<h3 id=\"对应函数\"><a href=\"#对应函数\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><!--�318-->\n<h3 id=\"函数参数\"><a href=\"#函数参数\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>vertexID：顶点ID</li>\n<li>x,y,z：顶点三维坐标</li>\n<li>setUnionedConstraints：顶点关联的约束集合</li>\n</ul>\n<h3 id=\"算法过程\"><a href=\"#算法过程\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>使用传入的参数创建待处理的顶点；</li>\n<li>定位顶点的位置；</li>\n<li>找到由此顶点引起的冲突Cell集合；</li>\n<li>对于每一个冲突Cell，将其从关联的约束的关联Cell列表中删除，同时得到所有冲突Cell关联的约束集合（作为算法输出）；</li>\n<li>删除冲突的Cell、插入新顶点并重新三角化空洞产生新的Cell；</li>\n<li>将顶点保存到全局顶点集合。</li>\n</ol>\n<h2 id=\"约束插入算法\"><a href=\"#约束插入算法\" class=\"headerlink\" title=\"约束插入算法\"></a>约束插入算法</h2><p>插入约束的函数有三种，分别适用于不同的情况。</p>\n<ol>\n<li><code>addConstraintNonKF()</code>：适用于没有和关键帧关联的顶点，函数直接输入顶点坐标信息；</li>\n<li><code>addConstraintKF()</code>：适用于和关键帧关联的顶点，通过关键帧的位姿获取顶点的坐标信息，约束的插入过程与第一种类似，只是增加了和关键帧相关的一些操作，例如该约束分类为<code>CON_KF</code>、当前关键帧的约束列表会添加该约束；</li>\n<li><code>addSetOfConstraints</code>：适用于插入已有的约束，函数输入约束集合，使用约束关联的顶点获取顶点坐标信息。</li>\n</ol>\n<p>顶点插入的过程大体类似，只介绍第一种插入函数。</p>\n<h3 id=\"对应函数-1\"><a href=\"#对应函数-1\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><!--�319-->\n<h3 id=\"函数参数-1\"><a href=\"#函数参数-1\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>vertexID：顶点ID</li>\n<li>pose_x,pose_y,pose_z：顶点三维坐标</li>\n<li>time：时间戳</li>\n</ul>\n<h3 id=\"算法过程-1\"><a href=\"#算法过程-1\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>通过顶点ID获取顶点信息、顶点操作手柄；</li>\n<li>使用传入的参数创建待处理的约束，设为<code>CON_NONKF</code>类型；</li>\n<li>将约束保存到全局约束集合；</li>\n<li>将约束关联到当前顶点；</li>\n<li>将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。</li>\n</ol>\n<h2 id=\"约束删除算法\"><a href=\"#约束删除算法\" class=\"headerlink\" title=\"约束删除算法\"></a>约束删除算法</h2><h3 id=\"对应函数-2\"><a href=\"#对应函数-2\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><!--�320-->\n<h3 id=\"函数参数-2\"><a href=\"#函数参数-2\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>constraintID：函数输入，要删除的约束ID</li>\n</ul>\n<h3 id=\"算法过程-2\"><a href=\"#算法过程-2\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>获取与该约束关联的所有Cell，将该约束与所有Cell消除关联；</li>\n<li>获取与该约束关联的顶点，将该约束从顶点的约束列表中删除；</li>\n<li>获取该约束关联的关键帧（如果是<code>CON_KF</code>类型的约束），将该约束从关键帧的约束列表中删除；</li>\n<li>从全局约束集合中删除该约束。</li>\n</ol>\n<h2 id=\"顶点删除算法\"><a href=\"#顶点删除算法\" class=\"headerlink\" title=\"顶点删除算法\"></a>顶点删除算法</h2><p>包括单个顶点的删除和顶点集合的删除两个函数。顶点删除的过程大致可以分为四个步骤：</p>\n<ul>\n<li>删除与该外点关联的约束</li>\n<li>收集外点附带的四面体关联的约束集合；</li>\n<li>删除外点及其附带的四面体，并对产生的空洞重新三角剖分；</li>\n<li>检查约束集合，约束可能会关联到新产生的四面体。</li>\n</ul>\n<h3 id=\"删除顶点\"><a href=\"#删除顶点\" class=\"headerlink\" title=\"删除顶点\"></a>删除顶点</h3><h4 id=\"对应函数-3\"><a href=\"#对应函数-3\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><!--�321-->\n<h4 id=\"函数参数-3\"><a href=\"#函数参数-3\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h4><ul>\n<li>vertexID：函数输入，要删除的外点ID</li>\n</ul>\n<h4 id=\"算法过程-3\"><a href=\"#算法过程-3\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h4><ol>\n<li>获取该点相关的约束集合（约束ID），调用约束删除算法剔除每一个约束；</li>\n<li>获取与该外点相关的所有四面体的<code>Cell_hande</code>，对于每一个执行如下操作：<ul>\n<li>获取与该Cell关联的约束集合；</li>\n<li>对于每一个约束，将当前Cell从约束的Cell列表中删除，并收集该约束到集合。</li>\n</ul>\n</li>\n<li>剔除该外点（同时会对新产生的空洞重新三角剖分）；</li>\n<li>处理前面收集的约束集合，将约束关联到四面体（快速搜索与新的约束相交的四面体，并标记为空）。</li>\n</ol>\n<h3 id=\"删除顶点集合\"><a href=\"#删除顶点集合\" class=\"headerlink\" title=\"删除顶点集合\"></a>删除顶点集合</h3><h4 id=\"对应函数-4\"><a href=\"#对应函数-4\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h4><!--�322-->\n<h4 id=\"函数参数-4\"><a href=\"#函数参数-4\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h4><ul>\n<li>currentOutlierVertexList：函数输入，要删除的外点集合</li>\n<li>setUnionedConstraints：函数输出，与删除外点相关联的约束集合，同顶点插入函数一样，也需要检查约束集合。</li>\n</ul>\n<h4 id=\"算法过程-4\"><a href=\"#算法过程-4\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h4><p>与顶点删除过程类似，只是多了访问待删除外点集合的循环。</p>\n<h2 id=\"顶点细化算法\"><a href=\"#顶点细化算法\" class=\"headerlink\" title=\"顶点细化算法\"></a>顶点细化算法</h2><h3 id=\"对应函数-5\"><a href=\"#对应函数-5\" class=\"headerlink\" title=\"对应函数\"></a>对应函数</h3><!--�323-->\n<h3 id=\"函数参数-5\"><a href=\"#函数参数-5\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h3><ul>\n<li>moveVertexList：函数输入，待细化（更新坐标）的顶点集合</li>\n</ul>\n<h3 id=\"算法过程-5\"><a href=\"#算法过程-5\" class=\"headerlink\" title=\"算法过程\"></a>算法过程</h3><ol>\n<li>对于待细化顶点集合中的每一个顶点，进行如下操作：<ul>\n<li>获取该顶点的ID、坐标信息（新值），构造<code>tmp</code>顶点（这些顶点具备足够的信息，在后续过程进行更新）；</li>\n<li>获取该顶点的约束集合，对于集合中的每一个约束进行如下操作：<ul>\n<li>如果该约束类型为<code>CON_KF</code>，则在<code>tmp</code>顶点中添加该顶点关联的关键帧位姿信息；</li>\n<li>如果该约束类新为<code>CON_NONKF</code>，则用该顶点的坐标值（旧值）为<code>tmp</code>顶点赋值。</li>\n</ul>\n</li>\n<li>将<code>tmp</code>顶点加入<code>moveList</code>集合；</li>\n</ul>\n</li>\n<li>调用顶点集合删除函数，将待细化顶点集合中的顶点全部删除，并得到与删除顶点关联的约束集合；</li>\n<li>调用顶点添加函数，添加<code>moveList</code>集合中的顶点（这一步和上一步会产生新的四面体）；</li>\n<li>调用<code>addSetOfConstraints</code>函数，处理2中得到的约束集合，与新生成的四面体关联；</li>\n<li>添加与<code>moveList</code>集合中的顶点关联的关键帧约束；</li>\n<li>添加与<code>moveList</code>集合中的顶点关联的非关键帧约束。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>论文：Building maps for autonomous navigation using sparse visual SLAM features</li>\n<li><a href=\"https://doc.cgal.org/latest/Triangulation_3/index.html\" target=\"_blank\" rel=\"noopener\">CGAL手册</a></li>\n<li>书籍：Computational Geometry Algorithms and Applications(third edition)</li>\n</ol>"},{"title":"当前开源SLAM方案一览","date":"2018-09-26T07:52:25.000Z","mathjax":true,"copyright":true,"_content":"---\n这篇文章记录下目前流行的开源SLAM系统的方案。\n<!--more--->\n最近课题进展不顺利，目标不明确、思路不清晰、没有创新点，迷茫、不知所措。还是暂时停一下，花时间查阅一些资料，充实一下自己。\n\n| 时间 |    开源方案    |     传感器形式     |    VO    | 稀疏\\稠密 | 论文 |                           地址链接                           |\n| :--: | :------------: | :----------------: | :------: | :-------: | :--: | :----------------------------------------------------------: |\n| 2007 |    MonoSLAM    |        单目        |          |           | [1]  |       [Github](https://github.com/hanmekim/SceneLib2)        |\n| 2007 |      PTAM      |        单目        |          |           | [2]  |     [Source Code]( http://www.robots.ox.ac.uk/~gk/PTAM/)     |\n| 2015 |    ORB-SLAM    |      单目为主      | 特征点法 |   稀疏    | [3]  | [链接](http://webdiis.unizar.es/~raulmur/orbslam/)   [Github](https://github.com/raulmur/ORB_SLAM) |\n| 2017 |   ORB-SLAM2    | 单目、双目、RGB-D  | 特征点法 |   稀疏    | [4]  |        [Github](https://github.com/raulmur/ORB_SLAM2)        |\n| 2014 |    LSD-SLAM    | 单目（为主）、双目 |  直接法  |  半稠密   | [5]  | [home]( http://vision.in.tum.de/research/vslam/lsdslam)   [Github](<https://github.com/tum-vision/lsd_slam> ) |\n| 2014 |      SVO       |        单目        | 半直接法 |           | [6]  |         [Github](https://github.com/uzh-rpg/rpg_svo)         |\n| 2014 |    RTAB-MAP    |     RGB-D/双目     |          |           | [7]  |        [Github](https://github.com/introlab/rtabmap )        |\n| 2015 |     OKVIS      |      多目+IMU      |          |           | [8]  |         [Github](https://github.com/ethz-asl/okvis )         |\n| 2015 |     ROVIO      |      单目+IMU      |          |           | [9]  |         [Github](https://github.com/ethz-asl/rovio)          |\n| 2011 |      DTAM      |       RGB-D        |  直接法  |   稠密    | [10] |       [Github](https://github.com/anuranbaka/OpenDTAM)       |\n| 2013 |      DVO       |       RGB-D        |          |           | [11] |       [Github](https://github.com/tum-vision/dvo_slam)       |\n| 2016 |      DSO       |        单目        |          |           | [12] |         [Github](https://github.com/JakobEngel/dso)          |\n| 2014 |   RGBD-SLAM2   |       RGB-D        |          |           | [13] |     [Github](https://github.com/felixendres/rgbdslam_v2)     |\n| 2015 | Elastic Fusion |       RGB-D        |          |   稠密    | [14] |      [Github](https://github.com/mp3guy/ElasticFusion)       |\n| 2011 |  Hector SLAM   |        激光        |          |           | [15] |           [wiki](http://wiki.ros.org/hector_slam)            |\n| 2007 |    GMapping    |        激光        |          |           | [16] |             [wiki](http://wiki.ros.org/gmapping)             |\n| 2015 |     OKVIS      |      多目+IMU      |          |           | [17] |         [Github](https://github.com/ethz-asl/ckvis)          |\n| 2015 |     ROVIO      |      单目+IMU      |          |           | [18] | [Github](https://github.com/ethz-asl/rovio)  [Paper](http://dx.doi.org/10.3929/ethz-a-010566547) |\n| 2011 | Kinetic Fusion |       RGB-D        |          |   稠密    | [19] |                                                              |\n|      |   Kintinuous   |                    |          |           | [20] |                                                              |\n|      | DynamicFusion  |                    |          |   稠密    | [21] |                                                              |\n|      |   InfiniTAM    |                    |          |   稠密    | [22] |                                                              |\n\n## 论文\n\n[2] Klein G, Murray D. Parallel tracking and mapping for small AR workspaces[C]//Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality. IEEE Computer Society, 2007: 1-10. [[pdf](http://www.robots.ox.ac.uk/~gk/publications/KleinMurray2007ISMAR.pdf)] [[slides](http://www.robots.ox.ac.uk/~gk/publications/Slides_KleinMurray2007ISMAR.pdf)]\n\n[3] \n\n- [Raúl Mur-Artal](http://webdiis.unizar.es/~raulmur/), [J. M. M. Montiel](http://webdiis.unizar.es/~josemari/) and [Juan D. Tardós](http://webdiis.unizar.es/~jdtardos/). ORB-SLAM: A Versatile and Accurate Monocular SLAM System.  IEEE Transactions on Robotics, vol. 31, no. 5, pp. 1147-1163, October 2015. [[pdf\\]](http://webdiis.unizar.es/~raulmur/MurMontielTardosTRO15.pdf)\n- [Raúl Mur-Artal](http://webdiis.unizar.es/~raulmur/) and [Juan D. Tardós](http://webdiis.unizar.es/~jdtardos/). Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM. Robotics: Science and Systems. Rome, Italy, July 2015. [[pdf\\]](http://webdiis.unizar.es/~raulmur/MurTardosRSS15.pdf) [[poster\\]](http://webdiis.unizar.es/~raulmur/MurTardosRSS15Poster.pdf)\n\n[5] LSD-SLAM: Large-Scale Direct Monocular SLAM (J. Engel, T. Schöps, D. Cremers), In European Conference on Computer Vision (ECCV), 2014. [[bib\\]](http://vision.in.tum.de/research/vslam/lsdslam?key=engel14eccv) [[pdf\\]](http://vision.in.tum.de/_media/spezial/bib/engel14eccv.pdf) [[video\\]](http://vision.in.tum.de/_media/spezial/bib/engel14eccv.mp4)\n\n[10] R. A. Newcombe, S. Lovegrove, and A. J. Davison. Dtam: Dense tracking and mapping in real-time. In IEEE International Conference on Computer Vision (ICCV), pages 2320–2327, 2011. 1, 2, 3\n\n[11]\n\n- **Dense Visual SLAM for RGB-D Cameras** (C. Kerl, J. Sturm, D. Cremers), In Proc. of the Int. Conf. on Intelligent Robot Systems (IROS), 2013.\n- **Robust Odometry Estimation for RGB-D Cameras** (C. Kerl, J. Sturm, D. Cremers), In Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), 2013\n- **Real-Time Visual Odometry from Dense RGB-D Images**  (F. Steinbruecker, J. Sturm, D. Cremers), In Workshop on Live Dense  Reconstruction with Moving Cameras at the Intl. Conf. on Computer Vision  (ICCV), 2011.\n\n[12] Fast Semi-Direct Monocular Visual Odometry (ICRA 2014)\n\n[13] \"3D Mapping with an RGB-D Camera\", F. Endres, J. Hess, J. Sturm, D. Cremers, W. Burgard, IEEE Transactions on Robotics, 2014.\n\n\\[14\\] \n\n- **ElasticFusion: Real-Time Dense SLAM and Light Source Estimation**, *T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison and S. Leutenegger*, IJRR '16\n- **ElasticFusion: Dense SLAM Without A Pose Graph**, *T. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker and A. J. Davison*, RSS '15\n\n[15] A Flexible and Scalable SLAM System with Full 3D Motion Estimation\n\n[16] Improved Techniques for Grid Mapping with Rao-Blackwellized Particle Filters \n\n[17] Stefan Leutenegger, Simon Lynen, Michael Bosse, Roland Siegwart and Paul Timothy Furgale. [Keyframe-based visual–inertial odometry using nonlinear optimization](http://www.roboticsproceedings.org/rss09/p37.pdf). The International Journal of Robotics Research, 2015.\n\n[20]\n\n- [Real-time Large Scale Dense RGB-D SLAM with Volumetric Fusion](http://thomaswhelan.ie/Whelan14ijrr.pdf), T. Whelan, M. Kaess, H. Johannsson, M.F. Fallon, J. J. Leonard and J.B. McDonald, IJRR '14 \n- [Kintinuous: Spatially Extended KinectFusion](http://thomaswhelan.ie/Whelan12rssw.pdf), T. Whelan, M. Kaess, M.F. Fallon, H. Johannsson, J. J. Leonard and J.B. McDonald, RSS RGB-D Workshop '12\n\n[23]\n\n- Reconstructing Street-Scenes in Real-Time From a Driving Car (V. Usenko, J. Engel, J. Stueckler, D. Cremers), In Proc. of the Int. Conference on 3D Vision (3DV), 2015.  [bib](https://vision.in.tum.de/research/vslam/lsdslam?key=usenko15_3drecon_stereolsdslam) [[pdf]](https://vision.in.tum.de/_media/spezial/bib/usenko15_3drecon_stereolsdslam.pdf)\n- Large-Scale Direct SLAM for Omnidirectional Cameras (D. Caruso, J. Engel, D. Cremers),In International Conference on Intelligent Robots and Systems (IROS), 2015. [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=caruso2015_omni_lsdslam) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.mp4)\n- Large-Scale Direct SLAM with Stereo Cameras (J. Engel, J. Stueckler, D. Cremers), In International Conference on Intelligent Robots and Systems (IROS), 2015.  [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=engel2015_stereo_lsdslam) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.mp4)\n- Semi-Dense Visual Odometry for AR on a Smartphone (T. Schöps, J. Engel, D. Cremers), In International Symposium on Mixed and Augmented Reality, 2014.  [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=schoeps14ismar) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.mp4)\n- Semi-Dense Visual Odometry for a Monocular Camera (J. Engel, J. Sturm, D. Cremers), In IEEE International Conference on Computer Vision (ICCV), 2013.  [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=engel2013iccv) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.avi)\n\n## 参考资料\n\n1. [当前的开源SLAM方案](https://www.cnblogs.com/Jessica-jie/p/7719359.html)\n2. [【干货】15种SLAM方案详解](http://www.vrtuoluo.cn/8821.html)\n3. [SLAM 综述](https://blog.csdn.net/darlingqiang/article/details/78901022)","source":"_posts/当前开源SLAM方案一览.md","raw":"---\ntitle: 当前开源SLAM方案一览\ndate: 2018-09-26 15:52:25\ntags:\n  - SLAM\nmathjax: true\ncategories:\n  - 机器人 \n  - SLAM\n  - 其他\ncopyright: true\n---\n---\n这篇文章记录下目前流行的开源SLAM系统的方案。\n<!--more--->\n最近课题进展不顺利，目标不明确、思路不清晰、没有创新点，迷茫、不知所措。还是暂时停一下，花时间查阅一些资料，充实一下自己。\n\n| 时间 |    开源方案    |     传感器形式     |    VO    | 稀疏\\稠密 | 论文 |                           地址链接                           |\n| :--: | :------------: | :----------------: | :------: | :-------: | :--: | :----------------------------------------------------------: |\n| 2007 |    MonoSLAM    |        单目        |          |           | [1]  |       [Github](https://github.com/hanmekim/SceneLib2)        |\n| 2007 |      PTAM      |        单目        |          |           | [2]  |     [Source Code]( http://www.robots.ox.ac.uk/~gk/PTAM/)     |\n| 2015 |    ORB-SLAM    |      单目为主      | 特征点法 |   稀疏    | [3]  | [链接](http://webdiis.unizar.es/~raulmur/orbslam/)   [Github](https://github.com/raulmur/ORB_SLAM) |\n| 2017 |   ORB-SLAM2    | 单目、双目、RGB-D  | 特征点法 |   稀疏    | [4]  |        [Github](https://github.com/raulmur/ORB_SLAM2)        |\n| 2014 |    LSD-SLAM    | 单目（为主）、双目 |  直接法  |  半稠密   | [5]  | [home]( http://vision.in.tum.de/research/vslam/lsdslam)   [Github](<https://github.com/tum-vision/lsd_slam> ) |\n| 2014 |      SVO       |        单目        | 半直接法 |           | [6]  |         [Github](https://github.com/uzh-rpg/rpg_svo)         |\n| 2014 |    RTAB-MAP    |     RGB-D/双目     |          |           | [7]  |        [Github](https://github.com/introlab/rtabmap )        |\n| 2015 |     OKVIS      |      多目+IMU      |          |           | [8]  |         [Github](https://github.com/ethz-asl/okvis )         |\n| 2015 |     ROVIO      |      单目+IMU      |          |           | [9]  |         [Github](https://github.com/ethz-asl/rovio)          |\n| 2011 |      DTAM      |       RGB-D        |  直接法  |   稠密    | [10] |       [Github](https://github.com/anuranbaka/OpenDTAM)       |\n| 2013 |      DVO       |       RGB-D        |          |           | [11] |       [Github](https://github.com/tum-vision/dvo_slam)       |\n| 2016 |      DSO       |        单目        |          |           | [12] |         [Github](https://github.com/JakobEngel/dso)          |\n| 2014 |   RGBD-SLAM2   |       RGB-D        |          |           | [13] |     [Github](https://github.com/felixendres/rgbdslam_v2)     |\n| 2015 | Elastic Fusion |       RGB-D        |          |   稠密    | [14] |      [Github](https://github.com/mp3guy/ElasticFusion)       |\n| 2011 |  Hector SLAM   |        激光        |          |           | [15] |           [wiki](http://wiki.ros.org/hector_slam)            |\n| 2007 |    GMapping    |        激光        |          |           | [16] |             [wiki](http://wiki.ros.org/gmapping)             |\n| 2015 |     OKVIS      |      多目+IMU      |          |           | [17] |         [Github](https://github.com/ethz-asl/ckvis)          |\n| 2015 |     ROVIO      |      单目+IMU      |          |           | [18] | [Github](https://github.com/ethz-asl/rovio)  [Paper](http://dx.doi.org/10.3929/ethz-a-010566547) |\n| 2011 | Kinetic Fusion |       RGB-D        |          |   稠密    | [19] |                                                              |\n|      |   Kintinuous   |                    |          |           | [20] |                                                              |\n|      | DynamicFusion  |                    |          |   稠密    | [21] |                                                              |\n|      |   InfiniTAM    |                    |          |   稠密    | [22] |                                                              |\n\n## 论文\n\n[2] Klein G, Murray D. Parallel tracking and mapping for small AR workspaces[C]//Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality. IEEE Computer Society, 2007: 1-10. [[pdf](http://www.robots.ox.ac.uk/~gk/publications/KleinMurray2007ISMAR.pdf)] [[slides](http://www.robots.ox.ac.uk/~gk/publications/Slides_KleinMurray2007ISMAR.pdf)]\n\n[3] \n\n- [Raúl Mur-Artal](http://webdiis.unizar.es/~raulmur/), [J. M. M. Montiel](http://webdiis.unizar.es/~josemari/) and [Juan D. Tardós](http://webdiis.unizar.es/~jdtardos/). ORB-SLAM: A Versatile and Accurate Monocular SLAM System.  IEEE Transactions on Robotics, vol. 31, no. 5, pp. 1147-1163, October 2015. [[pdf\\]](http://webdiis.unizar.es/~raulmur/MurMontielTardosTRO15.pdf)\n- [Raúl Mur-Artal](http://webdiis.unizar.es/~raulmur/) and [Juan D. Tardós](http://webdiis.unizar.es/~jdtardos/). Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM. Robotics: Science and Systems. Rome, Italy, July 2015. [[pdf\\]](http://webdiis.unizar.es/~raulmur/MurTardosRSS15.pdf) [[poster\\]](http://webdiis.unizar.es/~raulmur/MurTardosRSS15Poster.pdf)\n\n[5] LSD-SLAM: Large-Scale Direct Monocular SLAM (J. Engel, T. Schöps, D. Cremers), In European Conference on Computer Vision (ECCV), 2014. [[bib\\]](http://vision.in.tum.de/research/vslam/lsdslam?key=engel14eccv) [[pdf\\]](http://vision.in.tum.de/_media/spezial/bib/engel14eccv.pdf) [[video\\]](http://vision.in.tum.de/_media/spezial/bib/engel14eccv.mp4)\n\n[10] R. A. Newcombe, S. Lovegrove, and A. J. Davison. Dtam: Dense tracking and mapping in real-time. In IEEE International Conference on Computer Vision (ICCV), pages 2320–2327, 2011. 1, 2, 3\n\n[11]\n\n- **Dense Visual SLAM for RGB-D Cameras** (C. Kerl, J. Sturm, D. Cremers), In Proc. of the Int. Conf. on Intelligent Robot Systems (IROS), 2013.\n- **Robust Odometry Estimation for RGB-D Cameras** (C. Kerl, J. Sturm, D. Cremers), In Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), 2013\n- **Real-Time Visual Odometry from Dense RGB-D Images**  (F. Steinbruecker, J. Sturm, D. Cremers), In Workshop on Live Dense  Reconstruction with Moving Cameras at the Intl. Conf. on Computer Vision  (ICCV), 2011.\n\n[12] Fast Semi-Direct Monocular Visual Odometry (ICRA 2014)\n\n[13] \"3D Mapping with an RGB-D Camera\", F. Endres, J. Hess, J. Sturm, D. Cremers, W. Burgard, IEEE Transactions on Robotics, 2014.\n\n\\[14\\] \n\n- **ElasticFusion: Real-Time Dense SLAM and Light Source Estimation**, *T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison and S. Leutenegger*, IJRR '16\n- **ElasticFusion: Dense SLAM Without A Pose Graph**, *T. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker and A. J. Davison*, RSS '15\n\n[15] A Flexible and Scalable SLAM System with Full 3D Motion Estimation\n\n[16] Improved Techniques for Grid Mapping with Rao-Blackwellized Particle Filters \n\n[17] Stefan Leutenegger, Simon Lynen, Michael Bosse, Roland Siegwart and Paul Timothy Furgale. [Keyframe-based visual–inertial odometry using nonlinear optimization](http://www.roboticsproceedings.org/rss09/p37.pdf). The International Journal of Robotics Research, 2015.\n\n[20]\n\n- [Real-time Large Scale Dense RGB-D SLAM with Volumetric Fusion](http://thomaswhelan.ie/Whelan14ijrr.pdf), T. Whelan, M. Kaess, H. Johannsson, M.F. Fallon, J. J. Leonard and J.B. McDonald, IJRR '14 \n- [Kintinuous: Spatially Extended KinectFusion](http://thomaswhelan.ie/Whelan12rssw.pdf), T. Whelan, M. Kaess, M.F. Fallon, H. Johannsson, J. J. Leonard and J.B. McDonald, RSS RGB-D Workshop '12\n\n[23]\n\n- Reconstructing Street-Scenes in Real-Time From a Driving Car (V. Usenko, J. Engel, J. Stueckler, D. Cremers), In Proc. of the Int. Conference on 3D Vision (3DV), 2015.  [bib](https://vision.in.tum.de/research/vslam/lsdslam?key=usenko15_3drecon_stereolsdslam) [[pdf]](https://vision.in.tum.de/_media/spezial/bib/usenko15_3drecon_stereolsdslam.pdf)\n- Large-Scale Direct SLAM for Omnidirectional Cameras (D. Caruso, J. Engel, D. Cremers),In International Conference on Intelligent Robots and Systems (IROS), 2015. [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=caruso2015_omni_lsdslam) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.mp4)\n- Large-Scale Direct SLAM with Stereo Cameras (J. Engel, J. Stueckler, D. Cremers), In International Conference on Intelligent Robots and Systems (IROS), 2015.  [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=engel2015_stereo_lsdslam) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.mp4)\n- Semi-Dense Visual Odometry for AR on a Smartphone (T. Schöps, J. Engel, D. Cremers), In International Symposium on Mixed and Augmented Reality, 2014.  [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=schoeps14ismar) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.mp4)\n- Semi-Dense Visual Odometry for a Monocular Camera (J. Engel, J. Sturm, D. Cremers), In IEEE International Conference on Computer Vision (ICCV), 2013.  [[bib\\]](https://vision.in.tum.de/research/vslam/lsdslam?key=engel2013iccv) [[pdf\\]](https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.pdf) [[video\\]](https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.avi)\n\n## 参考资料\n\n1. [当前的开源SLAM方案](https://www.cnblogs.com/Jessica-jie/p/7719359.html)\n2. [【干货】15种SLAM方案详解](http://www.vrtuoluo.cn/8821.html)\n3. [SLAM 综述](https://blog.csdn.net/darlingqiang/article/details/78901022)","slug":"当前开源SLAM方案一览","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0800cgqlcrqt0dwvre","content":"<hr>\n<p>这篇文章记录下目前流行的开源SLAM系统的方案。<br><a id=\"more\"></a><br>最近课题进展不顺利，目标不明确、思路不清晰、没有创新点，迷茫、不知所措。还是暂时停一下，花时间查阅一些资料，充实一下自己。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">时间</th>\n<th style=\"text-align:center\">开源方案</th>\n<th style=\"text-align:center\">传感器形式</th>\n<th style=\"text-align:center\">VO</th>\n<th style=\"text-align:center\">稀疏\\稠密</th>\n<th style=\"text-align:center\">论文</th>\n<th style=\"text-align:center\">地址链接</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">2007</td>\n<td style=\"text-align:center\">MonoSLAM</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[1]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/hanmekim/SceneLib2\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2007</td>\n<td style=\"text-align:center\">PTAM</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[2]</td>\n<td style=\"text-align:center\"><a href=\"http://www.robots.ox.ac.uk/~gk/PTAM/\" target=\"_blank\" rel=\"noopener\">Source Code</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">ORB-SLAM</td>\n<td style=\"text-align:center\">单目为主</td>\n<td style=\"text-align:center\">特征点法</td>\n<td style=\"text-align:center\">稀疏</td>\n<td style=\"text-align:center\">[3]</td>\n<td style=\"text-align:center\"><a href=\"http://webdiis.unizar.es/~raulmur/orbslam/\" target=\"_blank\" rel=\"noopener\">链接</a>   <a href=\"https://github.com/raulmur/ORB_SLAM\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2017</td>\n<td style=\"text-align:center\">ORB-SLAM2</td>\n<td style=\"text-align:center\">单目、双目、RGB-D</td>\n<td style=\"text-align:center\">特征点法</td>\n<td style=\"text-align:center\">稀疏</td>\n<td style=\"text-align:center\">[4]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/raulmur/ORB_SLAM2\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">LSD-SLAM</td>\n<td style=\"text-align:center\">单目（为主）、双目</td>\n<td style=\"text-align:center\">直接法</td>\n<td style=\"text-align:center\">半稠密</td>\n<td style=\"text-align:center\">[5]</td>\n<td style=\"text-align:center\"><a href=\"http://vision.in.tum.de/research/vslam/lsdslam\" target=\"_blank\" rel=\"noopener\">home</a>   <a href=\"https://github.com/tum-vision/lsd_slam\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">SVO</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\">半直接法</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[6]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/uzh-rpg/rpg_svo\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">RTAB-MAP</td>\n<td style=\"text-align:center\">RGB-D/双目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[7]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/introlab/rtabmap\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">OKVIS</td>\n<td style=\"text-align:center\">多目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[8]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/okvis\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">ROVIO</td>\n<td style=\"text-align:center\">单目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[9]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/rovio\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2011</td>\n<td style=\"text-align:center\">DTAM</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\">直接法</td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[10]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/anuranbaka/OpenDTAM\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2013</td>\n<td style=\"text-align:center\">DVO</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[11]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/tum-vision/dvo_slam\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2016</td>\n<td style=\"text-align:center\">DSO</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[12]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/JakobEngel/dso\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">RGBD-SLAM2</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[13]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/felixendres/rgbdslam_v2\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">Elastic Fusion</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[14]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/mp3guy/ElasticFusion\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2011</td>\n<td style=\"text-align:center\">Hector SLAM</td>\n<td style=\"text-align:center\">激光</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[15]</td>\n<td style=\"text-align:center\"><a href=\"http://wiki.ros.org/hector_slam\" target=\"_blank\" rel=\"noopener\">wiki</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2007</td>\n<td style=\"text-align:center\">GMapping</td>\n<td style=\"text-align:center\">激光</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[16]</td>\n<td style=\"text-align:center\"><a href=\"http://wiki.ros.org/gmapping\" target=\"_blank\" rel=\"noopener\">wiki</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">OKVIS</td>\n<td style=\"text-align:center\">多目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[17]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/ckvis\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">ROVIO</td>\n<td style=\"text-align:center\">单目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[18]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/rovio\" target=\"_blank\" rel=\"noopener\">Github</a>  <a href=\"http://dx.doi.org/10.3929/ethz-a-010566547\" target=\"_blank\" rel=\"noopener\">Paper</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2011</td>\n<td style=\"text-align:center\">Kinetic Fusion</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[19]</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">Kintinuous</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[20]</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">DynamicFusion</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[21]</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">InfiniTAM</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[22]</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"论文\"><a href=\"#论文\" class=\"headerlink\" title=\"论文\"></a>论文</h2><p>[2] Klein G, Murray D. Parallel tracking and mapping for small AR workspaces[C]//Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality. IEEE Computer Society, 2007: 1-10. [<a href=\"http://www.robots.ox.ac.uk/~gk/publications/KleinMurray2007ISMAR.pdf\" target=\"_blank\" rel=\"noopener\">pdf</a>] [<a href=\"http://www.robots.ox.ac.uk/~gk/publications/Slides_KleinMurray2007ISMAR.pdf\" target=\"_blank\" rel=\"noopener\">slides</a>]</p>\n<p>[3] </p>\n<ul>\n<li><a href=\"http://webdiis.unizar.es/~raulmur/\" target=\"_blank\" rel=\"noopener\">Raúl Mur-Artal</a>, <a href=\"http://webdiis.unizar.es/~josemari/\" target=\"_blank\" rel=\"noopener\">J. M. M. Montiel</a> and <a href=\"http://webdiis.unizar.es/~jdtardos/\" target=\"_blank\" rel=\"noopener\">Juan D. Tardós</a>. ORB-SLAM: A Versatile and Accurate Monocular SLAM System.  IEEE Transactions on Robotics, vol. 31, no. 5, pp. 1147-1163, October 2015. <a href=\"http://webdiis.unizar.es/~raulmur/MurMontielTardosTRO15.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a></li>\n<li><a href=\"http://webdiis.unizar.es/~raulmur/\" target=\"_blank\" rel=\"noopener\">Raúl Mur-Artal</a> and <a href=\"http://webdiis.unizar.es/~jdtardos/\" target=\"_blank\" rel=\"noopener\">Juan D. Tardós</a>. Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM. Robotics: Science and Systems. Rome, Italy, July 2015. <a href=\"http://webdiis.unizar.es/~raulmur/MurTardosRSS15.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"http://webdiis.unizar.es/~raulmur/MurTardosRSS15Poster.pdf\" target=\"_blank\" rel=\"noopener\">[poster]</a></li>\n</ul>\n<p>[5] LSD-SLAM: Large-Scale Direct Monocular SLAM (J. Engel, T. Schöps, D. Cremers), In European Conference on Computer Vision (ECCV), 2014. <a href=\"http://vision.in.tum.de/research/vslam/lsdslam?key=engel14eccv\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"http://vision.in.tum.de/_media/spezial/bib/engel14eccv.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"http://vision.in.tum.de/_media/spezial/bib/engel14eccv.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></p>\n<p>[10] R. A. Newcombe, S. Lovegrove, and A. J. Davison. Dtam: Dense tracking and mapping in real-time. In IEEE International Conference on Computer Vision (ICCV), pages 2320–2327, 2011. 1, 2, 3</p>\n<p>[11]</p>\n<ul>\n<li><strong>Dense Visual SLAM for RGB-D Cameras</strong> (C. Kerl, J. Sturm, D. Cremers), In Proc. of the Int. Conf. on Intelligent Robot Systems (IROS), 2013.</li>\n<li><strong>Robust Odometry Estimation for RGB-D Cameras</strong> (C. Kerl, J. Sturm, D. Cremers), In Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), 2013</li>\n<li><strong>Real-Time Visual Odometry from Dense RGB-D Images</strong>  (F. Steinbruecker, J. Sturm, D. Cremers), In Workshop on Live Dense  Reconstruction with Moving Cameras at the Intl. Conf. on Computer Vision  (ICCV), 2011.</li>\n</ul>\n<p>[12] Fast Semi-Direct Monocular Visual Odometry (ICRA 2014)</p>\n<p>[13] “3D Mapping with an RGB-D Camera”, F. Endres, J. Hess, J. Sturm, D. Cremers, W. Burgard, IEEE Transactions on Robotics, 2014.</p>\n<p>[14] </p>\n<ul>\n<li><strong>ElasticFusion: Real-Time Dense SLAM and Light Source Estimation</strong>, <em>T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison and S. Leutenegger</em>, IJRR ‘16</li>\n<li><strong>ElasticFusion: Dense SLAM Without A Pose Graph</strong>, <em>T. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker and A. J. Davison</em>, RSS ‘15</li>\n</ul>\n<p>[15] A Flexible and Scalable SLAM System with Full 3D Motion Estimation</p>\n<p>[16] Improved Techniques for Grid Mapping with Rao-Blackwellized Particle Filters </p>\n<p>[17] Stefan Leutenegger, Simon Lynen, Michael Bosse, Roland Siegwart and Paul Timothy Furgale. <a href=\"http://www.roboticsproceedings.org/rss09/p37.pdf\" target=\"_blank\" rel=\"noopener\">Keyframe-based visual–inertial odometry using nonlinear optimization</a>. The International Journal of Robotics Research, 2015.</p>\n<p>[20]</p>\n<ul>\n<li><a href=\"http://thomaswhelan.ie/Whelan14ijrr.pdf\" target=\"_blank\" rel=\"noopener\">Real-time Large Scale Dense RGB-D SLAM with Volumetric Fusion</a>, T. Whelan, M. Kaess, H. Johannsson, M.F. Fallon, J. J. Leonard and J.B. McDonald, IJRR ‘14 </li>\n<li><a href=\"http://thomaswhelan.ie/Whelan12rssw.pdf\" target=\"_blank\" rel=\"noopener\">Kintinuous: Spatially Extended KinectFusion</a>, T. Whelan, M. Kaess, M.F. Fallon, H. Johannsson, J. J. Leonard and J.B. McDonald, RSS RGB-D Workshop ‘12</li>\n</ul>\n<p>[23]</p>\n<ul>\n<li>Reconstructing Street-Scenes in Real-Time From a Driving Car (V. Usenko, J. Engel, J. Stueckler, D. Cremers), In Proc. of the Int. Conference on 3D Vision (3DV), 2015.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=usenko15_3drecon_stereolsdslam\" target=\"_blank\" rel=\"noopener\">bib</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/usenko15_3drecon_stereolsdslam.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a></li>\n<li>Large-Scale Direct SLAM for Omnidirectional Cameras (D. Caruso, J. Engel, D. Cremers),In International Conference on Intelligent Robots and Systems (IROS), 2015. <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=caruso2015_omni_lsdslam\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n<li>Large-Scale Direct SLAM with Stereo Cameras (J. Engel, J. Stueckler, D. Cremers), In International Conference on Intelligent Robots and Systems (IROS), 2015.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=engel2015_stereo_lsdslam\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n<li>Semi-Dense Visual Odometry for AR on a Smartphone (T. Schöps, J. Engel, D. Cremers), In International Symposium on Mixed and Augmented Reality, 2014.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=schoeps14ismar\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n<li>Semi-Dense Visual Odometry for a Monocular Camera (J. Engel, J. Sturm, D. Cremers), In IEEE International Conference on Computer Vision (ICCV), 2013.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=engel2013iccv\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.avi\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/Jessica-jie/p/7719359.html\" target=\"_blank\" rel=\"noopener\">当前的开源SLAM方案</a></li>\n<li><a href=\"http://www.vrtuoluo.cn/8821.html\" target=\"_blank\" rel=\"noopener\">【干货】15种SLAM方案详解</a></li>\n<li><a href=\"https://blog.csdn.net/darlingqiang/article/details/78901022\" target=\"_blank\" rel=\"noopener\">SLAM 综述</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章记录下目前流行的开源SLAM系统的方案。<br>","more":"<br>最近课题进展不顺利，目标不明确、思路不清晰、没有创新点，迷茫、不知所措。还是暂时停一下，花时间查阅一些资料，充实一下自己。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">时间</th>\n<th style=\"text-align:center\">开源方案</th>\n<th style=\"text-align:center\">传感器形式</th>\n<th style=\"text-align:center\">VO</th>\n<th style=\"text-align:center\">稀疏\\稠密</th>\n<th style=\"text-align:center\">论文</th>\n<th style=\"text-align:center\">地址链接</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">2007</td>\n<td style=\"text-align:center\">MonoSLAM</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[1]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/hanmekim/SceneLib2\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2007</td>\n<td style=\"text-align:center\">PTAM</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[2]</td>\n<td style=\"text-align:center\"><a href=\"http://www.robots.ox.ac.uk/~gk/PTAM/\" target=\"_blank\" rel=\"noopener\">Source Code</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">ORB-SLAM</td>\n<td style=\"text-align:center\">单目为主</td>\n<td style=\"text-align:center\">特征点法</td>\n<td style=\"text-align:center\">稀疏</td>\n<td style=\"text-align:center\">[3]</td>\n<td style=\"text-align:center\"><a href=\"http://webdiis.unizar.es/~raulmur/orbslam/\" target=\"_blank\" rel=\"noopener\">链接</a>   <a href=\"https://github.com/raulmur/ORB_SLAM\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2017</td>\n<td style=\"text-align:center\">ORB-SLAM2</td>\n<td style=\"text-align:center\">单目、双目、RGB-D</td>\n<td style=\"text-align:center\">特征点法</td>\n<td style=\"text-align:center\">稀疏</td>\n<td style=\"text-align:center\">[4]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/raulmur/ORB_SLAM2\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">LSD-SLAM</td>\n<td style=\"text-align:center\">单目（为主）、双目</td>\n<td style=\"text-align:center\">直接法</td>\n<td style=\"text-align:center\">半稠密</td>\n<td style=\"text-align:center\">[5]</td>\n<td style=\"text-align:center\"><a href=\"http://vision.in.tum.de/research/vslam/lsdslam\" target=\"_blank\" rel=\"noopener\">home</a>   <a href=\"https://github.com/tum-vision/lsd_slam\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">SVO</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\">半直接法</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[6]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/uzh-rpg/rpg_svo\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">RTAB-MAP</td>\n<td style=\"text-align:center\">RGB-D/双目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[7]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/introlab/rtabmap\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">OKVIS</td>\n<td style=\"text-align:center\">多目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[8]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/okvis\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">ROVIO</td>\n<td style=\"text-align:center\">单目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[9]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/rovio\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2011</td>\n<td style=\"text-align:center\">DTAM</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\">直接法</td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[10]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/anuranbaka/OpenDTAM\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2013</td>\n<td style=\"text-align:center\">DVO</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[11]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/tum-vision/dvo_slam\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2016</td>\n<td style=\"text-align:center\">DSO</td>\n<td style=\"text-align:center\">单目</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[12]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/JakobEngel/dso\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2014</td>\n<td style=\"text-align:center\">RGBD-SLAM2</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[13]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/felixendres/rgbdslam_v2\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">Elastic Fusion</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[14]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/mp3guy/ElasticFusion\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2011</td>\n<td style=\"text-align:center\">Hector SLAM</td>\n<td style=\"text-align:center\">激光</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[15]</td>\n<td style=\"text-align:center\"><a href=\"http://wiki.ros.org/hector_slam\" target=\"_blank\" rel=\"noopener\">wiki</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2007</td>\n<td style=\"text-align:center\">GMapping</td>\n<td style=\"text-align:center\">激光</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[16]</td>\n<td style=\"text-align:center\"><a href=\"http://wiki.ros.org/gmapping\" target=\"_blank\" rel=\"noopener\">wiki</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">OKVIS</td>\n<td style=\"text-align:center\">多目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[17]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/ckvis\" target=\"_blank\" rel=\"noopener\">Github</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2015</td>\n<td style=\"text-align:center\">ROVIO</td>\n<td style=\"text-align:center\">单目+IMU</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[18]</td>\n<td style=\"text-align:center\"><a href=\"https://github.com/ethz-asl/rovio\" target=\"_blank\" rel=\"noopener\">Github</a>  <a href=\"http://dx.doi.org/10.3929/ethz-a-010566547\" target=\"_blank\" rel=\"noopener\">Paper</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2011</td>\n<td style=\"text-align:center\">Kinetic Fusion</td>\n<td style=\"text-align:center\">RGB-D</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[19]</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">Kintinuous</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">[20]</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">DynamicFusion</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[21]</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">InfiniTAM</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">稠密</td>\n<td style=\"text-align:center\">[22]</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"论文\"><a href=\"#论文\" class=\"headerlink\" title=\"论文\"></a>论文</h2><p>[2] Klein G, Murray D. Parallel tracking and mapping for small AR workspaces[C]//Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality. IEEE Computer Society, 2007: 1-10. [<a href=\"http://www.robots.ox.ac.uk/~gk/publications/KleinMurray2007ISMAR.pdf\" target=\"_blank\" rel=\"noopener\">pdf</a>] [<a href=\"http://www.robots.ox.ac.uk/~gk/publications/Slides_KleinMurray2007ISMAR.pdf\" target=\"_blank\" rel=\"noopener\">slides</a>]</p>\n<p>[3] </p>\n<ul>\n<li><a href=\"http://webdiis.unizar.es/~raulmur/\" target=\"_blank\" rel=\"noopener\">Raúl Mur-Artal</a>, <a href=\"http://webdiis.unizar.es/~josemari/\" target=\"_blank\" rel=\"noopener\">J. M. M. Montiel</a> and <a href=\"http://webdiis.unizar.es/~jdtardos/\" target=\"_blank\" rel=\"noopener\">Juan D. Tardós</a>. ORB-SLAM: A Versatile and Accurate Monocular SLAM System.  IEEE Transactions on Robotics, vol. 31, no. 5, pp. 1147-1163, October 2015. <a href=\"http://webdiis.unizar.es/~raulmur/MurMontielTardosTRO15.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a></li>\n<li><a href=\"http://webdiis.unizar.es/~raulmur/\" target=\"_blank\" rel=\"noopener\">Raúl Mur-Artal</a> and <a href=\"http://webdiis.unizar.es/~jdtardos/\" target=\"_blank\" rel=\"noopener\">Juan D. Tardós</a>. Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM. Robotics: Science and Systems. Rome, Italy, July 2015. <a href=\"http://webdiis.unizar.es/~raulmur/MurTardosRSS15.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"http://webdiis.unizar.es/~raulmur/MurTardosRSS15Poster.pdf\" target=\"_blank\" rel=\"noopener\">[poster]</a></li>\n</ul>\n<p>[5] LSD-SLAM: Large-Scale Direct Monocular SLAM (J. Engel, T. Schöps, D. Cremers), In European Conference on Computer Vision (ECCV), 2014. <a href=\"http://vision.in.tum.de/research/vslam/lsdslam?key=engel14eccv\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"http://vision.in.tum.de/_media/spezial/bib/engel14eccv.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"http://vision.in.tum.de/_media/spezial/bib/engel14eccv.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></p>\n<p>[10] R. A. Newcombe, S. Lovegrove, and A. J. Davison. Dtam: Dense tracking and mapping in real-time. In IEEE International Conference on Computer Vision (ICCV), pages 2320–2327, 2011. 1, 2, 3</p>\n<p>[11]</p>\n<ul>\n<li><strong>Dense Visual SLAM for RGB-D Cameras</strong> (C. Kerl, J. Sturm, D. Cremers), In Proc. of the Int. Conf. on Intelligent Robot Systems (IROS), 2013.</li>\n<li><strong>Robust Odometry Estimation for RGB-D Cameras</strong> (C. Kerl, J. Sturm, D. Cremers), In Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), 2013</li>\n<li><strong>Real-Time Visual Odometry from Dense RGB-D Images</strong>  (F. Steinbruecker, J. Sturm, D. Cremers), In Workshop on Live Dense  Reconstruction with Moving Cameras at the Intl. Conf. on Computer Vision  (ICCV), 2011.</li>\n</ul>\n<p>[12] Fast Semi-Direct Monocular Visual Odometry (ICRA 2014)</p>\n<p>[13] “3D Mapping with an RGB-D Camera”, F. Endres, J. Hess, J. Sturm, D. Cremers, W. Burgard, IEEE Transactions on Robotics, 2014.</p>\n<p>[14] </p>\n<ul>\n<li><strong>ElasticFusion: Real-Time Dense SLAM and Light Source Estimation</strong>, <em>T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison and S. Leutenegger</em>, IJRR ‘16</li>\n<li><strong>ElasticFusion: Dense SLAM Without A Pose Graph</strong>, <em>T. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker and A. J. Davison</em>, RSS ‘15</li>\n</ul>\n<p>[15] A Flexible and Scalable SLAM System with Full 3D Motion Estimation</p>\n<p>[16] Improved Techniques for Grid Mapping with Rao-Blackwellized Particle Filters </p>\n<p>[17] Stefan Leutenegger, Simon Lynen, Michael Bosse, Roland Siegwart and Paul Timothy Furgale. <a href=\"http://www.roboticsproceedings.org/rss09/p37.pdf\" target=\"_blank\" rel=\"noopener\">Keyframe-based visual–inertial odometry using nonlinear optimization</a>. The International Journal of Robotics Research, 2015.</p>\n<p>[20]</p>\n<ul>\n<li><a href=\"http://thomaswhelan.ie/Whelan14ijrr.pdf\" target=\"_blank\" rel=\"noopener\">Real-time Large Scale Dense RGB-D SLAM with Volumetric Fusion</a>, T. Whelan, M. Kaess, H. Johannsson, M.F. Fallon, J. J. Leonard and J.B. McDonald, IJRR ‘14 </li>\n<li><a href=\"http://thomaswhelan.ie/Whelan12rssw.pdf\" target=\"_blank\" rel=\"noopener\">Kintinuous: Spatially Extended KinectFusion</a>, T. Whelan, M. Kaess, M.F. Fallon, H. Johannsson, J. J. Leonard and J.B. McDonald, RSS RGB-D Workshop ‘12</li>\n</ul>\n<p>[23]</p>\n<ul>\n<li>Reconstructing Street-Scenes in Real-Time From a Driving Car (V. Usenko, J. Engel, J. Stueckler, D. Cremers), In Proc. of the Int. Conference on 3D Vision (3DV), 2015.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=usenko15_3drecon_stereolsdslam\" target=\"_blank\" rel=\"noopener\">bib</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/usenko15_3drecon_stereolsdslam.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a></li>\n<li>Large-Scale Direct SLAM for Omnidirectional Cameras (D. Caruso, J. Engel, D. Cremers),In International Conference on Intelligent Robots and Systems (IROS), 2015. <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=caruso2015_omni_lsdslam\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n<li>Large-Scale Direct SLAM with Stereo Cameras (J. Engel, J. Stueckler, D. Cremers), In International Conference on Intelligent Robots and Systems (IROS), 2015.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=engel2015_stereo_lsdslam\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2015_stereo_lsdslam.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n<li>Semi-Dense Visual Odometry for AR on a Smartphone (T. Schöps, J. Engel, D. Cremers), In International Symposium on Mixed and Augmented Reality, 2014.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=schoeps14ismar\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.mp4\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n<li>Semi-Dense Visual Odometry for a Monocular Camera (J. Engel, J. Sturm, D. Cremers), In IEEE International Conference on Computer Vision (ICCV), 2013.  <a href=\"https://vision.in.tum.de/research/vslam/lsdslam?key=engel2013iccv\" target=\"_blank\" rel=\"noopener\">[bib]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.pdf\" target=\"_blank\" rel=\"noopener\">[pdf]</a> <a href=\"https://vision.in.tum.de/_media/spezial/bib/engel2013iccv.avi\" target=\"_blank\" rel=\"noopener\">[video]</a></li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"https://www.cnblogs.com/Jessica-jie/p/7719359.html\" target=\"_blank\" rel=\"noopener\">当前的开源SLAM方案</a></li>\n<li><a href=\"http://www.vrtuoluo.cn/8821.html\" target=\"_blank\" rel=\"noopener\">【干货】15种SLAM方案详解</a></li>\n<li><a href=\"https://blog.csdn.net/darlingqiang/article/details/78901022\" target=\"_blank\" rel=\"noopener\">SLAM 综述</a></li>\n</ol>"},{"title":"视觉SLAM十四讲阅读笔记一-三维空间刚体运动","date":"2018-08-04T07:52:25.000Z","mathjax":true,"copyright":true,"_content":"\n-----\n\n这篇文章是视觉SLAM十四讲第3讲阅读过程中总结和记录的学习内容。\n\n<!---more-->\n\n三维空间中的刚体（相机、机器人）不光有位置，还有姿态，即**位姿**，位置表示相机在空间中哪个地方，姿态表示相机的指向。SLAM中一个很基本的问题就是计算机器人在三维空间中的位姿。而机器人在三维空间中位姿的计算往往与三维空间中的刚体运动有关。本篇是学习《视觉SLAM十四讲》第3讲三维空间刚体运动有关记录，参考了童博士的笔记内容。介绍在三维空间中刚体运动的位姿表示方法。\n\n## 位姿=位置+姿态\n\nSLAM中的位姿有6个自由度，即**位置和姿态**，其变换过程包含了**旋转（Rotation）**和**平移（Translation）**。直观地理解就是，对于在平面中运动的机器人，其位姿的变换由两个位置和一个转角来描述，转角描述旋转过程，两个位置描述平移过程。机器人任意两个时间间隔位置和转角的变化都可以通过运动传感器检测得到。这里涉及到SLAM中一个很重要的问题，即位姿的**表达**、**优化**。\n\n### 位置表示\n\n> 准确地说应该是机器人运动过程中位置变化的表示。\n\n在一个三维空间中，建立三维坐标系之后，就可以用一个三维坐标来表示机器人的位置。\n对于机器人的位置变换，可以用一个三维的平移向量来表示，比如机器人从初始位置为$(x_0,y_0,z_0)$经过一个平移向量$t=(a,b,c)$，可以得到平移后的位置$(x_0+a,y_0+b,z_0+c)$。相对来说，机器人的位置表达比较简单，只需要一个平移向量即可。\n\n### 姿态表示\n\n> 准确地说应该是机器人运动过程中姿态变化的表示。\n\n在一个三维空间中，通常用一个三维向量来表示机器人的姿态。更直观的讲，机器人的姿态可以想象成机器人自带一个坐标系，这个坐标系的原点就是机器人，z轴表示机器人面向的方向，这样的一个坐标系可以通过表示机器人姿态的三维向量来构造。\n\n机器人的姿态表达相对复杂，表达方法通常有旋转矩阵、旋转向量、欧拉角、四元数。\n\n## 旋转矩阵$SO(3)$\n\n在SLAM问题中，旋转矩阵是表示姿态变换最常用的方式。\n假设空间中的某一点$P$，机器人旋转前的坐标系的单位正交基为$(e1,e2,e3)$，$P$的坐标为$(x_1,y_1,z_1)$。。机器人旋转后的坐标系的单位正交基为$(e′_1,e′_2,e′_3)$，$P$的坐标为$(x′_1,y′_1,z′_1)$。\n\n根据坐标的定义有：\n\n$\\left[ \\begin{matrix}e_1&e_2&e_3\\end{matrix} \\right] \\left[ \\begin{matrix}a_1\\\\a_2\\\\a_3\\\\\\end{matrix} \\right]=[e′_1 e′_2 e′_3]\\left [\\begin{matrix}a′_1\\\\a′_2\\\\a′_3\\\\\\end{matrix} \\right]$\n\n在等式的左右同时左乘$\\left[ \\begin{matrix}a^T_1\\\\a^T_2\\\\a^T_3\\\\\\end{matrix} \\right]​$，可得\n\n$\\left[ \\begin{matrix}a1\\\\a2\\\\a3\\\\\\end{matrix} \\right]=\\left[ \\begin{matrix}e^T_1e′_1 & e^T_1e′_2 &e^T_1e′_3\\\\ e^T_2e′_1 &  e^T_2e′_2 & e^T_2e′_3 \\\\e^T_3e′_1&e^T_3e′_2&e^T_3e′_3  \\end{matrix} \\right]\\left [\\begin{matrix}a′_1\\\\a′_2\\\\a′_3\\\\\\end{matrix} \\right]=Ra′​$\n\n矩阵$R$即为旋转矩阵。旋转矩阵是一个行列式为1的正交矩阵。同样所有行列式为1的正交矩阵都是旋转矩阵，因此可以把旋转矩阵做如下定义：\n\n$SO(n)=\\{Rϵℝ^{n×n}∣RR^T=I,det(R)=1\\}$\n\n$SO(n)$称为特殊正交群，这个集合由$n$维空间的旋转矩阵组成，特别的，$SO(3)$就是三维空间下的旋转矩阵。\n\n值得注意的是，旋转矩阵本质上是表示两个坐标系之间的旋转，而坐标系恰恰能够表示机器人姿态，因此**旋转矩阵可以描述机器人(相机)的旋转，即姿态变换。**\n\n### 变换矩阵$SE(3)$\n\n在旋转矩阵的基础之上，加上平移向量，就可以完整的刻画三维空间中的刚体运动，即：$a′=Ra+t$。该式用一个旋转矩阵$R$和一个平移向量$t$完整地描述了一个欧式空间的坐标变换关系。\n\n但是这种形式下会存在一个问题，假设我们进行了两次变换$R_1$，$t_1$和$R_2$，$t_2$。相应的三维空间中经历了从a点到b点到c点的变换。则满足公式：\n\n$b=R_{1}a+t_1,c=R_{2}b+t_2$\n\n从a到c的变换为：\n$c=R_2(R_{1}a+t_1)+t_2$\n\n这样的形式在变换多次之后会过于复杂。聪明的数学家引入了齐次坐标和变换矩阵的概念，使得三维空间中的刚体运动有如下的变换形式：\n\n$\\left[ \\begin{matrix}a′\\\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}R&t\\\\0^T&1\\end{matrix} \\right]\\left [\\begin{matrix}a\\\\1\\\\\\end{matrix} \\right]=T\\left [\\begin{matrix}a\\\\1\\\\\\end{matrix} \\right]$\n\n矩阵$T$即称为**变换矩阵**。\n\n此时从a到c的变换可表示为：\n$c=T_2T_1a$\n\n此处的a和c为相应齐次坐标。\n\n变换矩阵的左上角为旋转矩阵，右侧为平移向量，左下角为0向量，右下角为1。这种矩阵称为**特殊欧式群(Special Euclidean Group)**：\n\n$SE(3)=\\{T=\\left[ \\begin{matrix}R&t\\\\0^T&1\\end{matrix} \\right]ϵℝ^{4×4}∣RϵSO(3),tϵℝ^3\\}$\n\n> ### 齐次坐标\n>\n> 透视变换是非线性变换，可以通过引入齐次坐标以线性表示透视变换。齐次坐标是在普通坐标上增加一维（值为1）后的坐标表示。在是三维向量的末尾添加1，将其变成了四维向量，多了一个自由度，允许把变换写成线性的形式。对于四维向量，就可以把平移和旋转写在一个矩阵里面，使得整个关系变成线性关系。\n>\n> 1. 将普通坐标转换为齐次坐标：增加一维坐标，值为1。 \n>\n>    $$\n>    (x,y) \\Rightarrow \\left[ \\begin{matrix}\n>    a \\\\\n>    b  \\\\\n>    1 \\\\\n>    \\end{matrix} \\right] (像点齐次坐标)\n>    $$\n>    $$\n>    (x,y,z) \\Rightarrow \\left[ \\begin{matrix}\n>    x \\\\\n>    y  \\\\\n>    z \\\\\n>    1\\\\\n>    \\end{matrix} \\right] (物点齐次坐标)\n>    $$\n>\n> 2. 齐次坐标转换为普通坐标：除以最后一维坐标。\n>\n>    $$\n>    \\left[ \\begin{matrix}\n>    x  \\\\\n>    y  \\\\\n>    z \\\\\n>    w \\\\\n>    \\end{matrix} \\right] \\Rightarrow \n>    \\left[ \\begin{matrix}\n>    x/w, & y/w, & z/w\\\\\n>    \\end{matrix} \\right]\n>    $$\n>\n> 3. 齐次坐标是缩放不变的（Invariant to scaling）\n>    $$\n>    k\\left[ \\begin{matrix}\n>    x \\\\\n>    y  \\\\\n>    w \\\\\n>    \\end{matrix} \\right] = \n>    \\left[ \\begin{matrix}\n>    \n>    kx \\\\\n>    ky  \\\\\n>    kw \\\\\n>    \n>    \\end{matrix} \\right] \\Rightarrow\n>    \\left[ \\begin{matrix}\n>    \n>    \\frac{kx}{kw}  \\\\\n>    \\frac{ky}{kw}  \\\\\n>    \n>    \\end{matrix} \\right] =\n>    \\left[ \\begin{matrix}\n>    \n>    \\frac {x}{w}\\ \\\\\n>    \\frac{y}{w}  \\\\\n>    \n>    \\end{matrix} \\right]\n>    $$\n>\n>\n>\n\n## 旋转向量\n\n用旋转矩阵来表示旋转有两个缺点：\n\n1. $SO(3)$的旋转矩阵有九个量，但一次旋转只有三个自由度。因此这种表达方式是冗余的。\n2. 旋转矩阵自身两个约束，即必须是正交矩阵和行列式为1，这些约束会使得求解变得更困难。\n\n从直观上讲，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是可以使用一个向量，其方向与旋转轴一致，而长度等于旋转角。这种向量称为**旋转向量**（或轴角，Axis-Angle），这样只需要一个三维向量就可以描述旋转。**旋转向量跟之后要介绍的李代数是相对应的**。旋转向量到旋转矩阵的变换可由**罗德里格斯公式**求得。\n假设旋转轴为$n$，角度为$θ$，则旋转向量为$θn$对应的旋转矩阵$R$为：\n\n$R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$\n\n反之，对于转角$\\theta$有：\n\n$tr(R)=cos\\theta tr(I)+(1-cos\\theta)tr(nn^T)+sin\\theta tr(n^\\wedge)\\\\=3cos\\theta+(1-cos\\theta)\\\\=1+2cos\\theta$\n\n因此：\n\n$θ=arccos(\\frac{tr(R)−1}2)$\n\n由于旋转轴上的向量在旋转后不发生改变，说明：$Rn=n$\n\n因此转轴$n$是矩阵$R$特征值1对应的特征向量。求解此方程，再归一化，就得到了旋转轴。\n\n## 欧拉角\n\n欧拉角是一种最为直观的姿态变换描述方式。在欧拉角的表示方式中，将旋转分解成沿三个坐标轴旋转的量：滚转角－俯仰角－偏航角(roll-pitch-yaw)，此时可以使用$[r,p,y]^T$这样一个三维向量描述任意旋转。\n\n欧拉角的一个重大缺点就是万向锁问题：在俯仰角为±90度时，第一次旋转与第三次旋转将使用同一个轴，这被称为奇异性问题。由于欧拉角不适于插值和迭代，所以在SLAM问题中通常不使用欧拉角来表示旋转，所以不再展开记录。\n\n## 四元数\n\n旋转矩阵具有冗余性，欧拉角和旋转向量不冗余但是具有奇异性。其实，我们找不到不带奇异性的三维向量描述方式。\n四元数只有四个自由度，即是紧凑的而且没有奇异性。它是一种扩展的复数的表达方式。缺点是不够直观，运算稍复杂。\n\n四元数q拥有一个实部和三个虚部。如下：\n\n$q=q_0+q_1i+q_2j+q_3k$\n\n其中：\n\n$\\left\\{ \\begin{array}{ll} i^2=j^2=k^2=−1\\\\ ij=k,ji=−k \\\\jk=i,kj=−i,ki=j,ik=−j\\end{array} \\right.​$\n\n> 我们可以用单位四元数表示三维空间中的任意一个旋转。\n\n假设某个旋转绕单位向量$n=[n_x,n_y,n_z]^T$进行了角度$θ$的旋转，那么对应的四元数为：\n\n$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$\n\n反之也可以从单位四元数中计算出对应旋转轴和夹角：\n\n$\\left\\{ \\begin{array}{ll} θ=2arccosq_0\\\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$\n\n对$θ$加上$2π$可以得到一个相同的旋转，但此时对应的四元数变成了$−q$。因此任意的旋转都可以由两个互为相反数的四元数表示，即两个互为相反数的四元数可以表示同一个旋转。\n\n### 四元数的运算\n\n见《视觉SLAM十四讲》P55，不再做记录。\n\n### 四元数表示旋转\n\n假设空间中有一点$p=[x,y,z]$，，其绕旋转轴$n$，进行了角度为$θ$的旋转得到了点$p′$，使用旋转矩阵表述有：\n\n$p′=Rp$。\n\n使用四元数描述旋转该如何表达？首先，把三维空间点用一个虚四元数表示：\n\n$p=[0,x,y,z]=[0,v]$\n\n相当于把四元数的3个虚部与空间中的3个轴相对应。然后，由前述公式可知，用四元数$q$表示该旋转：\n\n$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$\n\n则可以验证：\n$p′=qpq^{−1}$\n\n最终结果实部为0,故为纯虚四元数，其虚部的3个分量表示旋转后的3D点的坐标。\n\n### 四元数到旋转矩阵的转换\n\n设四元数$q=q_0+q_1i+q_2j+q_3k$，对应的旋转矩阵$R$为：\n\n$R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&2q_1q_2-2q_0q_3&2q_1q_3+2q_0q_2\\\\2q_1q_2+2q_0q_3&1-2q^2_1-2q^2_3&2q_2q_3-2q_0q_1\\\\2q_1q_3-2q_0q_2&2q_2q_3+2q_0q_1&1-2q^2_1-2q^2_2\\end{array} \\right]$\n\n反之，假设旋转矩阵为$R={m_{ij}},i,j\\epsilon[1,2,3]$，其对应的四元数$q$为：\n\n$q_0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m_{23}-m_{32}}{4q_0},q_2=\\frac{m_{31}-m_{13}}{4q_0},q_3=\\frac{m_{12}-m_{21}}{4q_0}​$\n\n注意：实际编程中，当$q_0$的值接近0时，其它3个分量会非常大，导致解不稳定，此时可以再考虑使用其他方式进行转换。\n\n## 旋转的四种表示方法比较\n\n|    表示方法    | 形式|是否奇异性 | 分量数目 | 紧凑or冗余程度 | 直观性 |\n| :------------: | :--------: | :------: | :------------: | :--: | :------------: |\n|    旋转矩阵    |     $R$     |    否    |      9      | 冗余 | 不直观 |\n| 旋转向量 |     $\\theta{n}$     |    是    |    3    | 较紧凑 | 不直观 |\n|     欧拉角     |     $[r,p,y]^T$     |    是    |    3    | 较紧凑 | 直观 |\n|     四元数     |     $q=q_0+q_1i+q_2j+q_3k$     |    否    |    4    | 较紧凑 | 较不直观 |\n\n## 旋转的四种表示方法间互相转换\n\n1.矩阵转换成其他方式\n\n|              |         旋转矩阵 **$R={m_{ij}},i,j\\epsilon[1,2,3]$**         |\n| :----------: | :----------------------------------------------------------: |\n| **旋转向量** | $θ=arccos(\\frac{tr(R)−1}2)$；求解方程$Rn=n$，归一化处理得到旋转轴n |\n|  **欧拉**角  |                              -                               |\n|  **四元数**  | $q_0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m_{23}-m_{32}}{4q_0},q_2=\\frac{m_{31}-m_{13}}{4q_0},q_3=\\frac{m_{12}-m_{21}}{4q_0}$ |\n\n2.向量转换成其他方式\n\n|              |                     旋转向量  **$θn$**                     |\n| :----------: | :--------------------------------------------------------: |\n| **旋转矩阵** |           $R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$            |\n|  **欧拉角**  |                             -                              |\n|  **四元数**  | $q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$ |\n\n3.数转换成其他方式\n\n|              |              四元数 **$q=q_0+q_1i+q_2j+q_3k$**               |\n| :----------: | :----------------------------------------------------------: |\n| **旋转矩阵** | $R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&2q_1q_2-2q_0q_3&2q_1q_3+2q_0q_2\\\\2q_1q_2+2q_0q_3&1-2q^2_1-2q^2_3&2q_2q_3-2q_0q_1\\\\2q_1q_3-2q_0q_2&2q_2q_3+2q_0q_1&1-2q^2_1-2q^2_2\\end{array} \\right]$ |\n| **旋转向量** | $\\left\\{ \\begin{array}{ll} θ=2arccosq_0\\\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$ |\n|  **欧拉角**  |                              -                               |\n\n## 参考资料\n\n1. 《视觉SLAM十四讲》第二讲、第三讲\n2. [一索哥传奇-《三维空间中的刚体运动》](zhehangt.win/2017/02/24/SLAM/RigidMotion/)","source":"_posts/视觉SLAM十四讲阅读笔记一.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记一-三维空间刚体运动\ndate: 2018-08-04 15:52:25\ntags:\n  - SLAM基础\n  - 读书笔记\nmathjax: true\ncategories:\n  - 机器人 \n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n-----\n\n这篇文章是视觉SLAM十四讲第3讲阅读过程中总结和记录的学习内容。\n\n<!---more-->\n\n三维空间中的刚体（相机、机器人）不光有位置，还有姿态，即**位姿**，位置表示相机在空间中哪个地方，姿态表示相机的指向。SLAM中一个很基本的问题就是计算机器人在三维空间中的位姿。而机器人在三维空间中位姿的计算往往与三维空间中的刚体运动有关。本篇是学习《视觉SLAM十四讲》第3讲三维空间刚体运动有关记录，参考了童博士的笔记内容。介绍在三维空间中刚体运动的位姿表示方法。\n\n## 位姿=位置+姿态\n\nSLAM中的位姿有6个自由度，即**位置和姿态**，其变换过程包含了**旋转（Rotation）**和**平移（Translation）**。直观地理解就是，对于在平面中运动的机器人，其位姿的变换由两个位置和一个转角来描述，转角描述旋转过程，两个位置描述平移过程。机器人任意两个时间间隔位置和转角的变化都可以通过运动传感器检测得到。这里涉及到SLAM中一个很重要的问题，即位姿的**表达**、**优化**。\n\n### 位置表示\n\n> 准确地说应该是机器人运动过程中位置变化的表示。\n\n在一个三维空间中，建立三维坐标系之后，就可以用一个三维坐标来表示机器人的位置。\n对于机器人的位置变换，可以用一个三维的平移向量来表示，比如机器人从初始位置为$(x_0,y_0,z_0)$经过一个平移向量$t=(a,b,c)$，可以得到平移后的位置$(x_0+a,y_0+b,z_0+c)$。相对来说，机器人的位置表达比较简单，只需要一个平移向量即可。\n\n### 姿态表示\n\n> 准确地说应该是机器人运动过程中姿态变化的表示。\n\n在一个三维空间中，通常用一个三维向量来表示机器人的姿态。更直观的讲，机器人的姿态可以想象成机器人自带一个坐标系，这个坐标系的原点就是机器人，z轴表示机器人面向的方向，这样的一个坐标系可以通过表示机器人姿态的三维向量来构造。\n\n机器人的姿态表达相对复杂，表达方法通常有旋转矩阵、旋转向量、欧拉角、四元数。\n\n## 旋转矩阵$SO(3)$\n\n在SLAM问题中，旋转矩阵是表示姿态变换最常用的方式。\n假设空间中的某一点$P$，机器人旋转前的坐标系的单位正交基为$(e1,e2,e3)$，$P$的坐标为$(x_1,y_1,z_1)$。。机器人旋转后的坐标系的单位正交基为$(e′_1,e′_2,e′_3)$，$P$的坐标为$(x′_1,y′_1,z′_1)$。\n\n根据坐标的定义有：\n\n$\\left[ \\begin{matrix}e_1&e_2&e_3\\end{matrix} \\right] \\left[ \\begin{matrix}a_1\\\\a_2\\\\a_3\\\\\\end{matrix} \\right]=[e′_1 e′_2 e′_3]\\left [\\begin{matrix}a′_1\\\\a′_2\\\\a′_3\\\\\\end{matrix} \\right]$\n\n在等式的左右同时左乘$\\left[ \\begin{matrix}a^T_1\\\\a^T_2\\\\a^T_3\\\\\\end{matrix} \\right]​$，可得\n\n$\\left[ \\begin{matrix}a1\\\\a2\\\\a3\\\\\\end{matrix} \\right]=\\left[ \\begin{matrix}e^T_1e′_1 & e^T_1e′_2 &e^T_1e′_3\\\\ e^T_2e′_1 &  e^T_2e′_2 & e^T_2e′_3 \\\\e^T_3e′_1&e^T_3e′_2&e^T_3e′_3  \\end{matrix} \\right]\\left [\\begin{matrix}a′_1\\\\a′_2\\\\a′_3\\\\\\end{matrix} \\right]=Ra′​$\n\n矩阵$R$即为旋转矩阵。旋转矩阵是一个行列式为1的正交矩阵。同样所有行列式为1的正交矩阵都是旋转矩阵，因此可以把旋转矩阵做如下定义：\n\n$SO(n)=\\{Rϵℝ^{n×n}∣RR^T=I,det(R)=1\\}$\n\n$SO(n)$称为特殊正交群，这个集合由$n$维空间的旋转矩阵组成，特别的，$SO(3)$就是三维空间下的旋转矩阵。\n\n值得注意的是，旋转矩阵本质上是表示两个坐标系之间的旋转，而坐标系恰恰能够表示机器人姿态，因此**旋转矩阵可以描述机器人(相机)的旋转，即姿态变换。**\n\n### 变换矩阵$SE(3)$\n\n在旋转矩阵的基础之上，加上平移向量，就可以完整的刻画三维空间中的刚体运动，即：$a′=Ra+t$。该式用一个旋转矩阵$R$和一个平移向量$t$完整地描述了一个欧式空间的坐标变换关系。\n\n但是这种形式下会存在一个问题，假设我们进行了两次变换$R_1$，$t_1$和$R_2$，$t_2$。相应的三维空间中经历了从a点到b点到c点的变换。则满足公式：\n\n$b=R_{1}a+t_1,c=R_{2}b+t_2$\n\n从a到c的变换为：\n$c=R_2(R_{1}a+t_1)+t_2$\n\n这样的形式在变换多次之后会过于复杂。聪明的数学家引入了齐次坐标和变换矩阵的概念，使得三维空间中的刚体运动有如下的变换形式：\n\n$\\left[ \\begin{matrix}a′\\\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}R&t\\\\0^T&1\\end{matrix} \\right]\\left [\\begin{matrix}a\\\\1\\\\\\end{matrix} \\right]=T\\left [\\begin{matrix}a\\\\1\\\\\\end{matrix} \\right]$\n\n矩阵$T$即称为**变换矩阵**。\n\n此时从a到c的变换可表示为：\n$c=T_2T_1a$\n\n此处的a和c为相应齐次坐标。\n\n变换矩阵的左上角为旋转矩阵，右侧为平移向量，左下角为0向量，右下角为1。这种矩阵称为**特殊欧式群(Special Euclidean Group)**：\n\n$SE(3)=\\{T=\\left[ \\begin{matrix}R&t\\\\0^T&1\\end{matrix} \\right]ϵℝ^{4×4}∣RϵSO(3),tϵℝ^3\\}$\n\n> ### 齐次坐标\n>\n> 透视变换是非线性变换，可以通过引入齐次坐标以线性表示透视变换。齐次坐标是在普通坐标上增加一维（值为1）后的坐标表示。在是三维向量的末尾添加1，将其变成了四维向量，多了一个自由度，允许把变换写成线性的形式。对于四维向量，就可以把平移和旋转写在一个矩阵里面，使得整个关系变成线性关系。\n>\n> 1. 将普通坐标转换为齐次坐标：增加一维坐标，值为1。 \n>\n>    $$\n>    (x,y) \\Rightarrow \\left[ \\begin{matrix}\n>    a \\\\\n>    b  \\\\\n>    1 \\\\\n>    \\end{matrix} \\right] (像点齐次坐标)\n>    $$\n>    $$\n>    (x,y,z) \\Rightarrow \\left[ \\begin{matrix}\n>    x \\\\\n>    y  \\\\\n>    z \\\\\n>    1\\\\\n>    \\end{matrix} \\right] (物点齐次坐标)\n>    $$\n>\n> 2. 齐次坐标转换为普通坐标：除以最后一维坐标。\n>\n>    $$\n>    \\left[ \\begin{matrix}\n>    x  \\\\\n>    y  \\\\\n>    z \\\\\n>    w \\\\\n>    \\end{matrix} \\right] \\Rightarrow \n>    \\left[ \\begin{matrix}\n>    x/w, & y/w, & z/w\\\\\n>    \\end{matrix} \\right]\n>    $$\n>\n> 3. 齐次坐标是缩放不变的（Invariant to scaling）\n>    $$\n>    k\\left[ \\begin{matrix}\n>    x \\\\\n>    y  \\\\\n>    w \\\\\n>    \\end{matrix} \\right] = \n>    \\left[ \\begin{matrix}\n>    \n>    kx \\\\\n>    ky  \\\\\n>    kw \\\\\n>    \n>    \\end{matrix} \\right] \\Rightarrow\n>    \\left[ \\begin{matrix}\n>    \n>    \\frac{kx}{kw}  \\\\\n>    \\frac{ky}{kw}  \\\\\n>    \n>    \\end{matrix} \\right] =\n>    \\left[ \\begin{matrix}\n>    \n>    \\frac {x}{w}\\ \\\\\n>    \\frac{y}{w}  \\\\\n>    \n>    \\end{matrix} \\right]\n>    $$\n>\n>\n>\n\n## 旋转向量\n\n用旋转矩阵来表示旋转有两个缺点：\n\n1. $SO(3)$的旋转矩阵有九个量，但一次旋转只有三个自由度。因此这种表达方式是冗余的。\n2. 旋转矩阵自身两个约束，即必须是正交矩阵和行列式为1，这些约束会使得求解变得更困难。\n\n从直观上讲，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是可以使用一个向量，其方向与旋转轴一致，而长度等于旋转角。这种向量称为**旋转向量**（或轴角，Axis-Angle），这样只需要一个三维向量就可以描述旋转。**旋转向量跟之后要介绍的李代数是相对应的**。旋转向量到旋转矩阵的变换可由**罗德里格斯公式**求得。\n假设旋转轴为$n$，角度为$θ$，则旋转向量为$θn$对应的旋转矩阵$R$为：\n\n$R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$\n\n反之，对于转角$\\theta$有：\n\n$tr(R)=cos\\theta tr(I)+(1-cos\\theta)tr(nn^T)+sin\\theta tr(n^\\wedge)\\\\=3cos\\theta+(1-cos\\theta)\\\\=1+2cos\\theta$\n\n因此：\n\n$θ=arccos(\\frac{tr(R)−1}2)$\n\n由于旋转轴上的向量在旋转后不发生改变，说明：$Rn=n$\n\n因此转轴$n$是矩阵$R$特征值1对应的特征向量。求解此方程，再归一化，就得到了旋转轴。\n\n## 欧拉角\n\n欧拉角是一种最为直观的姿态变换描述方式。在欧拉角的表示方式中，将旋转分解成沿三个坐标轴旋转的量：滚转角－俯仰角－偏航角(roll-pitch-yaw)，此时可以使用$[r,p,y]^T$这样一个三维向量描述任意旋转。\n\n欧拉角的一个重大缺点就是万向锁问题：在俯仰角为±90度时，第一次旋转与第三次旋转将使用同一个轴，这被称为奇异性问题。由于欧拉角不适于插值和迭代，所以在SLAM问题中通常不使用欧拉角来表示旋转，所以不再展开记录。\n\n## 四元数\n\n旋转矩阵具有冗余性，欧拉角和旋转向量不冗余但是具有奇异性。其实，我们找不到不带奇异性的三维向量描述方式。\n四元数只有四个自由度，即是紧凑的而且没有奇异性。它是一种扩展的复数的表达方式。缺点是不够直观，运算稍复杂。\n\n四元数q拥有一个实部和三个虚部。如下：\n\n$q=q_0+q_1i+q_2j+q_3k$\n\n其中：\n\n$\\left\\{ \\begin{array}{ll} i^2=j^2=k^2=−1\\\\ ij=k,ji=−k \\\\jk=i,kj=−i,ki=j,ik=−j\\end{array} \\right.​$\n\n> 我们可以用单位四元数表示三维空间中的任意一个旋转。\n\n假设某个旋转绕单位向量$n=[n_x,n_y,n_z]^T$进行了角度$θ$的旋转，那么对应的四元数为：\n\n$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$\n\n反之也可以从单位四元数中计算出对应旋转轴和夹角：\n\n$\\left\\{ \\begin{array}{ll} θ=2arccosq_0\\\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$\n\n对$θ$加上$2π$可以得到一个相同的旋转，但此时对应的四元数变成了$−q$。因此任意的旋转都可以由两个互为相反数的四元数表示，即两个互为相反数的四元数可以表示同一个旋转。\n\n### 四元数的运算\n\n见《视觉SLAM十四讲》P55，不再做记录。\n\n### 四元数表示旋转\n\n假设空间中有一点$p=[x,y,z]$，，其绕旋转轴$n$，进行了角度为$θ$的旋转得到了点$p′$，使用旋转矩阵表述有：\n\n$p′=Rp$。\n\n使用四元数描述旋转该如何表达？首先，把三维空间点用一个虚四元数表示：\n\n$p=[0,x,y,z]=[0,v]$\n\n相当于把四元数的3个虚部与空间中的3个轴相对应。然后，由前述公式可知，用四元数$q$表示该旋转：\n\n$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$\n\n则可以验证：\n$p′=qpq^{−1}$\n\n最终结果实部为0,故为纯虚四元数，其虚部的3个分量表示旋转后的3D点的坐标。\n\n### 四元数到旋转矩阵的转换\n\n设四元数$q=q_0+q_1i+q_2j+q_3k$，对应的旋转矩阵$R$为：\n\n$R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&2q_1q_2-2q_0q_3&2q_1q_3+2q_0q_2\\\\2q_1q_2+2q_0q_3&1-2q^2_1-2q^2_3&2q_2q_3-2q_0q_1\\\\2q_1q_3-2q_0q_2&2q_2q_3+2q_0q_1&1-2q^2_1-2q^2_2\\end{array} \\right]$\n\n反之，假设旋转矩阵为$R={m_{ij}},i,j\\epsilon[1,2,3]$，其对应的四元数$q$为：\n\n$q_0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m_{23}-m_{32}}{4q_0},q_2=\\frac{m_{31}-m_{13}}{4q_0},q_3=\\frac{m_{12}-m_{21}}{4q_0}​$\n\n注意：实际编程中，当$q_0$的值接近0时，其它3个分量会非常大，导致解不稳定，此时可以再考虑使用其他方式进行转换。\n\n## 旋转的四种表示方法比较\n\n|    表示方法    | 形式|是否奇异性 | 分量数目 | 紧凑or冗余程度 | 直观性 |\n| :------------: | :--------: | :------: | :------------: | :--: | :------------: |\n|    旋转矩阵    |     $R$     |    否    |      9      | 冗余 | 不直观 |\n| 旋转向量 |     $\\theta{n}$     |    是    |    3    | 较紧凑 | 不直观 |\n|     欧拉角     |     $[r,p,y]^T$     |    是    |    3    | 较紧凑 | 直观 |\n|     四元数     |     $q=q_0+q_1i+q_2j+q_3k$     |    否    |    4    | 较紧凑 | 较不直观 |\n\n## 旋转的四种表示方法间互相转换\n\n1.矩阵转换成其他方式\n\n|              |         旋转矩阵 **$R={m_{ij}},i,j\\epsilon[1,2,3]$**         |\n| :----------: | :----------------------------------------------------------: |\n| **旋转向量** | $θ=arccos(\\frac{tr(R)−1}2)$；求解方程$Rn=n$，归一化处理得到旋转轴n |\n|  **欧拉**角  |                              -                               |\n|  **四元数**  | $q_0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m_{23}-m_{32}}{4q_0},q_2=\\frac{m_{31}-m_{13}}{4q_0},q_3=\\frac{m_{12}-m_{21}}{4q_0}$ |\n\n2.向量转换成其他方式\n\n|              |                     旋转向量  **$θn$**                     |\n| :----------: | :--------------------------------------------------------: |\n| **旋转矩阵** |           $R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$            |\n|  **欧拉角**  |                             -                              |\n|  **四元数**  | $q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$ |\n\n3.数转换成其他方式\n\n|              |              四元数 **$q=q_0+q_1i+q_2j+q_3k$**               |\n| :----------: | :----------------------------------------------------------: |\n| **旋转矩阵** | $R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&2q_1q_2-2q_0q_3&2q_1q_3+2q_0q_2\\\\2q_1q_2+2q_0q_3&1-2q^2_1-2q^2_3&2q_2q_3-2q_0q_1\\\\2q_1q_3-2q_0q_2&2q_2q_3+2q_0q_1&1-2q^2_1-2q^2_2\\end{array} \\right]$ |\n| **旋转向量** | $\\left\\{ \\begin{array}{ll} θ=2arccosq_0\\\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$ |\n|  **欧拉角**  |                              -                               |\n\n## 参考资料\n\n1. 《视觉SLAM十四讲》第二讲、第三讲\n2. [一索哥传奇-《三维空间中的刚体运动》](zhehangt.win/2017/02/24/SLAM/RigidMotion/)","slug":"视觉SLAM十四讲阅读笔记一","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0900ckqlcrrogphqzq","content":"<hr>\n<p>这篇文章是视觉SLAM十四讲第3讲阅读过程中总结和记录的学习内容。</p>\n<a id=\"more\"></a>\n<p>三维空间中的刚体（相机、机器人）不光有位置，还有姿态，即<strong>位姿</strong>，位置表示相机在空间中哪个地方，姿态表示相机的指向。SLAM中一个很基本的问题就是计算机器人在三维空间中的位姿。而机器人在三维空间中位姿的计算往往与三维空间中的刚体运动有关。本篇是学习《视觉SLAM十四讲》第3讲三维空间刚体运动有关记录，参考了童博士的笔记内容。介绍在三维空间中刚体运动的位姿表示方法。</p>\n<h2 id=\"位姿-位置-姿态\"><a href=\"#位姿-位置-姿态\" class=\"headerlink\" title=\"位姿=位置+姿态\"></a>位姿=位置+姿态</h2><p>SLAM中的位姿有6个自由度，即<strong>位置和姿态</strong>，其变换过程包含了<strong>旋转（Rotation）</strong>和<strong>平移（Translation）</strong>。直观地理解就是，对于在平面中运动的机器人，其位姿的变换由两个位置和一个转角来描述，转角描述旋转过程，两个位置描述平移过程。机器人任意两个时间间隔位置和转角的变化都可以通过运动传感器检测得到。这里涉及到SLAM中一个很重要的问题，即位姿的<strong>表达</strong>、<strong>优化</strong>。</p>\n<h3 id=\"位置表示\"><a href=\"#位置表示\" class=\"headerlink\" title=\"位置表示\"></a>位置表示</h3><blockquote>\n<p>准确地说应该是机器人运动过程中位置变化的表示。</p>\n</blockquote>\n<p>在一个三维空间中，建立三维坐标系之后，就可以用一个三维坐标来表示机器人的位置。<br>对于机器人的位置变换，可以用一个三维的平移向量来表示，比如机器人从初始位置为$(x_0,y_0,z_0)$经过一个平移向量$t=(a,b,c)$，可以得到平移后的位置$(x_0+a,y_0+b,z_0+c)$。相对来说，机器人的位置表达比较简单，只需要一个平移向量即可。</p>\n<h3 id=\"姿态表示\"><a href=\"#姿态表示\" class=\"headerlink\" title=\"姿态表示\"></a>姿态表示</h3><blockquote>\n<p>准确地说应该是机器人运动过程中姿态变化的表示。</p>\n</blockquote>\n<p>在一个三维空间中，通常用一个三维向量来表示机器人的姿态。更直观的讲，机器人的姿态可以想象成机器人自带一个坐标系，这个坐标系的原点就是机器人，z轴表示机器人面向的方向，这样的一个坐标系可以通过表示机器人姿态的三维向量来构造。</p>\n<p>机器人的姿态表达相对复杂，表达方法通常有旋转矩阵、旋转向量、欧拉角、四元数。</p>\n<h2 id=\"旋转矩阵-SO-3\"><a href=\"#旋转矩阵-SO-3\" class=\"headerlink\" title=\"旋转矩阵$SO(3)$\"></a>旋转矩阵$SO(3)$</h2><p>在SLAM问题中，旋转矩阵是表示姿态变换最常用的方式。<br>假设空间中的某一点$P$，机器人旋转前的坐标系的单位正交基为$(e1,e2,e3)$，$P$的坐标为$(x_1,y_1,z_1)$。。机器人旋转后的坐标系的单位正交基为$(e′_1,e′_2,e′_3)$，$P$的坐标为$(x′_1,y′_1,z′_1)$。</p>\n<p>根据坐标的定义有：</p>\n<p>$\\left[ \\begin{matrix}e_1&amp;e_2&amp;e_3\\end{matrix} \\right] \\left[ \\begin{matrix}a_1\\a_2\\a_3\\\\end{matrix} \\right]=[e′_1 e′_2 e′_3]\\left [\\begin{matrix}a′_1\\a′_2\\a′_3\\\\end{matrix} \\right]$</p>\n<p>在等式的左右同时左乘$\\left[ \\begin{matrix}a^T_1\\a^T_2\\a^T_3\\\\end{matrix} \\right]​$，可得</p>\n<p>$\\left[ \\begin{matrix}a1\\a2\\a3\\\\end{matrix} \\right]=\\left[ \\begin{matrix}e^T_1e′_1 &amp; e^T_1e′_2 &amp;e^T_1e′_3\\ e^T_2e′_1 &amp;  e^T_2e′_2 &amp; e^T_2e′_3 \\e^T_3e′_1&amp;e^T_3e′_2&amp;e^T_3e′_3  \\end{matrix} \\right]\\left [\\begin{matrix}a′_1\\a′_2\\a′_3\\\\end{matrix} \\right]=Ra′​$</p>\n<p>矩阵$R$即为旋转矩阵。旋转矩阵是一个行列式为1的正交矩阵。同样所有行列式为1的正交矩阵都是旋转矩阵，因此可以把旋转矩阵做如下定义：</p>\n<p>$SO(n)={Rϵℝ^{n×n}∣RR^T=I,det(R)=1}$</p>\n<p>$SO(n)$称为特殊正交群，这个集合由$n$维空间的旋转矩阵组成，特别的，$SO(3)$就是三维空间下的旋转矩阵。</p>\n<p>值得注意的是，旋转矩阵本质上是表示两个坐标系之间的旋转，而坐标系恰恰能够表示机器人姿态，因此<strong>旋转矩阵可以描述机器人(相机)的旋转，即姿态变换。</strong></p>\n<h3 id=\"变换矩阵-SE-3\"><a href=\"#变换矩阵-SE-3\" class=\"headerlink\" title=\"变换矩阵$SE(3)$\"></a>变换矩阵$SE(3)$</h3><p>在旋转矩阵的基础之上，加上平移向量，就可以完整的刻画三维空间中的刚体运动，即：$a′=Ra+t$。该式用一个旋转矩阵$R$和一个平移向量$t$完整地描述了一个欧式空间的坐标变换关系。</p>\n<p>但是这种形式下会存在一个问题，假设我们进行了两次变换$R_1$，$t_1$和$R_2$，$t_2$。相应的三维空间中经历了从a点到b点到c点的变换。则满足公式：</p>\n<p>$b=R<em>{1}a+t_1,c=R</em>{2}b+t_2$</p>\n<p>从a到c的变换为：<br>$c=R<em>2(R</em>{1}a+t_1)+t_2$</p>\n<p>这样的形式在变换多次之后会过于复杂。聪明的数学家引入了齐次坐标和变换矩阵的概念，使得三维空间中的刚体运动有如下的变换形式：</p>\n<p>$\\left[ \\begin{matrix}a′\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}R&amp;t\\0^T&amp;1\\end{matrix} \\right]\\left [\\begin{matrix}a\\1\\\\end{matrix} \\right]=T\\left [\\begin{matrix}a\\1\\\\end{matrix} \\right]$</p>\n<p>矩阵$T$即称为<strong>变换矩阵</strong>。</p>\n<p>此时从a到c的变换可表示为：<br>$c=T_2T_1a$</p>\n<p>此处的a和c为相应齐次坐标。</p>\n<p>变换矩阵的左上角为旋转矩阵，右侧为平移向量，左下角为0向量，右下角为1。这种矩阵称为<strong>特殊欧式群(Special Euclidean Group)</strong>：</p>\n<p>$SE(3)={T=\\left[ \\begin{matrix}R&amp;t\\0^T&amp;1\\end{matrix} \\right]ϵℝ^{4×4}∣RϵSO(3),tϵℝ^3}$</p>\n<blockquote>\n<h3 id=\"齐次坐标\"><a href=\"#齐次坐标\" class=\"headerlink\" title=\"齐次坐标\"></a>齐次坐标</h3><p>透视变换是非线性变换，可以通过引入齐次坐标以线性表示透视变换。齐次坐标是在普通坐标上增加一维（值为1）后的坐标表示。在是三维向量的末尾添加1，将其变成了四维向量，多了一个自由度，允许把变换写成线性的形式。对于四维向量，就可以把平移和旋转写在一个矩阵里面，使得整个关系变成线性关系。</p>\n<ol>\n<li><p>将普通坐标转换为齐次坐标：增加一维坐标，值为1。 </p>\n<script type=\"math/tex; mode=display\">\n(x,y) \\Rightarrow \\left[ \\begin{matrix}\na \\\\\nb  \\\\\n1 \\\\\n\\end{matrix} \\right] (像点齐次坐标)</script><script type=\"math/tex; mode=display\">\n(x,y,z) \\Rightarrow \\left[ \\begin{matrix}\nx \\\\\ny  \\\\\nz \\\\\n1\\\\\n\\end{matrix} \\right] (物点齐次坐标)</script></li>\n<li><p>齐次坐标转换为普通坐标：除以最后一维坐标。</p>\n<script type=\"math/tex; mode=display\">\n\\left[ \\begin{matrix}\nx  \\\\\ny  \\\\\nz \\\\\nw \\\\\n\\end{matrix} \\right] \\Rightarrow \n\\left[ \\begin{matrix}\nx/w, & y/w, & z/w\\\\\n\\end{matrix} \\right]</script></li>\n<li><p>齐次坐标是缩放不变的（Invariant to scaling）</p>\n<script type=\"math/tex; mode=display\">\nk\\left[ \\begin{matrix}\nx \\\\\ny  \\\\\nw \\\\\n\\end{matrix} \\right] = \n\\left[ \\begin{matrix}\n\nkx \\\\\nky  \\\\\nkw \\\\\n\n\\end{matrix} \\right] \\Rightarrow\n\\left[ \\begin{matrix}\n\n\\frac{kx}{kw}  \\\\\n\\frac{ky}{kw}  \\\\\n\n\\end{matrix} \\right] =\n\\left[ \\begin{matrix}\n\n\\frac {x}{w}\\ \\\\\n\\frac{y}{w}  \\\\\n\n\\end{matrix} \\right]</script></li>\n</ol>\n</blockquote>\n<h2 id=\"旋转向量\"><a href=\"#旋转向量\" class=\"headerlink\" title=\"旋转向量\"></a>旋转向量</h2><p>用旋转矩阵来表示旋转有两个缺点：</p>\n<ol>\n<li>$SO(3)$的旋转矩阵有九个量，但一次旋转只有三个自由度。因此这种表达方式是冗余的。</li>\n<li>旋转矩阵自身两个约束，即必须是正交矩阵和行列式为1，这些约束会使得求解变得更困难。</li>\n</ol>\n<p>从直观上讲，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是可以使用一个向量，其方向与旋转轴一致，而长度等于旋转角。这种向量称为<strong>旋转向量</strong>（或轴角，Axis-Angle），这样只需要一个三维向量就可以描述旋转。<strong>旋转向量跟之后要介绍的李代数是相对应的</strong>。旋转向量到旋转矩阵的变换可由<strong>罗德里格斯公式</strong>求得。<br>假设旋转轴为$n$，角度为$θ$，则旋转向量为$θn$对应的旋转矩阵$R$为：</p>\n<p>$R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$</p>\n<p>反之，对于转角$\\theta$有：</p>\n<p>$tr(R)=cos\\theta tr(I)+(1-cos\\theta)tr(nn^T)+sin\\theta tr(n^\\wedge)\\=3cos\\theta+(1-cos\\theta)\\=1+2cos\\theta$</p>\n<p>因此：</p>\n<p>$θ=arccos(\\frac{tr(R)−1}2)$</p>\n<p>由于旋转轴上的向量在旋转后不发生改变，说明：$Rn=n$</p>\n<p>因此转轴$n$是矩阵$R$特征值1对应的特征向量。求解此方程，再归一化，就得到了旋转轴。</p>\n<h2 id=\"欧拉角\"><a href=\"#欧拉角\" class=\"headerlink\" title=\"欧拉角\"></a>欧拉角</h2><p>欧拉角是一种最为直观的姿态变换描述方式。在欧拉角的表示方式中，将旋转分解成沿三个坐标轴旋转的量：滚转角－俯仰角－偏航角(roll-pitch-yaw)，此时可以使用$[r,p,y]^T$这样一个三维向量描述任意旋转。</p>\n<p>欧拉角的一个重大缺点就是万向锁问题：在俯仰角为±90度时，第一次旋转与第三次旋转将使用同一个轴，这被称为奇异性问题。由于欧拉角不适于插值和迭代，所以在SLAM问题中通常不使用欧拉角来表示旋转，所以不再展开记录。</p>\n<h2 id=\"四元数\"><a href=\"#四元数\" class=\"headerlink\" title=\"四元数\"></a>四元数</h2><p>旋转矩阵具有冗余性，欧拉角和旋转向量不冗余但是具有奇异性。其实，我们找不到不带奇异性的三维向量描述方式。<br>四元数只有四个自由度，即是紧凑的而且没有奇异性。它是一种扩展的复数的表达方式。缺点是不够直观，运算稍复杂。</p>\n<p>四元数q拥有一个实部和三个虚部。如下：</p>\n<p>$q=q_0+q_1i+q_2j+q_3k$</p>\n<p>其中：</p>\n<p>$\\left{ \\begin{array}{ll} i^2=j^2=k^2=−1\\ ij=k,ji=−k \\jk=i,kj=−i,ki=j,ik=−j\\end{array} \\right.​$</p>\n<blockquote>\n<p>我们可以用单位四元数表示三维空间中的任意一个旋转。</p>\n</blockquote>\n<p>假设某个旋转绕单位向量$n=[n_x,n_y,n_z]^T$进行了角度$θ$的旋转，那么对应的四元数为：</p>\n<p>$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$</p>\n<p>反之也可以从单位四元数中计算出对应旋转轴和夹角：</p>\n<p>$\\left{ \\begin{array}{ll} θ=2arccosq_0\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$</p>\n<p>对$θ$加上$2π$可以得到一个相同的旋转，但此时对应的四元数变成了$−q$。因此任意的旋转都可以由两个互为相反数的四元数表示，即两个互为相反数的四元数可以表示同一个旋转。</p>\n<h3 id=\"四元数的运算\"><a href=\"#四元数的运算\" class=\"headerlink\" title=\"四元数的运算\"></a>四元数的运算</h3><p>见《视觉SLAM十四讲》P55，不再做记录。</p>\n<h3 id=\"四元数表示旋转\"><a href=\"#四元数表示旋转\" class=\"headerlink\" title=\"四元数表示旋转\"></a>四元数表示旋转</h3><p>假设空间中有一点$p=[x,y,z]$，，其绕旋转轴$n$，进行了角度为$θ$的旋转得到了点$p′$，使用旋转矩阵表述有：</p>\n<p>$p′=Rp$。</p>\n<p>使用四元数描述旋转该如何表达？首先，把三维空间点用一个虚四元数表示：</p>\n<p>$p=[0,x,y,z]=[0,v]$</p>\n<p>相当于把四元数的3个虚部与空间中的3个轴相对应。然后，由前述公式可知，用四元数$q$表示该旋转：</p>\n<p>$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$</p>\n<p>则可以验证：<br>$p′=qpq^{−1}$</p>\n<p>最终结果实部为0,故为纯虚四元数，其虚部的3个分量表示旋转后的3D点的坐标。</p>\n<h3 id=\"四元数到旋转矩阵的转换\"><a href=\"#四元数到旋转矩阵的转换\" class=\"headerlink\" title=\"四元数到旋转矩阵的转换\"></a>四元数到旋转矩阵的转换</h3><p>设四元数$q=q_0+q_1i+q_2j+q_3k$，对应的旋转矩阵$R$为：</p>\n<p>$R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&amp;2q_1q_2-2q_0q_3&amp;2q_1q_3+2q_0q_2\\2q_1q_2+2q_0q_3&amp;1-2q^2_1-2q^2_3&amp;2q_2q_3-2q_0q_1\\2q_1q_3-2q_0q_2&amp;2q_2q_3+2q_0q_1&amp;1-2q^2_1-2q^2_2\\end{array} \\right]$</p>\n<p>反之，假设旋转矩阵为$R={m_{ij}},i,j\\epsilon[1,2,3]$，其对应的四元数$q$为：</p>\n<p>$q<em>0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m</em>{23}-m<em>{32}}{4q_0},q_2=\\frac{m</em>{31}-m<em>{13}}{4q_0},q_3=\\frac{m</em>{12}-m_{21}}{4q_0}​$</p>\n<p>注意：实际编程中，当$q_0$的值接近0时，其它3个分量会非常大，导致解不稳定，此时可以再考虑使用其他方式进行转换。</p>\n<h2 id=\"旋转的四种表示方法比较\"><a href=\"#旋转的四种表示方法比较\" class=\"headerlink\" title=\"旋转的四种表示方法比较\"></a>旋转的四种表示方法比较</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">表示方法</th>\n<th style=\"text-align:center\">形式</th>\n<th style=\"text-align:center\">是否奇异性</th>\n<th style=\"text-align:center\">分量数目</th>\n<th style=\"text-align:center\">紧凑or冗余程度</th>\n<th style=\"text-align:center\">直观性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">旋转矩阵</td>\n<td style=\"text-align:center\">$R$</td>\n<td style=\"text-align:center\">否</td>\n<td style=\"text-align:center\">9</td>\n<td style=\"text-align:center\">冗余</td>\n<td style=\"text-align:center\">不直观</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">旋转向量</td>\n<td style=\"text-align:center\">$\\theta{n}$</td>\n<td style=\"text-align:center\">是</td>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">较紧凑</td>\n<td style=\"text-align:center\">不直观</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">欧拉角</td>\n<td style=\"text-align:center\">$[r,p,y]^T$</td>\n<td style=\"text-align:center\">是</td>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">较紧凑</td>\n<td style=\"text-align:center\">直观</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">四元数</td>\n<td style=\"text-align:center\">$q=q_0+q_1i+q_2j+q_3k$</td>\n<td style=\"text-align:center\">否</td>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">较紧凑</td>\n<td style=\"text-align:center\">较不直观</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"旋转的四种表示方法间互相转换\"><a href=\"#旋转的四种表示方法间互相转换\" class=\"headerlink\" title=\"旋转的四种表示方法间互相转换\"></a>旋转的四种表示方法间互相转换</h2><p>1.矩阵转换成其他方式</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">旋转矩阵 <strong>$R={m_{ij}},i,j\\epsilon[1,2,3]$</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>旋转向量</strong></td>\n<td style=\"text-align:center\">$θ=arccos(\\frac{tr(R)−1}2)$；求解方程$Rn=n$，归一化处理得到旋转轴n</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>欧拉</strong>角</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>四元数</strong></td>\n<td style=\"text-align:center\">$q<em>0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m</em>{23}-m<em>{32}}{4q_0},q_2=\\frac{m</em>{31}-m<em>{13}}{4q_0},q_3=\\frac{m</em>{12}-m_{21}}{4q_0}$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2.向量转换成其他方式</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">旋转向量  <strong>$θn$</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>旋转矩阵</strong></td>\n<td style=\"text-align:center\">$R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>欧拉角</strong></td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>四元数</strong></td>\n<td style=\"text-align:center\">$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>3.数转换成其他方式</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">四元数 <strong>$q=q_0+q_1i+q_2j+q_3k$</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>旋转矩阵</strong></td>\n<td style=\"text-align:center\">$R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&amp;2q_1q_2-2q_0q_3&amp;2q_1q_3+2q_0q_2\\2q_1q_2+2q_0q_3&amp;1-2q^2_1-2q^2_3&amp;2q_2q_3-2q_0q_1\\2q_1q_3-2q_0q_2&amp;2q_2q_3+2q_0q_1&amp;1-2q^2_1-2q^2_2\\end{array} \\right]$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>旋转向量</strong></td>\n<td style=\"text-align:center\">$\\left{ \\begin{array}{ll} θ=2arccosq_0\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>欧拉角</strong></td>\n<td style=\"text-align:center\">-</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>《视觉SLAM十四讲》第二讲、第三讲</li>\n<li><a href=\"zhehangt.win/2017/02/24/SLAM/RigidMotion/\">一索哥传奇-《三维空间中的刚体运动》</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是视觉SLAM十四讲第3讲阅读过程中总结和记录的学习内容。</p>","more":"<p>三维空间中的刚体（相机、机器人）不光有位置，还有姿态，即<strong>位姿</strong>，位置表示相机在空间中哪个地方，姿态表示相机的指向。SLAM中一个很基本的问题就是计算机器人在三维空间中的位姿。而机器人在三维空间中位姿的计算往往与三维空间中的刚体运动有关。本篇是学习《视觉SLAM十四讲》第3讲三维空间刚体运动有关记录，参考了童博士的笔记内容。介绍在三维空间中刚体运动的位姿表示方法。</p>\n<h2 id=\"位姿-位置-姿态\"><a href=\"#位姿-位置-姿态\" class=\"headerlink\" title=\"位姿=位置+姿态\"></a>位姿=位置+姿态</h2><p>SLAM中的位姿有6个自由度，即<strong>位置和姿态</strong>，其变换过程包含了<strong>旋转（Rotation）</strong>和<strong>平移（Translation）</strong>。直观地理解就是，对于在平面中运动的机器人，其位姿的变换由两个位置和一个转角来描述，转角描述旋转过程，两个位置描述平移过程。机器人任意两个时间间隔位置和转角的变化都可以通过运动传感器检测得到。这里涉及到SLAM中一个很重要的问题，即位姿的<strong>表达</strong>、<strong>优化</strong>。</p>\n<h3 id=\"位置表示\"><a href=\"#位置表示\" class=\"headerlink\" title=\"位置表示\"></a>位置表示</h3><blockquote>\n<p>准确地说应该是机器人运动过程中位置变化的表示。</p>\n</blockquote>\n<p>在一个三维空间中，建立三维坐标系之后，就可以用一个三维坐标来表示机器人的位置。<br>对于机器人的位置变换，可以用一个三维的平移向量来表示，比如机器人从初始位置为$(x_0,y_0,z_0)$经过一个平移向量$t=(a,b,c)$，可以得到平移后的位置$(x_0+a,y_0+b,z_0+c)$。相对来说，机器人的位置表达比较简单，只需要一个平移向量即可。</p>\n<h3 id=\"姿态表示\"><a href=\"#姿态表示\" class=\"headerlink\" title=\"姿态表示\"></a>姿态表示</h3><blockquote>\n<p>准确地说应该是机器人运动过程中姿态变化的表示。</p>\n</blockquote>\n<p>在一个三维空间中，通常用一个三维向量来表示机器人的姿态。更直观的讲，机器人的姿态可以想象成机器人自带一个坐标系，这个坐标系的原点就是机器人，z轴表示机器人面向的方向，这样的一个坐标系可以通过表示机器人姿态的三维向量来构造。</p>\n<p>机器人的姿态表达相对复杂，表达方法通常有旋转矩阵、旋转向量、欧拉角、四元数。</p>\n<h2 id=\"旋转矩阵-SO-3\"><a href=\"#旋转矩阵-SO-3\" class=\"headerlink\" title=\"旋转矩阵$SO(3)$\"></a>旋转矩阵$SO(3)$</h2><p>在SLAM问题中，旋转矩阵是表示姿态变换最常用的方式。<br>假设空间中的某一点$P$，机器人旋转前的坐标系的单位正交基为$(e1,e2,e3)$，$P$的坐标为$(x_1,y_1,z_1)$。。机器人旋转后的坐标系的单位正交基为$(e′_1,e′_2,e′_3)$，$P$的坐标为$(x′_1,y′_1,z′_1)$。</p>\n<p>根据坐标的定义有：</p>\n<p>$\\left[ \\begin{matrix}e_1&amp;e_2&amp;e_3\\end{matrix} \\right] \\left[ \\begin{matrix}a_1\\a_2\\a_3\\\\end{matrix} \\right]=[e′_1 e′_2 e′_3]\\left [\\begin{matrix}a′_1\\a′_2\\a′_3\\\\end{matrix} \\right]$</p>\n<p>在等式的左右同时左乘$\\left[ \\begin{matrix}a^T_1\\a^T_2\\a^T_3\\\\end{matrix} \\right]​$，可得</p>\n<p>$\\left[ \\begin{matrix}a1\\a2\\a3\\\\end{matrix} \\right]=\\left[ \\begin{matrix}e^T_1e′_1 &amp; e^T_1e′_2 &amp;e^T_1e′_3\\ e^T_2e′_1 &amp;  e^T_2e′_2 &amp; e^T_2e′_3 \\e^T_3e′_1&amp;e^T_3e′_2&amp;e^T_3e′_3  \\end{matrix} \\right]\\left [\\begin{matrix}a′_1\\a′_2\\a′_3\\\\end{matrix} \\right]=Ra′​$</p>\n<p>矩阵$R$即为旋转矩阵。旋转矩阵是一个行列式为1的正交矩阵。同样所有行列式为1的正交矩阵都是旋转矩阵，因此可以把旋转矩阵做如下定义：</p>\n<p>$SO(n)={Rϵℝ^{n×n}∣RR^T=I,det(R)=1}$</p>\n<p>$SO(n)$称为特殊正交群，这个集合由$n$维空间的旋转矩阵组成，特别的，$SO(3)$就是三维空间下的旋转矩阵。</p>\n<p>值得注意的是，旋转矩阵本质上是表示两个坐标系之间的旋转，而坐标系恰恰能够表示机器人姿态，因此<strong>旋转矩阵可以描述机器人(相机)的旋转，即姿态变换。</strong></p>\n<h3 id=\"变换矩阵-SE-3\"><a href=\"#变换矩阵-SE-3\" class=\"headerlink\" title=\"变换矩阵$SE(3)$\"></a>变换矩阵$SE(3)$</h3><p>在旋转矩阵的基础之上，加上平移向量，就可以完整的刻画三维空间中的刚体运动，即：$a′=Ra+t$。该式用一个旋转矩阵$R$和一个平移向量$t$完整地描述了一个欧式空间的坐标变换关系。</p>\n<p>但是这种形式下会存在一个问题，假设我们进行了两次变换$R_1$，$t_1$和$R_2$，$t_2$。相应的三维空间中经历了从a点到b点到c点的变换。则满足公式：</p>\n<p>$b=R<em>{1}a+t_1,c=R</em>{2}b+t_2$</p>\n<p>从a到c的变换为：<br>$c=R<em>2(R</em>{1}a+t_1)+t_2$</p>\n<p>这样的形式在变换多次之后会过于复杂。聪明的数学家引入了齐次坐标和变换矩阵的概念，使得三维空间中的刚体运动有如下的变换形式：</p>\n<p>$\\left[ \\begin{matrix}a′\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}R&amp;t\\0^T&amp;1\\end{matrix} \\right]\\left [\\begin{matrix}a\\1\\\\end{matrix} \\right]=T\\left [\\begin{matrix}a\\1\\\\end{matrix} \\right]$</p>\n<p>矩阵$T$即称为<strong>变换矩阵</strong>。</p>\n<p>此时从a到c的变换可表示为：<br>$c=T_2T_1a$</p>\n<p>此处的a和c为相应齐次坐标。</p>\n<p>变换矩阵的左上角为旋转矩阵，右侧为平移向量，左下角为0向量，右下角为1。这种矩阵称为<strong>特殊欧式群(Special Euclidean Group)</strong>：</p>\n<p>$SE(3)={T=\\left[ \\begin{matrix}R&amp;t\\0^T&amp;1\\end{matrix} \\right]ϵℝ^{4×4}∣RϵSO(3),tϵℝ^3}$</p>\n<blockquote>\n<h3 id=\"齐次坐标\"><a href=\"#齐次坐标\" class=\"headerlink\" title=\"齐次坐标\"></a>齐次坐标</h3><p>透视变换是非线性变换，可以通过引入齐次坐标以线性表示透视变换。齐次坐标是在普通坐标上增加一维（值为1）后的坐标表示。在是三维向量的末尾添加1，将其变成了四维向量，多了一个自由度，允许把变换写成线性的形式。对于四维向量，就可以把平移和旋转写在一个矩阵里面，使得整个关系变成线性关系。</p>\n<ol>\n<li><p>将普通坐标转换为齐次坐标：增加一维坐标，值为1。 </p>\n<script type=\"math/tex; mode=display\">\n(x,y) \\Rightarrow \\left[ \\begin{matrix}\na \\\\\nb  \\\\\n1 \\\\\n\\end{matrix} \\right] (像点齐次坐标)</script><script type=\"math/tex; mode=display\">\n(x,y,z) \\Rightarrow \\left[ \\begin{matrix}\nx \\\\\ny  \\\\\nz \\\\\n1\\\\\n\\end{matrix} \\right] (物点齐次坐标)</script></li>\n<li><p>齐次坐标转换为普通坐标：除以最后一维坐标。</p>\n<script type=\"math/tex; mode=display\">\n\\left[ \\begin{matrix}\nx  \\\\\ny  \\\\\nz \\\\\nw \\\\\n\\end{matrix} \\right] \\Rightarrow \n\\left[ \\begin{matrix}\nx/w, & y/w, & z/w\\\\\n\\end{matrix} \\right]</script></li>\n<li><p>齐次坐标是缩放不变的（Invariant to scaling）</p>\n<script type=\"math/tex; mode=display\">\nk\\left[ \\begin{matrix}\nx \\\\\ny  \\\\\nw \\\\\n\\end{matrix} \\right] = \n\\left[ \\begin{matrix}\n\nkx \\\\\nky  \\\\\nkw \\\\\n\n\\end{matrix} \\right] \\Rightarrow\n\\left[ \\begin{matrix}\n\n\\frac{kx}{kw}  \\\\\n\\frac{ky}{kw}  \\\\\n\n\\end{matrix} \\right] =\n\\left[ \\begin{matrix}\n\n\\frac {x}{w}\\ \\\\\n\\frac{y}{w}  \\\\\n\n\\end{matrix} \\right]</script></li>\n</ol>\n</blockquote>\n<h2 id=\"旋转向量\"><a href=\"#旋转向量\" class=\"headerlink\" title=\"旋转向量\"></a>旋转向量</h2><p>用旋转矩阵来表示旋转有两个缺点：</p>\n<ol>\n<li>$SO(3)$的旋转矩阵有九个量，但一次旋转只有三个自由度。因此这种表达方式是冗余的。</li>\n<li>旋转矩阵自身两个约束，即必须是正交矩阵和行列式为1，这些约束会使得求解变得更困难。</li>\n</ol>\n<p>从直观上讲，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是可以使用一个向量，其方向与旋转轴一致，而长度等于旋转角。这种向量称为<strong>旋转向量</strong>（或轴角，Axis-Angle），这样只需要一个三维向量就可以描述旋转。<strong>旋转向量跟之后要介绍的李代数是相对应的</strong>。旋转向量到旋转矩阵的变换可由<strong>罗德里格斯公式</strong>求得。<br>假设旋转轴为$n$，角度为$θ$，则旋转向量为$θn$对应的旋转矩阵$R$为：</p>\n<p>$R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$</p>\n<p>反之，对于转角$\\theta$有：</p>\n<p>$tr(R)=cos\\theta tr(I)+(1-cos\\theta)tr(nn^T)+sin\\theta tr(n^\\wedge)\\=3cos\\theta+(1-cos\\theta)\\=1+2cos\\theta$</p>\n<p>因此：</p>\n<p>$θ=arccos(\\frac{tr(R)−1}2)$</p>\n<p>由于旋转轴上的向量在旋转后不发生改变，说明：$Rn=n$</p>\n<p>因此转轴$n$是矩阵$R$特征值1对应的特征向量。求解此方程，再归一化，就得到了旋转轴。</p>\n<h2 id=\"欧拉角\"><a href=\"#欧拉角\" class=\"headerlink\" title=\"欧拉角\"></a>欧拉角</h2><p>欧拉角是一种最为直观的姿态变换描述方式。在欧拉角的表示方式中，将旋转分解成沿三个坐标轴旋转的量：滚转角－俯仰角－偏航角(roll-pitch-yaw)，此时可以使用$[r,p,y]^T$这样一个三维向量描述任意旋转。</p>\n<p>欧拉角的一个重大缺点就是万向锁问题：在俯仰角为±90度时，第一次旋转与第三次旋转将使用同一个轴，这被称为奇异性问题。由于欧拉角不适于插值和迭代，所以在SLAM问题中通常不使用欧拉角来表示旋转，所以不再展开记录。</p>\n<h2 id=\"四元数\"><a href=\"#四元数\" class=\"headerlink\" title=\"四元数\"></a>四元数</h2><p>旋转矩阵具有冗余性，欧拉角和旋转向量不冗余但是具有奇异性。其实，我们找不到不带奇异性的三维向量描述方式。<br>四元数只有四个自由度，即是紧凑的而且没有奇异性。它是一种扩展的复数的表达方式。缺点是不够直观，运算稍复杂。</p>\n<p>四元数q拥有一个实部和三个虚部。如下：</p>\n<p>$q=q_0+q_1i+q_2j+q_3k$</p>\n<p>其中：</p>\n<p>$\\left{ \\begin{array}{ll} i^2=j^2=k^2=−1\\ ij=k,ji=−k \\jk=i,kj=−i,ki=j,ik=−j\\end{array} \\right.​$</p>\n<blockquote>\n<p>我们可以用单位四元数表示三维空间中的任意一个旋转。</p>\n</blockquote>\n<p>假设某个旋转绕单位向量$n=[n_x,n_y,n_z]^T$进行了角度$θ$的旋转，那么对应的四元数为：</p>\n<p>$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$</p>\n<p>反之也可以从单位四元数中计算出对应旋转轴和夹角：</p>\n<p>$\\left{ \\begin{array}{ll} θ=2arccosq_0\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$</p>\n<p>对$θ$加上$2π$可以得到一个相同的旋转，但此时对应的四元数变成了$−q$。因此任意的旋转都可以由两个互为相反数的四元数表示，即两个互为相反数的四元数可以表示同一个旋转。</p>\n<h3 id=\"四元数的运算\"><a href=\"#四元数的运算\" class=\"headerlink\" title=\"四元数的运算\"></a>四元数的运算</h3><p>见《视觉SLAM十四讲》P55，不再做记录。</p>\n<h3 id=\"四元数表示旋转\"><a href=\"#四元数表示旋转\" class=\"headerlink\" title=\"四元数表示旋转\"></a>四元数表示旋转</h3><p>假设空间中有一点$p=[x,y,z]$，，其绕旋转轴$n$，进行了角度为$θ$的旋转得到了点$p′$，使用旋转矩阵表述有：</p>\n<p>$p′=Rp$。</p>\n<p>使用四元数描述旋转该如何表达？首先，把三维空间点用一个虚四元数表示：</p>\n<p>$p=[0,x,y,z]=[0,v]$</p>\n<p>相当于把四元数的3个虚部与空间中的3个轴相对应。然后，由前述公式可知，用四元数$q$表示该旋转：</p>\n<p>$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$</p>\n<p>则可以验证：<br>$p′=qpq^{−1}$</p>\n<p>最终结果实部为0,故为纯虚四元数，其虚部的3个分量表示旋转后的3D点的坐标。</p>\n<h3 id=\"四元数到旋转矩阵的转换\"><a href=\"#四元数到旋转矩阵的转换\" class=\"headerlink\" title=\"四元数到旋转矩阵的转换\"></a>四元数到旋转矩阵的转换</h3><p>设四元数$q=q_0+q_1i+q_2j+q_3k$，对应的旋转矩阵$R$为：</p>\n<p>$R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&amp;2q_1q_2-2q_0q_3&amp;2q_1q_3+2q_0q_2\\2q_1q_2+2q_0q_3&amp;1-2q^2_1-2q^2_3&amp;2q_2q_3-2q_0q_1\\2q_1q_3-2q_0q_2&amp;2q_2q_3+2q_0q_1&amp;1-2q^2_1-2q^2_2\\end{array} \\right]$</p>\n<p>反之，假设旋转矩阵为$R={m_{ij}},i,j\\epsilon[1,2,3]$，其对应的四元数$q$为：</p>\n<p>$q<em>0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m</em>{23}-m<em>{32}}{4q_0},q_2=\\frac{m</em>{31}-m<em>{13}}{4q_0},q_3=\\frac{m</em>{12}-m_{21}}{4q_0}​$</p>\n<p>注意：实际编程中，当$q_0$的值接近0时，其它3个分量会非常大，导致解不稳定，此时可以再考虑使用其他方式进行转换。</p>\n<h2 id=\"旋转的四种表示方法比较\"><a href=\"#旋转的四种表示方法比较\" class=\"headerlink\" title=\"旋转的四种表示方法比较\"></a>旋转的四种表示方法比较</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">表示方法</th>\n<th style=\"text-align:center\">形式</th>\n<th style=\"text-align:center\">是否奇异性</th>\n<th style=\"text-align:center\">分量数目</th>\n<th style=\"text-align:center\">紧凑or冗余程度</th>\n<th style=\"text-align:center\">直观性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">旋转矩阵</td>\n<td style=\"text-align:center\">$R$</td>\n<td style=\"text-align:center\">否</td>\n<td style=\"text-align:center\">9</td>\n<td style=\"text-align:center\">冗余</td>\n<td style=\"text-align:center\">不直观</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">旋转向量</td>\n<td style=\"text-align:center\">$\\theta{n}$</td>\n<td style=\"text-align:center\">是</td>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">较紧凑</td>\n<td style=\"text-align:center\">不直观</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">欧拉角</td>\n<td style=\"text-align:center\">$[r,p,y]^T$</td>\n<td style=\"text-align:center\">是</td>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">较紧凑</td>\n<td style=\"text-align:center\">直观</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">四元数</td>\n<td style=\"text-align:center\">$q=q_0+q_1i+q_2j+q_3k$</td>\n<td style=\"text-align:center\">否</td>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">较紧凑</td>\n<td style=\"text-align:center\">较不直观</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"旋转的四种表示方法间互相转换\"><a href=\"#旋转的四种表示方法间互相转换\" class=\"headerlink\" title=\"旋转的四种表示方法间互相转换\"></a>旋转的四种表示方法间互相转换</h2><p>1.矩阵转换成其他方式</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">旋转矩阵 <strong>$R={m_{ij}},i,j\\epsilon[1,2,3]$</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>旋转向量</strong></td>\n<td style=\"text-align:center\">$θ=arccos(\\frac{tr(R)−1}2)$；求解方程$Rn=n$，归一化处理得到旋转轴n</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>欧拉</strong>角</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>四元数</strong></td>\n<td style=\"text-align:center\">$q<em>0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m</em>{23}-m<em>{32}}{4q_0},q_2=\\frac{m</em>{31}-m<em>{13}}{4q_0},q_3=\\frac{m</em>{12}-m_{21}}{4q_0}$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2.向量转换成其他方式</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">旋转向量  <strong>$θn$</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>旋转矩阵</strong></td>\n<td style=\"text-align:center\">$R=cosθI+(1−cosθ)nn^T+sinθ[n]^\\wedge$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>欧拉角</strong></td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>四元数</strong></td>\n<td style=\"text-align:center\">$q=[cos\\fracθ2,n_xsin\\fracθ2,n_ysin\\fracθ2,n_zsin\\fracθ2]$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>3.数转换成其他方式</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">四元数 <strong>$q=q_0+q_1i+q_2j+q_3k$</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>旋转矩阵</strong></td>\n<td style=\"text-align:center\">$R=\\left[ \\begin{array}{ccc}1-2q^2_2-2q^2_3&amp;2q_1q_2-2q_0q_3&amp;2q_1q_3+2q_0q_2\\2q_1q_2+2q_0q_3&amp;1-2q^2_1-2q^2_3&amp;2q_2q_3-2q_0q_1\\2q_1q_3-2q_0q_2&amp;2q_2q_3+2q_0q_1&amp;1-2q^2_1-2q^2_2\\end{array} \\right]$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>旋转向量</strong></td>\n<td style=\"text-align:center\">$\\left{ \\begin{array}{ll} θ=2arccosq_0\\ [n_x,n_y,n_z]^T=\\frac{[q_1,q_2,q_3]^T}{sin\\fracθ2}\\end{array} \\right.$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>欧拉角</strong></td>\n<td style=\"text-align:center\">-</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>《视觉SLAM十四讲》第二讲、第三讲</li>\n<li><a href=\"zhehangt.win/2017/02/24/SLAM/RigidMotion/\">一索哥传奇-《三维空间中的刚体运动》</a></li>\n</ol>"},{"title":"视觉SLAM十四讲阅读笔记三-单目相机中的对极几何","date":"2018-08-24T15:14:43.000Z","mathjax":true,"copyright":true,"_content":"\n----\n\n这篇文章是视觉SLAM十四讲第7讲对极几何部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。\n\n<!--more--->\n\n## 概述\n\n在特征提取和匹配任务完成后，我们希望根据匹配的点对估计相机的运动。但是由于相机原理的不同需要采取不同的方法：\n\n- 对于单目相机，只知道2D的像素坐标，所以问题是根据**两组2D点**估计相机运动。该问题用对极几何解决。\n- 对于双目、RGB-D相机，或经某种方法得到了距离信息，问题就可以根据**两组3D点**估计运动。该问题用ICP解决。\n- 如果有3D点及其在相机的投影位置，也能估计相机的运动。该问题用PnP求解。\n\n在ORB_SLAM2系统中，单目初始化过程会使用专门的初始化器完成由两帧图像完成的初始化，该过程使用先后两帧满足关键点数条件的图像帧，使用对极几何约束方法进行求解，得到基础矩阵和单应矩阵，估计出相机的位姿；接着会使用三角测量，计算图像帧中特征点的空间位置。再往后的处理过程，在LocalMapping线程也会使用对极约束、三角测量生成新的地图点。因此，对极约束和三角测量在ORB_SLAM2系统中有着举足轻重的地位，有必要深入学习一下。\n\n## 对极约束\n\n假设得到了一堆匹配好的特征点，如下图所示。如果由若干对（具体多少呢？）这样的匹配点，就可以通过这些二维图像点的对应关系，恢复出在两帧之间相机的运动（位姿）。\n\n{% asset_img 对极几何约束.png %}\n\n在第一帧（左）图像的坐标系下，设$P$的空间位置为：\n\n$P=[X,Y,Z]^T$\n\n根据针孔相机模型可以得到两个像素点（特征点）$p_1$，$p_2$的像素位置为：\n\n$s_1p_1=KP$，$s_2p_2=K(RP+t)$\n\n其中$K$为相机内参矩阵，$R$，$t$为两个坐标系的相机运动，$s1$和$s2$分别表示两个像素点的深度。使用齐次坐标，可以把上式写成在乘以非零常数下成立的等式：\n\n$p_1=KP$，$p_2=K(RP+t)$\n\n在2D-2D问题中，我们只有像素坐标$p_1$和$p_2$，$P$是未知的，那该怎么办？ 此时可以引入一个归一化坐标的概念。取：\n\n$x_1=K^{-1}p_1$，$x_2=K^{-1}p_2$\n\n其中$x_1$，$x_2$是两个像素点的归一化平面上的坐标。带入上式，得：\n\n$x_2=Rx_1+t$\n\n两边同时左乘$t^\\wedge$，根据$^\\wedge$的定义，相当于两侧同时与$t$做外积：\n\n$t^\\wedge x_2=t^\\wedge Rx_1$\n\n两侧同时左乘$x^T_2$：\n\n$x^T_2t^\\wedge x_2=x^T_2t^\\wedge Rx_1$\n\n等式左侧$t^\\wedge x_2$是一个与$t$和$x_2$都垂直的向量，再和$x_2$做内积时，将得到0。因此，有如下简洁的式子：\n\n$x^T_2t^\\wedge Rx_1=0$\n\n重新代入$p_1$，$p_2$，有：\n\n$p^T_2K^{-T}t^\\wedge RK^{-1}p_1=0$\n\n上述两个式子都称为**对极约束**，其几何意义是$O_1$，$P_1$，$O_2$三者共面。对极约束中同时包含了平移和旋转。把中间部分分别记作两个矩阵：**基础矩阵（Fundamental Matrix）$F$**和**本质矩阵（Essential Matrix）$E$**：\n\n$E=t^\\wedge R$，$F=K^{-T}EK^{-1}$\n\n化简得到简化的对极约束：\n\n$x^T_2Ex_1=p^T_2Fp_1=0$\n\n对极约束简洁地给出了两个匹配点的空间位置关系。于是，相机位姿估计问题变为以下两步：\n\n1. 根据配对点的像素位置求出$E$或者$F$；\n2. 根据$E$或者$F$求出$R$，$t$。\n\n由于$E$和$F$相差了相机内参，而内参在SLAM中通常是已知的，所以实践中往往使用形式更加简单的$E$，当然了ORB_SLAM2中使用的是基础矩阵和单应矩阵。\n\n## 本质矩阵$E$求解\n\n本质矩阵$E=t^\\wedge R$，它是一个$3×3$的矩阵，内有9个未知数。从$E$的构造方式看，它由几个重要的特性：\n\n1. 本质矩阵是由对极约束定义的。由于对极约束是**等式为0**的约束，所以对$E$乘以任何非零常数后，**对极约束依然满足**。这一点被称为**E在不同尺度下是等价的**。\n2. 根据$E=t^\\wedge R$，可以证明，本质矩阵$E$的奇异值必定式$[\\sigma, \\sigma,0]^T$。这称为**本质矩阵的内在性质**。可以理解为：一个$3×3$的矩阵是本征矩阵的充要条件是对它奇异值分解后，它有两个相等的奇异值，并且第三个奇异值为0。\n3. 由于平移和旋转各有3个自由度，所以$t^\\wedge R$共有6个自由度。但由于尺度等价性，故$E$实际上只有5个自由度。\n\n现在，考虑一对匹配点的像素坐标$x_1$为$[u_1,v_1,1]$，$x_2$为$[u_2,v_2,1]$，则根据对极约束有：\n\n$\\left[ \\begin{matrix}u_1,v_1,1\\end{matrix} \\right]\\left[ \\begin{matrix}e_1 & e_2 &e_3\\\\ e_4 &  e_5 & e_6 \\\\e_7&e_8&e_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_2,v_2,1\\\\\\end{matrix} \\right]=0$\n\n另把矩阵$E$展开，写成向量的形式：\n\n$e=\\left[ \\begin{matrix}e_1,e_2,...,e_9\\end{matrix} \\right]^T$\n\n对极约束可以写成与$e$有关的线性形式：\n\n$\\left[ \\begin{matrix}u_1u_2,u_1v_2,u_1,v_1u_2,v_1v_2,v_1,u_2,v_2,1\\end{matrix} \\right]·e=0$\n\n对于这个线性方程，存在尺度等价性，即对$e$乘以任何常数，等式仍然成立。因此即使$e$有9个未知变量，只需要8个方程，构成**线程方程组**即可对$e$进行求解。这就是求解本质矩阵最经典的**八点法**。至此，我们求得了本质矩阵$E$。接下来的问题是如何根据已知估得的本质矩阵，恢复出相机的运动$R$，$t$。这个过程由奇异值分解（SVD）完成。设$E$的SVD分解为：\n\n$E=UΣV^T$\n\n根据$U$，$V$为正交阵，$Σ$为奇异值矩阵，即$Σ=diag(\\sigma, \\sigma,0)$。在SVD分解中，对于任意一个$E$，存在两个可能的$t$，$R$与它对应：\n\n$t^\\wedge_1=UR_Z(\\frac{\\pi}2)ΣU^T,R_1=UR^T_Z(\\frac{\\pi}2)V^T$\n\n$t^\\wedge_2=UR_Z(-\\frac{\\pi}2)ΣU^T,R_2=UR^T_Z(-\\frac{\\pi}2)V^T$\n\n其中$R_Z(\\frac{\\pi}2)$表示绕$Z$轴旋转90度得到的旋转矩阵。由于$-E$,$E$等价，所以对任意一个$t$取负号，也会得到同样的结果。因此，从$E$分解到$t$,$R$时，一共存在4个可能的解。如下图所示。\n\n{% asset_img 本质矩阵的解.png%}\n\n幸运的是，只有一种解中$P$在两个相机中都具有正的深度。因此，只要把任意一点代入四种解中，检测该点在两个相机下的深度，就可以确定哪个解是正确的。用用\n\n> 利用本质矩阵的内在性质，它只有5个自由度，所以最小可以通过5对点来求解相机运动。然而这种做法形式复杂，从工程实现角度考虑，平时通常会有几十对甚至上百对匹配点，从8对减到5对意义并不明显。\n\n因为一些误差的存在，通过8点法计算得到的本质矩阵$E$可能不会严格满足本质矩阵的特性2，因此通常会对奇异值矩阵$Σ$做调整。通常的做法是，对八点法求得的$E$进行SVD分解后，会得到奇异值矩阵$Σ=diag(σ1,σ2,σ3)$。不妨设$σ1≥σ2≥σ3$，取：\n\n$ E=Udiag(\\frac{σ1+σ2}2,\\frac{σ1+σ2}2,0)V^T $\n\n这相当于是把求出来的矩阵投影到了$E$所在的流形上。由于$E$具有尺度等价性，因此更简单的做法是将奇异值矩阵取为$diag(1,1,0)$。\n\n## 单应矩阵$H$\n\n除了基本矩阵和本质矩阵T，还有一种单应矩阵$H$(Homography)，它描述了两个平面之间的映射关系。若场景中的特征点都落同一个平面上（比如墙，地面等），则可以通过单应性来进行运动估计。\n\n**单应矩阵通常描述处于共同平面上的一些点（3D点共面）在两张图像之间的变换关系。**\n\n考虑两帧图像上匹配到的特征点$p_1$，$p_2$，这些特征点落在平面$P$上，设这个平面满足方程：\n\n$n^TP+d=0$\n\n则：\n\n$-\\frac{n^TP}d=1$\n\n推理可得：\n\n$p_2=K(R−\\frac{tn^T}d)K^{−1}p_1$\n\n这里就得到了一个直接描述图像坐标$p_1$，$p_2$之间的变换，把中间这部分**记作$H$**（3×3矩阵），则有：\n\n$p_2=Hp_1$\n\n单应矩阵的定义与旋转、平移以及平面的参数有关。对上式展开可得：\n\n$\\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}h_1 & h_2 &h_3\\\\ h_4 &  h_5 & h_6 \\\\h_7&h_8&h_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_1\\\\v_1\\\\1\\\\\\end{matrix} \\right]$\n\n 转换为：\n\n$u_2=\\frac{h_1v_1+h_2v_1+h_3}{h_7v_1+h_8v_1+h_9}$\n\n$v_2=\\frac{h_4v_1+h_5v_1+h_6}{h_7v_1+h_8v_1+h_9}$\n\n这样一组匹配点就可以构造2个方程。因为像素坐标为齐次坐标，所以单应矩阵乘以任意常数项，等式仍然成立。因此即使单应矩阵的未知变量为9个，但其自由度为8。因此需要**4组匹配点**，构造8个方程，来对单应矩阵进行求解。与本质矩阵相似，求出单应矩阵后需要对其进行分解，才可以得到相应的旋转矩阵$R$和平移向量$t$。\n\n> 单应性在SLAM中具有重要意义。当特征点共面时或相机发生纯旋转时，基础矩阵的自由度下降，这就出现了所谓的退化。这时候继续用8点法求解基础矩阵会导致受到噪声的影响增加。**为了避免这种情况，通常会同时估计基础矩阵$F$和单应矩阵$H$，选择重投影误差比较小的那个作为最终的运动估计矩阵。**\n\n## 讨论--对极约束方法的局限性\n\n### 尺度不确定性\n\n首先由于E具有尺度等价性，因此它分解得到的$t$和$R$也有一个尺度等价性。而$R∈SO(3)$自身具有约束，因此可以认为$t$也具有尺度等价性。$t$的尺度等价性直接导致$t$的大小与现实世界中平移的大小并不是对应的。也就是说在单目SLAM中，每次都要确定$t$的尺度，通常的做法是对$t$进行归一化。这称为单目SLAM的**初始化**。**初始化之后就可以用3D-2D来计算相机运动，初始化之后的轨迹和地图的单位，就是初始化时固定的尺度。 **\n\n> 1. 如何理解上述最后一句话表达的过程？\n>\n>    答：参见总结。\n>\n> 2. 如何理解“$t$的尺度等价性”和“初始化时固定尺度”？\n>\n>    答：参见参考资料3后面的内容。\n\n### 初始化的纯旋转问题\n\n即使可以用单应矩阵来处理纯旋转的情况，但是由于纯旋转缺少位移，因此无法对空间点进行三角化。也就是说对于单目SLAM来说，初始化必须要有位移。\n\n### 多于8对点的情况\n\n最后我们提到用8点法求解本质矩阵。但是实际中往往匹配点会远远多于8对，此时有两种求解思路。 当匹配正确率比较高的时候，可以构造**最小二乘**。当匹配错误率比较高的时候，可以用**随机采样一致性（RANSAC）**求解。\n\n## 总结\n\n由于对极几何方法需要使用8个或者8个以上的点对，并且存在上述需要初始化、纯旋转和尺度不确定性等问题。如果两帧图像中其中一帧图像特征点的3D位置已知，则最少可以使用3对点对（需要至少一个额外点验证结果）就可以估计相机运动。特征点的3D位置可以由三角化或者RGB-D相机的深度图确定。因此：\n\n1. 双目或RGB-D的视觉里程计中，可以直接使用PnP估计相机运动。\n2. 单目视觉里程计中，必须先进行初始化（这样就有了3D点），然后才能使用PnP。\n\n## 参考资料\n\n1. 视觉SLAM十四讲第7讲\n2. [单目相机中的对极几何](http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/)\n3. [Monocular slam 的理论基础(1)](https://blog.csdn.net/heyijia0327/article/details/50758944)\n4. [视觉slam十四讲学习笔记](https://blog.csdn.net/David_Han008/article/details/53560736)","source":"_posts/视觉SLAM十四讲阅读笔记三-对极几何.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记三-单目相机中的对极几何\ndate: 2018-08-24 23:14:43\ntags: \n  - 对极几何\n  - 2D-2D\n  - 单目SLAM\n  - SLAM基础\n  - 读书笔记\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n----\n\n这篇文章是视觉SLAM十四讲第7讲对极几何部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。\n\n<!--more--->\n\n## 概述\n\n在特征提取和匹配任务完成后，我们希望根据匹配的点对估计相机的运动。但是由于相机原理的不同需要采取不同的方法：\n\n- 对于单目相机，只知道2D的像素坐标，所以问题是根据**两组2D点**估计相机运动。该问题用对极几何解决。\n- 对于双目、RGB-D相机，或经某种方法得到了距离信息，问题就可以根据**两组3D点**估计运动。该问题用ICP解决。\n- 如果有3D点及其在相机的投影位置，也能估计相机的运动。该问题用PnP求解。\n\n在ORB_SLAM2系统中，单目初始化过程会使用专门的初始化器完成由两帧图像完成的初始化，该过程使用先后两帧满足关键点数条件的图像帧，使用对极几何约束方法进行求解，得到基础矩阵和单应矩阵，估计出相机的位姿；接着会使用三角测量，计算图像帧中特征点的空间位置。再往后的处理过程，在LocalMapping线程也会使用对极约束、三角测量生成新的地图点。因此，对极约束和三角测量在ORB_SLAM2系统中有着举足轻重的地位，有必要深入学习一下。\n\n## 对极约束\n\n假设得到了一堆匹配好的特征点，如下图所示。如果由若干对（具体多少呢？）这样的匹配点，就可以通过这些二维图像点的对应关系，恢复出在两帧之间相机的运动（位姿）。\n\n{% asset_img 对极几何约束.png %}\n\n在第一帧（左）图像的坐标系下，设$P$的空间位置为：\n\n$P=[X,Y,Z]^T$\n\n根据针孔相机模型可以得到两个像素点（特征点）$p_1$，$p_2$的像素位置为：\n\n$s_1p_1=KP$，$s_2p_2=K(RP+t)$\n\n其中$K$为相机内参矩阵，$R$，$t$为两个坐标系的相机运动，$s1$和$s2$分别表示两个像素点的深度。使用齐次坐标，可以把上式写成在乘以非零常数下成立的等式：\n\n$p_1=KP$，$p_2=K(RP+t)$\n\n在2D-2D问题中，我们只有像素坐标$p_1$和$p_2$，$P$是未知的，那该怎么办？ 此时可以引入一个归一化坐标的概念。取：\n\n$x_1=K^{-1}p_1$，$x_2=K^{-1}p_2$\n\n其中$x_1$，$x_2$是两个像素点的归一化平面上的坐标。带入上式，得：\n\n$x_2=Rx_1+t$\n\n两边同时左乘$t^\\wedge$，根据$^\\wedge$的定义，相当于两侧同时与$t$做外积：\n\n$t^\\wedge x_2=t^\\wedge Rx_1$\n\n两侧同时左乘$x^T_2$：\n\n$x^T_2t^\\wedge x_2=x^T_2t^\\wedge Rx_1$\n\n等式左侧$t^\\wedge x_2$是一个与$t$和$x_2$都垂直的向量，再和$x_2$做内积时，将得到0。因此，有如下简洁的式子：\n\n$x^T_2t^\\wedge Rx_1=0$\n\n重新代入$p_1$，$p_2$，有：\n\n$p^T_2K^{-T}t^\\wedge RK^{-1}p_1=0$\n\n上述两个式子都称为**对极约束**，其几何意义是$O_1$，$P_1$，$O_2$三者共面。对极约束中同时包含了平移和旋转。把中间部分分别记作两个矩阵：**基础矩阵（Fundamental Matrix）$F$**和**本质矩阵（Essential Matrix）$E$**：\n\n$E=t^\\wedge R$，$F=K^{-T}EK^{-1}$\n\n化简得到简化的对极约束：\n\n$x^T_2Ex_1=p^T_2Fp_1=0$\n\n对极约束简洁地给出了两个匹配点的空间位置关系。于是，相机位姿估计问题变为以下两步：\n\n1. 根据配对点的像素位置求出$E$或者$F$；\n2. 根据$E$或者$F$求出$R$，$t$。\n\n由于$E$和$F$相差了相机内参，而内参在SLAM中通常是已知的，所以实践中往往使用形式更加简单的$E$，当然了ORB_SLAM2中使用的是基础矩阵和单应矩阵。\n\n## 本质矩阵$E$求解\n\n本质矩阵$E=t^\\wedge R$，它是一个$3×3$的矩阵，内有9个未知数。从$E$的构造方式看，它由几个重要的特性：\n\n1. 本质矩阵是由对极约束定义的。由于对极约束是**等式为0**的约束，所以对$E$乘以任何非零常数后，**对极约束依然满足**。这一点被称为**E在不同尺度下是等价的**。\n2. 根据$E=t^\\wedge R$，可以证明，本质矩阵$E$的奇异值必定式$[\\sigma, \\sigma,0]^T$。这称为**本质矩阵的内在性质**。可以理解为：一个$3×3$的矩阵是本征矩阵的充要条件是对它奇异值分解后，它有两个相等的奇异值，并且第三个奇异值为0。\n3. 由于平移和旋转各有3个自由度，所以$t^\\wedge R$共有6个自由度。但由于尺度等价性，故$E$实际上只有5个自由度。\n\n现在，考虑一对匹配点的像素坐标$x_1$为$[u_1,v_1,1]$，$x_2$为$[u_2,v_2,1]$，则根据对极约束有：\n\n$\\left[ \\begin{matrix}u_1,v_1,1\\end{matrix} \\right]\\left[ \\begin{matrix}e_1 & e_2 &e_3\\\\ e_4 &  e_5 & e_6 \\\\e_7&e_8&e_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_2,v_2,1\\\\\\end{matrix} \\right]=0$\n\n另把矩阵$E$展开，写成向量的形式：\n\n$e=\\left[ \\begin{matrix}e_1,e_2,...,e_9\\end{matrix} \\right]^T$\n\n对极约束可以写成与$e$有关的线性形式：\n\n$\\left[ \\begin{matrix}u_1u_2,u_1v_2,u_1,v_1u_2,v_1v_2,v_1,u_2,v_2,1\\end{matrix} \\right]·e=0$\n\n对于这个线性方程，存在尺度等价性，即对$e$乘以任何常数，等式仍然成立。因此即使$e$有9个未知变量，只需要8个方程，构成**线程方程组**即可对$e$进行求解。这就是求解本质矩阵最经典的**八点法**。至此，我们求得了本质矩阵$E$。接下来的问题是如何根据已知估得的本质矩阵，恢复出相机的运动$R$，$t$。这个过程由奇异值分解（SVD）完成。设$E$的SVD分解为：\n\n$E=UΣV^T$\n\n根据$U$，$V$为正交阵，$Σ$为奇异值矩阵，即$Σ=diag(\\sigma, \\sigma,0)$。在SVD分解中，对于任意一个$E$，存在两个可能的$t$，$R$与它对应：\n\n$t^\\wedge_1=UR_Z(\\frac{\\pi}2)ΣU^T,R_1=UR^T_Z(\\frac{\\pi}2)V^T$\n\n$t^\\wedge_2=UR_Z(-\\frac{\\pi}2)ΣU^T,R_2=UR^T_Z(-\\frac{\\pi}2)V^T$\n\n其中$R_Z(\\frac{\\pi}2)$表示绕$Z$轴旋转90度得到的旋转矩阵。由于$-E$,$E$等价，所以对任意一个$t$取负号，也会得到同样的结果。因此，从$E$分解到$t$,$R$时，一共存在4个可能的解。如下图所示。\n\n{% asset_img 本质矩阵的解.png%}\n\n幸运的是，只有一种解中$P$在两个相机中都具有正的深度。因此，只要把任意一点代入四种解中，检测该点在两个相机下的深度，就可以确定哪个解是正确的。用用\n\n> 利用本质矩阵的内在性质，它只有5个自由度，所以最小可以通过5对点来求解相机运动。然而这种做法形式复杂，从工程实现角度考虑，平时通常会有几十对甚至上百对匹配点，从8对减到5对意义并不明显。\n\n因为一些误差的存在，通过8点法计算得到的本质矩阵$E$可能不会严格满足本质矩阵的特性2，因此通常会对奇异值矩阵$Σ$做调整。通常的做法是，对八点法求得的$E$进行SVD分解后，会得到奇异值矩阵$Σ=diag(σ1,σ2,σ3)$。不妨设$σ1≥σ2≥σ3$，取：\n\n$ E=Udiag(\\frac{σ1+σ2}2,\\frac{σ1+σ2}2,0)V^T $\n\n这相当于是把求出来的矩阵投影到了$E$所在的流形上。由于$E$具有尺度等价性，因此更简单的做法是将奇异值矩阵取为$diag(1,1,0)$。\n\n## 单应矩阵$H$\n\n除了基本矩阵和本质矩阵T，还有一种单应矩阵$H$(Homography)，它描述了两个平面之间的映射关系。若场景中的特征点都落同一个平面上（比如墙，地面等），则可以通过单应性来进行运动估计。\n\n**单应矩阵通常描述处于共同平面上的一些点（3D点共面）在两张图像之间的变换关系。**\n\n考虑两帧图像上匹配到的特征点$p_1$，$p_2$，这些特征点落在平面$P$上，设这个平面满足方程：\n\n$n^TP+d=0$\n\n则：\n\n$-\\frac{n^TP}d=1$\n\n推理可得：\n\n$p_2=K(R−\\frac{tn^T}d)K^{−1}p_1$\n\n这里就得到了一个直接描述图像坐标$p_1$，$p_2$之间的变换，把中间这部分**记作$H$**（3×3矩阵），则有：\n\n$p_2=Hp_1$\n\n单应矩阵的定义与旋转、平移以及平面的参数有关。对上式展开可得：\n\n$\\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}h_1 & h_2 &h_3\\\\ h_4 &  h_5 & h_6 \\\\h_7&h_8&h_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_1\\\\v_1\\\\1\\\\\\end{matrix} \\right]$\n\n 转换为：\n\n$u_2=\\frac{h_1v_1+h_2v_1+h_3}{h_7v_1+h_8v_1+h_9}$\n\n$v_2=\\frac{h_4v_1+h_5v_1+h_6}{h_7v_1+h_8v_1+h_9}$\n\n这样一组匹配点就可以构造2个方程。因为像素坐标为齐次坐标，所以单应矩阵乘以任意常数项，等式仍然成立。因此即使单应矩阵的未知变量为9个，但其自由度为8。因此需要**4组匹配点**，构造8个方程，来对单应矩阵进行求解。与本质矩阵相似，求出单应矩阵后需要对其进行分解，才可以得到相应的旋转矩阵$R$和平移向量$t$。\n\n> 单应性在SLAM中具有重要意义。当特征点共面时或相机发生纯旋转时，基础矩阵的自由度下降，这就出现了所谓的退化。这时候继续用8点法求解基础矩阵会导致受到噪声的影响增加。**为了避免这种情况，通常会同时估计基础矩阵$F$和单应矩阵$H$，选择重投影误差比较小的那个作为最终的运动估计矩阵。**\n\n## 讨论--对极约束方法的局限性\n\n### 尺度不确定性\n\n首先由于E具有尺度等价性，因此它分解得到的$t$和$R$也有一个尺度等价性。而$R∈SO(3)$自身具有约束，因此可以认为$t$也具有尺度等价性。$t$的尺度等价性直接导致$t$的大小与现实世界中平移的大小并不是对应的。也就是说在单目SLAM中，每次都要确定$t$的尺度，通常的做法是对$t$进行归一化。这称为单目SLAM的**初始化**。**初始化之后就可以用3D-2D来计算相机运动，初始化之后的轨迹和地图的单位，就是初始化时固定的尺度。 **\n\n> 1. 如何理解上述最后一句话表达的过程？\n>\n>    答：参见总结。\n>\n> 2. 如何理解“$t$的尺度等价性”和“初始化时固定尺度”？\n>\n>    答：参见参考资料3后面的内容。\n\n### 初始化的纯旋转问题\n\n即使可以用单应矩阵来处理纯旋转的情况，但是由于纯旋转缺少位移，因此无法对空间点进行三角化。也就是说对于单目SLAM来说，初始化必须要有位移。\n\n### 多于8对点的情况\n\n最后我们提到用8点法求解本质矩阵。但是实际中往往匹配点会远远多于8对，此时有两种求解思路。 当匹配正确率比较高的时候，可以构造**最小二乘**。当匹配错误率比较高的时候，可以用**随机采样一致性（RANSAC）**求解。\n\n## 总结\n\n由于对极几何方法需要使用8个或者8个以上的点对，并且存在上述需要初始化、纯旋转和尺度不确定性等问题。如果两帧图像中其中一帧图像特征点的3D位置已知，则最少可以使用3对点对（需要至少一个额外点验证结果）就可以估计相机运动。特征点的3D位置可以由三角化或者RGB-D相机的深度图确定。因此：\n\n1. 双目或RGB-D的视觉里程计中，可以直接使用PnP估计相机运动。\n2. 单目视觉里程计中，必须先进行初始化（这样就有了3D点），然后才能使用PnP。\n\n## 参考资料\n\n1. 视觉SLAM十四讲第7讲\n2. [单目相机中的对极几何](http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/)\n3. [Monocular slam 的理论基础(1)](https://blog.csdn.net/heyijia0327/article/details/50758944)\n4. [视觉slam十四讲学习笔记](https://blog.csdn.net/David_Han008/article/details/53560736)","slug":"视觉SLAM十四讲阅读笔记三-对极几何","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0900cnqlcrfpb95n1r","content":"<hr>\n<p>这篇文章是视觉SLAM十四讲第7讲对极几何部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>在特征提取和匹配任务完成后，我们希望根据匹配的点对估计相机的运动。但是由于相机原理的不同需要采取不同的方法：</p>\n<ul>\n<li>对于单目相机，只知道2D的像素坐标，所以问题是根据<strong>两组2D点</strong>估计相机运动。该问题用对极几何解决。</li>\n<li>对于双目、RGB-D相机，或经某种方法得到了距离信息，问题就可以根据<strong>两组3D点</strong>估计运动。该问题用ICP解决。</li>\n<li>如果有3D点及其在相机的投影位置，也能估计相机的运动。该问题用PnP求解。</li>\n</ul>\n<p>在ORB_SLAM2系统中，单目初始化过程会使用专门的初始化器完成由两帧图像完成的初始化，该过程使用先后两帧满足关键点数条件的图像帧，使用对极几何约束方法进行求解，得到基础矩阵和单应矩阵，估计出相机的位姿；接着会使用三角测量，计算图像帧中特征点的空间位置。再往后的处理过程，在LocalMapping线程也会使用对极约束、三角测量生成新的地图点。因此，对极约束和三角测量在ORB_SLAM2系统中有着举足轻重的地位，有必要深入学习一下。</p>\n<h2 id=\"对极约束\"><a href=\"#对极约束\" class=\"headerlink\" title=\"对极约束\"></a>对极约束</h2><p>假设得到了一堆匹配好的特征点，如下图所示。如果由若干对（具体多少呢？）这样的匹配点，就可以通过这些二维图像点的对应关系，恢复出在两帧之间相机的运动（位姿）。</p>\n<img src=\"/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/对极几何约束.png\">\n<p>在第一帧（左）图像的坐标系下，设$P$的空间位置为：</p>\n<p>$P=[X,Y,Z]^T$</p>\n<p>根据针孔相机模型可以得到两个像素点（特征点）$p_1$，$p_2$的像素位置为：</p>\n<p>$s_1p_1=KP$，$s_2p_2=K(RP+t)$</p>\n<p>其中$K$为相机内参矩阵，$R$，$t$为两个坐标系的相机运动，$s1$和$s2$分别表示两个像素点的深度。使用齐次坐标，可以把上式写成在乘以非零常数下成立的等式：</p>\n<p>$p_1=KP$，$p_2=K(RP+t)$</p>\n<p>在2D-2D问题中，我们只有像素坐标$p_1$和$p_2$，$P$是未知的，那该怎么办？ 此时可以引入一个归一化坐标的概念。取：</p>\n<p>$x_1=K^{-1}p_1$，$x_2=K^{-1}p_2$</p>\n<p>其中$x_1$，$x_2$是两个像素点的归一化平面上的坐标。带入上式，得：</p>\n<p>$x_2=Rx_1+t$</p>\n<p>两边同时左乘$t^\\wedge$，根据$^\\wedge$的定义，相当于两侧同时与$t$做外积：</p>\n<p>$t^\\wedge x_2=t^\\wedge Rx_1$</p>\n<p>两侧同时左乘$x^T_2$：</p>\n<p>$x^T_2t^\\wedge x_2=x^T_2t^\\wedge Rx_1$</p>\n<p>等式左侧$t^\\wedge x_2$是一个与$t$和$x_2$都垂直的向量，再和$x_2$做内积时，将得到0。因此，有如下简洁的式子：</p>\n<p>$x^T_2t^\\wedge Rx_1=0$</p>\n<p>重新代入$p_1$，$p_2$，有：</p>\n<p>$p^T_2K^{-T}t^\\wedge RK^{-1}p_1=0$</p>\n<p>上述两个式子都称为<strong>对极约束</strong>，其几何意义是$O_1$，$P_1$，$O_2$三者共面。对极约束中同时包含了平移和旋转。把中间部分分别记作两个矩阵：<strong>基础矩阵（Fundamental Matrix）$F$</strong>和<strong>本质矩阵（Essential Matrix）$E$</strong>：</p>\n<p>$E=t^\\wedge R$，$F=K^{-T}EK^{-1}$</p>\n<p>化简得到简化的对极约束：</p>\n<p>$x^T_2Ex_1=p^T_2Fp_1=0$</p>\n<p>对极约束简洁地给出了两个匹配点的空间位置关系。于是，相机位姿估计问题变为以下两步：</p>\n<ol>\n<li>根据配对点的像素位置求出$E$或者$F$；</li>\n<li>根据$E$或者$F$求出$R$，$t$。</li>\n</ol>\n<p>由于$E$和$F$相差了相机内参，而内参在SLAM中通常是已知的，所以实践中往往使用形式更加简单的$E$，当然了ORB_SLAM2中使用的是基础矩阵和单应矩阵。</p>\n<h2 id=\"本质矩阵-E-求解\"><a href=\"#本质矩阵-E-求解\" class=\"headerlink\" title=\"本质矩阵$E$求解\"></a>本质矩阵$E$求解</h2><p>本质矩阵$E=t^\\wedge R$，它是一个$3×3$的矩阵，内有9个未知数。从$E$的构造方式看，它由几个重要的特性：</p>\n<ol>\n<li>本质矩阵是由对极约束定义的。由于对极约束是<strong>等式为0</strong>的约束，所以对$E$乘以任何非零常数后，<strong>对极约束依然满足</strong>。这一点被称为<strong>E在不同尺度下是等价的</strong>。</li>\n<li>根据$E=t^\\wedge R$，可以证明，本质矩阵$E$的奇异值必定式$[\\sigma, \\sigma,0]^T$。这称为<strong>本质矩阵的内在性质</strong>。可以理解为：一个$3×3$的矩阵是本征矩阵的充要条件是对它奇异值分解后，它有两个相等的奇异值，并且第三个奇异值为0。</li>\n<li>由于平移和旋转各有3个自由度，所以$t^\\wedge R$共有6个自由度。但由于尺度等价性，故$E$实际上只有5个自由度。</li>\n</ol>\n<p>现在，考虑一对匹配点的像素坐标$x_1$为$[u_1,v_1,1]$，$x_2$为$[u_2,v_2,1]$，则根据对极约束有：</p>\n<p>$\\left[ \\begin{matrix}u_1,v_1,1\\end{matrix} \\right]\\left[ \\begin{matrix}e_1 &amp; e_2 &amp;e_3\\ e_4 &amp;  e_5 &amp; e_6 \\e_7&amp;e_8&amp;e_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_2,v_2,1\\\\end{matrix} \\right]=0$</p>\n<p>另把矩阵$E$展开，写成向量的形式：</p>\n<p>$e=\\left[ \\begin{matrix}e_1,e_2,…,e_9\\end{matrix} \\right]^T$</p>\n<p>对极约束可以写成与$e$有关的线性形式：</p>\n<p>$\\left[ \\begin{matrix}u_1u_2,u_1v_2,u_1,v_1u_2,v_1v_2,v_1,u_2,v_2,1\\end{matrix} \\right]·e=0$</p>\n<p>对于这个线性方程，存在尺度等价性，即对$e$乘以任何常数，等式仍然成立。因此即使$e$有9个未知变量，只需要8个方程，构成<strong>线程方程组</strong>即可对$e$进行求解。这就是求解本质矩阵最经典的<strong>八点法</strong>。至此，我们求得了本质矩阵$E$。接下来的问题是如何根据已知估得的本质矩阵，恢复出相机的运动$R$，$t$。这个过程由奇异值分解（SVD）完成。设$E$的SVD分解为：</p>\n<p>$E=UΣV^T$</p>\n<p>根据$U$，$V$为正交阵，$Σ$为奇异值矩阵，即$Σ=diag(\\sigma, \\sigma,0)$。在SVD分解中，对于任意一个$E$，存在两个可能的$t$，$R$与它对应：</p>\n<p>$t^\\wedge_1=UR_Z(\\frac{\\pi}2)ΣU^T,R_1=UR^T_Z(\\frac{\\pi}2)V^T$</p>\n<p>$t^\\wedge_2=UR_Z(-\\frac{\\pi}2)ΣU^T,R_2=UR^T_Z(-\\frac{\\pi}2)V^T$</p>\n<p>其中$R_Z(\\frac{\\pi}2)$表示绕$Z$轴旋转90度得到的旋转矩阵。由于$-E$,$E$等价，所以对任意一个$t$取负号，也会得到同样的结果。因此，从$E$分解到$t$,$R$时，一共存在4个可能的解。如下图所示。</p>\n<img src=\"/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/本质矩阵的解.png\">\n<p>幸运的是，只有一种解中$P$在两个相机中都具有正的深度。因此，只要把任意一点代入四种解中，检测该点在两个相机下的深度，就可以确定哪个解是正确的。用用</p>\n<blockquote>\n<p>利用本质矩阵的内在性质，它只有5个自由度，所以最小可以通过5对点来求解相机运动。然而这种做法形式复杂，从工程实现角度考虑，平时通常会有几十对甚至上百对匹配点，从8对减到5对意义并不明显。</p>\n</blockquote>\n<p>因为一些误差的存在，通过8点法计算得到的本质矩阵$E$可能不会严格满足本质矩阵的特性2，因此通常会对奇异值矩阵$Σ$做调整。通常的做法是，对八点法求得的$E$进行SVD分解后，会得到奇异值矩阵$Σ=diag(σ1,σ2,σ3)$。不妨设$σ1≥σ2≥σ3$，取：</p>\n<p>$ E=Udiag(\\frac{σ1+σ2}2,\\frac{σ1+σ2}2,0)V^T $</p>\n<p>这相当于是把求出来的矩阵投影到了$E$所在的流形上。由于$E$具有尺度等价性，因此更简单的做法是将奇异值矩阵取为$diag(1,1,0)$。</p>\n<h2 id=\"单应矩阵-H\"><a href=\"#单应矩阵-H\" class=\"headerlink\" title=\"单应矩阵$H$\"></a>单应矩阵$H$</h2><p>除了基本矩阵和本质矩阵T，还有一种单应矩阵$H$(Homography)，它描述了两个平面之间的映射关系。若场景中的特征点都落同一个平面上（比如墙，地面等），则可以通过单应性来进行运动估计。</p>\n<p><strong>单应矩阵通常描述处于共同平面上的一些点（3D点共面）在两张图像之间的变换关系。</strong></p>\n<p>考虑两帧图像上匹配到的特征点$p_1$，$p_2$，这些特征点落在平面$P$上，设这个平面满足方程：</p>\n<p>$n^TP+d=0$</p>\n<p>则：</p>\n<p>$-\\frac{n^TP}d=1$</p>\n<p>推理可得：</p>\n<p>$p_2=K(R−\\frac{tn^T}d)K^{−1}p_1$</p>\n<p>这里就得到了一个直接描述图像坐标$p_1$，$p_2$之间的变换，把中间这部分<strong>记作$H$</strong>（3×3矩阵），则有：</p>\n<p>$p_2=Hp_1$</p>\n<p>单应矩阵的定义与旋转、平移以及平面的参数有关。对上式展开可得：</p>\n<p>$\\left[ \\begin{matrix}u_2\\v_2\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}h_1 &amp; h_2 &amp;h_3\\ h_4 &amp;  h_5 &amp; h_6 \\h_7&amp;h_8&amp;h_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_1\\v_1\\1\\\\end{matrix} \\right]$</p>\n<p> 转换为：</p>\n<p>$u_2=\\frac{h_1v_1+h_2v_1+h_3}{h_7v_1+h_8v_1+h_9}$</p>\n<p>$v_2=\\frac{h_4v_1+h_5v_1+h_6}{h_7v_1+h_8v_1+h_9}$</p>\n<p>这样一组匹配点就可以构造2个方程。因为像素坐标为齐次坐标，所以单应矩阵乘以任意常数项，等式仍然成立。因此即使单应矩阵的未知变量为9个，但其自由度为8。因此需要<strong>4组匹配点</strong>，构造8个方程，来对单应矩阵进行求解。与本质矩阵相似，求出单应矩阵后需要对其进行分解，才可以得到相应的旋转矩阵$R$和平移向量$t$。</p>\n<blockquote>\n<p>单应性在SLAM中具有重要意义。当特征点共面时或相机发生纯旋转时，基础矩阵的自由度下降，这就出现了所谓的退化。这时候继续用8点法求解基础矩阵会导致受到噪声的影响增加。<strong>为了避免这种情况，通常会同时估计基础矩阵$F$和单应矩阵$H$，选择重投影误差比较小的那个作为最终的运动估计矩阵。</strong></p>\n</blockquote>\n<h2 id=\"讨论—对极约束方法的局限性\"><a href=\"#讨论—对极约束方法的局限性\" class=\"headerlink\" title=\"讨论—对极约束方法的局限性\"></a>讨论—对极约束方法的局限性</h2><h3 id=\"尺度不确定性\"><a href=\"#尺度不确定性\" class=\"headerlink\" title=\"尺度不确定性\"></a>尺度不确定性</h3><p>首先由于E具有尺度等价性，因此它分解得到的$t$和$R$也有一个尺度等价性。而$R∈SO(3)$自身具有约束，因此可以认为$t$也具有尺度等价性。$t$的尺度等价性直接导致$t$的大小与现实世界中平移的大小并不是对应的。也就是说在单目SLAM中，每次都要确定$t$的尺度，通常的做法是对$t$进行归一化。这称为单目SLAM的<strong>初始化</strong>。<strong>初始化之后就可以用3D-2D来计算相机运动，初始化之后的轨迹和地图的单位，就是初始化时固定的尺度。 </strong></p>\n<blockquote>\n<ol>\n<li><p>如何理解上述最后一句话表达的过程？</p>\n<p>答：参见总结。</p>\n</li>\n<li><p>如何理解“$t$的尺度等价性”和“初始化时固定尺度”？</p>\n<p>答：参见参考资料3后面的内容。</p>\n</li>\n</ol>\n</blockquote>\n<h3 id=\"初始化的纯旋转问题\"><a href=\"#初始化的纯旋转问题\" class=\"headerlink\" title=\"初始化的纯旋转问题\"></a>初始化的纯旋转问题</h3><p>即使可以用单应矩阵来处理纯旋转的情况，但是由于纯旋转缺少位移，因此无法对空间点进行三角化。也就是说对于单目SLAM来说，初始化必须要有位移。</p>\n<h3 id=\"多于8对点的情况\"><a href=\"#多于8对点的情况\" class=\"headerlink\" title=\"多于8对点的情况\"></a>多于8对点的情况</h3><p>最后我们提到用8点法求解本质矩阵。但是实际中往往匹配点会远远多于8对，此时有两种求解思路。 当匹配正确率比较高的时候，可以构造<strong>最小二乘</strong>。当匹配错误率比较高的时候，可以用<strong>随机采样一致性（RANSAC）</strong>求解。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>由于对极几何方法需要使用8个或者8个以上的点对，并且存在上述需要初始化、纯旋转和尺度不确定性等问题。如果两帧图像中其中一帧图像特征点的3D位置已知，则最少可以使用3对点对（需要至少一个额外点验证结果）就可以估计相机运动。特征点的3D位置可以由三角化或者RGB-D相机的深度图确定。因此：</p>\n<ol>\n<li>双目或RGB-D的视觉里程计中，可以直接使用PnP估计相机运动。</li>\n<li>单目视觉里程计中，必须先进行初始化（这样就有了3D点），然后才能使用PnP。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉SLAM十四讲第7讲</li>\n<li><a href=\"http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/\" target=\"_blank\" rel=\"noopener\">单目相机中的对极几何</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/50758944\" target=\"_blank\" rel=\"noopener\">Monocular slam 的理论基础(1)</a></li>\n<li><a href=\"https://blog.csdn.net/David_Han008/article/details/53560736\" target=\"_blank\" rel=\"noopener\">视觉slam十四讲学习笔记</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是视觉SLAM十四讲第7讲对极几何部分阅读过程中总结和记录的学习内容，属于单目SLAM的基础理论内容。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>在特征提取和匹配任务完成后，我们希望根据匹配的点对估计相机的运动。但是由于相机原理的不同需要采取不同的方法：</p>\n<ul>\n<li>对于单目相机，只知道2D的像素坐标，所以问题是根据<strong>两组2D点</strong>估计相机运动。该问题用对极几何解决。</li>\n<li>对于双目、RGB-D相机，或经某种方法得到了距离信息，问题就可以根据<strong>两组3D点</strong>估计运动。该问题用ICP解决。</li>\n<li>如果有3D点及其在相机的投影位置，也能估计相机的运动。该问题用PnP求解。</li>\n</ul>\n<p>在ORB_SLAM2系统中，单目初始化过程会使用专门的初始化器完成由两帧图像完成的初始化，该过程使用先后两帧满足关键点数条件的图像帧，使用对极几何约束方法进行求解，得到基础矩阵和单应矩阵，估计出相机的位姿；接着会使用三角测量，计算图像帧中特征点的空间位置。再往后的处理过程，在LocalMapping线程也会使用对极约束、三角测量生成新的地图点。因此，对极约束和三角测量在ORB_SLAM2系统中有着举足轻重的地位，有必要深入学习一下。</p>\n<h2 id=\"对极约束\"><a href=\"#对极约束\" class=\"headerlink\" title=\"对极约束\"></a>对极约束</h2><p>假设得到了一堆匹配好的特征点，如下图所示。如果由若干对（具体多少呢？）这样的匹配点，就可以通过这些二维图像点的对应关系，恢复出在两帧之间相机的运动（位姿）。</p>\n<img src=\"/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/对极几何约束.png\">\n<p>在第一帧（左）图像的坐标系下，设$P$的空间位置为：</p>\n<p>$P=[X,Y,Z]^T$</p>\n<p>根据针孔相机模型可以得到两个像素点（特征点）$p_1$，$p_2$的像素位置为：</p>\n<p>$s_1p_1=KP$，$s_2p_2=K(RP+t)$</p>\n<p>其中$K$为相机内参矩阵，$R$，$t$为两个坐标系的相机运动，$s1$和$s2$分别表示两个像素点的深度。使用齐次坐标，可以把上式写成在乘以非零常数下成立的等式：</p>\n<p>$p_1=KP$，$p_2=K(RP+t)$</p>\n<p>在2D-2D问题中，我们只有像素坐标$p_1$和$p_2$，$P$是未知的，那该怎么办？ 此时可以引入一个归一化坐标的概念。取：</p>\n<p>$x_1=K^{-1}p_1$，$x_2=K^{-1}p_2$</p>\n<p>其中$x_1$，$x_2$是两个像素点的归一化平面上的坐标。带入上式，得：</p>\n<p>$x_2=Rx_1+t$</p>\n<p>两边同时左乘$t^\\wedge$，根据$^\\wedge$的定义，相当于两侧同时与$t$做外积：</p>\n<p>$t^\\wedge x_2=t^\\wedge Rx_1$</p>\n<p>两侧同时左乘$x^T_2$：</p>\n<p>$x^T_2t^\\wedge x_2=x^T_2t^\\wedge Rx_1$</p>\n<p>等式左侧$t^\\wedge x_2$是一个与$t$和$x_2$都垂直的向量，再和$x_2$做内积时，将得到0。因此，有如下简洁的式子：</p>\n<p>$x^T_2t^\\wedge Rx_1=0$</p>\n<p>重新代入$p_1$，$p_2$，有：</p>\n<p>$p^T_2K^{-T}t^\\wedge RK^{-1}p_1=0$</p>\n<p>上述两个式子都称为<strong>对极约束</strong>，其几何意义是$O_1$，$P_1$，$O_2$三者共面。对极约束中同时包含了平移和旋转。把中间部分分别记作两个矩阵：<strong>基础矩阵（Fundamental Matrix）$F$</strong>和<strong>本质矩阵（Essential Matrix）$E$</strong>：</p>\n<p>$E=t^\\wedge R$，$F=K^{-T}EK^{-1}$</p>\n<p>化简得到简化的对极约束：</p>\n<p>$x^T_2Ex_1=p^T_2Fp_1=0$</p>\n<p>对极约束简洁地给出了两个匹配点的空间位置关系。于是，相机位姿估计问题变为以下两步：</p>\n<ol>\n<li>根据配对点的像素位置求出$E$或者$F$；</li>\n<li>根据$E$或者$F$求出$R$，$t$。</li>\n</ol>\n<p>由于$E$和$F$相差了相机内参，而内参在SLAM中通常是已知的，所以实践中往往使用形式更加简单的$E$，当然了ORB_SLAM2中使用的是基础矩阵和单应矩阵。</p>\n<h2 id=\"本质矩阵-E-求解\"><a href=\"#本质矩阵-E-求解\" class=\"headerlink\" title=\"本质矩阵$E$求解\"></a>本质矩阵$E$求解</h2><p>本质矩阵$E=t^\\wedge R$，它是一个$3×3$的矩阵，内有9个未知数。从$E$的构造方式看，它由几个重要的特性：</p>\n<ol>\n<li>本质矩阵是由对极约束定义的。由于对极约束是<strong>等式为0</strong>的约束，所以对$E$乘以任何非零常数后，<strong>对极约束依然满足</strong>。这一点被称为<strong>E在不同尺度下是等价的</strong>。</li>\n<li>根据$E=t^\\wedge R$，可以证明，本质矩阵$E$的奇异值必定式$[\\sigma, \\sigma,0]^T$。这称为<strong>本质矩阵的内在性质</strong>。可以理解为：一个$3×3$的矩阵是本征矩阵的充要条件是对它奇异值分解后，它有两个相等的奇异值，并且第三个奇异值为0。</li>\n<li>由于平移和旋转各有3个自由度，所以$t^\\wedge R$共有6个自由度。但由于尺度等价性，故$E$实际上只有5个自由度。</li>\n</ol>\n<p>现在，考虑一对匹配点的像素坐标$x_1$为$[u_1,v_1,1]$，$x_2$为$[u_2,v_2,1]$，则根据对极约束有：</p>\n<p>$\\left[ \\begin{matrix}u_1,v_1,1\\end{matrix} \\right]\\left[ \\begin{matrix}e_1 &amp; e_2 &amp;e_3\\ e_4 &amp;  e_5 &amp; e_6 \\e_7&amp;e_8&amp;e_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_2,v_2,1\\\\end{matrix} \\right]=0$</p>\n<p>另把矩阵$E$展开，写成向量的形式：</p>\n<p>$e=\\left[ \\begin{matrix}e_1,e_2,…,e_9\\end{matrix} \\right]^T$</p>\n<p>对极约束可以写成与$e$有关的线性形式：</p>\n<p>$\\left[ \\begin{matrix}u_1u_2,u_1v_2,u_1,v_1u_2,v_1v_2,v_1,u_2,v_2,1\\end{matrix} \\right]·e=0$</p>\n<p>对于这个线性方程，存在尺度等价性，即对$e$乘以任何常数，等式仍然成立。因此即使$e$有9个未知变量，只需要8个方程，构成<strong>线程方程组</strong>即可对$e$进行求解。这就是求解本质矩阵最经典的<strong>八点法</strong>。至此，我们求得了本质矩阵$E$。接下来的问题是如何根据已知估得的本质矩阵，恢复出相机的运动$R$，$t$。这个过程由奇异值分解（SVD）完成。设$E$的SVD分解为：</p>\n<p>$E=UΣV^T$</p>\n<p>根据$U$，$V$为正交阵，$Σ$为奇异值矩阵，即$Σ=diag(\\sigma, \\sigma,0)$。在SVD分解中，对于任意一个$E$，存在两个可能的$t$，$R$与它对应：</p>\n<p>$t^\\wedge_1=UR_Z(\\frac{\\pi}2)ΣU^T,R_1=UR^T_Z(\\frac{\\pi}2)V^T$</p>\n<p>$t^\\wedge_2=UR_Z(-\\frac{\\pi}2)ΣU^T,R_2=UR^T_Z(-\\frac{\\pi}2)V^T$</p>\n<p>其中$R_Z(\\frac{\\pi}2)$表示绕$Z$轴旋转90度得到的旋转矩阵。由于$-E$,$E$等价，所以对任意一个$t$取负号，也会得到同样的结果。因此，从$E$分解到$t$,$R$时，一共存在4个可能的解。如下图所示。</p>\n<img src=\"/2018/08/24/视觉SLAM十四讲阅读笔记三-对极几何/本质矩阵的解.png\">\n<p>幸运的是，只有一种解中$P$在两个相机中都具有正的深度。因此，只要把任意一点代入四种解中，检测该点在两个相机下的深度，就可以确定哪个解是正确的。用用</p>\n<blockquote>\n<p>利用本质矩阵的内在性质，它只有5个自由度，所以最小可以通过5对点来求解相机运动。然而这种做法形式复杂，从工程实现角度考虑，平时通常会有几十对甚至上百对匹配点，从8对减到5对意义并不明显。</p>\n</blockquote>\n<p>因为一些误差的存在，通过8点法计算得到的本质矩阵$E$可能不会严格满足本质矩阵的特性2，因此通常会对奇异值矩阵$Σ$做调整。通常的做法是，对八点法求得的$E$进行SVD分解后，会得到奇异值矩阵$Σ=diag(σ1,σ2,σ3)$。不妨设$σ1≥σ2≥σ3$，取：</p>\n<p>$ E=Udiag(\\frac{σ1+σ2}2,\\frac{σ1+σ2}2,0)V^T $</p>\n<p>这相当于是把求出来的矩阵投影到了$E$所在的流形上。由于$E$具有尺度等价性，因此更简单的做法是将奇异值矩阵取为$diag(1,1,0)$。</p>\n<h2 id=\"单应矩阵-H\"><a href=\"#单应矩阵-H\" class=\"headerlink\" title=\"单应矩阵$H$\"></a>单应矩阵$H$</h2><p>除了基本矩阵和本质矩阵T，还有一种单应矩阵$H$(Homography)，它描述了两个平面之间的映射关系。若场景中的特征点都落同一个平面上（比如墙，地面等），则可以通过单应性来进行运动估计。</p>\n<p><strong>单应矩阵通常描述处于共同平面上的一些点（3D点共面）在两张图像之间的变换关系。</strong></p>\n<p>考虑两帧图像上匹配到的特征点$p_1$，$p_2$，这些特征点落在平面$P$上，设这个平面满足方程：</p>\n<p>$n^TP+d=0$</p>\n<p>则：</p>\n<p>$-\\frac{n^TP}d=1$</p>\n<p>推理可得：</p>\n<p>$p_2=K(R−\\frac{tn^T}d)K^{−1}p_1$</p>\n<p>这里就得到了一个直接描述图像坐标$p_1$，$p_2$之间的变换，把中间这部分<strong>记作$H$</strong>（3×3矩阵），则有：</p>\n<p>$p_2=Hp_1$</p>\n<p>单应矩阵的定义与旋转、平移以及平面的参数有关。对上式展开可得：</p>\n<p>$\\left[ \\begin{matrix}u_2\\v_2\\1\\end{matrix} \\right]=\\left[ \\begin{matrix}h_1 &amp; h_2 &amp;h_3\\ h_4 &amp;  h_5 &amp; h_6 \\h_7&amp;h_8&amp;h_9  \\end{matrix} \\right]\\left [\\begin{matrix}u_1\\v_1\\1\\\\end{matrix} \\right]$</p>\n<p> 转换为：</p>\n<p>$u_2=\\frac{h_1v_1+h_2v_1+h_3}{h_7v_1+h_8v_1+h_9}$</p>\n<p>$v_2=\\frac{h_4v_1+h_5v_1+h_6}{h_7v_1+h_8v_1+h_9}$</p>\n<p>这样一组匹配点就可以构造2个方程。因为像素坐标为齐次坐标，所以单应矩阵乘以任意常数项，等式仍然成立。因此即使单应矩阵的未知变量为9个，但其自由度为8。因此需要<strong>4组匹配点</strong>，构造8个方程，来对单应矩阵进行求解。与本质矩阵相似，求出单应矩阵后需要对其进行分解，才可以得到相应的旋转矩阵$R$和平移向量$t$。</p>\n<blockquote>\n<p>单应性在SLAM中具有重要意义。当特征点共面时或相机发生纯旋转时，基础矩阵的自由度下降，这就出现了所谓的退化。这时候继续用8点法求解基础矩阵会导致受到噪声的影响增加。<strong>为了避免这种情况，通常会同时估计基础矩阵$F$和单应矩阵$H$，选择重投影误差比较小的那个作为最终的运动估计矩阵。</strong></p>\n</blockquote>\n<h2 id=\"讨论—对极约束方法的局限性\"><a href=\"#讨论—对极约束方法的局限性\" class=\"headerlink\" title=\"讨论—对极约束方法的局限性\"></a>讨论—对极约束方法的局限性</h2><h3 id=\"尺度不确定性\"><a href=\"#尺度不确定性\" class=\"headerlink\" title=\"尺度不确定性\"></a>尺度不确定性</h3><p>首先由于E具有尺度等价性，因此它分解得到的$t$和$R$也有一个尺度等价性。而$R∈SO(3)$自身具有约束，因此可以认为$t$也具有尺度等价性。$t$的尺度等价性直接导致$t$的大小与现实世界中平移的大小并不是对应的。也就是说在单目SLAM中，每次都要确定$t$的尺度，通常的做法是对$t$进行归一化。这称为单目SLAM的<strong>初始化</strong>。<strong>初始化之后就可以用3D-2D来计算相机运动，初始化之后的轨迹和地图的单位，就是初始化时固定的尺度。 </strong></p>\n<blockquote>\n<ol>\n<li><p>如何理解上述最后一句话表达的过程？</p>\n<p>答：参见总结。</p>\n</li>\n<li><p>如何理解“$t$的尺度等价性”和“初始化时固定尺度”？</p>\n<p>答：参见参考资料3后面的内容。</p>\n</li>\n</ol>\n</blockquote>\n<h3 id=\"初始化的纯旋转问题\"><a href=\"#初始化的纯旋转问题\" class=\"headerlink\" title=\"初始化的纯旋转问题\"></a>初始化的纯旋转问题</h3><p>即使可以用单应矩阵来处理纯旋转的情况，但是由于纯旋转缺少位移，因此无法对空间点进行三角化。也就是说对于单目SLAM来说，初始化必须要有位移。</p>\n<h3 id=\"多于8对点的情况\"><a href=\"#多于8对点的情况\" class=\"headerlink\" title=\"多于8对点的情况\"></a>多于8对点的情况</h3><p>最后我们提到用8点法求解本质矩阵。但是实际中往往匹配点会远远多于8对，此时有两种求解思路。 当匹配正确率比较高的时候，可以构造<strong>最小二乘</strong>。当匹配错误率比较高的时候，可以用<strong>随机采样一致性（RANSAC）</strong>求解。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>由于对极几何方法需要使用8个或者8个以上的点对，并且存在上述需要初始化、纯旋转和尺度不确定性等问题。如果两帧图像中其中一帧图像特征点的3D位置已知，则最少可以使用3对点对（需要至少一个额外点验证结果）就可以估计相机运动。特征点的3D位置可以由三角化或者RGB-D相机的深度图确定。因此：</p>\n<ol>\n<li>双目或RGB-D的视觉里程计中，可以直接使用PnP估计相机运动。</li>\n<li>单目视觉里程计中，必须先进行初始化（这样就有了3D点），然后才能使用PnP。</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉SLAM十四讲第7讲</li>\n<li><a href=\"http://zhehangt.win/2017/03/05/SLAM/EpipolarGeometry/\" target=\"_blank\" rel=\"noopener\">单目相机中的对极几何</a></li>\n<li><a href=\"https://blog.csdn.net/heyijia0327/article/details/50758944\" target=\"_blank\" rel=\"noopener\">Monocular slam 的理论基础(1)</a></li>\n<li><a href=\"https://blog.csdn.net/David_Han008/article/details/53560736\" target=\"_blank\" rel=\"noopener\">视觉slam十四讲学习笔记</a></li>\n</ol>"},{"title":"视觉SLAM十四讲阅读笔记二-SLAM问题的数学表述与经典框架","date":"2018-08-05T09:06:22.000Z","mathjax":true,"copyright":true,"_content":"\n-----\n\n这篇文章是视觉SLAM十四讲第2讲阅读过程中总结和记录的学习内容。\n\n<!--more-->\n\n## SLAM问题提出\n\nSLAM问题可以描述为：机器人在某个未知环境中从某个未知位置开始移动，在移动过程中根据传感器数据进行自身定位估计，同时在自身定位的基础上增量式构造地图，从而实现机器人对未知环境的地图构建和在地图中对自身的位置进行定位。对于机器人来说，SLAM主要回答了两个问题：1）我在什么地方？（**定位**） 2）周围环境是怎么样的？（**建图**），即机器人一方面要明白自身的**状态（即位置）**，另一方面也要了解外在的**环境（即地图）**。SLAM问题的本质：对运动主体自身和周围环境空间不确定性的估计。\n\n\n\n## SLAM问题的数学表述\n\nSLAM要回答这两个问题，机器人需要通过传感器采集数据，然后根据这些数据推断出自身的位姿信息和所处的环境信息。\n\n携带传感器的机器人在某未知环境中运动，由于相机通常是在某些时刻采集数据的，所以我们只关心这些时刻的位置和地图。这样就把一段连续时间的运动变成离散时刻$t=1,...,K$当中发生的事情。在这些时刻，用$x$表示小萝卜自身的位置。于是各时刻的位置就记为$x_1,...,x_K$，它们构成了机器人的轨迹。\n\n地图方面，假设地图由许多个**路标（landmark）**组成，每个时刻传感器会测量到一部分路标点，设路标点一共有$N$个，用$y_1,...y_N$表示。机器人在某个时间内通过传感器获得一系列连续的传感器数据（路标点的观测数据），即观测值$z$。依据机器人所配备的传感器，观测值$z$可以是激光雷达（laser）数据、图像数据、里程计（odometer）数据和惯性导航单元（IMU）数据等。\n\n### 运动方程\n\nSLAM需要解决的就是通过观测值$z$评估系统状态$x$。系统状态通常包含两部分，一部分用于表示机器人在环境中的位置，另一部分用于表示环境地图。通常，机器人会携带一个测量自身运动的传感器，比如里程计。因此可以构造一个评估函数，利用当前获得的传感器数据（不一定直接就是位置之差，还可能是加速度、角速度等信息），从前一时刻的系统状态评估当前时刻的系统状态，通用、抽象的数学模型如下所示：\n\n$x_k=f(x_{k-1},u_k,\\omega_k)$\n\n$u_k$是运动传感器的数据（或称为输入），$w_k$为噪声。这里的$f$指代一种计算模型，当输入的运动传感器类型不同时，$f$的具体形式会千差万别。我们通常把它称为**运动方程**。\n\n### 观测方程\n\n与运动方程相对应是**观测方程**。观测方程描述的是当机器人在$x_k$位置上利用传感器感知环境，看到了某个路标点$y_j$，产生了观测数据$z_{k,j}$。此处同样用一个抽象的函数$h$来表述这个关系：\n\n$z_{k,j}=h(y_j,x_k,\\upsilon_{k,j})$\n\n这里$v_k$表示此次观测的噪声。由于观测所用的传感器形式更多，因此这里的观测数据$z$以及观测方程$h$也有许多不同的形式。\n\n### 参数化过程\n\n对于上述函数$f$、$h$，我们并没有给出具体的形式，没有具体地说明运动和观测是怎么回事，也不知道$x$、$y$、$z$如何表示的。其实根据机器人的真实运动和传感器的种类，存在着若干种**参数化（Parameterization）**方式。\n\n举例来说，假设机器人在平面运动，其位姿由两个位置和一个转角来描述，即$x_k=[x,y,\\theta]^T_k$。同时，运动传感器能够测量到机器人在任意两个时间间隔位置和转角的变化量$u_k=[\\Delta x,\\Delta y,\\Delta \\theta]^T_k$，所以运动方程就可以具体化为：\n\n$\\left[ \\begin{matrix}x\\\\y\\\\\\theta\\end{matrix} \\right]_k=\\left[ \\begin{matrix}x\\\\y\\\\\\theta\\end{matrix} \\right]_{k-1}+\\left[ \\begin{matrix}\\Delta x\\\\\\Delta y\\\\\\Delta \\theta\\end{matrix} \\right]_k+\\omega_k$\n\n关于观测方程，机器人携带一个二维激光传感器，在激光传感器观测一个2D路标点时，能够测到两个量：路标点和机器人本体之间的距离$r$和夹角$\\phi$，所以观测方程具体化为：\n\n$\\left[ \\begin{matrix}r\\\\\\phi\\end{matrix} \\right]=\\left[ \\begin{matrix}\\sqrt{(p_x-x)^2+(p_y-y)^2}\\\\ arctan(\\frac{p_y-y}{p_x-x})\\end{matrix} \\right]+\\upsilon$\n\n在视觉SLAM中，传感器是相机，那么观测方程就是“对路标点拍摄后，得到图像中的像素”的过程。该过程牵扯到相机模型的描述，在后续的阅读中再详细记录。\n\n### 最基本的SLAM问题\n\n综上所述，针对不同的传感器，运动和观测方程会有不同的参数化形式。如果保持它们的通用性，取成通用的抽象形式，那么SLAM过程就可以表述为两个基本方程：\n\n$\\left\\{ \\begin{array}{ll} x_k=f(x_{k-1},u_k,\\omega_k)\\\\ z_{k,j}=h(y_j,x_k,\\upsilon_{k,j})\\end{array} \\right.$\n\n这两个方程描述了最基本的SLAM问题：当知道运动测量的读数$u$，以及传感器的读数$z$时，如果求解定位问题（估计$x$）h和建图问题（估计$y$）。即其中$z$和$u$是已知的，当选定了传感器，运动方程和观测方程也是已知的，因此SLAM求解的目标就是对$x$和$y$进行估计，使得**运动方程**和**观测方程**等式两边尽可能的成立。这时，就把SLAM问题建模为一个状态估计问题：如何通过带有噪声的测量数据，估计内部的、隐藏的状态变量。\n\n> 疑问：观测方程和运动方程会同时用到吗？视觉SLAM只用到观测方程？？？\n>\n> 视觉SLAM中：\n>\n> - 观测方程。就是“对路标点拍摄后，得到图像中的像素”的过程。具体来说，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。 \n> - 运动方程。SLAM系统中视觉里程计（VO）估计了两张图像间相机的运动，只需把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。\n\n### 后续深入理解\n\n本篇文章对SLAM问题的数学建模有了大致的了解，然而仍需深入理解一些问题。\n\n1. 如何说明**机器人的位置$x$是什么，即如何表达位姿**。对于三维空间中的机器人来说，其运动要由3个轴上的平移，以及绕着3个轴的旋转来描述，一共有6个自由度。那是否意味着随便用一个$ℝ^6$中的向量就可以描述它呢？其实并没那么简单。对6自由度的位姿（包括了旋转和平移），如何表达的问题涉及到三维空间刚体运动的问题，会在其他文章中详细介绍；\n2. **如何对位姿进行估计和优化。**因为在SLAM中位姿是未知的，而我们需要解决什么样的相机位姿最符合当前观测数据这样的问题，一种经典的解决方式是把它们构成一个优化问题，求解最优的$R$和$t$，使得误差最小化。而旋转矩阵自身是带有约束的（正交且行列式为1）.它们作为优化变量时，会引入额外的约束，使优化变得困难。通过李群-李代数间的转换关系，我们希望把位姿估计变成无约束的优化问题，以简化求解方式。涉及到李群和李代数会在后续记录；\n2. **视觉SLAM中观测方程如何参数化。**即空间中的路标点是如何投影到一张照片上的，这就需要解释相机的成像模型；\n3. **如何求解运动、观测方程。**需要用到非线性优化的知识。\n\n## SLAM问题的求解思路\n\n从应用的角度来看，SLAM问题涉及很多方面，包括传感器的选择，对$x$的估计方式，地图的表示形式等。\n从传感器的角度来讲，SLAM依赖的传感器主要包括激光传感器和视觉传感器两大类。\n从X的估计方式来讲，SLAM的求解思路主要包括基于滤波的求解和基于非线性优化的求解。目前普遍认为非线性优化的方法要由于滤波方法。\n从地图的表示形式来讲，SLAM得到的地图表示方式主要分为度量地图与拓扑地图，度量地图有二维，三维，稀疏，稠密等多种表现形式。\n\n## 视觉SLAM经典框架\n\n{% asset_img 视觉SLAM经典框架.png  %}\n\n1. 传感器获取。在视觉SLAM中主要为相机图像信息的读取和预处理。\n2. **视觉里程计（Visual Odometry，VO）。**任务是估算相邻图像间相机的运动，以及局部地图的样子，（恢复场景的空间结构）。又称**前端（Front End）**。为了定量地估计相机运动，必须在**了解相机与空间点的几何关系**后进行。视觉里程计估计了两张图像间的相机运动之后，只要把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。另一方面，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。仅仅通过视觉里程计估计轨迹，将不可避免地出现**累计漂移（Accumulatin Drift）**，将导致无法建立一致的地图。为了解决漂移问题，需要用到**后端优化**和**回环检测**，回环检测负责把“机器人回到原始位置”的事情检测出来，后端优化则根据该信息，校正整个轨迹的形状。\n3. **后端优化（Optimization）**。后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。由于接在VO之后，又称为后端（Back End）。笼统地说，它主要是指处理SLAM过程中噪声的问题，即考虑如何从带有噪声的数据中，估计整个系统的状态，以及这个状态估计的不确定性有多大——称为**最大后验概率估计（Maximum-a-Posteriori，MAP）**，这里的状态既包括机器人自身的轨迹，也包括地图。前端为后端提供待优化的数据，以及这些数据的初始值。而后端负责整体的优化过程，往往面对的只有数据，不必关心这些数据到底来自什么传感器。视觉SLAM中，前端和计算机视觉研究领域更为相关，比如图像的特征提取和匹配等，后端则主要是滤波与非线性优化算法。\n4. **回环检测（Loop Closing）**。回环检测判断机器人是否曾经到达过先前的位置。如果检测到回环，它会把信息提供给后端处理。又称闭环检测（Loop Closure Detection），主要解决位置估计随时间漂移的问题。为了实现回环检测，需要让机器人具有识别曾到达过的场景的能力，如果通过机器人通过相机获取的图像来完成这一任务，就可以采取判断图像间相似性的方法。视觉回环检测实质上是一种计算图像数据相似性的算法。\n5. **建图（Mapping）**。它根据估计的轨迹，建立与任务要求对应的地图。建图并没有一个固定的形式和算法，例如地图可以是一组空间点的集合，也可以是一个漂亮的3D模型。大体上分为度量地图和拓扑地图两种，前者更精确，后者则更强调地图元素之间的关系。拓扑地图是一个图，由节点和边组成，只考虑节点间的连通性，而不考虑节点间到达的过程，放松了地图对精确位置的需要，去掉了地图的细节问题，更为紧凑，但不擅长表达具有复杂结构的地图。\n\n## 有待研究问题及主要挑战\n\n1. 拓扑地图不擅长表达具有复杂结构的地图，如何对地图进行分割形成节点和边，又如何使用拓扑地图进行导航和路径规划，有待研究。\n2. 视觉SLAM中，产业化过程中仍需要解决一些关键性难题，比如，如何高效地获得尽可能长而且准确的特征轨迹并将多视频序列之间的复杂回路闭合起来， 如何对于海量图像/视频数据在有限的内存下进行高效的全局优化，如何在动态环境下进行鲁棒的同时定位与地图构建， 如何处理相机快速运动和强旋转， 如何在线动态调整重建的三维几何表面。\n3. 如何对回环序列或多序列进行处理，如何高效率、高精度处理大尺度环境，如何处理动态环境，如何处理快速移动和剧烈旋转的情况？\n4. Covisibility 是一直在用的概念，而Essential Graph是orbslam自己提出的概念，为了减小全局回环的计算量。当你自己实现SLAM时，也会碰到这些困难，并设计一些应对的策略，这些就是你的创新性。事实上，随着SLAM时间的增长，如何控制图的结构和优化的规模，仍是现在SLAM有待解决的一个问题。\n\n## 研究热点\n\n1. 在复杂场景中的三维视觉感知问题，主要包含三个方面：一是如何通过视觉和 IMU 融合，进行滑动窗口内的 Bundle Adjustment，来提高运动估计的准确性、稳定性和鲁棒性；二是如何基于深度学习的方法仅用单目相机来构建稠密的 3D 地图，并用于飞控避障、 AR 虚实融合等；三是如何基于单目视觉惯导融合，来实时跟踪动态物体，并恢复物体的绝对物理尺度。 \n2. 语义SLAM、激光SLAM\n3. 深度学习与SLAM结合，与新的传感器进行融合\n4. 应用领域：自动驾驶、AR、VR、无人机、无人车、扫地机器人\n\n## 热门公司和部门\n\n1. 商汤科技\n2. Momenta\n3. 镭神智能\n4. 图森未来\n5. 纵目科技\n6. 地平线\n7. 旷视科技\n8. [阿里巴巴达摩院AI Labs](https://zhuanlan.zhihu.com/p/41101700)\n\n## 参考资料\n\n1. 《视觉SLAM十四讲》第2讲\n2. [一索哥传奇《SLAM的基本概念》](http://zhehangt.win/2017/03/01/SLAM/ORBSLAM/SLAMConcept/)","source":"_posts/视觉SLAM十四讲阅读笔记二-SLAM的数学表述.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记二-SLAM问题的数学表述与经典框架\ndate: 2018-08-05 17:06:22\ntags:\n  - SLAM基础\n  - 读书笔记\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n-----\n\n这篇文章是视觉SLAM十四讲第2讲阅读过程中总结和记录的学习内容。\n\n<!--more-->\n\n## SLAM问题提出\n\nSLAM问题可以描述为：机器人在某个未知环境中从某个未知位置开始移动，在移动过程中根据传感器数据进行自身定位估计，同时在自身定位的基础上增量式构造地图，从而实现机器人对未知环境的地图构建和在地图中对自身的位置进行定位。对于机器人来说，SLAM主要回答了两个问题：1）我在什么地方？（**定位**） 2）周围环境是怎么样的？（**建图**），即机器人一方面要明白自身的**状态（即位置）**，另一方面也要了解外在的**环境（即地图）**。SLAM问题的本质：对运动主体自身和周围环境空间不确定性的估计。\n\n\n\n## SLAM问题的数学表述\n\nSLAM要回答这两个问题，机器人需要通过传感器采集数据，然后根据这些数据推断出自身的位姿信息和所处的环境信息。\n\n携带传感器的机器人在某未知环境中运动，由于相机通常是在某些时刻采集数据的，所以我们只关心这些时刻的位置和地图。这样就把一段连续时间的运动变成离散时刻$t=1,...,K$当中发生的事情。在这些时刻，用$x$表示小萝卜自身的位置。于是各时刻的位置就记为$x_1,...,x_K$，它们构成了机器人的轨迹。\n\n地图方面，假设地图由许多个**路标（landmark）**组成，每个时刻传感器会测量到一部分路标点，设路标点一共有$N$个，用$y_1,...y_N$表示。机器人在某个时间内通过传感器获得一系列连续的传感器数据（路标点的观测数据），即观测值$z$。依据机器人所配备的传感器，观测值$z$可以是激光雷达（laser）数据、图像数据、里程计（odometer）数据和惯性导航单元（IMU）数据等。\n\n### 运动方程\n\nSLAM需要解决的就是通过观测值$z$评估系统状态$x$。系统状态通常包含两部分，一部分用于表示机器人在环境中的位置，另一部分用于表示环境地图。通常，机器人会携带一个测量自身运动的传感器，比如里程计。因此可以构造一个评估函数，利用当前获得的传感器数据（不一定直接就是位置之差，还可能是加速度、角速度等信息），从前一时刻的系统状态评估当前时刻的系统状态，通用、抽象的数学模型如下所示：\n\n$x_k=f(x_{k-1},u_k,\\omega_k)$\n\n$u_k$是运动传感器的数据（或称为输入），$w_k$为噪声。这里的$f$指代一种计算模型，当输入的运动传感器类型不同时，$f$的具体形式会千差万别。我们通常把它称为**运动方程**。\n\n### 观测方程\n\n与运动方程相对应是**观测方程**。观测方程描述的是当机器人在$x_k$位置上利用传感器感知环境，看到了某个路标点$y_j$，产生了观测数据$z_{k,j}$。此处同样用一个抽象的函数$h$来表述这个关系：\n\n$z_{k,j}=h(y_j,x_k,\\upsilon_{k,j})$\n\n这里$v_k$表示此次观测的噪声。由于观测所用的传感器形式更多，因此这里的观测数据$z$以及观测方程$h$也有许多不同的形式。\n\n### 参数化过程\n\n对于上述函数$f$、$h$，我们并没有给出具体的形式，没有具体地说明运动和观测是怎么回事，也不知道$x$、$y$、$z$如何表示的。其实根据机器人的真实运动和传感器的种类，存在着若干种**参数化（Parameterization）**方式。\n\n举例来说，假设机器人在平面运动，其位姿由两个位置和一个转角来描述，即$x_k=[x,y,\\theta]^T_k$。同时，运动传感器能够测量到机器人在任意两个时间间隔位置和转角的变化量$u_k=[\\Delta x,\\Delta y,\\Delta \\theta]^T_k$，所以运动方程就可以具体化为：\n\n$\\left[ \\begin{matrix}x\\\\y\\\\\\theta\\end{matrix} \\right]_k=\\left[ \\begin{matrix}x\\\\y\\\\\\theta\\end{matrix} \\right]_{k-1}+\\left[ \\begin{matrix}\\Delta x\\\\\\Delta y\\\\\\Delta \\theta\\end{matrix} \\right]_k+\\omega_k$\n\n关于观测方程，机器人携带一个二维激光传感器，在激光传感器观测一个2D路标点时，能够测到两个量：路标点和机器人本体之间的距离$r$和夹角$\\phi$，所以观测方程具体化为：\n\n$\\left[ \\begin{matrix}r\\\\\\phi\\end{matrix} \\right]=\\left[ \\begin{matrix}\\sqrt{(p_x-x)^2+(p_y-y)^2}\\\\ arctan(\\frac{p_y-y}{p_x-x})\\end{matrix} \\right]+\\upsilon$\n\n在视觉SLAM中，传感器是相机，那么观测方程就是“对路标点拍摄后，得到图像中的像素”的过程。该过程牵扯到相机模型的描述，在后续的阅读中再详细记录。\n\n### 最基本的SLAM问题\n\n综上所述，针对不同的传感器，运动和观测方程会有不同的参数化形式。如果保持它们的通用性，取成通用的抽象形式，那么SLAM过程就可以表述为两个基本方程：\n\n$\\left\\{ \\begin{array}{ll} x_k=f(x_{k-1},u_k,\\omega_k)\\\\ z_{k,j}=h(y_j,x_k,\\upsilon_{k,j})\\end{array} \\right.$\n\n这两个方程描述了最基本的SLAM问题：当知道运动测量的读数$u$，以及传感器的读数$z$时，如果求解定位问题（估计$x$）h和建图问题（估计$y$）。即其中$z$和$u$是已知的，当选定了传感器，运动方程和观测方程也是已知的，因此SLAM求解的目标就是对$x$和$y$进行估计，使得**运动方程**和**观测方程**等式两边尽可能的成立。这时，就把SLAM问题建模为一个状态估计问题：如何通过带有噪声的测量数据，估计内部的、隐藏的状态变量。\n\n> 疑问：观测方程和运动方程会同时用到吗？视觉SLAM只用到观测方程？？？\n>\n> 视觉SLAM中：\n>\n> - 观测方程。就是“对路标点拍摄后，得到图像中的像素”的过程。具体来说，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。 \n> - 运动方程。SLAM系统中视觉里程计（VO）估计了两张图像间相机的运动，只需把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。\n\n### 后续深入理解\n\n本篇文章对SLAM问题的数学建模有了大致的了解，然而仍需深入理解一些问题。\n\n1. 如何说明**机器人的位置$x$是什么，即如何表达位姿**。对于三维空间中的机器人来说，其运动要由3个轴上的平移，以及绕着3个轴的旋转来描述，一共有6个自由度。那是否意味着随便用一个$ℝ^6$中的向量就可以描述它呢？其实并没那么简单。对6自由度的位姿（包括了旋转和平移），如何表达的问题涉及到三维空间刚体运动的问题，会在其他文章中详细介绍；\n2. **如何对位姿进行估计和优化。**因为在SLAM中位姿是未知的，而我们需要解决什么样的相机位姿最符合当前观测数据这样的问题，一种经典的解决方式是把它们构成一个优化问题，求解最优的$R$和$t$，使得误差最小化。而旋转矩阵自身是带有约束的（正交且行列式为1）.它们作为优化变量时，会引入额外的约束，使优化变得困难。通过李群-李代数间的转换关系，我们希望把位姿估计变成无约束的优化问题，以简化求解方式。涉及到李群和李代数会在后续记录；\n2. **视觉SLAM中观测方程如何参数化。**即空间中的路标点是如何投影到一张照片上的，这就需要解释相机的成像模型；\n3. **如何求解运动、观测方程。**需要用到非线性优化的知识。\n\n## SLAM问题的求解思路\n\n从应用的角度来看，SLAM问题涉及很多方面，包括传感器的选择，对$x$的估计方式，地图的表示形式等。\n从传感器的角度来讲，SLAM依赖的传感器主要包括激光传感器和视觉传感器两大类。\n从X的估计方式来讲，SLAM的求解思路主要包括基于滤波的求解和基于非线性优化的求解。目前普遍认为非线性优化的方法要由于滤波方法。\n从地图的表示形式来讲，SLAM得到的地图表示方式主要分为度量地图与拓扑地图，度量地图有二维，三维，稀疏，稠密等多种表现形式。\n\n## 视觉SLAM经典框架\n\n{% asset_img 视觉SLAM经典框架.png  %}\n\n1. 传感器获取。在视觉SLAM中主要为相机图像信息的读取和预处理。\n2. **视觉里程计（Visual Odometry，VO）。**任务是估算相邻图像间相机的运动，以及局部地图的样子，（恢复场景的空间结构）。又称**前端（Front End）**。为了定量地估计相机运动，必须在**了解相机与空间点的几何关系**后进行。视觉里程计估计了两张图像间的相机运动之后，只要把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。另一方面，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。仅仅通过视觉里程计估计轨迹，将不可避免地出现**累计漂移（Accumulatin Drift）**，将导致无法建立一致的地图。为了解决漂移问题，需要用到**后端优化**和**回环检测**，回环检测负责把“机器人回到原始位置”的事情检测出来，后端优化则根据该信息，校正整个轨迹的形状。\n3. **后端优化（Optimization）**。后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。由于接在VO之后，又称为后端（Back End）。笼统地说，它主要是指处理SLAM过程中噪声的问题，即考虑如何从带有噪声的数据中，估计整个系统的状态，以及这个状态估计的不确定性有多大——称为**最大后验概率估计（Maximum-a-Posteriori，MAP）**，这里的状态既包括机器人自身的轨迹，也包括地图。前端为后端提供待优化的数据，以及这些数据的初始值。而后端负责整体的优化过程，往往面对的只有数据，不必关心这些数据到底来自什么传感器。视觉SLAM中，前端和计算机视觉研究领域更为相关，比如图像的特征提取和匹配等，后端则主要是滤波与非线性优化算法。\n4. **回环检测（Loop Closing）**。回环检测判断机器人是否曾经到达过先前的位置。如果检测到回环，它会把信息提供给后端处理。又称闭环检测（Loop Closure Detection），主要解决位置估计随时间漂移的问题。为了实现回环检测，需要让机器人具有识别曾到达过的场景的能力，如果通过机器人通过相机获取的图像来完成这一任务，就可以采取判断图像间相似性的方法。视觉回环检测实质上是一种计算图像数据相似性的算法。\n5. **建图（Mapping）**。它根据估计的轨迹，建立与任务要求对应的地图。建图并没有一个固定的形式和算法，例如地图可以是一组空间点的集合，也可以是一个漂亮的3D模型。大体上分为度量地图和拓扑地图两种，前者更精确，后者则更强调地图元素之间的关系。拓扑地图是一个图，由节点和边组成，只考虑节点间的连通性，而不考虑节点间到达的过程，放松了地图对精确位置的需要，去掉了地图的细节问题，更为紧凑，但不擅长表达具有复杂结构的地图。\n\n## 有待研究问题及主要挑战\n\n1. 拓扑地图不擅长表达具有复杂结构的地图，如何对地图进行分割形成节点和边，又如何使用拓扑地图进行导航和路径规划，有待研究。\n2. 视觉SLAM中，产业化过程中仍需要解决一些关键性难题，比如，如何高效地获得尽可能长而且准确的特征轨迹并将多视频序列之间的复杂回路闭合起来， 如何对于海量图像/视频数据在有限的内存下进行高效的全局优化，如何在动态环境下进行鲁棒的同时定位与地图构建， 如何处理相机快速运动和强旋转， 如何在线动态调整重建的三维几何表面。\n3. 如何对回环序列或多序列进行处理，如何高效率、高精度处理大尺度环境，如何处理动态环境，如何处理快速移动和剧烈旋转的情况？\n4. Covisibility 是一直在用的概念，而Essential Graph是orbslam自己提出的概念，为了减小全局回环的计算量。当你自己实现SLAM时，也会碰到这些困难，并设计一些应对的策略，这些就是你的创新性。事实上，随着SLAM时间的增长，如何控制图的结构和优化的规模，仍是现在SLAM有待解决的一个问题。\n\n## 研究热点\n\n1. 在复杂场景中的三维视觉感知问题，主要包含三个方面：一是如何通过视觉和 IMU 融合，进行滑动窗口内的 Bundle Adjustment，来提高运动估计的准确性、稳定性和鲁棒性；二是如何基于深度学习的方法仅用单目相机来构建稠密的 3D 地图，并用于飞控避障、 AR 虚实融合等；三是如何基于单目视觉惯导融合，来实时跟踪动态物体，并恢复物体的绝对物理尺度。 \n2. 语义SLAM、激光SLAM\n3. 深度学习与SLAM结合，与新的传感器进行融合\n4. 应用领域：自动驾驶、AR、VR、无人机、无人车、扫地机器人\n\n## 热门公司和部门\n\n1. 商汤科技\n2. Momenta\n3. 镭神智能\n4. 图森未来\n5. 纵目科技\n6. 地平线\n7. 旷视科技\n8. [阿里巴巴达摩院AI Labs](https://zhuanlan.zhihu.com/p/41101700)\n\n## 参考资料\n\n1. 《视觉SLAM十四讲》第2讲\n2. [一索哥传奇《SLAM的基本概念》](http://zhehangt.win/2017/03/01/SLAM/ORBSLAM/SLAMConcept/)","slug":"视觉SLAM十四讲阅读笔记二-SLAM的数学表述","published":1,"updated":"2019-05-30T12:29:26.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0b00crqlcrkvnsv84c","content":"<hr>\n<p>这篇文章是视觉SLAM十四讲第2讲阅读过程中总结和记录的学习内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"SLAM问题提出\"><a href=\"#SLAM问题提出\" class=\"headerlink\" title=\"SLAM问题提出\"></a>SLAM问题提出</h2><p>SLAM问题可以描述为：机器人在某个未知环境中从某个未知位置开始移动，在移动过程中根据传感器数据进行自身定位估计，同时在自身定位的基础上增量式构造地图，从而实现机器人对未知环境的地图构建和在地图中对自身的位置进行定位。对于机器人来说，SLAM主要回答了两个问题：1）我在什么地方？（<strong>定位</strong>） 2）周围环境是怎么样的？（<strong>建图</strong>），即机器人一方面要明白自身的<strong>状态（即位置）</strong>，另一方面也要了解外在的<strong>环境（即地图）</strong>。SLAM问题的本质：对运动主体自身和周围环境空间不确定性的估计。</p>\n<h2 id=\"SLAM问题的数学表述\"><a href=\"#SLAM问题的数学表述\" class=\"headerlink\" title=\"SLAM问题的数学表述\"></a>SLAM问题的数学表述</h2><p>SLAM要回答这两个问题，机器人需要通过传感器采集数据，然后根据这些数据推断出自身的位姿信息和所处的环境信息。</p>\n<p>携带传感器的机器人在某未知环境中运动，由于相机通常是在某些时刻采集数据的，所以我们只关心这些时刻的位置和地图。这样就把一段连续时间的运动变成离散时刻$t=1,…,K$当中发生的事情。在这些时刻，用$x$表示小萝卜自身的位置。于是各时刻的位置就记为$x_1,…,x_K$，它们构成了机器人的轨迹。</p>\n<p>地图方面，假设地图由许多个<strong>路标（landmark）</strong>组成，每个时刻传感器会测量到一部分路标点，设路标点一共有$N$个，用$y_1,…y_N$表示。机器人在某个时间内通过传感器获得一系列连续的传感器数据（路标点的观测数据），即观测值$z$。依据机器人所配备的传感器，观测值$z$可以是激光雷达（laser）数据、图像数据、里程计（odometer）数据和惯性导航单元（IMU）数据等。</p>\n<h3 id=\"运动方程\"><a href=\"#运动方程\" class=\"headerlink\" title=\"运动方程\"></a>运动方程</h3><p>SLAM需要解决的就是通过观测值$z$评估系统状态$x$。系统状态通常包含两部分，一部分用于表示机器人在环境中的位置，另一部分用于表示环境地图。通常，机器人会携带一个测量自身运动的传感器，比如里程计。因此可以构造一个评估函数，利用当前获得的传感器数据（不一定直接就是位置之差，还可能是加速度、角速度等信息），从前一时刻的系统状态评估当前时刻的系统状态，通用、抽象的数学模型如下所示：</p>\n<p>$x<em>k=f(x</em>{k-1},u_k,\\omega_k)$</p>\n<p>$u_k$是运动传感器的数据（或称为输入），$w_k$为噪声。这里的$f$指代一种计算模型，当输入的运动传感器类型不同时，$f$的具体形式会千差万别。我们通常把它称为<strong>运动方程</strong>。</p>\n<h3 id=\"观测方程\"><a href=\"#观测方程\" class=\"headerlink\" title=\"观测方程\"></a>观测方程</h3><p>与运动方程相对应是<strong>观测方程</strong>。观测方程描述的是当机器人在$x<em>k$位置上利用传感器感知环境，看到了某个路标点$y_j$，产生了观测数据$z</em>{k,j}$。此处同样用一个抽象的函数$h$来表述这个关系：</p>\n<p>$z<em>{k,j}=h(y_j,x_k,\\upsilon</em>{k,j})$</p>\n<p>这里$v_k$表示此次观测的噪声。由于观测所用的传感器形式更多，因此这里的观测数据$z$以及观测方程$h$也有许多不同的形式。</p>\n<h3 id=\"参数化过程\"><a href=\"#参数化过程\" class=\"headerlink\" title=\"参数化过程\"></a>参数化过程</h3><p>对于上述函数$f$、$h$，我们并没有给出具体的形式，没有具体地说明运动和观测是怎么回事，也不知道$x$、$y$、$z$如何表示的。其实根据机器人的真实运动和传感器的种类，存在着若干种<strong>参数化（Parameterization）</strong>方式。</p>\n<p>举例来说，假设机器人在平面运动，其位姿由两个位置和一个转角来描述，即$x_k=[x,y,\\theta]^T_k$。同时，运动传感器能够测量到机器人在任意两个时间间隔位置和转角的变化量$u_k=[\\Delta x,\\Delta y,\\Delta \\theta]^T_k$，所以运动方程就可以具体化为：</p>\n<p>$\\left[ \\begin{matrix}x\\y\\\\theta\\end{matrix} \\right]<em>k=\\left[ \\begin{matrix}x\\y\\\\theta\\end{matrix} \\right]</em>{k-1}+\\left[ \\begin{matrix}\\Delta x\\\\Delta y\\\\Delta \\theta\\end{matrix} \\right]_k+\\omega_k$</p>\n<p>关于观测方程，机器人携带一个二维激光传感器，在激光传感器观测一个2D路标点时，能够测到两个量：路标点和机器人本体之间的距离$r$和夹角$\\phi$，所以观测方程具体化为：</p>\n<p>$\\left[ \\begin{matrix}r\\\\phi\\end{matrix} \\right]=\\left[ \\begin{matrix}\\sqrt{(p_x-x)^2+(p_y-y)^2}\\ arctan(\\frac{p_y-y}{p_x-x})\\end{matrix} \\right]+\\upsilon$</p>\n<p>在视觉SLAM中，传感器是相机，那么观测方程就是“对路标点拍摄后，得到图像中的像素”的过程。该过程牵扯到相机模型的描述，在后续的阅读中再详细记录。</p>\n<h3 id=\"最基本的SLAM问题\"><a href=\"#最基本的SLAM问题\" class=\"headerlink\" title=\"最基本的SLAM问题\"></a>最基本的SLAM问题</h3><p>综上所述，针对不同的传感器，运动和观测方程会有不同的参数化形式。如果保持它们的通用性，取成通用的抽象形式，那么SLAM过程就可以表述为两个基本方程：</p>\n<p>$\\left{ \\begin{array}{ll} x<em>k=f(x</em>{k-1},u<em>k,\\omega_k)\\ z</em>{k,j}=h(y<em>j,x_k,\\upsilon</em>{k,j})\\end{array} \\right.$</p>\n<p>这两个方程描述了最基本的SLAM问题：当知道运动测量的读数$u$，以及传感器的读数$z$时，如果求解定位问题（估计$x$）h和建图问题（估计$y$）。即其中$z$和$u$是已知的，当选定了传感器，运动方程和观测方程也是已知的，因此SLAM求解的目标就是对$x$和$y$进行估计，使得<strong>运动方程</strong>和<strong>观测方程</strong>等式两边尽可能的成立。这时，就把SLAM问题建模为一个状态估计问题：如何通过带有噪声的测量数据，估计内部的、隐藏的状态变量。</p>\n<blockquote>\n<p>疑问：观测方程和运动方程会同时用到吗？视觉SLAM只用到观测方程？？？</p>\n<p>视觉SLAM中：</p>\n<ul>\n<li>观测方程。就是“对路标点拍摄后，得到图像中的像素”的过程。具体来说，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。 </li>\n<li>运动方程。SLAM系统中视觉里程计（VO）估计了两张图像间相机的运动，只需把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。</li>\n</ul>\n</blockquote>\n<h3 id=\"后续深入理解\"><a href=\"#后续深入理解\" class=\"headerlink\" title=\"后续深入理解\"></a>后续深入理解</h3><p>本篇文章对SLAM问题的数学建模有了大致的了解，然而仍需深入理解一些问题。</p>\n<ol>\n<li>如何说明<strong>机器人的位置$x$是什么，即如何表达位姿</strong>。对于三维空间中的机器人来说，其运动要由3个轴上的平移，以及绕着3个轴的旋转来描述，一共有6个自由度。那是否意味着随便用一个$ℝ^6$中的向量就可以描述它呢？其实并没那么简单。对6自由度的位姿（包括了旋转和平移），如何表达的问题涉及到三维空间刚体运动的问题，会在其他文章中详细介绍；</li>\n<li><strong>如何对位姿进行估计和优化。</strong>因为在SLAM中位姿是未知的，而我们需要解决什么样的相机位姿最符合当前观测数据这样的问题，一种经典的解决方式是把它们构成一个优化问题，求解最优的$R$和$t$，使得误差最小化。而旋转矩阵自身是带有约束的（正交且行列式为1）.它们作为优化变量时，会引入额外的约束，使优化变得困难。通过李群-李代数间的转换关系，我们希望把位姿估计变成无约束的优化问题，以简化求解方式。涉及到李群和李代数会在后续记录；</li>\n<li><strong>视觉SLAM中观测方程如何参数化。</strong>即空间中的路标点是如何投影到一张照片上的，这就需要解释相机的成像模型；</li>\n<li><strong>如何求解运动、观测方程。</strong>需要用到非线性优化的知识。</li>\n</ol>\n<h2 id=\"SLAM问题的求解思路\"><a href=\"#SLAM问题的求解思路\" class=\"headerlink\" title=\"SLAM问题的求解思路\"></a>SLAM问题的求解思路</h2><p>从应用的角度来看，SLAM问题涉及很多方面，包括传感器的选择，对$x$的估计方式，地图的表示形式等。<br>从传感器的角度来讲，SLAM依赖的传感器主要包括激光传感器和视觉传感器两大类。<br>从X的估计方式来讲，SLAM的求解思路主要包括基于滤波的求解和基于非线性优化的求解。目前普遍认为非线性优化的方法要由于滤波方法。<br>从地图的表示形式来讲，SLAM得到的地图表示方式主要分为度量地图与拓扑地图，度量地图有二维，三维，稀疏，稠密等多种表现形式。</p>\n<h2 id=\"视觉SLAM经典框架\"><a href=\"#视觉SLAM经典框架\" class=\"headerlink\" title=\"视觉SLAM经典框架\"></a>视觉SLAM经典框架</h2><img src=\"/2018/08/05/视觉SLAM十四讲阅读笔记二-SLAM的数学表述/视觉SLAM经典框架.png\">\n<ol>\n<li>传感器获取。在视觉SLAM中主要为相机图像信息的读取和预处理。</li>\n<li><strong>视觉里程计（Visual Odometry，VO）。</strong>任务是估算相邻图像间相机的运动，以及局部地图的样子，（恢复场景的空间结构）。又称<strong>前端（Front End）</strong>。为了定量地估计相机运动，必须在<strong>了解相机与空间点的几何关系</strong>后进行。视觉里程计估计了两张图像间的相机运动之后，只要把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。另一方面，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。仅仅通过视觉里程计估计轨迹，将不可避免地出现<strong>累计漂移（Accumulatin Drift）</strong>，将导致无法建立一致的地图。为了解决漂移问题，需要用到<strong>后端优化</strong>和<strong>回环检测</strong>，回环检测负责把“机器人回到原始位置”的事情检测出来，后端优化则根据该信息，校正整个轨迹的形状。</li>\n<li><strong>后端优化（Optimization）</strong>。后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。由于接在VO之后，又称为后端（Back End）。笼统地说，它主要是指处理SLAM过程中噪声的问题，即考虑如何从带有噪声的数据中，估计整个系统的状态，以及这个状态估计的不确定性有多大——称为<strong>最大后验概率估计（Maximum-a-Posteriori，MAP）</strong>，这里的状态既包括机器人自身的轨迹，也包括地图。前端为后端提供待优化的数据，以及这些数据的初始值。而后端负责整体的优化过程，往往面对的只有数据，不必关心这些数据到底来自什么传感器。视觉SLAM中，前端和计算机视觉研究领域更为相关，比如图像的特征提取和匹配等，后端则主要是滤波与非线性优化算法。</li>\n<li><strong>回环检测（Loop Closing）</strong>。回环检测判断机器人是否曾经到达过先前的位置。如果检测到回环，它会把信息提供给后端处理。又称闭环检测（Loop Closure Detection），主要解决位置估计随时间漂移的问题。为了实现回环检测，需要让机器人具有识别曾到达过的场景的能力，如果通过机器人通过相机获取的图像来完成这一任务，就可以采取判断图像间相似性的方法。视觉回环检测实质上是一种计算图像数据相似性的算法。</li>\n<li><strong>建图（Mapping）</strong>。它根据估计的轨迹，建立与任务要求对应的地图。建图并没有一个固定的形式和算法，例如地图可以是一组空间点的集合，也可以是一个漂亮的3D模型。大体上分为度量地图和拓扑地图两种，前者更精确，后者则更强调地图元素之间的关系。拓扑地图是一个图，由节点和边组成，只考虑节点间的连通性，而不考虑节点间到达的过程，放松了地图对精确位置的需要，去掉了地图的细节问题，更为紧凑，但不擅长表达具有复杂结构的地图。</li>\n</ol>\n<h2 id=\"有待研究问题及主要挑战\"><a href=\"#有待研究问题及主要挑战\" class=\"headerlink\" title=\"有待研究问题及主要挑战\"></a>有待研究问题及主要挑战</h2><ol>\n<li>拓扑地图不擅长表达具有复杂结构的地图，如何对地图进行分割形成节点和边，又如何使用拓扑地图进行导航和路径规划，有待研究。</li>\n<li>视觉SLAM中，产业化过程中仍需要解决一些关键性难题，比如，如何高效地获得尽可能长而且准确的特征轨迹并将多视频序列之间的复杂回路闭合起来， 如何对于海量图像/视频数据在有限的内存下进行高效的全局优化，如何在动态环境下进行鲁棒的同时定位与地图构建， 如何处理相机快速运动和强旋转， 如何在线动态调整重建的三维几何表面。</li>\n<li>如何对回环序列或多序列进行处理，如何高效率、高精度处理大尺度环境，如何处理动态环境，如何处理快速移动和剧烈旋转的情况？</li>\n<li>Covisibility 是一直在用的概念，而Essential Graph是orbslam自己提出的概念，为了减小全局回环的计算量。当你自己实现SLAM时，也会碰到这些困难，并设计一些应对的策略，这些就是你的创新性。事实上，随着SLAM时间的增长，如何控制图的结构和优化的规模，仍是现在SLAM有待解决的一个问题。</li>\n</ol>\n<h2 id=\"研究热点\"><a href=\"#研究热点\" class=\"headerlink\" title=\"研究热点\"></a>研究热点</h2><ol>\n<li>在复杂场景中的三维视觉感知问题，主要包含三个方面：一是如何通过视觉和 IMU 融合，进行滑动窗口内的 Bundle Adjustment，来提高运动估计的准确性、稳定性和鲁棒性；二是如何基于深度学习的方法仅用单目相机来构建稠密的 3D 地图，并用于飞控避障、 AR 虚实融合等；三是如何基于单目视觉惯导融合，来实时跟踪动态物体，并恢复物体的绝对物理尺度。 </li>\n<li>语义SLAM、激光SLAM</li>\n<li>深度学习与SLAM结合，与新的传感器进行融合</li>\n<li>应用领域：自动驾驶、AR、VR、无人机、无人车、扫地机器人</li>\n</ol>\n<h2 id=\"热门公司和部门\"><a href=\"#热门公司和部门\" class=\"headerlink\" title=\"热门公司和部门\"></a>热门公司和部门</h2><ol>\n<li>商汤科技</li>\n<li>Momenta</li>\n<li>镭神智能</li>\n<li>图森未来</li>\n<li>纵目科技</li>\n<li>地平线</li>\n<li>旷视科技</li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/41101700\" target=\"_blank\" rel=\"noopener\">阿里巴巴达摩院AI Labs</a></li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>《视觉SLAM十四讲》第2讲</li>\n<li><a href=\"http://zhehangt.win/2017/03/01/SLAM/ORBSLAM/SLAMConcept/\" target=\"_blank\" rel=\"noopener\">一索哥传奇《SLAM的基本概念》</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是视觉SLAM十四讲第2讲阅读过程中总结和记录的学习内容。</p>","more":"<h2 id=\"SLAM问题提出\"><a href=\"#SLAM问题提出\" class=\"headerlink\" title=\"SLAM问题提出\"></a>SLAM问题提出</h2><p>SLAM问题可以描述为：机器人在某个未知环境中从某个未知位置开始移动，在移动过程中根据传感器数据进行自身定位估计，同时在自身定位的基础上增量式构造地图，从而实现机器人对未知环境的地图构建和在地图中对自身的位置进行定位。对于机器人来说，SLAM主要回答了两个问题：1）我在什么地方？（<strong>定位</strong>） 2）周围环境是怎么样的？（<strong>建图</strong>），即机器人一方面要明白自身的<strong>状态（即位置）</strong>，另一方面也要了解外在的<strong>环境（即地图）</strong>。SLAM问题的本质：对运动主体自身和周围环境空间不确定性的估计。</p>\n<h2 id=\"SLAM问题的数学表述\"><a href=\"#SLAM问题的数学表述\" class=\"headerlink\" title=\"SLAM问题的数学表述\"></a>SLAM问题的数学表述</h2><p>SLAM要回答这两个问题，机器人需要通过传感器采集数据，然后根据这些数据推断出自身的位姿信息和所处的环境信息。</p>\n<p>携带传感器的机器人在某未知环境中运动，由于相机通常是在某些时刻采集数据的，所以我们只关心这些时刻的位置和地图。这样就把一段连续时间的运动变成离散时刻$t=1,…,K$当中发生的事情。在这些时刻，用$x$表示小萝卜自身的位置。于是各时刻的位置就记为$x_1,…,x_K$，它们构成了机器人的轨迹。</p>\n<p>地图方面，假设地图由许多个<strong>路标（landmark）</strong>组成，每个时刻传感器会测量到一部分路标点，设路标点一共有$N$个，用$y_1,…y_N$表示。机器人在某个时间内通过传感器获得一系列连续的传感器数据（路标点的观测数据），即观测值$z$。依据机器人所配备的传感器，观测值$z$可以是激光雷达（laser）数据、图像数据、里程计（odometer）数据和惯性导航单元（IMU）数据等。</p>\n<h3 id=\"运动方程\"><a href=\"#运动方程\" class=\"headerlink\" title=\"运动方程\"></a>运动方程</h3><p>SLAM需要解决的就是通过观测值$z$评估系统状态$x$。系统状态通常包含两部分，一部分用于表示机器人在环境中的位置，另一部分用于表示环境地图。通常，机器人会携带一个测量自身运动的传感器，比如里程计。因此可以构造一个评估函数，利用当前获得的传感器数据（不一定直接就是位置之差，还可能是加速度、角速度等信息），从前一时刻的系统状态评估当前时刻的系统状态，通用、抽象的数学模型如下所示：</p>\n<p>$x<em>k=f(x</em>{k-1},u_k,\\omega_k)$</p>\n<p>$u_k$是运动传感器的数据（或称为输入），$w_k$为噪声。这里的$f$指代一种计算模型，当输入的运动传感器类型不同时，$f$的具体形式会千差万别。我们通常把它称为<strong>运动方程</strong>。</p>\n<h3 id=\"观测方程\"><a href=\"#观测方程\" class=\"headerlink\" title=\"观测方程\"></a>观测方程</h3><p>与运动方程相对应是<strong>观测方程</strong>。观测方程描述的是当机器人在$x<em>k$位置上利用传感器感知环境，看到了某个路标点$y_j$，产生了观测数据$z</em>{k,j}$。此处同样用一个抽象的函数$h$来表述这个关系：</p>\n<p>$z<em>{k,j}=h(y_j,x_k,\\upsilon</em>{k,j})$</p>\n<p>这里$v_k$表示此次观测的噪声。由于观测所用的传感器形式更多，因此这里的观测数据$z$以及观测方程$h$也有许多不同的形式。</p>\n<h3 id=\"参数化过程\"><a href=\"#参数化过程\" class=\"headerlink\" title=\"参数化过程\"></a>参数化过程</h3><p>对于上述函数$f$、$h$，我们并没有给出具体的形式，没有具体地说明运动和观测是怎么回事，也不知道$x$、$y$、$z$如何表示的。其实根据机器人的真实运动和传感器的种类，存在着若干种<strong>参数化（Parameterization）</strong>方式。</p>\n<p>举例来说，假设机器人在平面运动，其位姿由两个位置和一个转角来描述，即$x_k=[x,y,\\theta]^T_k$。同时，运动传感器能够测量到机器人在任意两个时间间隔位置和转角的变化量$u_k=[\\Delta x,\\Delta y,\\Delta \\theta]^T_k$，所以运动方程就可以具体化为：</p>\n<p>$\\left[ \\begin{matrix}x\\y\\\\theta\\end{matrix} \\right]<em>k=\\left[ \\begin{matrix}x\\y\\\\theta\\end{matrix} \\right]</em>{k-1}+\\left[ \\begin{matrix}\\Delta x\\\\Delta y\\\\Delta \\theta\\end{matrix} \\right]_k+\\omega_k$</p>\n<p>关于观测方程，机器人携带一个二维激光传感器，在激光传感器观测一个2D路标点时，能够测到两个量：路标点和机器人本体之间的距离$r$和夹角$\\phi$，所以观测方程具体化为：</p>\n<p>$\\left[ \\begin{matrix}r\\\\phi\\end{matrix} \\right]=\\left[ \\begin{matrix}\\sqrt{(p_x-x)^2+(p_y-y)^2}\\ arctan(\\frac{p_y-y}{p_x-x})\\end{matrix} \\right]+\\upsilon$</p>\n<p>在视觉SLAM中，传感器是相机，那么观测方程就是“对路标点拍摄后，得到图像中的像素”的过程。该过程牵扯到相机模型的描述，在后续的阅读中再详细记录。</p>\n<h3 id=\"最基本的SLAM问题\"><a href=\"#最基本的SLAM问题\" class=\"headerlink\" title=\"最基本的SLAM问题\"></a>最基本的SLAM问题</h3><p>综上所述，针对不同的传感器，运动和观测方程会有不同的参数化形式。如果保持它们的通用性，取成通用的抽象形式，那么SLAM过程就可以表述为两个基本方程：</p>\n<p>$\\left{ \\begin{array}{ll} x<em>k=f(x</em>{k-1},u<em>k,\\omega_k)\\ z</em>{k,j}=h(y<em>j,x_k,\\upsilon</em>{k,j})\\end{array} \\right.$</p>\n<p>这两个方程描述了最基本的SLAM问题：当知道运动测量的读数$u$，以及传感器的读数$z$时，如果求解定位问题（估计$x$）h和建图问题（估计$y$）。即其中$z$和$u$是已知的，当选定了传感器，运动方程和观测方程也是已知的，因此SLAM求解的目标就是对$x$和$y$进行估计，使得<strong>运动方程</strong>和<strong>观测方程</strong>等式两边尽可能的成立。这时，就把SLAM问题建模为一个状态估计问题：如何通过带有噪声的测量数据，估计内部的、隐藏的状态变量。</p>\n<blockquote>\n<p>疑问：观测方程和运动方程会同时用到吗？视觉SLAM只用到观测方程？？？</p>\n<p>视觉SLAM中：</p>\n<ul>\n<li>观测方程。就是“对路标点拍摄后，得到图像中的像素”的过程。具体来说，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。 </li>\n<li>运动方程。SLAM系统中视觉里程计（VO）估计了两张图像间相机的运动，只需把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。</li>\n</ul>\n</blockquote>\n<h3 id=\"后续深入理解\"><a href=\"#后续深入理解\" class=\"headerlink\" title=\"后续深入理解\"></a>后续深入理解</h3><p>本篇文章对SLAM问题的数学建模有了大致的了解，然而仍需深入理解一些问题。</p>\n<ol>\n<li>如何说明<strong>机器人的位置$x$是什么，即如何表达位姿</strong>。对于三维空间中的机器人来说，其运动要由3个轴上的平移，以及绕着3个轴的旋转来描述，一共有6个自由度。那是否意味着随便用一个$ℝ^6$中的向量就可以描述它呢？其实并没那么简单。对6自由度的位姿（包括了旋转和平移），如何表达的问题涉及到三维空间刚体运动的问题，会在其他文章中详细介绍；</li>\n<li><strong>如何对位姿进行估计和优化。</strong>因为在SLAM中位姿是未知的，而我们需要解决什么样的相机位姿最符合当前观测数据这样的问题，一种经典的解决方式是把它们构成一个优化问题，求解最优的$R$和$t$，使得误差最小化。而旋转矩阵自身是带有约束的（正交且行列式为1）.它们作为优化变量时，会引入额外的约束，使优化变得困难。通过李群-李代数间的转换关系，我们希望把位姿估计变成无约束的优化问题，以简化求解方式。涉及到李群和李代数会在后续记录；</li>\n<li><strong>视觉SLAM中观测方程如何参数化。</strong>即空间中的路标点是如何投影到一张照片上的，这就需要解释相机的成像模型；</li>\n<li><strong>如何求解运动、观测方程。</strong>需要用到非线性优化的知识。</li>\n</ol>\n<h2 id=\"SLAM问题的求解思路\"><a href=\"#SLAM问题的求解思路\" class=\"headerlink\" title=\"SLAM问题的求解思路\"></a>SLAM问题的求解思路</h2><p>从应用的角度来看，SLAM问题涉及很多方面，包括传感器的选择，对$x$的估计方式，地图的表示形式等。<br>从传感器的角度来讲，SLAM依赖的传感器主要包括激光传感器和视觉传感器两大类。<br>从X的估计方式来讲，SLAM的求解思路主要包括基于滤波的求解和基于非线性优化的求解。目前普遍认为非线性优化的方法要由于滤波方法。<br>从地图的表示形式来讲，SLAM得到的地图表示方式主要分为度量地图与拓扑地图，度量地图有二维，三维，稀疏，稠密等多种表现形式。</p>\n<h2 id=\"视觉SLAM经典框架\"><a href=\"#视觉SLAM经典框架\" class=\"headerlink\" title=\"视觉SLAM经典框架\"></a>视觉SLAM经典框架</h2><img src=\"/2018/08/05/视觉SLAM十四讲阅读笔记二-SLAM的数学表述/视觉SLAM经典框架.png\">\n<ol>\n<li>传感器获取。在视觉SLAM中主要为相机图像信息的读取和预处理。</li>\n<li><strong>视觉里程计（Visual Odometry，VO）。</strong>任务是估算相邻图像间相机的运动，以及局部地图的样子，（恢复场景的空间结构）。又称<strong>前端（Front End）</strong>。为了定量地估计相机运动，必须在<strong>了解相机与空间点的几何关系</strong>后进行。视觉里程计估计了两张图像间的相机运动之后，只要把相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决了定位问题。另一方面，根据每个时刻的相机位置，计算出各像素对应的空间点的位置，就得到了地图。仅仅通过视觉里程计估计轨迹，将不可避免地出现<strong>累计漂移（Accumulatin Drift）</strong>，将导致无法建立一致的地图。为了解决漂移问题，需要用到<strong>后端优化</strong>和<strong>回环检测</strong>，回环检测负责把“机器人回到原始位置”的事情检测出来，后端优化则根据该信息，校正整个轨迹的形状。</li>\n<li><strong>后端优化（Optimization）</strong>。后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。由于接在VO之后，又称为后端（Back End）。笼统地说，它主要是指处理SLAM过程中噪声的问题，即考虑如何从带有噪声的数据中，估计整个系统的状态，以及这个状态估计的不确定性有多大——称为<strong>最大后验概率估计（Maximum-a-Posteriori，MAP）</strong>，这里的状态既包括机器人自身的轨迹，也包括地图。前端为后端提供待优化的数据，以及这些数据的初始值。而后端负责整体的优化过程，往往面对的只有数据，不必关心这些数据到底来自什么传感器。视觉SLAM中，前端和计算机视觉研究领域更为相关，比如图像的特征提取和匹配等，后端则主要是滤波与非线性优化算法。</li>\n<li><strong>回环检测（Loop Closing）</strong>。回环检测判断机器人是否曾经到达过先前的位置。如果检测到回环，它会把信息提供给后端处理。又称闭环检测（Loop Closure Detection），主要解决位置估计随时间漂移的问题。为了实现回环检测，需要让机器人具有识别曾到达过的场景的能力，如果通过机器人通过相机获取的图像来完成这一任务，就可以采取判断图像间相似性的方法。视觉回环检测实质上是一种计算图像数据相似性的算法。</li>\n<li><strong>建图（Mapping）</strong>。它根据估计的轨迹，建立与任务要求对应的地图。建图并没有一个固定的形式和算法，例如地图可以是一组空间点的集合，也可以是一个漂亮的3D模型。大体上分为度量地图和拓扑地图两种，前者更精确，后者则更强调地图元素之间的关系。拓扑地图是一个图，由节点和边组成，只考虑节点间的连通性，而不考虑节点间到达的过程，放松了地图对精确位置的需要，去掉了地图的细节问题，更为紧凑，但不擅长表达具有复杂结构的地图。</li>\n</ol>\n<h2 id=\"有待研究问题及主要挑战\"><a href=\"#有待研究问题及主要挑战\" class=\"headerlink\" title=\"有待研究问题及主要挑战\"></a>有待研究问题及主要挑战</h2><ol>\n<li>拓扑地图不擅长表达具有复杂结构的地图，如何对地图进行分割形成节点和边，又如何使用拓扑地图进行导航和路径规划，有待研究。</li>\n<li>视觉SLAM中，产业化过程中仍需要解决一些关键性难题，比如，如何高效地获得尽可能长而且准确的特征轨迹并将多视频序列之间的复杂回路闭合起来， 如何对于海量图像/视频数据在有限的内存下进行高效的全局优化，如何在动态环境下进行鲁棒的同时定位与地图构建， 如何处理相机快速运动和强旋转， 如何在线动态调整重建的三维几何表面。</li>\n<li>如何对回环序列或多序列进行处理，如何高效率、高精度处理大尺度环境，如何处理动态环境，如何处理快速移动和剧烈旋转的情况？</li>\n<li>Covisibility 是一直在用的概念，而Essential Graph是orbslam自己提出的概念，为了减小全局回环的计算量。当你自己实现SLAM时，也会碰到这些困难，并设计一些应对的策略，这些就是你的创新性。事实上，随着SLAM时间的增长，如何控制图的结构和优化的规模，仍是现在SLAM有待解决的一个问题。</li>\n</ol>\n<h2 id=\"研究热点\"><a href=\"#研究热点\" class=\"headerlink\" title=\"研究热点\"></a>研究热点</h2><ol>\n<li>在复杂场景中的三维视觉感知问题，主要包含三个方面：一是如何通过视觉和 IMU 融合，进行滑动窗口内的 Bundle Adjustment，来提高运动估计的准确性、稳定性和鲁棒性；二是如何基于深度学习的方法仅用单目相机来构建稠密的 3D 地图，并用于飞控避障、 AR 虚实融合等；三是如何基于单目视觉惯导融合，来实时跟踪动态物体，并恢复物体的绝对物理尺度。 </li>\n<li>语义SLAM、激光SLAM</li>\n<li>深度学习与SLAM结合，与新的传感器进行融合</li>\n<li>应用领域：自动驾驶、AR、VR、无人机、无人车、扫地机器人</li>\n</ol>\n<h2 id=\"热门公司和部门\"><a href=\"#热门公司和部门\" class=\"headerlink\" title=\"热门公司和部门\"></a>热门公司和部门</h2><ol>\n<li>商汤科技</li>\n<li>Momenta</li>\n<li>镭神智能</li>\n<li>图森未来</li>\n<li>纵目科技</li>\n<li>地平线</li>\n<li>旷视科技</li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/41101700\" target=\"_blank\" rel=\"noopener\">阿里巴巴达摩院AI Labs</a></li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>《视觉SLAM十四讲》第2讲</li>\n<li><a href=\"http://zhehangt.win/2017/03/01/SLAM/ORBSLAM/SLAMConcept/\" target=\"_blank\" rel=\"noopener\">一索哥传奇《SLAM的基本概念》</a></li>\n</ol>"},{"title":"视觉SLAM十四讲阅读笔记六-针孔相机模型","date":"2018-09-01T14:26:11.000Z","mathjax":true,"copyright":true,"_content":"\n---\n\n这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录针孔相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。\n\n<!--more--->\n\n## 概述\n\n“机器人如何表示自身位姿”属于SLAM经典模型的运动方程部分。“机器人如何观测外部世界”属于观测方程部分，以相机为主的视觉SLAM中，观测主要是指**相机成像**的过程，这里就涉及到相机的成像原理和成像模型。相机模型中常常涉及到四个坐标系：图像像素坐标系、成像平面坐标系、相机坐标系和世界坐标系。\n\n## 针孔相机模型\n\n{% asset_img 针孔相机模型.png %}\n\n针孔相机模型如上图所示，其中，$O-x-y-x$是相机坐标系，$O$是相机的光心，$f$为相机焦距，$z$轴指向相机的正前方；$O'-x'-y'$是物理成像平面，三维世界中的点$P[X_w,Y_w,Z_w]$，相机坐标系的坐标为$[X_c,Y_c,Z_c]$，经过相机光心投影到物理成像平面上，形成成像点$P'[x,y]$。根据相似三角形原理，有：\n\n$\\frac{Z_c}{f}=\\frac{X_c}{x} =\\frac{Y_c}{y}  \\qquad (1)$\n\n整理得：\n\n$x=f\\frac{X_c}{Z_c} ,y=f\\frac{Y_c}{Z_c} \\qquad (2)$\n\n## 像素坐标系\n\n图像像素坐标系通常简称为图像坐标系或者像素坐标系。如下图所示：\n\n{% asset_img 像素坐标系.png %}\n\n像素坐标系的平面为相机的成像平面，原点在图像的左上方，$u$轴向右与$x$轴平行，$v$轴向下与$y$轴平行。像素坐标系的单位是像素(pixel)，也就是我们常说的分辨率。\n\n## 物理成像平面坐标系\n\n物理成像平面在距相机光心一倍焦距的平面上，和像素坐标系处于同一平面，原点是相机光轴与成像平面的交点，即成像平面的中点或者叫principal  point。单位为物理单位，比如毫米。因此成像平面坐标系和像素坐标系只是原点和度量单位不同，两个坐标系之间相差了一个缩放比例和一个原点的平移。\n\n假设某个像素点$P'$坐标为$($u,v$)$，$P'$对应的成像平面坐标为$($x,y$)$，设像素坐标在$u$轴上缩放了$\\alpha$倍，在$v$轴上缩放了$\\beta$倍（$\\alpha,\\beta$单位都为像素/米）。成像平面的原点在像素坐标系中的坐标为($c_x$,$c_y$)，则像素坐标系与成像平面坐标系之间有如下转换公式，用到齐次坐标：\n\n$\\left\\{ \\begin{array}{ll} u=\\alpha x+c_x\\\\v=\\beta y+c_y \\end{array} \\right. \\Rightarrow \\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&0&c_x\\\\0&\\beta&c_y\\\\0&0&1\\end{matrix}\\right]\\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right] \\qquad (3)$\n\n## 相机坐标系\n\n相机坐标系的原点是相机光心，$X_c$和$Y_c$轴与像素坐标系$u$轴和$v$轴平行，$Z_c$轴为相机的光轴。光心到像素平面的距离为焦距$f$。\n\n由图可以看出相机坐标系上的点和成像平面坐标系上的点存在透视投影关系。根据相似三角形关系，成像平面坐标系与相机坐标系之间有如下转换关系：\n\n$\\left\\{ \\begin{array}{ll} x=f\\frac{X_c}{Z_c}\\\\y=f\\frac{Y_c}{Z_c} \\end{array} \\right. \\Rightarrow  Z_c\\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f&0&0&0\\\\0&f&0&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right] \\qquad (2)$\n\n根据(2)(3)两式，将$\\alpha f$合并成$f_x$，$\\beta f$合并成$f_y$，其中$f$称为物理焦距，单位为米，$f_x,f_y$称为像素焦距，单位为像素，得到：\n\n$\\left\\{ \\begin{array}{ll} u=f_x \\frac{X_c}{Z_c}+c_x\\\\v=f_y \\frac{Y_c}{Z_c}+c_y \\end{array} \\right. \\qquad (4)$\n\n写成矩阵的形式，用到齐次坐标：\n\n$\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}\\alpha&0&c_x\\\\0&\\beta&c_y\\\\0&0&1\\end{matrix}\\right] \\left[\\begin{matrix}f&0&0&0\\\\0&f&0&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]\\triangleq\\frac1{Z_c} KP_c \\qquad (5)$\n\n传统习惯上把$Z_c$挪到左侧：\n\n$Z_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]\\triangleq KP_c \\qquad(6)$\n\n## 世界坐标系\n\n在环境中选择一个参考坐标系来描述相机和物体的位置，该坐标系称为世界坐标系，单位为m。相机坐标系和世界坐标系之间的关系可以用旋转矩阵$R$和平移向量$t$来描述。假设$P$在世界坐标系下的坐标为$(X_w,Y_w,Z_w)$，则相机坐标系与世界坐标系之间有如下转换关系：\n\n$\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right] \\qquad (7)$\n\n## 坐标系转换\n\n|               坐标系               | 单位  |       备注       |\n| :--------------------------------: | :---: | :--------------: |\n|             世界坐标系             |   m   |   描述相机位置   |\n| 相机坐标系（可化为归一化相机坐标） |   m   |  原点为相机光心  |\n|           成像平面坐标系           |  mm   |  原点为图像中点  |\n|             像素坐标系             | pixel | 原点为图像左上角 |\n\n通过上述的四个坐标系可以实现从世界坐标系与像素坐标系之间的转换，如下所示：\n\n$Z_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&0&c_x\\\\0&\\beta&c_y\\\\0&0&1\\end{matrix}\\right]\\left[\\begin{matrix}f&0&0&0\\\\0&f&0&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right] \\qquad (8)$\n\n其中$\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]$称为内参数矩阵$K$，$\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]$称为外参数矩阵$T$。\n\n上式简写成：\n\n$Z_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=KT\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right] \\qquad (9)$\n\n到此，针孔相机成像模型就搞清楚了。\n\n相机的内参数矩阵往往是已知的并且是固定的，而外参数矩阵在SLAM问题中往往是需要求解的，用于相机的位姿定位。\n从世界坐标系到像素坐标系之间的转换关系可知，已知世界坐标系下的三维点坐标，只要已知内外参矩阵，就可以求得像素坐标。而如果已知像素坐标，即使已知内外参矩阵，其世界坐标下的三维点也不是唯一确定的，而是空间的一条直线。即单目相机只能测平面信息，而不能获取深度信息。\n\n## 归一化\n\n在坐标变换过程中通常需要进行归一化处理，得到点在相机归一化平面上的投影，归一化平面是假想的。\n\n三维点在相机坐标系下表示形式为：\n\n$P_c=\\left[\\begin{matrix}x_c\\\\y_c\\\\z_c\\end{matrix}\\right]$\n\n所以有：\n\n$\\left[ \\begin{matrix}z_cu\\\\z_cv\\\\z_c\\end{matrix}\\right] = K\\left[ \\begin{matrix}x_c\\\\y_c\\\\z_c\\end{matrix}\\right]=KPc$\n\n由上式可知，三维点直接经过内参得到的坐标相当于$u,v$坐标在各自的方向上都放大了$z_c$倍。归一化平面是指位于相机前方z=1处的平面上，该平面称为归一化平面。归一化坐标就相当于在$z$的方向上当z=1时用一个平面截断，这时光心与3D点的连线在该面上的点即为该三维点的归一化点，记做$P_{c1}$：\n\n$P_{c1}=\\left[\\begin{matrix}\\frac{x_c}{z_c}\\\\\\frac{y_c}{z_c}\\\\1\\end{matrix}\\right]$\n\n由归一化坐标经过内参矩阵后就得到了像素坐标：\n\n$\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=K\\left[\\begin{matrix}\\frac{x_c}{z_c}\\\\\\frac{y_c}{z_c}\\\\1\\end{matrix}\\right]=KP_{c1}$\n\n因此可以把像素坐标看成对归一化平面上的点进行量化测量的结果。\n\n## 畸变\n\n由于相机透镜的使用，会引入径向畸变，主要分为桶型畸变和枕型畸变 ；由于相机透镜组装过程的误差，导致透镜与成像平面不能严格平行，会引入切向畸变。严格意义上，还需要对这些畸变进行畸变矫正。\n\n## 参考资料\n\n1. 视觉SLAM十四讲第5讲\n2. [针孔相机模型](http://zhehangt.win/2017/02/16/SLAM/CameraModel/)\n3. [计算机视觉：相机成像原理：世界坐标系、相机坐标系、图像坐标系、像素坐标系之间的转换](https://blog.csdn.net/chentravelling/article/details/53558096)\n4. [相机成像模型](https://blog.csdn.net/huangjingwei13/article/details/71439293)","source":"_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型.md","raw":"---\ntitle: 视觉SLAM十四讲阅读笔记六-针孔相机模型\ndate: 2018-09-01 22:26:11\ntags: \n  - SLAM基础\n  - 读书笔记\n  - 单目\nmathjax: true\ncategories: \n  - 机器人\n  - SLAM\n  - 读书笔记\ncopyright: true\n---\n\n---\n\n这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录针孔相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。\n\n<!--more--->\n\n## 概述\n\n“机器人如何表示自身位姿”属于SLAM经典模型的运动方程部分。“机器人如何观测外部世界”属于观测方程部分，以相机为主的视觉SLAM中，观测主要是指**相机成像**的过程，这里就涉及到相机的成像原理和成像模型。相机模型中常常涉及到四个坐标系：图像像素坐标系、成像平面坐标系、相机坐标系和世界坐标系。\n\n## 针孔相机模型\n\n{% asset_img 针孔相机模型.png %}\n\n针孔相机模型如上图所示，其中，$O-x-y-x$是相机坐标系，$O$是相机的光心，$f$为相机焦距，$z$轴指向相机的正前方；$O'-x'-y'$是物理成像平面，三维世界中的点$P[X_w,Y_w,Z_w]$，相机坐标系的坐标为$[X_c,Y_c,Z_c]$，经过相机光心投影到物理成像平面上，形成成像点$P'[x,y]$。根据相似三角形原理，有：\n\n$\\frac{Z_c}{f}=\\frac{X_c}{x} =\\frac{Y_c}{y}  \\qquad (1)$\n\n整理得：\n\n$x=f\\frac{X_c}{Z_c} ,y=f\\frac{Y_c}{Z_c} \\qquad (2)$\n\n## 像素坐标系\n\n图像像素坐标系通常简称为图像坐标系或者像素坐标系。如下图所示：\n\n{% asset_img 像素坐标系.png %}\n\n像素坐标系的平面为相机的成像平面，原点在图像的左上方，$u$轴向右与$x$轴平行，$v$轴向下与$y$轴平行。像素坐标系的单位是像素(pixel)，也就是我们常说的分辨率。\n\n## 物理成像平面坐标系\n\n物理成像平面在距相机光心一倍焦距的平面上，和像素坐标系处于同一平面，原点是相机光轴与成像平面的交点，即成像平面的中点或者叫principal  point。单位为物理单位，比如毫米。因此成像平面坐标系和像素坐标系只是原点和度量单位不同，两个坐标系之间相差了一个缩放比例和一个原点的平移。\n\n假设某个像素点$P'$坐标为$($u,v$)$，$P'$对应的成像平面坐标为$($x,y$)$，设像素坐标在$u$轴上缩放了$\\alpha$倍，在$v$轴上缩放了$\\beta$倍（$\\alpha,\\beta$单位都为像素/米）。成像平面的原点在像素坐标系中的坐标为($c_x$,$c_y$)，则像素坐标系与成像平面坐标系之间有如下转换公式，用到齐次坐标：\n\n$\\left\\{ \\begin{array}{ll} u=\\alpha x+c_x\\\\v=\\beta y+c_y \\end{array} \\right. \\Rightarrow \\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&0&c_x\\\\0&\\beta&c_y\\\\0&0&1\\end{matrix}\\right]\\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right] \\qquad (3)$\n\n## 相机坐标系\n\n相机坐标系的原点是相机光心，$X_c$和$Y_c$轴与像素坐标系$u$轴和$v$轴平行，$Z_c$轴为相机的光轴。光心到像素平面的距离为焦距$f$。\n\n由图可以看出相机坐标系上的点和成像平面坐标系上的点存在透视投影关系。根据相似三角形关系，成像平面坐标系与相机坐标系之间有如下转换关系：\n\n$\\left\\{ \\begin{array}{ll} x=f\\frac{X_c}{Z_c}\\\\y=f\\frac{Y_c}{Z_c} \\end{array} \\right. \\Rightarrow  Z_c\\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f&0&0&0\\\\0&f&0&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right] \\qquad (2)$\n\n根据(2)(3)两式，将$\\alpha f$合并成$f_x$，$\\beta f$合并成$f_y$，其中$f$称为物理焦距，单位为米，$f_x,f_y$称为像素焦距，单位为像素，得到：\n\n$\\left\\{ \\begin{array}{ll} u=f_x \\frac{X_c}{Z_c}+c_x\\\\v=f_y \\frac{Y_c}{Z_c}+c_y \\end{array} \\right. \\qquad (4)$\n\n写成矩阵的形式，用到齐次坐标：\n\n$\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}\\alpha&0&c_x\\\\0&\\beta&c_y\\\\0&0&1\\end{matrix}\\right] \\left[\\begin{matrix}f&0&0&0\\\\0&f&0&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]\\triangleq\\frac1{Z_c} KP_c \\qquad (5)$\n\n传统习惯上把$Z_c$挪到左侧：\n\n$Z_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]\\triangleq KP_c \\qquad(6)$\n\n## 世界坐标系\n\n在环境中选择一个参考坐标系来描述相机和物体的位置，该坐标系称为世界坐标系，单位为m。相机坐标系和世界坐标系之间的关系可以用旋转矩阵$R$和平移向量$t$来描述。假设$P$在世界坐标系下的坐标为$(X_w,Y_w,Z_w)$，则相机坐标系与世界坐标系之间有如下转换关系：\n\n$\\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right] \\qquad (7)$\n\n## 坐标系转换\n\n|               坐标系               | 单位  |       备注       |\n| :--------------------------------: | :---: | :--------------: |\n|             世界坐标系             |   m   |   描述相机位置   |\n| 相机坐标系（可化为归一化相机坐标） |   m   |  原点为相机光心  |\n|           成像平面坐标系           |  mm   |  原点为图像中点  |\n|             像素坐标系             | pixel | 原点为图像左上角 |\n\n通过上述的四个坐标系可以实现从世界坐标系与像素坐标系之间的转换，如下所示：\n\n$Z_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&0&c_x\\\\0&\\beta&c_y\\\\0&0&1\\end{matrix}\\right]\\left[\\begin{matrix}f&0&0&0\\\\0&f&0&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right] \\qquad (8)$\n\n其中$\\left[\\begin{matrix}f_x&0&c_x&0\\\\0&f_y&c_y&0\\\\0&0&1&0\\end{matrix}\\right]$称为内参数矩阵$K$，$\\left[\\begin{matrix}R&t\\\\0&1\\end{matrix}\\right]$称为外参数矩阵$T$。\n\n上式简写成：\n\n$Z_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=KT\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right] \\qquad (9)$\n\n到此，针孔相机成像模型就搞清楚了。\n\n相机的内参数矩阵往往是已知的并且是固定的，而外参数矩阵在SLAM问题中往往是需要求解的，用于相机的位姿定位。\n从世界坐标系到像素坐标系之间的转换关系可知，已知世界坐标系下的三维点坐标，只要已知内外参矩阵，就可以求得像素坐标。而如果已知像素坐标，即使已知内外参矩阵，其世界坐标下的三维点也不是唯一确定的，而是空间的一条直线。即单目相机只能测平面信息，而不能获取深度信息。\n\n## 归一化\n\n在坐标变换过程中通常需要进行归一化处理，得到点在相机归一化平面上的投影，归一化平面是假想的。\n\n三维点在相机坐标系下表示形式为：\n\n$P_c=\\left[\\begin{matrix}x_c\\\\y_c\\\\z_c\\end{matrix}\\right]$\n\n所以有：\n\n$\\left[ \\begin{matrix}z_cu\\\\z_cv\\\\z_c\\end{matrix}\\right] = K\\left[ \\begin{matrix}x_c\\\\y_c\\\\z_c\\end{matrix}\\right]=KPc$\n\n由上式可知，三维点直接经过内参得到的坐标相当于$u,v$坐标在各自的方向上都放大了$z_c$倍。归一化平面是指位于相机前方z=1处的平面上，该平面称为归一化平面。归一化坐标就相当于在$z$的方向上当z=1时用一个平面截断，这时光心与3D点的连线在该面上的点即为该三维点的归一化点，记做$P_{c1}$：\n\n$P_{c1}=\\left[\\begin{matrix}\\frac{x_c}{z_c}\\\\\\frac{y_c}{z_c}\\\\1\\end{matrix}\\right]$\n\n由归一化坐标经过内参矩阵后就得到了像素坐标：\n\n$\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]=K\\left[\\begin{matrix}\\frac{x_c}{z_c}\\\\\\frac{y_c}{z_c}\\\\1\\end{matrix}\\right]=KP_{c1}$\n\n因此可以把像素坐标看成对归一化平面上的点进行量化测量的结果。\n\n## 畸变\n\n由于相机透镜的使用，会引入径向畸变，主要分为桶型畸变和枕型畸变 ；由于相机透镜组装过程的误差，导致透镜与成像平面不能严格平行，会引入切向畸变。严格意义上，还需要对这些畸变进行畸变矫正。\n\n## 参考资料\n\n1. 视觉SLAM十四讲第5讲\n2. [针孔相机模型](http://zhehangt.win/2017/02/16/SLAM/CameraModel/)\n3. [计算机视觉：相机成像原理：世界坐标系、相机坐标系、图像坐标系、像素坐标系之间的转换](https://blog.csdn.net/chentravelling/article/details/53558096)\n4. [相机成像模型](https://blog.csdn.net/huangjingwei13/article/details/71439293)","slug":"视觉SLAM十四讲阅读笔记六-针孔相机模型","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0c00cvqlcrdhqa5s2w","content":"<hr>\n<p>这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录针孔相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>“机器人如何表示自身位姿”属于SLAM经典模型的运动方程部分。“机器人如何观测外部世界”属于观测方程部分，以相机为主的视觉SLAM中，观测主要是指<strong>相机成像</strong>的过程，这里就涉及到相机的成像原理和成像模型。相机模型中常常涉及到四个坐标系：图像像素坐标系、成像平面坐标系、相机坐标系和世界坐标系。</p>\n<h2 id=\"针孔相机模型\"><a href=\"#针孔相机模型\" class=\"headerlink\" title=\"针孔相机模型\"></a>针孔相机模型</h2><img src=\"/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/针孔相机模型.png\">\n<p>针孔相机模型如上图所示，其中，$O-x-y-x$是相机坐标系，$O$是相机的光心，$f$为相机焦距，$z$轴指向相机的正前方；$O’-x’-y’$是物理成像平面，三维世界中的点$P[X_w,Y_w,Z_w]$，相机坐标系的坐标为$[X_c,Y_c,Z_c]$，经过相机光心投影到物理成像平面上，形成成像点$P’[x,y]$。根据相似三角形原理，有：</p>\n<p>$\\frac{Z_c}{f}=\\frac{X_c}{x} =\\frac{Y_c}{y}  \\qquad (1)$</p>\n<p>整理得：</p>\n<p>$x=f\\frac{X_c}{Z_c} ,y=f\\frac{Y_c}{Z_c} \\qquad (2)$</p>\n<h2 id=\"像素坐标系\"><a href=\"#像素坐标系\" class=\"headerlink\" title=\"像素坐标系\"></a>像素坐标系</h2><p>图像像素坐标系通常简称为图像坐标系或者像素坐标系。如下图所示：</p>\n<img src=\"/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/像素坐标系.png\">\n<p>像素坐标系的平面为相机的成像平面，原点在图像的左上方，$u$轴向右与$x$轴平行，$v$轴向下与$y$轴平行。像素坐标系的单位是像素(pixel)，也就是我们常说的分辨率。</p>\n<h2 id=\"物理成像平面坐标系\"><a href=\"#物理成像平面坐标系\" class=\"headerlink\" title=\"物理成像平面坐标系\"></a>物理成像平面坐标系</h2><p>物理成像平面在距相机光心一倍焦距的平面上，和像素坐标系处于同一平面，原点是相机光轴与成像平面的交点，即成像平面的中点或者叫principal  point。单位为物理单位，比如毫米。因此成像平面坐标系和像素坐标系只是原点和度量单位不同，两个坐标系之间相差了一个缩放比例和一个原点的平移。</p>\n<p>假设某个像素点$P’$坐标为$($u,v$)$，$P’$对应的成像平面坐标为$($x,y$)$，设像素坐标在$u$轴上缩放了$\\alpha$倍，在$v$轴上缩放了$\\beta$倍（$\\alpha,\\beta$单位都为像素/米）。成像平面的原点在像素坐标系中的坐标为($c_x$,$c_y$)，则像素坐标系与成像平面坐标系之间有如下转换公式，用到齐次坐标：</p>\n<p>$\\left{ \\begin{array}{ll} u=\\alpha x+c_x\\v=\\beta y+c_y \\end{array} \\right. \\Rightarrow \\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&amp;0&amp;c_x\\0&amp;\\beta&amp;c_y\\0&amp;0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}x\\y\\1\\end{matrix}\\right] \\qquad (3)$</p>\n<h2 id=\"相机坐标系\"><a href=\"#相机坐标系\" class=\"headerlink\" title=\"相机坐标系\"></a>相机坐标系</h2><p>相机坐标系的原点是相机光心，$X_c$和$Y_c$轴与像素坐标系$u$轴和$v$轴平行，$Z_c$轴为相机的光轴。光心到像素平面的距离为焦距$f$。</p>\n<p>由图可以看出相机坐标系上的点和成像平面坐标系上的点存在透视投影关系。根据相似三角形关系，成像平面坐标系与相机坐标系之间有如下转换关系：</p>\n<p>$\\left{ \\begin{array}{ll} x=f\\frac{X_c}{Z_c}\\y=f\\frac{Y_c}{Z_c} \\end{array} \\right. \\Rightarrow  Z_c\\left[\\begin{matrix}x\\y\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f&amp;0&amp;0&amp;0\\0&amp;f&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right] \\qquad (2)$</p>\n<p>根据(2)(3)两式，将$\\alpha f$合并成$f_x$，$\\beta f$合并成$f_y$，其中$f$称为物理焦距，单位为米，$f_x,f_y$称为像素焦距，单位为像素，得到：</p>\n<p>$\\left{ \\begin{array}{ll} u=f_x \\frac{X_c}{Z_c}+c_x\\v=f_y \\frac{Y_c}{Z_c}+c_y \\end{array} \\right. \\qquad (4)$</p>\n<p>写成矩阵的形式，用到齐次坐标：</p>\n<p>$\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}\\alpha&amp;0&amp;c_x\\0&amp;\\beta&amp;c_y\\0&amp;0&amp;1\\end{matrix}\\right] \\left[\\begin{matrix}f&amp;0&amp;0&amp;0\\0&amp;f&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]\\triangleq\\frac1{Z_c} KP_c \\qquad (5)$</p>\n<p>传统习惯上把$Z_c$挪到左侧：</p>\n<p>$Z_c\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]\\triangleq KP_c \\qquad(6)$</p>\n<h2 id=\"世界坐标系\"><a href=\"#世界坐标系\" class=\"headerlink\" title=\"世界坐标系\"></a>世界坐标系</h2><p>在环境中选择一个参考坐标系来描述相机和物体的位置，该坐标系称为世界坐标系，单位为m。相机坐标系和世界坐标系之间的关系可以用旋转矩阵$R$和平移向量$t$来描述。假设$P$在世界坐标系下的坐标为$(X_w,Y_w,Z_w)$，则相机坐标系与世界坐标系之间有如下转换关系：</p>\n<p>$\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]=\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right] \\qquad (7)$</p>\n<h2 id=\"坐标系转换\"><a href=\"#坐标系转换\" class=\"headerlink\" title=\"坐标系转换\"></a>坐标系转换</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">坐标系</th>\n<th style=\"text-align:center\">单位</th>\n<th style=\"text-align:center\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">世界坐标系</td>\n<td style=\"text-align:center\">m</td>\n<td style=\"text-align:center\">描述相机位置</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">相机坐标系（可化为归一化相机坐标）</td>\n<td style=\"text-align:center\">m</td>\n<td style=\"text-align:center\">原点为相机光心</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">成像平面坐标系</td>\n<td style=\"text-align:center\">mm</td>\n<td style=\"text-align:center\">原点为图像中点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">像素坐标系</td>\n<td style=\"text-align:center\">pixel</td>\n<td style=\"text-align:center\">原点为图像左上角</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>通过上述的四个坐标系可以实现从世界坐标系与像素坐标系之间的转换，如下所示：</p>\n<p>$Z_c\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&amp;0&amp;c_x\\0&amp;\\beta&amp;c_y\\0&amp;0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}f&amp;0&amp;0&amp;0\\0&amp;f&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right] \\qquad (8)$</p>\n<p>其中$\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]$称为内参数矩阵$K$，$\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]$称为外参数矩阵$T$。</p>\n<p>上式简写成：</p>\n<p>$Z_c\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=KT\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right] \\qquad (9)$</p>\n<p>到此，针孔相机成像模型就搞清楚了。</p>\n<p>相机的内参数矩阵往往是已知的并且是固定的，而外参数矩阵在SLAM问题中往往是需要求解的，用于相机的位姿定位。<br>从世界坐标系到像素坐标系之间的转换关系可知，已知世界坐标系下的三维点坐标，只要已知内外参矩阵，就可以求得像素坐标。而如果已知像素坐标，即使已知内外参矩阵，其世界坐标下的三维点也不是唯一确定的，而是空间的一条直线。即单目相机只能测平面信息，而不能获取深度信息。</p>\n<h2 id=\"归一化\"><a href=\"#归一化\" class=\"headerlink\" title=\"归一化\"></a>归一化</h2><p>在坐标变换过程中通常需要进行归一化处理，得到点在相机归一化平面上的投影，归一化平面是假想的。</p>\n<p>三维点在相机坐标系下表示形式为：</p>\n<p>$P_c=\\left[\\begin{matrix}x_c\\y_c\\z_c\\end{matrix}\\right]$</p>\n<p>所以有：</p>\n<p>$\\left[ \\begin{matrix}z_cu\\z_cv\\z_c\\end{matrix}\\right] = K\\left[ \\begin{matrix}x_c\\y_c\\z_c\\end{matrix}\\right]=KPc$</p>\n<p>由上式可知，三维点直接经过内参得到的坐标相当于$u,v$坐标在各自的方向上都放大了$z<em>c$倍。归一化平面是指位于相机前方z=1处的平面上，该平面称为归一化平面。归一化坐标就相当于在$z$的方向上当z=1时用一个平面截断，这时光心与3D点的连线在该面上的点即为该三维点的归一化点，记做$P</em>{c1}$：</p>\n<p>$P_{c1}=\\left[\\begin{matrix}\\frac{x_c}{z_c}\\\\frac{y_c}{z_c}\\1\\end{matrix}\\right]$</p>\n<p>由归一化坐标经过内参矩阵后就得到了像素坐标：</p>\n<p>$\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=K\\left[\\begin{matrix}\\frac{x<em>c}{z_c}\\\\frac{y_c}{z_c}\\1\\end{matrix}\\right]=KP</em>{c1}$</p>\n<p>因此可以把像素坐标看成对归一化平面上的点进行量化测量的结果。</p>\n<h2 id=\"畸变\"><a href=\"#畸变\" class=\"headerlink\" title=\"畸变\"></a>畸变</h2><p>由于相机透镜的使用，会引入径向畸变，主要分为桶型畸变和枕型畸变 ；由于相机透镜组装过程的误差，导致透镜与成像平面不能严格平行，会引入切向畸变。严格意义上，还需要对这些畸变进行畸变矫正。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉SLAM十四讲第5讲</li>\n<li><a href=\"http://zhehangt.win/2017/02/16/SLAM/CameraModel/\" target=\"_blank\" rel=\"noopener\">针孔相机模型</a></li>\n<li><a href=\"https://blog.csdn.net/chentravelling/article/details/53558096\" target=\"_blank\" rel=\"noopener\">计算机视觉：相机成像原理：世界坐标系、相机坐标系、图像坐标系、像素坐标系之间的转换</a></li>\n<li><a href=\"https://blog.csdn.net/huangjingwei13/article/details/71439293\" target=\"_blank\" rel=\"noopener\">相机成像模型</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是视觉SLAM十四讲第5讲阅读过程中总结和记录的学习内容，主要记录针孔相机模型，这是视觉SLAM投影、坐标变换等内容的基础，一定要一次性全搞透。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>“机器人如何表示自身位姿”属于SLAM经典模型的运动方程部分。“机器人如何观测外部世界”属于观测方程部分，以相机为主的视觉SLAM中，观测主要是指<strong>相机成像</strong>的过程，这里就涉及到相机的成像原理和成像模型。相机模型中常常涉及到四个坐标系：图像像素坐标系、成像平面坐标系、相机坐标系和世界坐标系。</p>\n<h2 id=\"针孔相机模型\"><a href=\"#针孔相机模型\" class=\"headerlink\" title=\"针孔相机模型\"></a>针孔相机模型</h2><img src=\"/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/针孔相机模型.png\">\n<p>针孔相机模型如上图所示，其中，$O-x-y-x$是相机坐标系，$O$是相机的光心，$f$为相机焦距，$z$轴指向相机的正前方；$O’-x’-y’$是物理成像平面，三维世界中的点$P[X_w,Y_w,Z_w]$，相机坐标系的坐标为$[X_c,Y_c,Z_c]$，经过相机光心投影到物理成像平面上，形成成像点$P’[x,y]$。根据相似三角形原理，有：</p>\n<p>$\\frac{Z_c}{f}=\\frac{X_c}{x} =\\frac{Y_c}{y}  \\qquad (1)$</p>\n<p>整理得：</p>\n<p>$x=f\\frac{X_c}{Z_c} ,y=f\\frac{Y_c}{Z_c} \\qquad (2)$</p>\n<h2 id=\"像素坐标系\"><a href=\"#像素坐标系\" class=\"headerlink\" title=\"像素坐标系\"></a>像素坐标系</h2><p>图像像素坐标系通常简称为图像坐标系或者像素坐标系。如下图所示：</p>\n<img src=\"/2018/09/01/视觉SLAM十四讲阅读笔记六-针孔相机模型/像素坐标系.png\">\n<p>像素坐标系的平面为相机的成像平面，原点在图像的左上方，$u$轴向右与$x$轴平行，$v$轴向下与$y$轴平行。像素坐标系的单位是像素(pixel)，也就是我们常说的分辨率。</p>\n<h2 id=\"物理成像平面坐标系\"><a href=\"#物理成像平面坐标系\" class=\"headerlink\" title=\"物理成像平面坐标系\"></a>物理成像平面坐标系</h2><p>物理成像平面在距相机光心一倍焦距的平面上，和像素坐标系处于同一平面，原点是相机光轴与成像平面的交点，即成像平面的中点或者叫principal  point。单位为物理单位，比如毫米。因此成像平面坐标系和像素坐标系只是原点和度量单位不同，两个坐标系之间相差了一个缩放比例和一个原点的平移。</p>\n<p>假设某个像素点$P’$坐标为$($u,v$)$，$P’$对应的成像平面坐标为$($x,y$)$，设像素坐标在$u$轴上缩放了$\\alpha$倍，在$v$轴上缩放了$\\beta$倍（$\\alpha,\\beta$单位都为像素/米）。成像平面的原点在像素坐标系中的坐标为($c_x$,$c_y$)，则像素坐标系与成像平面坐标系之间有如下转换公式，用到齐次坐标：</p>\n<p>$\\left{ \\begin{array}{ll} u=\\alpha x+c_x\\v=\\beta y+c_y \\end{array} \\right. \\Rightarrow \\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&amp;0&amp;c_x\\0&amp;\\beta&amp;c_y\\0&amp;0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}x\\y\\1\\end{matrix}\\right] \\qquad (3)$</p>\n<h2 id=\"相机坐标系\"><a href=\"#相机坐标系\" class=\"headerlink\" title=\"相机坐标系\"></a>相机坐标系</h2><p>相机坐标系的原点是相机光心，$X_c$和$Y_c$轴与像素坐标系$u$轴和$v$轴平行，$Z_c$轴为相机的光轴。光心到像素平面的距离为焦距$f$。</p>\n<p>由图可以看出相机坐标系上的点和成像平面坐标系上的点存在透视投影关系。根据相似三角形关系，成像平面坐标系与相机坐标系之间有如下转换关系：</p>\n<p>$\\left{ \\begin{array}{ll} x=f\\frac{X_c}{Z_c}\\y=f\\frac{Y_c}{Z_c} \\end{array} \\right. \\Rightarrow  Z_c\\left[\\begin{matrix}x\\y\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f&amp;0&amp;0&amp;0\\0&amp;f&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right] \\qquad (2)$</p>\n<p>根据(2)(3)两式，将$\\alpha f$合并成$f_x$，$\\beta f$合并成$f_y$，其中$f$称为物理焦距，单位为米，$f_x,f_y$称为像素焦距，单位为像素，得到：</p>\n<p>$\\left{ \\begin{array}{ll} u=f_x \\frac{X_c}{Z_c}+c_x\\v=f_y \\frac{Y_c}{Z_c}+c_y \\end{array} \\right. \\qquad (4)$</p>\n<p>写成矩阵的形式，用到齐次坐标：</p>\n<p>$\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}\\alpha&amp;0&amp;c_x\\0&amp;\\beta&amp;c_y\\0&amp;0&amp;1\\end{matrix}\\right] \\left[\\begin{matrix}f&amp;0&amp;0&amp;0\\0&amp;f&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]=\\frac1{Z_c}\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]\\triangleq\\frac1{Z_c} KP_c \\qquad (5)$</p>\n<p>传统习惯上把$Z_c$挪到左侧：</p>\n<p>$Z_c\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]\\triangleq KP_c \\qquad(6)$</p>\n<h2 id=\"世界坐标系\"><a href=\"#世界坐标系\" class=\"headerlink\" title=\"世界坐标系\"></a>世界坐标系</h2><p>在环境中选择一个参考坐标系来描述相机和物体的位置，该坐标系称为世界坐标系，单位为m。相机坐标系和世界坐标系之间的关系可以用旋转矩阵$R$和平移向量$t$来描述。假设$P$在世界坐标系下的坐标为$(X_w,Y_w,Z_w)$，则相机坐标系与世界坐标系之间有如下转换关系：</p>\n<p>$\\left[\\begin{matrix}X_c\\Y_c\\Z_c\\1\\end{matrix}\\right]=\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right] \\qquad (7)$</p>\n<h2 id=\"坐标系转换\"><a href=\"#坐标系转换\" class=\"headerlink\" title=\"坐标系转换\"></a>坐标系转换</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">坐标系</th>\n<th style=\"text-align:center\">单位</th>\n<th style=\"text-align:center\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">世界坐标系</td>\n<td style=\"text-align:center\">m</td>\n<td style=\"text-align:center\">描述相机位置</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">相机坐标系（可化为归一化相机坐标）</td>\n<td style=\"text-align:center\">m</td>\n<td style=\"text-align:center\">原点为相机光心</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">成像平面坐标系</td>\n<td style=\"text-align:center\">mm</td>\n<td style=\"text-align:center\">原点为图像中点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">像素坐标系</td>\n<td style=\"text-align:center\">pixel</td>\n<td style=\"text-align:center\">原点为图像左上角</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>通过上述的四个坐标系可以实现从世界坐标系与像素坐标系之间的转换，如下所示：</p>\n<p>$Z_c\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=\\left[\\begin{matrix}\\alpha&amp;0&amp;c_x\\0&amp;\\beta&amp;c_y\\0&amp;0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}f&amp;0&amp;0&amp;0\\0&amp;f&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right]=\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right] \\qquad (8)$</p>\n<p>其中$\\left[\\begin{matrix}f_x&amp;0&amp;c_x&amp;0\\0&amp;f_y&amp;c_y&amp;0\\0&amp;0&amp;1&amp;0\\end{matrix}\\right]$称为内参数矩阵$K$，$\\left[\\begin{matrix}R&amp;t\\0&amp;1\\end{matrix}\\right]$称为外参数矩阵$T$。</p>\n<p>上式简写成：</p>\n<p>$Z_c\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=KT\\left[\\begin{matrix}X_w\\Y_w\\Z_w\\1\\end{matrix}\\right] \\qquad (9)$</p>\n<p>到此，针孔相机成像模型就搞清楚了。</p>\n<p>相机的内参数矩阵往往是已知的并且是固定的，而外参数矩阵在SLAM问题中往往是需要求解的，用于相机的位姿定位。<br>从世界坐标系到像素坐标系之间的转换关系可知，已知世界坐标系下的三维点坐标，只要已知内外参矩阵，就可以求得像素坐标。而如果已知像素坐标，即使已知内外参矩阵，其世界坐标下的三维点也不是唯一确定的，而是空间的一条直线。即单目相机只能测平面信息，而不能获取深度信息。</p>\n<h2 id=\"归一化\"><a href=\"#归一化\" class=\"headerlink\" title=\"归一化\"></a>归一化</h2><p>在坐标变换过程中通常需要进行归一化处理，得到点在相机归一化平面上的投影，归一化平面是假想的。</p>\n<p>三维点在相机坐标系下表示形式为：</p>\n<p>$P_c=\\left[\\begin{matrix}x_c\\y_c\\z_c\\end{matrix}\\right]$</p>\n<p>所以有：</p>\n<p>$\\left[ \\begin{matrix}z_cu\\z_cv\\z_c\\end{matrix}\\right] = K\\left[ \\begin{matrix}x_c\\y_c\\z_c\\end{matrix}\\right]=KPc$</p>\n<p>由上式可知，三维点直接经过内参得到的坐标相当于$u,v$坐标在各自的方向上都放大了$z<em>c$倍。归一化平面是指位于相机前方z=1处的平面上，该平面称为归一化平面。归一化坐标就相当于在$z$的方向上当z=1时用一个平面截断，这时光心与3D点的连线在该面上的点即为该三维点的归一化点，记做$P</em>{c1}$：</p>\n<p>$P_{c1}=\\left[\\begin{matrix}\\frac{x_c}{z_c}\\\\frac{y_c}{z_c}\\1\\end{matrix}\\right]$</p>\n<p>由归一化坐标经过内参矩阵后就得到了像素坐标：</p>\n<p>$\\left[\\begin{matrix}u\\v\\1\\end{matrix}\\right]=K\\left[\\begin{matrix}\\frac{x<em>c}{z_c}\\\\frac{y_c}{z_c}\\1\\end{matrix}\\right]=KP</em>{c1}$</p>\n<p>因此可以把像素坐标看成对归一化平面上的点进行量化测量的结果。</p>\n<h2 id=\"畸变\"><a href=\"#畸变\" class=\"headerlink\" title=\"畸变\"></a>畸变</h2><p>由于相机透镜的使用，会引入径向畸变，主要分为桶型畸变和枕型畸变 ；由于相机透镜组装过程的误差，导致透镜与成像平面不能严格平行，会引入切向畸变。严格意义上，还需要对这些畸变进行畸变矫正。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>视觉SLAM十四讲第5讲</li>\n<li><a href=\"http://zhehangt.win/2017/02/16/SLAM/CameraModel/\" target=\"_blank\" rel=\"noopener\">针孔相机模型</a></li>\n<li><a href=\"https://blog.csdn.net/chentravelling/article/details/53558096\" target=\"_blank\" rel=\"noopener\">计算机视觉：相机成像原理：世界坐标系、相机坐标系、图像坐标系、像素坐标系之间的转换</a></li>\n<li><a href=\"https://blog.csdn.net/huangjingwei13/article/details/71439293\" target=\"_blank\" rel=\"noopener\">相机成像模型</a></li>\n</ol>"},{"title":"论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》","date":"2019-05-20T13:11:34.000Z","mathjax":true,"copyright":true,"_content":"---\n\n本篇文章记录自己在阅读PTAM论文时整理的一些要点。\n<!--more--->\n\nPTAM，是最早提出将Track和Map并行处理的一种SLAM算法，是一种**基于关键帧**和**非线性优化**的**单目视觉SLAM算法**。PTAM的贡献是具有重大意义的：\n\n- 首次实现跟踪与建图的并行化；\n- 首次使用非线性优化，替代传统滤波器后端方案；\n- 引入关键帧机制。\n\n**缺点**：适用场景小，跟踪容易丢失。\n\n## Tracker线程\n\n> 鲁棒估计相机运动。\n\n### 主要任务\n\n- 估计相机位姿，使用Map完成追踪（初始化时使用2D-2D方法估算初始位姿，后续过程使用3D-2D方法追踪）\n- 与Map线程通信，选取添加关键帧到缓存队列，进而发送到Map\n- 构建关键帧，关键帧的选择\n- 地图初始化\n- 重定位\n\nTracking线程也用到关键帧，每一个新的图像帧都会在追踪过程进行之前构建一个关键帧。但，大部分关键帧都被丢弃，未被丢弃的关键帧加入到Map，这些是真正意义上的关键帧。\n\n### 重要函数\n\n1. `MakeKeyFrame_Lite`：使用当前帧构建初始关键帧\n\n2. `TrackForInitialMap`：**地图初始化**。由于刚开始没有地图，需要在双目图像帧（使用的是第一帧图像以及有足够平移的另一帧图像，保证双目模型的基线满足）中进行简单的Patch搜索。Patch搜索是在`TrailTracking_Advance`进行的。具体过程如下：\n\n   {% asset_img patchsearch.png %}\n\n   - 第一帧图像构建初始关键帧（该过程检测FAST角点），调用`TrailTracking_Start`函数，完善关键帧结构，包括对金字塔层级所有图像中的FAST角点非极大值抑制，并使用Shi-Tomasi方法计算角点得分，选取高得分角点（作为候选关键点）；\n   - 根据Shi-Tomasi得分，对上述候选关键点排序，将这些候选关键点全部加入待追踪/匹配集合，并提取它们的局部Patch；\n   - 正向搜索。第二帧（合适的、距离第一帧有一定距离）图像构建初始关键帧，调用`TrailTracking_Advance`函数，对于上一帧关键帧中的每一个$Corner_i$的$Patch_i$，在当前关键帧的FAST角点中基于SSD匹配（是块匹配），搜索最佳的角点$Corner_j$，提取$Corner_j$的局部块$Patch_j$；\n   - 反向搜索（Cross Check Test？）。在上一帧关键帧中的FAST角点中搜索与$Pathc_j$匹配的最佳的角点$Corner_k$；\n   - 判断$i-k<=2$，则$Corner_j$是$Corner_i$的匹配关键点；如果没找到$Corner_i$的匹配点，则将$Corner_i$删除，是从待追踪/匹配集合中删除，而不是从关键帧候选关键点集合中删除（后面三角化完成之后还会根据候选关键点集合，采用极线搜索添加三维地图点，所以这里不会删除候选关键点）；\n   - 如果追踪/匹配到的角点对数量>=10，则用这些匹配到的点对，调用`InitFromStereo`函数，求取两个关键帧的初始位姿和初始地图：\n     - 使用单应矩阵求位姿，作为相机初始位姿；\n     - 设置尺度，缩小为实际距离的0.1倍；\n     - 使用匹配点对三角化求三维地图点（[三角化参考博客](https://blog.csdn.net/u011178262/article/details/86729887)），`Triangulate`函数得到第一视图坐标系下的坐标；\n     - 全局BA优化三维地图点和相机位姿；\n     - 极线搜索添加三维地图点。将地图点对应的二维坐标周围10*10区域内的候选关键点删除，使用剩下的候选关键点进行极线搜索，并三角化添加三维地图点，极线搜索是在最新的关键帧与其最近的关键帧之间进行的；\n     - 统一世界坐标系。\n   - 至此，`TrackForInitialMap`函数完成**地图初始化**。\n\n3. `PredictPoseWithMotionModel`：减速运动模型（匀速运动模型使用比较多）预测相机位姿\n\n   - 计算上一帧图像高斯模糊小图的雅可比矩阵\n   - 采用ESM（[Efficient Second-order Minimization](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6918&rep=rep1&type=pdf)）跟踪算法跟踪当前帧，计算当前帧图像相对于上一帧图像的旋转矩阵\n\n4. `TrackMap`：使用估算的位姿，将所有地图点投影到当前帧图像，不在当前帧图像中的地图点丢弃\n\n   - 根据预测的相机位姿，将当前所有世界点根据小孔成像原理进行投影，投影后的像素点记为pi，并计算出对应的金字塔层级\n   - 根据金字塔高层优先原则，选取一定数量世界点（通常，粗搜索选取30～60个，细搜索选取1000个左右）\n\n5. \n\n## Mapping\n\n> 从之前观测到的视频帧中产生三维地图点特征。\n\n主要任务：\n\n- 从缓存队列中提取关键帧到地图\n- Global BA\n- Local BA：只调整一部分关键帧的位姿，以及这些关键帧对应的所有地图点的位置。PTAM中调整地图中最新的5个关键帧的位姿。\n- **极线搜索添加新的地图点到地图**\n- 数据关联的细化\n\n优先级：关键帧插入>BA>数据关联细化操作。\n\n### 地图 Map\n\n- 3D Point Features\n- Keyframes\n\n### 地图点\n\n- 每个地图点`MapPoint`保存第一次观测到该地图点的关键帧索引，保存该地图点对应的特征点所在金字塔层级，以及在该层级图像中的像素坐标\n- 每个地图点对应一个观测结构`Measurement`，该结构中保存地图点在关键帧图像中的金字塔层级、像素坐标以及观测来源，即该地图点是如何观测到的\n\n### 关键帧 Keyframes\n\n每个关键帧包括四层金字塔图像，下采样（四个像素的平均）得到的低分辨率的上层图像，每一层为一个数据结构Level，金字塔每层图像（每层Level）保存该层图像上的所有的FAST角点，它们经过Shi-Tomasi得分筛选之后，成为关键点候选`Candidate`，即可能会对应一个三维地图点，这些候选能够生成三维地图点的方式：\n\n- Patch匹配三角化得到三维地图点\n- 极线搜索三角化得到三维地图点\n- ....\n\n构造金字塔的目的：加快匹配；提高地图点相对于相机远近变化的鲁棒性。\n\n> - 每个关键帧中保存所有与其关联的（该关键帧观测范围内的）地图点\n>\n> - 每个关键帧中的金字塔图像中保存候选的关键点，会在后续过程中三角化生成地图点\n\n#### 关键帧有关的操作\n\n- 关键帧构建（`MakeKeyFrame_Lite`函数）过程/初始化，在关键帧四层金字塔，即四层图像中，进行FAST角点的检测，没有非极大值抑制（其实是在Tracking线程中进行）；\n- 关键帧初始化过程使用Tracking线程估计的相机位姿和特征点的观测数据；\n- Tracking线程只测量图像帧中潜在视觉特征的一部分，Mapping线程将这些特征反投影、测量其他的特征。即与关键帧关联的地图点可能是Tracking线程得到的，可能是Mapping线程得到的；\n- Mapping线程（`MakeKeyFrame_Rest`函数）对FAST角点进行极大值抑制，使用Shi-Tomasi分数，确定生成地图点的候选特征点；候选特征点对应的地图点如果距离已有的观测地图点比较近，这些候选特征点将会被剔除。\n\n#### 关键帧加入地图的条件\n\n- 关键帧追踪的质量达到标准；\n- 距离上一次加入的关键帧已经超过20个图像帧；\n- 相机必须与地图中已有的最近关键点保持最小距离，需要保证三角化的基线不能过大、过小。最小距离取决于观测到的特征的平均深度值，即观测到的特征距离相机越远，关键帧之间的距离就越大。\n\n### Map初始化？？？？\n\n地图初始化过程需要前两帧图像，前两帧图像都设定为关键帧。随着相机的运动，新的关键帧和地图点被加入到地图中。\n\n- 首先在第一帧关键帧中检测1000个FAST角点，构成2D图像块；\n- 在第二帧图像中追踪上述图像块；\n- 采用五点法对极约束，求取基础矩阵，提取两帧图像之间的旋转和平移；\n- 同时使用RANSAC方法剔除异常点；\n- 使用匹配到的点对，三角化生成三维地图点，建立初始地图。\n\n### 特征点三角化\n\n基于关键帧图像，三角化获取特征点的三维坐标信息，该过程一个关键帧是无法完成的，需要两个关键帧。PTAM选择地图中已有的最近的两个关键帧进行三角化操作。使用对极搜索获取两个关键帧中的关联特征，关联过程为：\n\n- 对于第一个关键帧图像中的某个特征，提取其像素坐标周围的局部像素块P； \n- 在第二帧关键帧图像中的极线上搜索与P最接近的像素块，确定关联特征的位置；\n- 两个像素块的比较使用zero-mean SSD，并且只在相同的金字塔层级内进行；\n- 一旦匹配到一对特征点，则采用三角化方法求取新的地图点，并将新的地图点插入地图。\n\n### Bundle Adjustment\n\n全局的BA能够调整所有关键帧的位姿以及所有地图点的位置。\n\n全局BA利用了SFM问题固有的稀疏性，将三次代价矩阵分解的复杂性从$O((N+M)^3)$降低为$O(N^3)$。\n\n有新的关键帧插入Maping线程时，会中断BA操作，保证新的关键帧可以及时插入地图中。\n\n局部BA的复杂性也是和地图的大小有关的。\n\n### 数据关联细化\n\nBA收敛并且不再需要新的关键帧时，即相机已经处于一个建图比较理想的环境中，此时Mapping处于空闲状态，可以进行地图的优化，即数据关联的细化。\n\n数据关联的细化主要是通过在旧的关键帧中进行新的测量来完成的，可以是测量新加入的地图点在旧的关键帧中的位置，例如，通过对极搜索新加入的特征点，对其进行的初始测量只和两个关键帧有关联，即进行对极约束的两个关键帧。但是其他的关键帧也可能会观测到该特征点；也可以是再次进行异常点测量。\n\n该过程优先级低于BA。\n\n## 参考资料\n\n1. 墙裂推荐：https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM\n2. https://blog.csdn.net/ilotuo/article/category/6297333\n3. https://blog.csdn.net/u013925378/article/details/77455555\n4. https://blog.csdn.net/u011178262/article/details/79315782\n5. https://blog.csdn.net/u011178262/article/details/86729887","source":"_posts/论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》.md","raw":"---\ntitle: 论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》\ndate: 2019-05-20 21:11:34\ntags: \n  - SLAM\n  - PTAM\n  - 特征法SLAM\n  - 单目SLAM\ncategories: \n  - 机器人\n  - SLAM\n  - 论文阅读\nmathjax: true\ncopyright: true\n---\n---\n\n本篇文章记录自己在阅读PTAM论文时整理的一些要点。\n<!--more--->\n\nPTAM，是最早提出将Track和Map并行处理的一种SLAM算法，是一种**基于关键帧**和**非线性优化**的**单目视觉SLAM算法**。PTAM的贡献是具有重大意义的：\n\n- 首次实现跟踪与建图的并行化；\n- 首次使用非线性优化，替代传统滤波器后端方案；\n- 引入关键帧机制。\n\n**缺点**：适用场景小，跟踪容易丢失。\n\n## Tracker线程\n\n> 鲁棒估计相机运动。\n\n### 主要任务\n\n- 估计相机位姿，使用Map完成追踪（初始化时使用2D-2D方法估算初始位姿，后续过程使用3D-2D方法追踪）\n- 与Map线程通信，选取添加关键帧到缓存队列，进而发送到Map\n- 构建关键帧，关键帧的选择\n- 地图初始化\n- 重定位\n\nTracking线程也用到关键帧，每一个新的图像帧都会在追踪过程进行之前构建一个关键帧。但，大部分关键帧都被丢弃，未被丢弃的关键帧加入到Map，这些是真正意义上的关键帧。\n\n### 重要函数\n\n1. `MakeKeyFrame_Lite`：使用当前帧构建初始关键帧\n\n2. `TrackForInitialMap`：**地图初始化**。由于刚开始没有地图，需要在双目图像帧（使用的是第一帧图像以及有足够平移的另一帧图像，保证双目模型的基线满足）中进行简单的Patch搜索。Patch搜索是在`TrailTracking_Advance`进行的。具体过程如下：\n\n   {% asset_img patchsearch.png %}\n\n   - 第一帧图像构建初始关键帧（该过程检测FAST角点），调用`TrailTracking_Start`函数，完善关键帧结构，包括对金字塔层级所有图像中的FAST角点非极大值抑制，并使用Shi-Tomasi方法计算角点得分，选取高得分角点（作为候选关键点）；\n   - 根据Shi-Tomasi得分，对上述候选关键点排序，将这些候选关键点全部加入待追踪/匹配集合，并提取它们的局部Patch；\n   - 正向搜索。第二帧（合适的、距离第一帧有一定距离）图像构建初始关键帧，调用`TrailTracking_Advance`函数，对于上一帧关键帧中的每一个$Corner_i$的$Patch_i$，在当前关键帧的FAST角点中基于SSD匹配（是块匹配），搜索最佳的角点$Corner_j$，提取$Corner_j$的局部块$Patch_j$；\n   - 反向搜索（Cross Check Test？）。在上一帧关键帧中的FAST角点中搜索与$Pathc_j$匹配的最佳的角点$Corner_k$；\n   - 判断$i-k<=2$，则$Corner_j$是$Corner_i$的匹配关键点；如果没找到$Corner_i$的匹配点，则将$Corner_i$删除，是从待追踪/匹配集合中删除，而不是从关键帧候选关键点集合中删除（后面三角化完成之后还会根据候选关键点集合，采用极线搜索添加三维地图点，所以这里不会删除候选关键点）；\n   - 如果追踪/匹配到的角点对数量>=10，则用这些匹配到的点对，调用`InitFromStereo`函数，求取两个关键帧的初始位姿和初始地图：\n     - 使用单应矩阵求位姿，作为相机初始位姿；\n     - 设置尺度，缩小为实际距离的0.1倍；\n     - 使用匹配点对三角化求三维地图点（[三角化参考博客](https://blog.csdn.net/u011178262/article/details/86729887)），`Triangulate`函数得到第一视图坐标系下的坐标；\n     - 全局BA优化三维地图点和相机位姿；\n     - 极线搜索添加三维地图点。将地图点对应的二维坐标周围10*10区域内的候选关键点删除，使用剩下的候选关键点进行极线搜索，并三角化添加三维地图点，极线搜索是在最新的关键帧与其最近的关键帧之间进行的；\n     - 统一世界坐标系。\n   - 至此，`TrackForInitialMap`函数完成**地图初始化**。\n\n3. `PredictPoseWithMotionModel`：减速运动模型（匀速运动模型使用比较多）预测相机位姿\n\n   - 计算上一帧图像高斯模糊小图的雅可比矩阵\n   - 采用ESM（[Efficient Second-order Minimization](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6918&rep=rep1&type=pdf)）跟踪算法跟踪当前帧，计算当前帧图像相对于上一帧图像的旋转矩阵\n\n4. `TrackMap`：使用估算的位姿，将所有地图点投影到当前帧图像，不在当前帧图像中的地图点丢弃\n\n   - 根据预测的相机位姿，将当前所有世界点根据小孔成像原理进行投影，投影后的像素点记为pi，并计算出对应的金字塔层级\n   - 根据金字塔高层优先原则，选取一定数量世界点（通常，粗搜索选取30～60个，细搜索选取1000个左右）\n\n5. \n\n## Mapping\n\n> 从之前观测到的视频帧中产生三维地图点特征。\n\n主要任务：\n\n- 从缓存队列中提取关键帧到地图\n- Global BA\n- Local BA：只调整一部分关键帧的位姿，以及这些关键帧对应的所有地图点的位置。PTAM中调整地图中最新的5个关键帧的位姿。\n- **极线搜索添加新的地图点到地图**\n- 数据关联的细化\n\n优先级：关键帧插入>BA>数据关联细化操作。\n\n### 地图 Map\n\n- 3D Point Features\n- Keyframes\n\n### 地图点\n\n- 每个地图点`MapPoint`保存第一次观测到该地图点的关键帧索引，保存该地图点对应的特征点所在金字塔层级，以及在该层级图像中的像素坐标\n- 每个地图点对应一个观测结构`Measurement`，该结构中保存地图点在关键帧图像中的金字塔层级、像素坐标以及观测来源，即该地图点是如何观测到的\n\n### 关键帧 Keyframes\n\n每个关键帧包括四层金字塔图像，下采样（四个像素的平均）得到的低分辨率的上层图像，每一层为一个数据结构Level，金字塔每层图像（每层Level）保存该层图像上的所有的FAST角点，它们经过Shi-Tomasi得分筛选之后，成为关键点候选`Candidate`，即可能会对应一个三维地图点，这些候选能够生成三维地图点的方式：\n\n- Patch匹配三角化得到三维地图点\n- 极线搜索三角化得到三维地图点\n- ....\n\n构造金字塔的目的：加快匹配；提高地图点相对于相机远近变化的鲁棒性。\n\n> - 每个关键帧中保存所有与其关联的（该关键帧观测范围内的）地图点\n>\n> - 每个关键帧中的金字塔图像中保存候选的关键点，会在后续过程中三角化生成地图点\n\n#### 关键帧有关的操作\n\n- 关键帧构建（`MakeKeyFrame_Lite`函数）过程/初始化，在关键帧四层金字塔，即四层图像中，进行FAST角点的检测，没有非极大值抑制（其实是在Tracking线程中进行）；\n- 关键帧初始化过程使用Tracking线程估计的相机位姿和特征点的观测数据；\n- Tracking线程只测量图像帧中潜在视觉特征的一部分，Mapping线程将这些特征反投影、测量其他的特征。即与关键帧关联的地图点可能是Tracking线程得到的，可能是Mapping线程得到的；\n- Mapping线程（`MakeKeyFrame_Rest`函数）对FAST角点进行极大值抑制，使用Shi-Tomasi分数，确定生成地图点的候选特征点；候选特征点对应的地图点如果距离已有的观测地图点比较近，这些候选特征点将会被剔除。\n\n#### 关键帧加入地图的条件\n\n- 关键帧追踪的质量达到标准；\n- 距离上一次加入的关键帧已经超过20个图像帧；\n- 相机必须与地图中已有的最近关键点保持最小距离，需要保证三角化的基线不能过大、过小。最小距离取决于观测到的特征的平均深度值，即观测到的特征距离相机越远，关键帧之间的距离就越大。\n\n### Map初始化？？？？\n\n地图初始化过程需要前两帧图像，前两帧图像都设定为关键帧。随着相机的运动，新的关键帧和地图点被加入到地图中。\n\n- 首先在第一帧关键帧中检测1000个FAST角点，构成2D图像块；\n- 在第二帧图像中追踪上述图像块；\n- 采用五点法对极约束，求取基础矩阵，提取两帧图像之间的旋转和平移；\n- 同时使用RANSAC方法剔除异常点；\n- 使用匹配到的点对，三角化生成三维地图点，建立初始地图。\n\n### 特征点三角化\n\n基于关键帧图像，三角化获取特征点的三维坐标信息，该过程一个关键帧是无法完成的，需要两个关键帧。PTAM选择地图中已有的最近的两个关键帧进行三角化操作。使用对极搜索获取两个关键帧中的关联特征，关联过程为：\n\n- 对于第一个关键帧图像中的某个特征，提取其像素坐标周围的局部像素块P； \n- 在第二帧关键帧图像中的极线上搜索与P最接近的像素块，确定关联特征的位置；\n- 两个像素块的比较使用zero-mean SSD，并且只在相同的金字塔层级内进行；\n- 一旦匹配到一对特征点，则采用三角化方法求取新的地图点，并将新的地图点插入地图。\n\n### Bundle Adjustment\n\n全局的BA能够调整所有关键帧的位姿以及所有地图点的位置。\n\n全局BA利用了SFM问题固有的稀疏性，将三次代价矩阵分解的复杂性从$O((N+M)^3)$降低为$O(N^3)$。\n\n有新的关键帧插入Maping线程时，会中断BA操作，保证新的关键帧可以及时插入地图中。\n\n局部BA的复杂性也是和地图的大小有关的。\n\n### 数据关联细化\n\nBA收敛并且不再需要新的关键帧时，即相机已经处于一个建图比较理想的环境中，此时Mapping处于空闲状态，可以进行地图的优化，即数据关联的细化。\n\n数据关联的细化主要是通过在旧的关键帧中进行新的测量来完成的，可以是测量新加入的地图点在旧的关键帧中的位置，例如，通过对极搜索新加入的特征点，对其进行的初始测量只和两个关键帧有关联，即进行对极约束的两个关键帧。但是其他的关键帧也可能会观测到该特征点；也可以是再次进行异常点测量。\n\n该过程优先级低于BA。\n\n## 参考资料\n\n1. 墙裂推荐：https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM\n2. https://blog.csdn.net/ilotuo/article/category/6297333\n3. https://blog.csdn.net/u013925378/article/details/77455555\n4. https://blog.csdn.net/u011178262/article/details/79315782\n5. https://blog.csdn.net/u011178262/article/details/86729887","slug":"论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc0d00cyqlcr14q6b7ob","content":"<hr>\n<p>本篇文章记录自己在阅读PTAM论文时整理的一些要点。<br><a id=\"more\"></a></p>\n<p>PTAM，是最早提出将Track和Map并行处理的一种SLAM算法，是一种<strong>基于关键帧</strong>和<strong>非线性优化</strong>的<strong>单目视觉SLAM算法</strong>。PTAM的贡献是具有重大意义的：</p>\n<ul>\n<li>首次实现跟踪与建图的并行化；</li>\n<li>首次使用非线性优化，替代传统滤波器后端方案；</li>\n<li>引入关键帧机制。</li>\n</ul>\n<p><strong>缺点</strong>：适用场景小，跟踪容易丢失。</p>\n<h2 id=\"Tracker线程\"><a href=\"#Tracker线程\" class=\"headerlink\" title=\"Tracker线程\"></a>Tracker线程</h2><blockquote>\n<p>鲁棒估计相机运动。</p>\n</blockquote>\n<h3 id=\"主要任务\"><a href=\"#主要任务\" class=\"headerlink\" title=\"主要任务\"></a>主要任务</h3><ul>\n<li>估计相机位姿，使用Map完成追踪（初始化时使用2D-2D方法估算初始位姿，后续过程使用3D-2D方法追踪）</li>\n<li>与Map线程通信，选取添加关键帧到缓存队列，进而发送到Map</li>\n<li>构建关键帧，关键帧的选择</li>\n<li>地图初始化</li>\n<li>重定位</li>\n</ul>\n<p>Tracking线程也用到关键帧，每一个新的图像帧都会在追踪过程进行之前构建一个关键帧。但，大部分关键帧都被丢弃，未被丢弃的关键帧加入到Map，这些是真正意义上的关键帧。</p>\n<h3 id=\"重要函数\"><a href=\"#重要函数\" class=\"headerlink\" title=\"重要函数\"></a>重要函数</h3><ol>\n<li><p><code>MakeKeyFrame_Lite</code>：使用当前帧构建初始关键帧</p>\n</li>\n<li><p><code>TrackForInitialMap</code>：<strong>地图初始化</strong>。由于刚开始没有地图，需要在双目图像帧（使用的是第一帧图像以及有足够平移的另一帧图像，保证双目模型的基线满足）中进行简单的Patch搜索。Patch搜索是在<code>TrailTracking_Advance</code>进行的。具体过程如下：</p>\n<img src=\"/2019/05/20/论文阅读之《Parallel%20Tracking%20and%20Mapping%20for%20Small%20AR%20Workspaces》/patchsearch.png\">\n<ul>\n<li>第一帧图像构建初始关键帧（该过程检测FAST角点），调用<code>TrailTracking_Start</code>函数，完善关键帧结构，包括对金字塔层级所有图像中的FAST角点非极大值抑制，并使用Shi-Tomasi方法计算角点得分，选取高得分角点（作为候选关键点）；</li>\n<li>根据Shi-Tomasi得分，对上述候选关键点排序，将这些候选关键点全部加入待追踪/匹配集合，并提取它们的局部Patch；</li>\n<li>正向搜索。第二帧（合适的、距离第一帧有一定距离）图像构建初始关键帧，调用<code>TrailTracking_Advance</code>函数，对于上一帧关键帧中的每一个$Corner_i$的$Patch_i$，在当前关键帧的FAST角点中基于SSD匹配（是块匹配），搜索最佳的角点$Corner_j$，提取$Corner_j$的局部块$Patch_j$；</li>\n<li>反向搜索（Cross Check Test？）。在上一帧关键帧中的FAST角点中搜索与$Pathc_j$匹配的最佳的角点$Corner_k$；</li>\n<li>判断$i-k&lt;=2$，则$Corner_j$是$Corner_i$的匹配关键点；如果没找到$Corner_i$的匹配点，则将$Corner_i$删除，是从待追踪/匹配集合中删除，而不是从关键帧候选关键点集合中删除（后面三角化完成之后还会根据候选关键点集合，采用极线搜索添加三维地图点，所以这里不会删除候选关键点）；</li>\n<li>如果追踪/匹配到的角点对数量&gt;=10，则用这些匹配到的点对，调用<code>InitFromStereo</code>函数，求取两个关键帧的初始位姿和初始地图：<ul>\n<li>使用单应矩阵求位姿，作为相机初始位姿；</li>\n<li>设置尺度，缩小为实际距离的0.1倍；</li>\n<li>使用匹配点对三角化求三维地图点（<a href=\"https://blog.csdn.net/u011178262/article/details/86729887\" target=\"_blank\" rel=\"noopener\">三角化参考博客</a>），<code>Triangulate</code>函数得到第一视图坐标系下的坐标；</li>\n<li>全局BA优化三维地图点和相机位姿；</li>\n<li>极线搜索添加三维地图点。将地图点对应的二维坐标周围10*10区域内的候选关键点删除，使用剩下的候选关键点进行极线搜索，并三角化添加三维地图点，极线搜索是在最新的关键帧与其最近的关键帧之间进行的；</li>\n<li>统一世界坐标系。</li>\n</ul>\n</li>\n<li>至此，<code>TrackForInitialMap</code>函数完成<strong>地图初始化</strong>。</li>\n</ul>\n</li>\n<li><p><code>PredictPoseWithMotionModel</code>：减速运动模型（匀速运动模型使用比较多）预测相机位姿</p>\n<ul>\n<li>计算上一帧图像高斯模糊小图的雅可比矩阵</li>\n<li>采用ESM（<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6918&amp;rep=rep1&amp;type=pdf\" target=\"_blank\" rel=\"noopener\">Efficient Second-order Minimization</a>）跟踪算法跟踪当前帧，计算当前帧图像相对于上一帧图像的旋转矩阵</li>\n</ul>\n</li>\n<li><p><code>TrackMap</code>：使用估算的位姿，将所有地图点投影到当前帧图像，不在当前帧图像中的地图点丢弃</p>\n<ul>\n<li>根据预测的相机位姿，将当前所有世界点根据小孔成像原理进行投影，投影后的像素点记为pi，并计算出对应的金字塔层级</li>\n<li>根据金字塔高层优先原则，选取一定数量世界点（通常，粗搜索选取30～60个，细搜索选取1000个左右）</li>\n</ul>\n</li>\n<li></li>\n</ol>\n<h2 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h2><blockquote>\n<p>从之前观测到的视频帧中产生三维地图点特征。</p>\n</blockquote>\n<p>主要任务：</p>\n<ul>\n<li>从缓存队列中提取关键帧到地图</li>\n<li>Global BA</li>\n<li>Local BA：只调整一部分关键帧的位姿，以及这些关键帧对应的所有地图点的位置。PTAM中调整地图中最新的5个关键帧的位姿。</li>\n<li><strong>极线搜索添加新的地图点到地图</strong></li>\n<li>数据关联的细化</li>\n</ul>\n<p>优先级：关键帧插入&gt;BA&gt;数据关联细化操作。</p>\n<h3 id=\"地图-Map\"><a href=\"#地图-Map\" class=\"headerlink\" title=\"地图 Map\"></a>地图 Map</h3><ul>\n<li>3D Point Features</li>\n<li>Keyframes</li>\n</ul>\n<h3 id=\"地图点\"><a href=\"#地图点\" class=\"headerlink\" title=\"地图点\"></a>地图点</h3><ul>\n<li>每个地图点<code>MapPoint</code>保存第一次观测到该地图点的关键帧索引，保存该地图点对应的特征点所在金字塔层级，以及在该层级图像中的像素坐标</li>\n<li>每个地图点对应一个观测结构<code>Measurement</code>，该结构中保存地图点在关键帧图像中的金字塔层级、像素坐标以及观测来源，即该地图点是如何观测到的</li>\n</ul>\n<h3 id=\"关键帧-Keyframes\"><a href=\"#关键帧-Keyframes\" class=\"headerlink\" title=\"关键帧 Keyframes\"></a>关键帧 Keyframes</h3><p>每个关键帧包括四层金字塔图像，下采样（四个像素的平均）得到的低分辨率的上层图像，每一层为一个数据结构Level，金字塔每层图像（每层Level）保存该层图像上的所有的FAST角点，它们经过Shi-Tomasi得分筛选之后，成为关键点候选<code>Candidate</code>，即可能会对应一个三维地图点，这些候选能够生成三维地图点的方式：</p>\n<ul>\n<li>Patch匹配三角化得到三维地图点</li>\n<li>极线搜索三角化得到三维地图点</li>\n<li>….</li>\n</ul>\n<p>构造金字塔的目的：加快匹配；提高地图点相对于相机远近变化的鲁棒性。</p>\n<blockquote>\n<ul>\n<li><p>每个关键帧中保存所有与其关联的（该关键帧观测范围内的）地图点</p>\n</li>\n<li><p>每个关键帧中的金字塔图像中保存候选的关键点，会在后续过程中三角化生成地图点</p>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"关键帧有关的操作\"><a href=\"#关键帧有关的操作\" class=\"headerlink\" title=\"关键帧有关的操作\"></a>关键帧有关的操作</h4><ul>\n<li>关键帧构建（<code>MakeKeyFrame_Lite</code>函数）过程/初始化，在关键帧四层金字塔，即四层图像中，进行FAST角点的检测，没有非极大值抑制（其实是在Tracking线程中进行）；</li>\n<li>关键帧初始化过程使用Tracking线程估计的相机位姿和特征点的观测数据；</li>\n<li>Tracking线程只测量图像帧中潜在视觉特征的一部分，Mapping线程将这些特征反投影、测量其他的特征。即与关键帧关联的地图点可能是Tracking线程得到的，可能是Mapping线程得到的；</li>\n<li>Mapping线程（<code>MakeKeyFrame_Rest</code>函数）对FAST角点进行极大值抑制，使用Shi-Tomasi分数，确定生成地图点的候选特征点；候选特征点对应的地图点如果距离已有的观测地图点比较近，这些候选特征点将会被剔除。</li>\n</ul>\n<h4 id=\"关键帧加入地图的条件\"><a href=\"#关键帧加入地图的条件\" class=\"headerlink\" title=\"关键帧加入地图的条件\"></a>关键帧加入地图的条件</h4><ul>\n<li>关键帧追踪的质量达到标准；</li>\n<li>距离上一次加入的关键帧已经超过20个图像帧；</li>\n<li>相机必须与地图中已有的最近关键点保持最小距离，需要保证三角化的基线不能过大、过小。最小距离取决于观测到的特征的平均深度值，即观测到的特征距离相机越远，关键帧之间的距离就越大。</li>\n</ul>\n<h3 id=\"Map初始化？？？？\"><a href=\"#Map初始化？？？？\" class=\"headerlink\" title=\"Map初始化？？？？\"></a>Map初始化？？？？</h3><p>地图初始化过程需要前两帧图像，前两帧图像都设定为关键帧。随着相机的运动，新的关键帧和地图点被加入到地图中。</p>\n<ul>\n<li>首先在第一帧关键帧中检测1000个FAST角点，构成2D图像块；</li>\n<li>在第二帧图像中追踪上述图像块；</li>\n<li>采用五点法对极约束，求取基础矩阵，提取两帧图像之间的旋转和平移；</li>\n<li>同时使用RANSAC方法剔除异常点；</li>\n<li>使用匹配到的点对，三角化生成三维地图点，建立初始地图。</li>\n</ul>\n<h3 id=\"特征点三角化\"><a href=\"#特征点三角化\" class=\"headerlink\" title=\"特征点三角化\"></a>特征点三角化</h3><p>基于关键帧图像，三角化获取特征点的三维坐标信息，该过程一个关键帧是无法完成的，需要两个关键帧。PTAM选择地图中已有的最近的两个关键帧进行三角化操作。使用对极搜索获取两个关键帧中的关联特征，关联过程为：</p>\n<ul>\n<li>对于第一个关键帧图像中的某个特征，提取其像素坐标周围的局部像素块P； </li>\n<li>在第二帧关键帧图像中的极线上搜索与P最接近的像素块，确定关联特征的位置；</li>\n<li>两个像素块的比较使用zero-mean SSD，并且只在相同的金字塔层级内进行；</li>\n<li>一旦匹配到一对特征点，则采用三角化方法求取新的地图点，并将新的地图点插入地图。</li>\n</ul>\n<h3 id=\"Bundle-Adjustment\"><a href=\"#Bundle-Adjustment\" class=\"headerlink\" title=\"Bundle Adjustment\"></a>Bundle Adjustment</h3><p>全局的BA能够调整所有关键帧的位姿以及所有地图点的位置。</p>\n<p>全局BA利用了SFM问题固有的稀疏性，将三次代价矩阵分解的复杂性从$O((N+M)^3)$降低为$O(N^3)$。</p>\n<p>有新的关键帧插入Maping线程时，会中断BA操作，保证新的关键帧可以及时插入地图中。</p>\n<p>局部BA的复杂性也是和地图的大小有关的。</p>\n<h3 id=\"数据关联细化\"><a href=\"#数据关联细化\" class=\"headerlink\" title=\"数据关联细化\"></a>数据关联细化</h3><p>BA收敛并且不再需要新的关键帧时，即相机已经处于一个建图比较理想的环境中，此时Mapping处于空闲状态，可以进行地图的优化，即数据关联的细化。</p>\n<p>数据关联的细化主要是通过在旧的关键帧中进行新的测量来完成的，可以是测量新加入的地图点在旧的关键帧中的位置，例如，通过对极搜索新加入的特征点，对其进行的初始测量只和两个关键帧有关联，即进行对极约束的两个关键帧。但是其他的关键帧也可能会观测到该特征点；也可以是再次进行异常点测量。</p>\n<p>该过程优先级低于BA。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>墙裂推荐：<a href=\"https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM\" target=\"_blank\" rel=\"noopener\">https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM</a></li>\n<li><a href=\"https://blog.csdn.net/ilotuo/article/category/6297333\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ilotuo/article/category/6297333</a></li>\n<li><a href=\"https://blog.csdn.net/u013925378/article/details/77455555\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013925378/article/details/77455555</a></li>\n<li><a href=\"https://blog.csdn.net/u011178262/article/details/79315782\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011178262/article/details/79315782</a></li>\n<li><a href=\"https://blog.csdn.net/u011178262/article/details/86729887\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011178262/article/details/86729887</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本篇文章记录自己在阅读PTAM论文时整理的一些要点。<br>","more":"</p>\n<p>PTAM，是最早提出将Track和Map并行处理的一种SLAM算法，是一种<strong>基于关键帧</strong>和<strong>非线性优化</strong>的<strong>单目视觉SLAM算法</strong>。PTAM的贡献是具有重大意义的：</p>\n<ul>\n<li>首次实现跟踪与建图的并行化；</li>\n<li>首次使用非线性优化，替代传统滤波器后端方案；</li>\n<li>引入关键帧机制。</li>\n</ul>\n<p><strong>缺点</strong>：适用场景小，跟踪容易丢失。</p>\n<h2 id=\"Tracker线程\"><a href=\"#Tracker线程\" class=\"headerlink\" title=\"Tracker线程\"></a>Tracker线程</h2><blockquote>\n<p>鲁棒估计相机运动。</p>\n</blockquote>\n<h3 id=\"主要任务\"><a href=\"#主要任务\" class=\"headerlink\" title=\"主要任务\"></a>主要任务</h3><ul>\n<li>估计相机位姿，使用Map完成追踪（初始化时使用2D-2D方法估算初始位姿，后续过程使用3D-2D方法追踪）</li>\n<li>与Map线程通信，选取添加关键帧到缓存队列，进而发送到Map</li>\n<li>构建关键帧，关键帧的选择</li>\n<li>地图初始化</li>\n<li>重定位</li>\n</ul>\n<p>Tracking线程也用到关键帧，每一个新的图像帧都会在追踪过程进行之前构建一个关键帧。但，大部分关键帧都被丢弃，未被丢弃的关键帧加入到Map，这些是真正意义上的关键帧。</p>\n<h3 id=\"重要函数\"><a href=\"#重要函数\" class=\"headerlink\" title=\"重要函数\"></a>重要函数</h3><ol>\n<li><p><code>MakeKeyFrame_Lite</code>：使用当前帧构建初始关键帧</p>\n</li>\n<li><p><code>TrackForInitialMap</code>：<strong>地图初始化</strong>。由于刚开始没有地图，需要在双目图像帧（使用的是第一帧图像以及有足够平移的另一帧图像，保证双目模型的基线满足）中进行简单的Patch搜索。Patch搜索是在<code>TrailTracking_Advance</code>进行的。具体过程如下：</p>\n<img src=\"/2019/05/20/论文阅读之《Parallel%20Tracking%20and%20Mapping%20for%20Small%20AR%20Workspaces》/patchsearch.png\">\n<ul>\n<li>第一帧图像构建初始关键帧（该过程检测FAST角点），调用<code>TrailTracking_Start</code>函数，完善关键帧结构，包括对金字塔层级所有图像中的FAST角点非极大值抑制，并使用Shi-Tomasi方法计算角点得分，选取高得分角点（作为候选关键点）；</li>\n<li>根据Shi-Tomasi得分，对上述候选关键点排序，将这些候选关键点全部加入待追踪/匹配集合，并提取它们的局部Patch；</li>\n<li>正向搜索。第二帧（合适的、距离第一帧有一定距离）图像构建初始关键帧，调用<code>TrailTracking_Advance</code>函数，对于上一帧关键帧中的每一个$Corner_i$的$Patch_i$，在当前关键帧的FAST角点中基于SSD匹配（是块匹配），搜索最佳的角点$Corner_j$，提取$Corner_j$的局部块$Patch_j$；</li>\n<li>反向搜索（Cross Check Test？）。在上一帧关键帧中的FAST角点中搜索与$Pathc_j$匹配的最佳的角点$Corner_k$；</li>\n<li>判断$i-k&lt;=2$，则$Corner_j$是$Corner_i$的匹配关键点；如果没找到$Corner_i$的匹配点，则将$Corner_i$删除，是从待追踪/匹配集合中删除，而不是从关键帧候选关键点集合中删除（后面三角化完成之后还会根据候选关键点集合，采用极线搜索添加三维地图点，所以这里不会删除候选关键点）；</li>\n<li>如果追踪/匹配到的角点对数量&gt;=10，则用这些匹配到的点对，调用<code>InitFromStereo</code>函数，求取两个关键帧的初始位姿和初始地图：<ul>\n<li>使用单应矩阵求位姿，作为相机初始位姿；</li>\n<li>设置尺度，缩小为实际距离的0.1倍；</li>\n<li>使用匹配点对三角化求三维地图点（<a href=\"https://blog.csdn.net/u011178262/article/details/86729887\" target=\"_blank\" rel=\"noopener\">三角化参考博客</a>），<code>Triangulate</code>函数得到第一视图坐标系下的坐标；</li>\n<li>全局BA优化三维地图点和相机位姿；</li>\n<li>极线搜索添加三维地图点。将地图点对应的二维坐标周围10*10区域内的候选关键点删除，使用剩下的候选关键点进行极线搜索，并三角化添加三维地图点，极线搜索是在最新的关键帧与其最近的关键帧之间进行的；</li>\n<li>统一世界坐标系。</li>\n</ul>\n</li>\n<li>至此，<code>TrackForInitialMap</code>函数完成<strong>地图初始化</strong>。</li>\n</ul>\n</li>\n<li><p><code>PredictPoseWithMotionModel</code>：减速运动模型（匀速运动模型使用比较多）预测相机位姿</p>\n<ul>\n<li>计算上一帧图像高斯模糊小图的雅可比矩阵</li>\n<li>采用ESM（<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6918&amp;rep=rep1&amp;type=pdf\" target=\"_blank\" rel=\"noopener\">Efficient Second-order Minimization</a>）跟踪算法跟踪当前帧，计算当前帧图像相对于上一帧图像的旋转矩阵</li>\n</ul>\n</li>\n<li><p><code>TrackMap</code>：使用估算的位姿，将所有地图点投影到当前帧图像，不在当前帧图像中的地图点丢弃</p>\n<ul>\n<li>根据预测的相机位姿，将当前所有世界点根据小孔成像原理进行投影，投影后的像素点记为pi，并计算出对应的金字塔层级</li>\n<li>根据金字塔高层优先原则，选取一定数量世界点（通常，粗搜索选取30～60个，细搜索选取1000个左右）</li>\n</ul>\n</li>\n<li></li>\n</ol>\n<h2 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h2><blockquote>\n<p>从之前观测到的视频帧中产生三维地图点特征。</p>\n</blockquote>\n<p>主要任务：</p>\n<ul>\n<li>从缓存队列中提取关键帧到地图</li>\n<li>Global BA</li>\n<li>Local BA：只调整一部分关键帧的位姿，以及这些关键帧对应的所有地图点的位置。PTAM中调整地图中最新的5个关键帧的位姿。</li>\n<li><strong>极线搜索添加新的地图点到地图</strong></li>\n<li>数据关联的细化</li>\n</ul>\n<p>优先级：关键帧插入&gt;BA&gt;数据关联细化操作。</p>\n<h3 id=\"地图-Map\"><a href=\"#地图-Map\" class=\"headerlink\" title=\"地图 Map\"></a>地图 Map</h3><ul>\n<li>3D Point Features</li>\n<li>Keyframes</li>\n</ul>\n<h3 id=\"地图点\"><a href=\"#地图点\" class=\"headerlink\" title=\"地图点\"></a>地图点</h3><ul>\n<li>每个地图点<code>MapPoint</code>保存第一次观测到该地图点的关键帧索引，保存该地图点对应的特征点所在金字塔层级，以及在该层级图像中的像素坐标</li>\n<li>每个地图点对应一个观测结构<code>Measurement</code>，该结构中保存地图点在关键帧图像中的金字塔层级、像素坐标以及观测来源，即该地图点是如何观测到的</li>\n</ul>\n<h3 id=\"关键帧-Keyframes\"><a href=\"#关键帧-Keyframes\" class=\"headerlink\" title=\"关键帧 Keyframes\"></a>关键帧 Keyframes</h3><p>每个关键帧包括四层金字塔图像，下采样（四个像素的平均）得到的低分辨率的上层图像，每一层为一个数据结构Level，金字塔每层图像（每层Level）保存该层图像上的所有的FAST角点，它们经过Shi-Tomasi得分筛选之后，成为关键点候选<code>Candidate</code>，即可能会对应一个三维地图点，这些候选能够生成三维地图点的方式：</p>\n<ul>\n<li>Patch匹配三角化得到三维地图点</li>\n<li>极线搜索三角化得到三维地图点</li>\n<li>….</li>\n</ul>\n<p>构造金字塔的目的：加快匹配；提高地图点相对于相机远近变化的鲁棒性。</p>\n<blockquote>\n<ul>\n<li><p>每个关键帧中保存所有与其关联的（该关键帧观测范围内的）地图点</p>\n</li>\n<li><p>每个关键帧中的金字塔图像中保存候选的关键点，会在后续过程中三角化生成地图点</p>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"关键帧有关的操作\"><a href=\"#关键帧有关的操作\" class=\"headerlink\" title=\"关键帧有关的操作\"></a>关键帧有关的操作</h4><ul>\n<li>关键帧构建（<code>MakeKeyFrame_Lite</code>函数）过程/初始化，在关键帧四层金字塔，即四层图像中，进行FAST角点的检测，没有非极大值抑制（其实是在Tracking线程中进行）；</li>\n<li>关键帧初始化过程使用Tracking线程估计的相机位姿和特征点的观测数据；</li>\n<li>Tracking线程只测量图像帧中潜在视觉特征的一部分，Mapping线程将这些特征反投影、测量其他的特征。即与关键帧关联的地图点可能是Tracking线程得到的，可能是Mapping线程得到的；</li>\n<li>Mapping线程（<code>MakeKeyFrame_Rest</code>函数）对FAST角点进行极大值抑制，使用Shi-Tomasi分数，确定生成地图点的候选特征点；候选特征点对应的地图点如果距离已有的观测地图点比较近，这些候选特征点将会被剔除。</li>\n</ul>\n<h4 id=\"关键帧加入地图的条件\"><a href=\"#关键帧加入地图的条件\" class=\"headerlink\" title=\"关键帧加入地图的条件\"></a>关键帧加入地图的条件</h4><ul>\n<li>关键帧追踪的质量达到标准；</li>\n<li>距离上一次加入的关键帧已经超过20个图像帧；</li>\n<li>相机必须与地图中已有的最近关键点保持最小距离，需要保证三角化的基线不能过大、过小。最小距离取决于观测到的特征的平均深度值，即观测到的特征距离相机越远，关键帧之间的距离就越大。</li>\n</ul>\n<h3 id=\"Map初始化？？？？\"><a href=\"#Map初始化？？？？\" class=\"headerlink\" title=\"Map初始化？？？？\"></a>Map初始化？？？？</h3><p>地图初始化过程需要前两帧图像，前两帧图像都设定为关键帧。随着相机的运动，新的关键帧和地图点被加入到地图中。</p>\n<ul>\n<li>首先在第一帧关键帧中检测1000个FAST角点，构成2D图像块；</li>\n<li>在第二帧图像中追踪上述图像块；</li>\n<li>采用五点法对极约束，求取基础矩阵，提取两帧图像之间的旋转和平移；</li>\n<li>同时使用RANSAC方法剔除异常点；</li>\n<li>使用匹配到的点对，三角化生成三维地图点，建立初始地图。</li>\n</ul>\n<h3 id=\"特征点三角化\"><a href=\"#特征点三角化\" class=\"headerlink\" title=\"特征点三角化\"></a>特征点三角化</h3><p>基于关键帧图像，三角化获取特征点的三维坐标信息，该过程一个关键帧是无法完成的，需要两个关键帧。PTAM选择地图中已有的最近的两个关键帧进行三角化操作。使用对极搜索获取两个关键帧中的关联特征，关联过程为：</p>\n<ul>\n<li>对于第一个关键帧图像中的某个特征，提取其像素坐标周围的局部像素块P； </li>\n<li>在第二帧关键帧图像中的极线上搜索与P最接近的像素块，确定关联特征的位置；</li>\n<li>两个像素块的比较使用zero-mean SSD，并且只在相同的金字塔层级内进行；</li>\n<li>一旦匹配到一对特征点，则采用三角化方法求取新的地图点，并将新的地图点插入地图。</li>\n</ul>\n<h3 id=\"Bundle-Adjustment\"><a href=\"#Bundle-Adjustment\" class=\"headerlink\" title=\"Bundle Adjustment\"></a>Bundle Adjustment</h3><p>全局的BA能够调整所有关键帧的位姿以及所有地图点的位置。</p>\n<p>全局BA利用了SFM问题固有的稀疏性，将三次代价矩阵分解的复杂性从$O((N+M)^3)$降低为$O(N^3)$。</p>\n<p>有新的关键帧插入Maping线程时，会中断BA操作，保证新的关键帧可以及时插入地图中。</p>\n<p>局部BA的复杂性也是和地图的大小有关的。</p>\n<h3 id=\"数据关联细化\"><a href=\"#数据关联细化\" class=\"headerlink\" title=\"数据关联细化\"></a>数据关联细化</h3><p>BA收敛并且不再需要新的关键帧时，即相机已经处于一个建图比较理想的环境中，此时Mapping处于空闲状态，可以进行地图的优化，即数据关联的细化。</p>\n<p>数据关联的细化主要是通过在旧的关键帧中进行新的测量来完成的，可以是测量新加入的地图点在旧的关键帧中的位置，例如，通过对极搜索新加入的特征点，对其进行的初始测量只和两个关键帧有关联，即进行对极约束的两个关键帧。但是其他的关键帧也可能会观测到该特征点；也可以是再次进行异常点测量。</p>\n<p>该过程优先级低于BA。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>墙裂推荐：<a href=\"https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM\" target=\"_blank\" rel=\"noopener\">https://github.com/Ewenwan/MVision/tree/master/vSLAM/PTAM</a></li>\n<li><a href=\"https://blog.csdn.net/ilotuo/article/category/6297333\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ilotuo/article/category/6297333</a></li>\n<li><a href=\"https://blog.csdn.net/u013925378/article/details/77455555\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013925378/article/details/77455555</a></li>\n<li><a href=\"https://blog.csdn.net/u011178262/article/details/79315782\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011178262/article/details/79315782</a></li>\n<li><a href=\"https://blog.csdn.net/u011178262/article/details/86729887\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011178262/article/details/86729887</a></li>\n</ol>"},{"title":"C++学习之STL sort排序","date":"2018-04-12T03:41:08.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++ STL sort的学习内容。\n\n<!--more--->\n\n`std::sort`函数是C++ STL中自带的排序函数，该函数对给定区间所有元素进行排序。函数原型为：\n\n~~~c++\n//default (1)\t使用了函数模板\ntemplate <class RandomAccessIterator>\n  void sort (RandomAccessIterator first, RandomAccessIterator last);\n//custom (2)\t\ntemplate <class RandomAccessIterator, class Compare>\n  void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp);\n~~~\n\n## 用法\n\n- 需引用`#include <algorithm>`、`using namespace std`；\n- 使用类似快速排序的方法，时间复杂度为`n*logn`；\n- 默认的`sort`函数有两个参数，也可以使用三个参数：\n  - 参数`first`是要排序的数组的起始地址\n  - 参数`last`是数组结束的地址（最后一位要排序的地址），排序范围：[first, last)\n  - 参数`comp`是排序的方法，返回值为`bool`类型，可以升序或降序。可省略，此时默认的排序方法是升序。\n\n## 举例\n\n~~~c++\n/ sort algorithm example\n#include <iostream>     // std::cout\n#include <algorithm>    // std::sort\n#include <vector>       // std::vector\n\nbool myfunction (int i,int j) { return (i<j); }　//升序\nbool myfunction１ (int i,int j) { return (i>j); }//降序\n\nstruct myclass {\n  bool operator() (int i,int j) { return (i<j);}//运算符重载????\n} myobject;\n\nint main () {\n  int myints[] = {32,71,12,45,26,80,53,33};\n  std::vector<int> myvector (myints, myints+8);               // 32 71 12 45 26 80 53 33\n\n  // using default comparison (operator <):\n  std::sort (myvector.begin(), myvector.begin()+4);           //(12 32 45 71)26 80 53 33\n\n  // using function as comp\n  std::sort (myvector.begin()+4, myvector.end(), myfunction); // 12 32 45 71(26 33 53 80)\n\n  // using function as comp\n  std::sort (myvector.begin()+4, myvector.end(), myfunction1); // 12 32 45 71(80 53 33 26)\n\n  // using object as comp\n  std::sort (myvector.begin(), myvector.end(), myobject);     //(12 26 32 33 45 53 71 80)\n\n  // print out content:\n  std::cout << \"myvector contains:\";\n  for (std::vector<int>::iterator it=myvector.begin(); it!=myvector.end(); ++it)\n    std::cout << ' ' << *it;\n  std::cout << '\\n';\n\n  return 0;\n} \n~~~\n\n## 另一个例子\n\n~~~c++\n#include <iostream>\n#include <vector>\n#include <algorithm>\n\nusing namespace std;\n\nstruct Edge\n{\n  int vertexStart; //边连接的一个顶点编号\n  int vertexEnd; //边连接另一个顶点编号\n  int vertexWeight; //边的权值\n  friend bool operator<(const Edge& E1, const Edge& E2)//友元函数\n  {\n      return E1.vertexWeight < E2.vertexWeight;\n  }\n};\n\n// bool operator<(const Algorithm::Edge& E1, const Algorithm::Edge& E2)\n// {\n//     return E1.vertexWeight < E2.vertexWeight;\n// }\n// \n// bool compare_edge(const Algorithm::Edge& E1, const Algorithm::Edge& E2)\n// {\n//   return E1<E2;\n// }\n\nint main(int argc ,char **argv)\n{\n  vector<Edge> edge;\n  edge.assign(10, Edge());\n  for (int i = 0; i < 10; i++)\n      edge[i].vertexStart = edge[i].vertexEnd = edge[i].vertexWeight = i;\n  sort(edge.begin(), edge.end());\n  //sort(edge.begin(), edge.end(), compare_edge);\n  return 1;\n }\n~~~\n\n可以使用在结构体（或者是类）声明的友元函数运算符重载函数，这时调用两个参数的sort函数即可；\n\n也可以在结构体定义外面单独声明运算符重载函数、比较函数，要使用三个参数的sort函数，第三个参数传入比较函数。\n\n","source":"_posts/C++学习之STL sort排序.md","raw":"---\ntitle: C++学习之STL sort排序\ndate: 2018-04-12 11:41:08\ntags:\n  - STL\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++ STL sort的学习内容。\n\n<!--more--->\n\n`std::sort`函数是C++ STL中自带的排序函数，该函数对给定区间所有元素进行排序。函数原型为：\n\n~~~c++\n//default (1)\t使用了函数模板\ntemplate <class RandomAccessIterator>\n  void sort (RandomAccessIterator first, RandomAccessIterator last);\n//custom (2)\t\ntemplate <class RandomAccessIterator, class Compare>\n  void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp);\n~~~\n\n## 用法\n\n- 需引用`#include <algorithm>`、`using namespace std`；\n- 使用类似快速排序的方法，时间复杂度为`n*logn`；\n- 默认的`sort`函数有两个参数，也可以使用三个参数：\n  - 参数`first`是要排序的数组的起始地址\n  - 参数`last`是数组结束的地址（最后一位要排序的地址），排序范围：[first, last)\n  - 参数`comp`是排序的方法，返回值为`bool`类型，可以升序或降序。可省略，此时默认的排序方法是升序。\n\n## 举例\n\n~~~c++\n/ sort algorithm example\n#include <iostream>     // std::cout\n#include <algorithm>    // std::sort\n#include <vector>       // std::vector\n\nbool myfunction (int i,int j) { return (i<j); }　//升序\nbool myfunction１ (int i,int j) { return (i>j); }//降序\n\nstruct myclass {\n  bool operator() (int i,int j) { return (i<j);}//运算符重载????\n} myobject;\n\nint main () {\n  int myints[] = {32,71,12,45,26,80,53,33};\n  std::vector<int> myvector (myints, myints+8);               // 32 71 12 45 26 80 53 33\n\n  // using default comparison (operator <):\n  std::sort (myvector.begin(), myvector.begin()+4);           //(12 32 45 71)26 80 53 33\n\n  // using function as comp\n  std::sort (myvector.begin()+4, myvector.end(), myfunction); // 12 32 45 71(26 33 53 80)\n\n  // using function as comp\n  std::sort (myvector.begin()+4, myvector.end(), myfunction1); // 12 32 45 71(80 53 33 26)\n\n  // using object as comp\n  std::sort (myvector.begin(), myvector.end(), myobject);     //(12 26 32 33 45 53 71 80)\n\n  // print out content:\n  std::cout << \"myvector contains:\";\n  for (std::vector<int>::iterator it=myvector.begin(); it!=myvector.end(); ++it)\n    std::cout << ' ' << *it;\n  std::cout << '\\n';\n\n  return 0;\n} \n~~~\n\n## 另一个例子\n\n~~~c++\n#include <iostream>\n#include <vector>\n#include <algorithm>\n\nusing namespace std;\n\nstruct Edge\n{\n  int vertexStart; //边连接的一个顶点编号\n  int vertexEnd; //边连接另一个顶点编号\n  int vertexWeight; //边的权值\n  friend bool operator<(const Edge& E1, const Edge& E2)//友元函数\n  {\n      return E1.vertexWeight < E2.vertexWeight;\n  }\n};\n\n// bool operator<(const Algorithm::Edge& E1, const Algorithm::Edge& E2)\n// {\n//     return E1.vertexWeight < E2.vertexWeight;\n// }\n// \n// bool compare_edge(const Algorithm::Edge& E1, const Algorithm::Edge& E2)\n// {\n//   return E1<E2;\n// }\n\nint main(int argc ,char **argv)\n{\n  vector<Edge> edge;\n  edge.assign(10, Edge());\n  for (int i = 0; i < 10; i++)\n      edge[i].vertexStart = edge[i].vertexEnd = edge[i].vertexWeight = i;\n  sort(edge.begin(), edge.end());\n  //sort(edge.begin(), edge.end(), compare_edge);\n  return 1;\n }\n~~~\n\n可以使用在结构体（或者是类）声明的友元函数运算符重载函数，这时调用两个参数的sort函数即可；\n\n也可以在结构体定义外面单独声明运算符重载函数、比较函数，要使用三个参数的sort函数，第三个参数传入比较函数。\n\n","slug":"C++学习之STL sort排序","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc1e00exqlcrtvof17sk","content":"<hr>\n<p>这篇文章是有关C++ STL sort的学习内容。</p>\n<a id=\"more\"></a>\n<p><code>std::sort</code>函数是C++ STL中自带的排序函数，该函数对给定区间所有元素进行排序。函数原型为：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//default (1)\t使用了函数模板</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RandomAccessIterator</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\">  <span class=\"title\">void</span> <span class=\"title\">sort</span> (<span class=\"title\">RandomAccessIterator</span> <span class=\"title\">first</span>, <span class=\"title\">RandomAccessIterator</span> <span class=\"title\">last</span>);</span></span><br><span class=\"line\"><span class=\"comment\">//custom (2)\t</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RandomAccessIterator</span>, <span class=\"title\">class</span> <span class=\"title\">Compare</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\">  <span class=\"title\">void</span> <span class=\"title\">sort</span> (<span class=\"title\">RandomAccessIterator</span> <span class=\"title\">first</span>, <span class=\"title\">RandomAccessIterator</span> <span class=\"title\">last</span>, <span class=\"title\">Compare</span> <span class=\"title\">comp</span>);</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h2><ul>\n<li>需引用<code>#include &lt;algorithm&gt;</code>、<code>using namespace std</code>；</li>\n<li>使用类似快速排序的方法，时间复杂度为<code>n*logn</code>；</li>\n<li>默认的<code>sort</code>函数有两个参数，也可以使用三个参数：<ul>\n<li>参数<code>first</code>是要排序的数组的起始地址</li>\n<li>参数<code>last</code>是数组结束的地址（最后一位要排序的地址），排序范围：[first, last)</li>\n<li>参数<code>comp</code>是排序的方法，返回值为<code>bool</code>类型，可以升序或降序。可省略，此时默认的排序方法是升序。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"举例\"><a href=\"#举例\" class=\"headerlink\" title=\"举例\"></a>举例</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/ sort algorithm example</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;     // std::cout</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;    // std::sort</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;vector&gt;       // std::vector</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">myfunction</span> <span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j)</span> </span>&#123; <span class=\"keyword\">return</span> (i&lt;j); &#125;　<span class=\"comment\">//升序</span></span><br><span class=\"line\"><span class=\"keyword\">bool</span> myfunction１ (<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j) &#123; <span class=\"keyword\">return</span> (i&gt;j); &#125;<span class=\"comment\">//降序</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">myclass</span> &#123;</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">operator</span><span class=\"params\">()</span> <span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j)</span> </span>&#123; <span class=\"keyword\">return</span> (i&lt;j);&#125;<span class=\"comment\">//运算符重载????</span></span><br><span class=\"line\">&#125; myobject;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">int</span> myints[] = &#123;<span class=\"number\">32</span>,<span class=\"number\">71</span>,<span class=\"number\">12</span>,<span class=\"number\">45</span>,<span class=\"number\">26</span>,<span class=\"number\">80</span>,<span class=\"number\">53</span>,<span class=\"number\">33</span>&#125;;</span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; myvector (myints, myints+<span class=\"number\">8</span>);               <span class=\"comment\">// 32 71 12 45 26 80 53 33</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// using default comparison (operator &lt;):</span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::sort (myvector.begin(), myvector.begin()+<span class=\"number\">4</span>);           <span class=\"comment\">//(12 32 45 71)26 80 53 33</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// using function as comp</span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::sort (myvector.begin()+<span class=\"number\">4</span>, myvector.end(), myfunction); <span class=\"comment\">// 12 32 45 71(26 33 53 80)</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// using function as comp</span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::sort (myvector.begin()+<span class=\"number\">4</span>, myvector.end(), myfunction1); <span class=\"comment\">// 12 32 45 71(80 53 33 26)</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// using object as comp</span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::sort (myvector.begin(), myvector.end(), myobject);     <span class=\"comment\">//(12 26 32 33 45 53 71 80)</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// print out content:</span></span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"myvector contains:\"</span>;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"built_in\">std</span>::<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;::iterator it=myvector.begin(); it!=myvector.end(); ++it)</span><br><span class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">' '</span> &lt;&lt; *it;</span><br><span class=\"line\">  <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">'\\n'</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"另一个例子\"><a href=\"#另一个例子\" class=\"headerlink\" title=\"另一个例子\"></a>另一个例子</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;vector&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Edge</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">  <span class=\"keyword\">int</span> vertexStart; <span class=\"comment\">//边连接的一个顶点编号</span></span><br><span class=\"line\">  <span class=\"keyword\">int</span> vertexEnd; <span class=\"comment\">//边连接另一个顶点编号</span></span><br><span class=\"line\">  <span class=\"keyword\">int</span> vertexWeight; <span class=\"comment\">//边的权值</span></span><br><span class=\"line\">  <span class=\"keyword\">friend</span> <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(<span class=\"keyword\">const</span> Edge&amp; E1, <span class=\"keyword\">const</span> Edge&amp; E2)<span class=\"comment\">//友元函数</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> E1.vertexWeight &lt; E2.vertexWeight;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// bool operator&lt;(const Algorithm::Edge&amp; E1, const Algorithm::Edge&amp; E2)</span></span><br><span class=\"line\"><span class=\"comment\">// &#123;</span></span><br><span class=\"line\"><span class=\"comment\">//     return E1.vertexWeight &lt; E2.vertexWeight;</span></span><br><span class=\"line\"><span class=\"comment\">// &#125;</span></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"comment\">// bool compare_edge(const Algorithm::Edge&amp; E1, const Algorithm::Edge&amp; E2)</span></span><br><span class=\"line\"><span class=\"comment\">// &#123;</span></span><br><span class=\"line\"><span class=\"comment\">//   return E1&lt;E2;</span></span><br><span class=\"line\"><span class=\"comment\">// &#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc ,<span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;Edge&gt; edge;</span><br><span class=\"line\">  edge.assign(<span class=\"number\">10</span>, Edge());</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++)</span><br><span class=\"line\">      edge[i].vertexStart = edge[i].vertexEnd = edge[i].vertexWeight = i;</span><br><span class=\"line\">  sort(edge.begin(), edge.end());</span><br><span class=\"line\">  <span class=\"comment\">//sort(edge.begin(), edge.end(), compare_edge);</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n<p>可以使用在结构体（或者是类）声明的友元函数运算符重载函数，这时调用两个参数的sort函数即可；</p>\n<p>也可以在结构体定义外面单独声明运算符重载函数、比较函数，要使用三个参数的sort函数，第三个参数传入比较函数。</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++ STL sort的学习内容。</p>","more":"<p><code>std::sort</code>函数是C++ STL中自带的排序函数，该函数对给定区间所有元素进行排序。函数原型为：</p>\n<!--�324-->\n<h2 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h2><ul>\n<li>需引用<code>#include &lt;algorithm&gt;</code>、<code>using namespace std</code>；</li>\n<li>使用类似快速排序的方法，时间复杂度为<code>n*logn</code>；</li>\n<li>默认的<code>sort</code>函数有两个参数，也可以使用三个参数：<ul>\n<li>参数<code>first</code>是要排序的数组的起始地址</li>\n<li>参数<code>last</code>是数组结束的地址（最后一位要排序的地址），排序范围：[first, last)</li>\n<li>参数<code>comp</code>是排序的方法，返回值为<code>bool</code>类型，可以升序或降序。可省略，此时默认的排序方法是升序。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"举例\"><a href=\"#举例\" class=\"headerlink\" title=\"举例\"></a>举例</h2><!--�325-->\n<h2 id=\"另一个例子\"><a href=\"#另一个例子\" class=\"headerlink\" title=\"另一个例子\"></a>另一个例子</h2><!--�326-->\n<p>可以使用在结构体（或者是类）声明的友元函数运算符重载函数，这时调用两个参数的sort函数即可；</p>\n<p>也可以在结构体定义外面单独声明运算符重载函数、比较函数，要使用三个参数的sort函数，第三个参数传入比较函数。</p>"},{"title":"C++学习之explicit关键字详解","date":"2018-05-09T02:58:38.000Z","copyright":true,"_content":"\n-----\n\n这篇文章是有关C++ explicit学习的内容。\n\n<!--more--->\n\n### 作用和使用方法\n\n`explicit`关键字可以阻止不应该允许的经过转换函数进行的隐式转换的发生，声明为`explicit`的构造函数不能在隐式转换中使用。\n\n`explicit`关键字只能用于修饰只有一个参数的类构造函数，它的作用是表明该构造函数是显式的，而非隐式的，跟它相对应的另一个关键字是`implicit`，意思是隐藏的，类构造函数默认情况下即声明为`implicit`(隐式)。\n\n*注意：当类的声明和定义分别在两个文件中时，explicit只能写在在声明中，不能写在定义中。*\n\n### 理解\n\n由于在C++中， 一个参数的构造函数(或者除了第一个参数外其余参数都有默认值的多参构造函数)， 承担了两个角色。一 是构造；二是默认且隐含的类型转换操作符。所以，如果写下如`AAA = XXX`这样的代码， 且恰好`XXX`的类型正好是`AAA`单参数构造器（构造函数）的参数类型， 这时候编译器就自动调用这个构造器， 创建一个`AAA`的对象。这种隐式转换在某些情况下， 违背了程序员的本意。 这就要在该构造器前加上`explicit`修饰， 指定该构造器只能被明确的调用/使用， 不能作为类型转换操作符被隐含的使用。\n\n示例程序：\n\n~~~c++\n#include <iostream>  \nusing namespace std;  \nclass Test1  \n{  \npublic :  \n    Test1(int num):n(num){}  \nprivate:  \n    int n;  \n};  \nclass Test2  \n{  \n public :  \n    explicit Test2(int num):n(num){}  \n private:  \n    int n;  \n};  \n\nint main()  \n{  \n    Test1 t1 = 12;  //1 通过\n    Test2 t2(13);   //2 通过\n    Test2 t3 = 14;  //3 此行会编译错误，提示：无法从“int”转换为“Test2”\n\n    return 0;  \n}  \n~~~\n\n1处编译通过，是因为C++中，如果构造函数只有一个参数，在编译时就会有一个缺省的转换操作：将该构造函数对应数据类型的数据转换为该类对象。也就是说 `Test1 t1 = 12;`这段代码，编译器自动将整型转换为`Test1`类对象，实际上等同于下面的操作：\n\n~~~c++\nTest1 t1(12);\n~~~\n\n或者：\n\n~~~c++\nTest1 temp(12);\nTest1 t1 = temp;\n~~~\n\n3处编译不通过，就是因为`Test3`类的定义中，构造函数前面加了`explicit`关键字，阻止了类构造函数的隐式自动转换。\n\n\n\n参考链接：\n\n1、http://www.cnblogs.com/ymy124/p/3632634.html\n\n2、https://blog.csdn.net/tianmingdyx/article/details/79823470","source":"_posts/C++学习之explicit关键字详解.md","raw":"---\ntitle: C++学习之explicit关键字详解\ndate: 2018-05-09 10:58:38\ntags:\n  - C++\ncategories: \n  - 语言\n  - C++\ncopyright: true\n---\n\n-----\n\n这篇文章是有关C++ explicit学习的内容。\n\n<!--more--->\n\n### 作用和使用方法\n\n`explicit`关键字可以阻止不应该允许的经过转换函数进行的隐式转换的发生，声明为`explicit`的构造函数不能在隐式转换中使用。\n\n`explicit`关键字只能用于修饰只有一个参数的类构造函数，它的作用是表明该构造函数是显式的，而非隐式的，跟它相对应的另一个关键字是`implicit`，意思是隐藏的，类构造函数默认情况下即声明为`implicit`(隐式)。\n\n*注意：当类的声明和定义分别在两个文件中时，explicit只能写在在声明中，不能写在定义中。*\n\n### 理解\n\n由于在C++中， 一个参数的构造函数(或者除了第一个参数外其余参数都有默认值的多参构造函数)， 承担了两个角色。一 是构造；二是默认且隐含的类型转换操作符。所以，如果写下如`AAA = XXX`这样的代码， 且恰好`XXX`的类型正好是`AAA`单参数构造器（构造函数）的参数类型， 这时候编译器就自动调用这个构造器， 创建一个`AAA`的对象。这种隐式转换在某些情况下， 违背了程序员的本意。 这就要在该构造器前加上`explicit`修饰， 指定该构造器只能被明确的调用/使用， 不能作为类型转换操作符被隐含的使用。\n\n示例程序：\n\n~~~c++\n#include <iostream>  \nusing namespace std;  \nclass Test1  \n{  \npublic :  \n    Test1(int num):n(num){}  \nprivate:  \n    int n;  \n};  \nclass Test2  \n{  \n public :  \n    explicit Test2(int num):n(num){}  \n private:  \n    int n;  \n};  \n\nint main()  \n{  \n    Test1 t1 = 12;  //1 通过\n    Test2 t2(13);   //2 通过\n    Test2 t3 = 14;  //3 此行会编译错误，提示：无法从“int”转换为“Test2”\n\n    return 0;  \n}  \n~~~\n\n1处编译通过，是因为C++中，如果构造函数只有一个参数，在编译时就会有一个缺省的转换操作：将该构造函数对应数据类型的数据转换为该类对象。也就是说 `Test1 t1 = 12;`这段代码，编译器自动将整型转换为`Test1`类对象，实际上等同于下面的操作：\n\n~~~c++\nTest1 t1(12);\n~~~\n\n或者：\n\n~~~c++\nTest1 temp(12);\nTest1 t1 = temp;\n~~~\n\n3处编译不通过，就是因为`Test3`类的定义中，构造函数前面加了`explicit`关键字，阻止了类构造函数的隐式自动转换。\n\n\n\n参考链接：\n\n1、http://www.cnblogs.com/ymy124/p/3632634.html\n\n2、https://blog.csdn.net/tianmingdyx/article/details/79823470","slug":"C++学习之explicit关键字详解","published":1,"updated":"2019-05-30T12:29:26.239Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc1f00eyqlcr78z7kgbk","content":"<hr>\n<p>这篇文章是有关C++ explicit学习的内容。</p>\n<a id=\"more\"></a>\n<h3 id=\"作用和使用方法\"><a href=\"#作用和使用方法\" class=\"headerlink\" title=\"作用和使用方法\"></a>作用和使用方法</h3><p><code>explicit</code>关键字可以阻止不应该允许的经过转换函数进行的隐式转换的发生，声明为<code>explicit</code>的构造函数不能在隐式转换中使用。</p>\n<p><code>explicit</code>关键字只能用于修饰只有一个参数的类构造函数，它的作用是表明该构造函数是显式的，而非隐式的，跟它相对应的另一个关键字是<code>implicit</code>，意思是隐藏的，类构造函数默认情况下即声明为<code>implicit</code>(隐式)。</p>\n<p><em>注意：当类的声明和定义分别在两个文件中时，explicit只能写在在声明中，不能写在定义中。</em></p>\n<h3 id=\"理解\"><a href=\"#理解\" class=\"headerlink\" title=\"理解\"></a>理解</h3><p>由于在C++中， 一个参数的构造函数(或者除了第一个参数外其余参数都有默认值的多参构造函数)， 承担了两个角色。一 是构造；二是默认且隐含的类型转换操作符。所以，如果写下如<code>AAA = XXX</code>这样的代码， 且恰好<code>XXX</code>的类型正好是<code>AAA</code>单参数构造器（构造函数）的参数类型， 这时候编译器就自动调用这个构造器， 创建一个<code>AAA</code>的对象。这种隐式转换在某些情况下， 违背了程序员的本意。 这就要在该构造器前加上<code>explicit</code>修饰， 指定该构造器只能被明确的调用/使用， 不能作为类型转换操作符被隐含的使用。</p>\n<p>示例程序：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;  </span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;  </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test1</span>  </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span>  </span><br><span class=\"line\"><span class=\"keyword\">public</span> :  </span><br><span class=\"line\">    Test1(<span class=\"keyword\">int</span> num):n(num)&#123;&#125;  </span><br><span class=\"line\"><span class=\"keyword\">private</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">int</span> n;  </span><br><span class=\"line\">&#125;;  </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test2</span>  </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span>  </span><br><span class=\"line\"> <span class=\"keyword\">public</span> :  </span><br><span class=\"line\">    explicit Test2(int num):n(num)&#123;&#125;  </span><br><span class=\"line\"> <span class=\"keyword\">private</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">int</span> n;  </span><br><span class=\"line\">&#125;;  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;  </span><br><span class=\"line\">    Test1 t1 = <span class=\"number\">12</span>;  <span class=\"comment\">//1 通过</span></span><br><span class=\"line\">    <span class=\"function\">Test2 <span class=\"title\">t2</span><span class=\"params\">(<span class=\"number\">13</span>)</span></span>;   <span class=\"comment\">//2 通过</span></span><br><span class=\"line\">    Test2 t3 = <span class=\"number\">14</span>;  <span class=\"comment\">//3 此行会编译错误，提示：无法从“int”转换为“Test2”</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>1处编译通过，是因为C++中，如果构造函数只有一个参数，在编译时就会有一个缺省的转换操作：将该构造函数对应数据类型的数据转换为该类对象。也就是说 <code>Test1 t1 = 12;</code>这段代码，编译器自动将整型转换为<code>Test1</code>类对象，实际上等同于下面的操作：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Test1 <span class=\"title\">t1</span><span class=\"params\">(<span class=\"number\">12</span>)</span></span>;</span><br></pre></td></tr></table></figure>\n<p>或者：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Test1 <span class=\"title\">temp</span><span class=\"params\">(<span class=\"number\">12</span>)</span></span>;</span><br><span class=\"line\">Test1 t1 = temp;</span><br></pre></td></tr></table></figure>\n<p>3处编译不通过，就是因为<code>Test3</code>类的定义中，构造函数前面加了<code>explicit</code>关键字，阻止了类构造函数的隐式自动转换。</p>\n<p>参考链接：</p>\n<p>1、<a href=\"http://www.cnblogs.com/ymy124/p/3632634.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/ymy124/p/3632634.html</a></p>\n<p>2、<a href=\"https://blog.csdn.net/tianmingdyx/article/details/79823470\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/tianmingdyx/article/details/79823470</a></p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关C++ explicit学习的内容。</p>","more":"<h3 id=\"作用和使用方法\"><a href=\"#作用和使用方法\" class=\"headerlink\" title=\"作用和使用方法\"></a>作用和使用方法</h3><p><code>explicit</code>关键字可以阻止不应该允许的经过转换函数进行的隐式转换的发生，声明为<code>explicit</code>的构造函数不能在隐式转换中使用。</p>\n<p><code>explicit</code>关键字只能用于修饰只有一个参数的类构造函数，它的作用是表明该构造函数是显式的，而非隐式的，跟它相对应的另一个关键字是<code>implicit</code>，意思是隐藏的，类构造函数默认情况下即声明为<code>implicit</code>(隐式)。</p>\n<p><em>注意：当类的声明和定义分别在两个文件中时，explicit只能写在在声明中，不能写在定义中。</em></p>\n<h3 id=\"理解\"><a href=\"#理解\" class=\"headerlink\" title=\"理解\"></a>理解</h3><p>由于在C++中， 一个参数的构造函数(或者除了第一个参数外其余参数都有默认值的多参构造函数)， 承担了两个角色。一 是构造；二是默认且隐含的类型转换操作符。所以，如果写下如<code>AAA = XXX</code>这样的代码， 且恰好<code>XXX</code>的类型正好是<code>AAA</code>单参数构造器（构造函数）的参数类型， 这时候编译器就自动调用这个构造器， 创建一个<code>AAA</code>的对象。这种隐式转换在某些情况下， 违背了程序员的本意。 这就要在该构造器前加上<code>explicit</code>修饰， 指定该构造器只能被明确的调用/使用， 不能作为类型转换操作符被隐含的使用。</p>\n<p>示例程序：</p>\n<!--�327-->\n<p>1处编译通过，是因为C++中，如果构造函数只有一个参数，在编译时就会有一个缺省的转换操作：将该构造函数对应数据类型的数据转换为该类对象。也就是说 <code>Test1 t1 = 12;</code>这段代码，编译器自动将整型转换为<code>Test1</code>类对象，实际上等同于下面的操作：</p>\n<!--�328-->\n<p>或者：</p>\n<!--�329-->\n<p>3处编译不通过，就是因为<code>Test3</code>类的定义中，构造函数前面加了<code>explicit</code>关键字，阻止了类构造函数的隐式自动转换。</p>\n<p>参考链接：</p>\n<p>1、<a href=\"http://www.cnblogs.com/ymy124/p/3632634.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/ymy124/p/3632634.html</a></p>\n<p>2、<a href=\"https://blog.csdn.net/tianmingdyx/article/details/79823470\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/tianmingdyx/article/details/79823470</a></p>"},{"title":"Cartographer学习一论文阅读","date":"2018-09-12T08:56:16.000Z","copyright":true,"mathjax":true,"_content":"\n---\n\n本篇文章记录阅读Google开源Cartographer SLAM系统论文过程中的学习内容。\n\n<!--more-->\n\n## 概况\n\n`Real-time loop closure in 2D LIDAR SLAM`是Google发表在ICRA2016上的一篇论文，开源的系统是大名鼎鼎的Cartographer，目前该系统已经有大神改到Cartographer-ROS版本。本文在阅读论文的基础上，参考其他网络博客资料，学习并记录论文的一些要点，通过这个过程希望能够理解论文的核心内容和系统的实现。\n\n### 主要论文\n\n- Real-Time Loop Closure in 2D LIDAR SLAM , ICRA 2016\n\n- Efficient Sparse Pose Adjustment for 2D Mapping  (SPA)\n\n- Real-Time Correlative Scan Matching  (BBS)\n\n### 文章重点\n\n- 第四部分：local 2d slam，主要是将局部地图的scan matching作为一个最小二乘优化问题，由ceres slover解决。       \n\n- 第五部分： closing loop， 采用了 SPA（Sparse Pose Adjustment）进行后端loop  closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，这里采用了BBS（Branch-and-bound scan  matching）, 它可大幅提高精度和速度。\n\n## 文章贡献\n\n文章的重点不是关注SLAM本身，而是提出了一种基于激光的5cm分辨率实时建图和回环检测方法，减少了计算量，满足实时的大场景地图构建以及大规模的实时优化的性能需求。\n\n为了达到实时闭环检测，文章使用了分支上界法来计算scan-to-submap的匹配作为约束。\n\n## Scan Matching方法介绍\n\n涉及到的相关文献在文后列出，以便以后学习。\n\n1. scan-to-scan matching：基于激光的SLAM中最常用来估计相关位姿的方法。但是非常容易造成累积误差。[1,2,3,4]\n\n2. scan-to-map matching：可以较少累计误差。其中一种方法是使用Gauss-Newton法在线性插值地图上找到局部最优值，前提是获取到了最优的初始位姿估计，这就需要使用有足够高数据获取速率的激光雷达，以保证局部优化的scan-to-map匹配是高效并且鲁棒的。在不稳定的平台上，需要使用惯性测量单元（IMU）将激光扫描投影到水平面上以估计重力方向。[5]\n\n3. pixel-accurate scan matching：可以进一步减少局部误差，但是计算量比较大。这个方法同样可以用来检测回环。[1]\n\n4. 从laser scans中提取特征做匹配，从而减少计算量[4]。\n\n5. histogram-based matching用于回环检测[6]。\n\n6. 用机器学习做laser scan data的特征检测[7]。\n\n## 累积误差处理方式\n\n1. 基于粒子滤波（Particle Filter）的优化。粒子滤波在处理大场景地图时，由于粒子数的极具增长造成资源密集。[8,9,10]\n\n2. 基于位姿图的优化（**Graph-based SLAM**）。与视觉SLAM的位姿图优化大同小异，主要是在观测方程上的区别。[2,11,12,13]\n\n## 系统概述\n\n1. Cartographer是实时的室内建图系统，系统生成5cm分辨率的2D栅格地图地图。\n\n2. laser scans数据被插入到submap中的最佳估计位置，并假定最佳估计位置在短时间内足够准确。\n\n3. scan matching针对最近的submap发生，因此它只取决于最近的scans和全局帧位姿估计中累计的误差。\n\n4. 系统使用pose optimization处理误差累计。\n\n5. submap一旦构建完成，就不会再插入新的scans。submap会用于回环检测过程的scan matching，其实回环检测会将所有已经构建完成的submaps和scans考虑在内。\n\n   如果scan和submap在当前位姿估计下足够接近的话，scan matcher会尝试在submap中寻找回环scan。\n\n   > 当一个新的laser scan加入到地图中时，如果该laser scan的估计位姿与地图中某个submap的某个laser scan的位姿比较接近的话，那么通过某种 scan match策略就会找到该闭环。\n\n   为了减少计算量，Cartographer设计了特殊的策略来找到回环scan。这个策略就是在当前的位姿估计附近设置搜索窗口，在这个搜索窗口内执行branch-and-bound方法来寻找回环scan，如果在搜索窗口中找到了一个足够好的匹配，则会将该匹配作为回环检测约束条件添加到优化问题中。\n\n6. 系统通过使用branch-and-bound方法，并对每个生成的submap预计算出几个栅格地图，保证回环优化的快速完成，快到可以在加入新的scans之前就完成优化，从而保证了一种软实时约束。\n\n7. cartographer的整体架构是典型的 前端建图 （局部地图）+后端优化。 \n\n## 符号说明\n\n- 位姿表示：$\\xi=(\\xi_x,\\xi_y,\\xi_{\\theta})$\n- 扫描scan：$H=\\{h_k\\}_{k=1,…,K},h_k \\in \\mathbb{R^2}​$\n- scan-to-submap变换矩阵：$T_\\xi​$\n- scan-to-submap变换：$T_{\\xi }h_k=\\underbrace{\\left(\\begin{matrix}cos\\xi_\\theta&-sin\\xi_\\theta\\\\sin\\xi_\\theta&cos\\xi_\\theta\\end{matrix} \\right)}_{R_\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\\\xi_y\\end{matrix}\\right)}_{t_\\xi}​$\n- 概率栅格地图概率值：$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p_{min},p_{max}]$\n- submap世界坐标系下的位姿（m代表map）：$\\Xi^m=\\{\\xi^m_i\\}_{i=1,...,m}​$\n- scan世界坐标系下的位姿（s代表scan）：$\\Xi^s=\\{\\xi^s_j\\}_{j=1,...,n}​$\n- scan $i​$在匹配到的submap $j​$坐标系下的位姿：$\\xi_{ij}​$\n- 与scan $i​$和submap $j​$相对应的协方差矩阵：$\\sum_{ij}​$\n\n## Local 2D SLAM\n\n系统将局部和全局方法结合到2D SLAM中，两种方法都对LIDAR观测到的位姿进行了优化。这一部分介绍局部地图的scan matching，该问题被构造成最小二乘问题，使用ceres solver解决。\n\n位姿表示为$\\xi=(\\xi_x,\\xi_y,\\xi_{\\theta})$，这个位姿表示包括$(x,y)$坐标变换（注意这里是二维坐标），以及角度的旋转$\\xi_\\theta$，对观测位姿的优化实际上就是对scans的优化。平台采用IMU测量重力方向，将水平安装的LIDAR观测到的scans映射到2D平面。 \n\n> #### scan matching\n>\n> 局部方法中，将每个连续的scan点集和整个地图的一部分进行匹配，就是和submap $M$进行匹配。这个过程中使用了一种非线性的优化方法将submap和scan点集对齐，这也是scan matching的过程。局部方法积累的误差在全局方法消除，即回环检测。\n\n### A. Scans\n\nsubmap的构建是一个不断将scan和submap坐标系对齐的迭代过程。\n\n一个scan包含一个起点和很多个终点，起点称为scan origin，终点称为scan points，将scan表示为$H=\\{h_k\\}_{k=1,…,K},h_k \\in \\mathbb{R^2}$。在scan坐标系下，origin就是坐标原点，scan points就是在scan坐标系下的坐标。\n\n当把一个scans插入到一个submap中时，假设scan坐标系到submap坐标系的坐标转换表示为$T_\\xi$（即scan坐标系在submap坐标系下的位姿$\\xi$表示为变换矩阵$T_\\xi$），即激光传感器在submap坐标系下的位姿。\n\n每个$h_k$在submap坐标系下的坐标为：$T_{\\xi }h_k=\\underbrace{\\left(\\begin{matrix}cos\\xi_\\theta&-sin\\xi_\\theta\\\\sin\\xi_\\theta&cos\\xi_\\theta\\end{matrix} \\right)}_{R_\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\\\xi_y\\end{matrix}\\right)}_{t_\\xi}$\n\n### B. Submaps\n\n一些连续的scans组成submap。采用概率栅格地图的形式表示这些submaps，$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p_{min},p_{max}]$，以给定的分辨率（例如5cm）将离散栅格地图点映射到值，这些值可以记作栅格地图点被占用的概率。对于每个栅格地图点，都定义一个相应的pixel，这个piexl是针对于分辨率来说的，对于5cm的分辨率来说，一个pixel相当于一个5*5的方格，那么对应于scan中应该有很多个point，即论文中定义的：pixel包含了所有靠近这个栅格地图点的points。\n\n{% asset_img 栅格地图点和相关像素.png %}\n\n> #### 疑问\n>\n> 1. 这里栅格地图点和像素的定义不明白？\n>\n>    答：栅格地图点就是上图中的叉号处，像素定义为叉号周围所有的点的集合，即小方框。\n>\n> 2. submaps是扫描点的集合？？概率栅格地图表示submaps怎么理解？？\n>\n>    看源码理解。\n>\n\n对于每个要插入submap的scan，都会产生一组称为hits的grid point和一组称为misses的grid point。如下图所示。\n\n{% asset_img submap.png %}\n\n其中阴影带叉的是hit，加入hits集合；阴影不带叉的是miss（scan origin和scan points连线经过的grid points，排除在hits中的），加入misses集合。每个hits中的grid point被赋予初始值$M=p_{hit}$，每个misses中的grid point被赋予初始值$M=p_{miss}$。如果grid point已经有$p$值，则用下述公式更新：\n\n$odds(p)=\\frac{p}{1−p}$\n\n$M_{new(x)}=clamp(odds^{−1}(odds(M_{old}(x))⋅odds(p_{hit})))$\n\n> Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内，小于min的数值返回min，大于max的数值返回max。\n\nmiss集合的更新也是类似的。\n\n### C. Ceres scan matching\n\n将scan插入submap之前，需要通过scan matching对scan的位姿$ \\xi $进行优化（优化过程参照当前局部submap），优化过程使用基于Ceres库的scan matcher。scan matcher的任务就是找到一个scan的位姿，能够满足scan points在submap中有最大概率值。这里涉及到的优化问题为非线性最小二乘问题，通过Ceres库进行求解。使得scan在栅格地图中的概率值最大，那么就需要使得（cs）最小，非线性最小二乘问题目标函数构造形式如下：\n\n$\\mathop{\\arg\\min} \\limits_{\\xi}\\sum \\limits_{k=1}^K(1−M_{smooth}(T_{\\xi}h_k))^2 \\qquad\\qquad(CS)​$\n\n平滑函数$M_{smooth}$完成了局部submap中概率值从2D到1D的平滑，将值限制在$[0; 1]$范围内，使用双三次插值法（bicubic interpolation）。通常情况下，这种平滑函数的数学优化比栅格地图的分辨率能够提供更好的精度。\n\n对于局部优化问题，一个相对精确的初始估计非常重要。因此如果通过IMU提供角度信息（角速度），来估计scan matching中位姿的旋转分量$\\theta$，可以提高优化的准确性。在缺少IMU的情况下，高频率的scan matching或者pixel-accurate scan matching也可以提高准确性，但会增加时间复杂度。\n\n## Closing Loops\n\n> closing loop采用了 SPA（Sparse Pose Adjustment）进行后端loop closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，采用的算法是BBS（Branch-and-bound scan matching）, 它可大幅提高精度和速度。\n\n### SPA\n\n由于scans只和一个包含最近的几个scans的submap进行匹配，上面所讲的scan matcher会产生比较小的累计误差。\n\n系统通过创建一个个小的submaps实现大的场景地图构建，并使用Sparse Pose Adjustment方法[2]优化所有scans和submaps的位姿，提高精准度。\n\n### BBS\n\n将scans插入处的相关位姿保存在内存中，以便在回环检测优化时使用。此外，所有其他的包含一个scan和一个submap组合，一旦submap不再变化，都会被用于回环检测。一个scan matcher会在后台一直不断的运行，当一个好的scan match被找到，该匹配的约束也会被加入到优化问题（是指回环优化问题）中。\n\n> **上面这一段内容理解的还不是特别清楚？**\n>\n> 其实是下文要提到的$\\xi_{ij}$的求解过程。\n\n### A. 优化问题\n\n回环的优化问题与scan matching的优化问题类似，都是通过构造非线性最小二乘的方式进行的，允许方便地添加残差以考虑附加的数据。每隔几秒，就使用Ceres计算下式的解：\n\n{% raw %}\n\n$\\mathop{\\arg\\min} \\limits_{{\\Xi^m},{\\Xi^s}} \\frac{1}{2}\\sum \\limits_{ij}\\rho(E^2(\\xi^m_i,\\xi^s_j;\\sum \\limits_{ij},\\xi_{ij})) \\qquad(SPA)$ [15]\n\n{% endraw %}\n\n$\\rho$是一个损失函数，比如Huber loss等。使用损失函数的目的是减少加入到优化问题中的离群点对于系统的影响，这种情况在局部对称的环境，如办公室走廊容易发生，scan matching会将错误的约束加入到优化问题。\n\n$\\Xi^m=\\{\\xi^m_i\\}_{i=1,...,m}$是submap的位姿，$\\Xi^s=\\{\\xi^s_j\\}_{j=1,...,n}$是scan的位姿，submap位姿和scan位姿都是世界坐标系下的，并且它们之间存在约束条件（这个约束条件是指什么？）用于完成优化。\n\n对于submap $i$和scan $j$，$\\xi_{ij}$表示scan在匹配到的submap坐标系下的位姿（$j$在$i$坐标系下的位姿，求解方法在下一节介绍），$\\sum_{ij}$是相应的协方差矩阵，这个协方差矩阵可以通过[14]的方式获得，也可以通过(CS)公式获得。残差$E$的计算：\n\n$E^2(\\xi^m_i,\\xi^s_j;\\sum_{ij},\\xi_{ij})=e(\\xi^m_i,\\xi^s_j;\\xi_{ij})^T\\sum_{ij}^{-1}e(\\xi^m_i,\\xi^s_j;\\xi_{ij})$\n\n$e(\\xi^m_i,\\xi^s_j;\\xi_{ij})=\\xi_{ij}-\\left(\\begin{matrix}R^{-1}_{\\xi^m_i}(t_{\\xi^m_i}-t_{\\xi^s_j}) \\\\ \\xi^m_{i;\\theta}-\\xi^s_{j;\\theta}\\end{matrix}\\right)$\n\n> ### 协方差\n>\n> 统计学中，标准差、方差一般是用来描述一维数据的。对于多维数据，一般使用协方差度量两个随机变量关系。\n>\n> 方差定义：$var(X)=\\frac{\\sum \\limits_{i=1}^{n}(X_i-\\overline X)(X_i-\\overline X)}{n-1}$\n>\n> 协方差定义：$cov(X,Y)=\\frac{\\sum \\limits (X_i-\\overline X)(Y_i-\\overline Y)}{n-1}$\n>\n> 使用协方差来度量各个维度偏离其均值的程度。如果协方差为正，两个变量是正相关；为负，负相关；为0，无关，即相互独立。\n>\n> ### 协方差矩阵\n>\n> 协方差只能处理二维问题，对于多维数据，就需要计算多个协方差。一般使用协方差矩阵组织。\n>\n> 协方差矩阵定义：$C_{n\\times n}=(c_{i,j},c_{i,j}=cov(Dim_i,Dim_j))$\n>\n> 如三维数据的协方差矩阵为：$C=\\left(\\begin{matrix}cov(x,x)&cov(x,y)&cov(x,z)\\\\cov(y,x)&cov(y,y)&cov(y,z)\\\\cov(z,x)&cov(z,y)&cov(z,z)\\end{matrix}\\right)$\n>\n> 协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。\n\n### B. Branch-and-bound scan matching\n\n之前提到的回环约束关系$ξij$（scan $j$在submap $i$坐标系中的位姿）就是通过这里的方法得到的，也是整篇论文最核心的地方。首先看一下pixel-accurate match的匹配过程：\n\n$\\xi^*=\\mathop{\\arg\\max} \\limits_{\\xi \\in W}\\sum\\limits_{k=1}^{K}M_{nearest}(T_\\xi h_k)\\qquad\\ \\ (BBS)$  [14]\n\n其中$W$是搜索空间（搜索窗口），$M_{nearest}$就是该pixel对应的grid point的M值。之后可以通过(CS)公式进一步提高$\\xi$匹配的准确度。\n\n搜索空间和搜索步长的选择是决定pixel-accurate match是否高效的关键。搜索步长的计算方式：\n\n$d_{max}=\\mathop{max}\\limits_{k=1,...,K} \\ \\ \\| \\mathrm{h} _k\\|$\n\n$\\delta_\\theta=arccos(1-\\frac{r^2}{2d^2_{max}})$\n\n$w_x=\\lceil \\frac{W_x}{r} \\rceil$,  $w_y=\\lceil \\frac{W_y}{r} \\rceil$,  $w_\\theta=\\lceil \\frac{W_\\theta}{\\delta_\\theta} \\rceil$\n\n其中$d_{max}$是所有scan点集中跨度最大的那个值，$Wx=Wy=7m$，$W_θ=30^\\circ$，因此搜索空间就可以确定了。此时搜索空间的大小是7m*7m。\n\n$\\overline{W}=\\{-w_x,...,w_x\\}\\times\\{-w_y,...,w_y\\}\\times\\{-w_\\theta,...,w_\\theta\\}$\n\n$W=\\{\\xi_0+(rj_x,rj_y,\\delta_\\theta j_\\theta):(j_x,j_y,j_\\theta)\\in\\overline{W}\\}​$\n\n有了搜索空间和搜索步长，就可以得到最原始的暴力搜索方式。算法1如下图所示：\n\n{% asset_img 暴力搜索.png %}\n\n为了进一步提高搜索效率，Cartograoher采用了branch and bound approach的方式。branch and bound\napproach是一种在问题的解空间树上搜索问题的解的方法，被Google套用在最优位姿的搜索中，从而将无法实时化暴力解优化到可以满足实时化。分支上界法就是每个分支代表一种可能，使用DFS找到最佳位置即可，和算法1解决的是相同的问题。只不过这个节点的score是可能的最大值而已。\n\n分支上界法分为以下几步：**节点选择、分支、计算上限**。对于这三步，论文中有具体讲解。节点选择采用的是DFS，分支算法，采用的是算法2。算法3是将节点选择和分支结合到一起之后的算法。\n{% asset_img 算法2.png %}\n\n{% asset_img 算法3.png %}\n\n## 总结\n\n论文阐述了一个2D的SLAM系统，系统采用闭环检测的scan-to-submap matching，同时还有图优化（graph \noptimization）。一个submap的创建使用的是局部的、基于栅格地图的（grid-based）SLAM方法。在后台，所有的点集与相近的submap的匹配使用的是pixel-accurate scan matching的方法，然后建立闭环检测的约束。这个约束图（基于submap和scan pose的）都会周期性的被后台更改。这个操作是采用GPU加速将已完成的submap和当前的submap进行结合。系统图引用的[博客](https://blog.csdn.net/jsgaobiao/article/details/53116042)中的。\n\n{% asset_img 系统图.png %}\n\nScan是激光扫描的单帧数据，通过累加Scan来构建局部地图（Submap），采用的是grid-based 的SLAM方法。生成约束关系的scan和submap的匹配算法采用的是pixel-accurate scan matching的方法。Cartographer的实现并没有采用滤波方法，而是采用了类似图优化的模型进行Pose estimation，具体的实现是用了Ceres scan matching(Ceres是Google自家的库) 。 这样构造出来的很多很多submap是会产生累计误差的，最后通过Loop closing来消除这些误差，完成闭环。\n\n## 参考资料\n\n1. Real-time loop closure in 2D LIDAR SLAM\n2. [google cartographer的论文《real-time loop closure in 2D LIDAR SLAM》翻译](https://blog.csdn.net/lilynothing/article/details/60875825)\n3. [cartographer对应论文的琢磨(2)](https://note.youdao.com/share/?id=d8d15963d4577236399aa52c2cd968a7&type=note#/)\n4. [Real-Time Loop Closure in 2D LIDAR SLAM 论文笔记](https://zhehangt.github.io/2017/05/01/SLAM/CartographerPaper/)\n5. [cartographer算法简析](https://blog.csdn.net/sean_xyz/article/details/68957747)\n6. [【SLAM】（一）Google Cartographer的初步尝试](https://blog.csdn.net/jsgaobiao/article/details/53116042)\n7. [[转\\]浅谈协方差矩阵](https://www.cnblogs.com/chaosimple/p/3182157.html) \n\n## 相关文献\n\n[1] E. Olson, “M3RSM: Many-to-many multi-resolution scan matching,” in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), June 2015.\n[2] K. Konolige, G. Grisetti, R. Kümmerle, W. Burgard, B. Limketkai, and R. Vincent, “Sparse pose adjustment for 2D mapping,” in IROS, Taipei, Taiwan, 10/2010 2010.\n[3] F. Lu and E. Milios, “Globally consistent range scan alignment for environment mapping,” Autonomous robots, vol. 4, no. 4, pp. 333–349, 1997.\n[4] F. Martı́n, R. Triebel, L. Moreno, and R. Siegwart, “Two different tools for three-dimensional mapping: DE-based scan matching and feature-based loop detection,” Robotica, vol. 32, no. 01, pp. 19–41,2014.\n[5] S. Kohlbrecher, J. Meyer, O. von Stryk, and U. Klingauf, “A flexible and scalable SLAM system with full 3D motion \nestimation,” in Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR). IEEE, November 2011.\n[6] M. Himstedt, J. Frost, S. Hellbach, H.-J. Böhme, and E. Maehle, “Large scale place recognition in 2D LIDAR scans using geometrical landmark relations,” in Intelligent Robots and Systems (IROS 2014),2014 IEEE/RSJ International \nConference on. IEEE, 2014, pp. 5030–5035.\n[7] K. Granström, T. B. Schön, J. I. Nieto, and F. T. Ramos, “Learning to close loops from range data,” The International Journal of Robotics Research, vol. 30, no. 14, pp. 1728–1754, 2011.\n[8] G. Grisetti, C. Stachniss, and W. Burgard, “Improving grid-based SLAM with Rao-Blackwellized particle filters by adaptive proposals and selective resampling,” in Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on. IEEE, 2005, pp. 2432–2437.\n[9] G. D. Tipaldi, M. Braun, and K. O. Arras, “FLIRT: Interest regions for 2D range data with applications to robot navigation,” in Experimental Robotics. Springer, 2014, pp. 695–710.\n[10] J. Strom and E. Olson, “Occupancy grid rasterization in large environments for teams of robots,” in Intelligent\n Robots and Systems (IROS),2011 IEEE/RSJ International Conference on. IEEE, 2011, pp. 4271–4276.\n[11] R. Kümmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard,“g2o: A general framework for graph optimization,” in Robotics and Automation (ICRA), 2011 IEEE International Conference on. IEEE,2011, pp. 3607–3613.\n[12] L. Carlone, R. Aragues, J. A. Castellanos, and B. Bona, “A fast and accurate approximation for planar pose graph optimization,” The International Journal of Robotics Research, pp. 965–987, 2014.\n[13] M. Bosse and R. Zlot, “Map matching and data association for large-scale two-dimensional laser scan-based SLAM,” The International Journal of Robotics Research, vol. 27, no. 6, pp. 667–691, 2008.\n[14] E. B. Olson, “Real-time correlative scan matching,” in Robotics and Automation, 2009. ICRA’09. IEEE International Conference on. IEEE, 2009, pp. 4387–4393.\n\n[15]Efficient Sparse Pose Adjustment for 2D Mapping\n\n","source":"_posts/Cartographer学习一论文阅读.md","raw":"---\ntitle: Cartographer学习一论文阅读\ndate: 2018-09-12 16:56:16\ntags: \n  - Lidar SLAM\n  - Cartographer\ncategories:\n  - 机器人 \n  - SLAM\n  - Cartographer\ncopyright: true\nmathjax: true\n---\n\n---\n\n本篇文章记录阅读Google开源Cartographer SLAM系统论文过程中的学习内容。\n\n<!--more-->\n\n## 概况\n\n`Real-time loop closure in 2D LIDAR SLAM`是Google发表在ICRA2016上的一篇论文，开源的系统是大名鼎鼎的Cartographer，目前该系统已经有大神改到Cartographer-ROS版本。本文在阅读论文的基础上，参考其他网络博客资料，学习并记录论文的一些要点，通过这个过程希望能够理解论文的核心内容和系统的实现。\n\n### 主要论文\n\n- Real-Time Loop Closure in 2D LIDAR SLAM , ICRA 2016\n\n- Efficient Sparse Pose Adjustment for 2D Mapping  (SPA)\n\n- Real-Time Correlative Scan Matching  (BBS)\n\n### 文章重点\n\n- 第四部分：local 2d slam，主要是将局部地图的scan matching作为一个最小二乘优化问题，由ceres slover解决。       \n\n- 第五部分： closing loop， 采用了 SPA（Sparse Pose Adjustment）进行后端loop  closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，这里采用了BBS（Branch-and-bound scan  matching）, 它可大幅提高精度和速度。\n\n## 文章贡献\n\n文章的重点不是关注SLAM本身，而是提出了一种基于激光的5cm分辨率实时建图和回环检测方法，减少了计算量，满足实时的大场景地图构建以及大规模的实时优化的性能需求。\n\n为了达到实时闭环检测，文章使用了分支上界法来计算scan-to-submap的匹配作为约束。\n\n## Scan Matching方法介绍\n\n涉及到的相关文献在文后列出，以便以后学习。\n\n1. scan-to-scan matching：基于激光的SLAM中最常用来估计相关位姿的方法。但是非常容易造成累积误差。[1,2,3,4]\n\n2. scan-to-map matching：可以较少累计误差。其中一种方法是使用Gauss-Newton法在线性插值地图上找到局部最优值，前提是获取到了最优的初始位姿估计，这就需要使用有足够高数据获取速率的激光雷达，以保证局部优化的scan-to-map匹配是高效并且鲁棒的。在不稳定的平台上，需要使用惯性测量单元（IMU）将激光扫描投影到水平面上以估计重力方向。[5]\n\n3. pixel-accurate scan matching：可以进一步减少局部误差，但是计算量比较大。这个方法同样可以用来检测回环。[1]\n\n4. 从laser scans中提取特征做匹配，从而减少计算量[4]。\n\n5. histogram-based matching用于回环检测[6]。\n\n6. 用机器学习做laser scan data的特征检测[7]。\n\n## 累积误差处理方式\n\n1. 基于粒子滤波（Particle Filter）的优化。粒子滤波在处理大场景地图时，由于粒子数的极具增长造成资源密集。[8,9,10]\n\n2. 基于位姿图的优化（**Graph-based SLAM**）。与视觉SLAM的位姿图优化大同小异，主要是在观测方程上的区别。[2,11,12,13]\n\n## 系统概述\n\n1. Cartographer是实时的室内建图系统，系统生成5cm分辨率的2D栅格地图地图。\n\n2. laser scans数据被插入到submap中的最佳估计位置，并假定最佳估计位置在短时间内足够准确。\n\n3. scan matching针对最近的submap发生，因此它只取决于最近的scans和全局帧位姿估计中累计的误差。\n\n4. 系统使用pose optimization处理误差累计。\n\n5. submap一旦构建完成，就不会再插入新的scans。submap会用于回环检测过程的scan matching，其实回环检测会将所有已经构建完成的submaps和scans考虑在内。\n\n   如果scan和submap在当前位姿估计下足够接近的话，scan matcher会尝试在submap中寻找回环scan。\n\n   > 当一个新的laser scan加入到地图中时，如果该laser scan的估计位姿与地图中某个submap的某个laser scan的位姿比较接近的话，那么通过某种 scan match策略就会找到该闭环。\n\n   为了减少计算量，Cartographer设计了特殊的策略来找到回环scan。这个策略就是在当前的位姿估计附近设置搜索窗口，在这个搜索窗口内执行branch-and-bound方法来寻找回环scan，如果在搜索窗口中找到了一个足够好的匹配，则会将该匹配作为回环检测约束条件添加到优化问题中。\n\n6. 系统通过使用branch-and-bound方法，并对每个生成的submap预计算出几个栅格地图，保证回环优化的快速完成，快到可以在加入新的scans之前就完成优化，从而保证了一种软实时约束。\n\n7. cartographer的整体架构是典型的 前端建图 （局部地图）+后端优化。 \n\n## 符号说明\n\n- 位姿表示：$\\xi=(\\xi_x,\\xi_y,\\xi_{\\theta})$\n- 扫描scan：$H=\\{h_k\\}_{k=1,…,K},h_k \\in \\mathbb{R^2}​$\n- scan-to-submap变换矩阵：$T_\\xi​$\n- scan-to-submap变换：$T_{\\xi }h_k=\\underbrace{\\left(\\begin{matrix}cos\\xi_\\theta&-sin\\xi_\\theta\\\\sin\\xi_\\theta&cos\\xi_\\theta\\end{matrix} \\right)}_{R_\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\\\xi_y\\end{matrix}\\right)}_{t_\\xi}​$\n- 概率栅格地图概率值：$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p_{min},p_{max}]$\n- submap世界坐标系下的位姿（m代表map）：$\\Xi^m=\\{\\xi^m_i\\}_{i=1,...,m}​$\n- scan世界坐标系下的位姿（s代表scan）：$\\Xi^s=\\{\\xi^s_j\\}_{j=1,...,n}​$\n- scan $i​$在匹配到的submap $j​$坐标系下的位姿：$\\xi_{ij}​$\n- 与scan $i​$和submap $j​$相对应的协方差矩阵：$\\sum_{ij}​$\n\n## Local 2D SLAM\n\n系统将局部和全局方法结合到2D SLAM中，两种方法都对LIDAR观测到的位姿进行了优化。这一部分介绍局部地图的scan matching，该问题被构造成最小二乘问题，使用ceres solver解决。\n\n位姿表示为$\\xi=(\\xi_x,\\xi_y,\\xi_{\\theta})$，这个位姿表示包括$(x,y)$坐标变换（注意这里是二维坐标），以及角度的旋转$\\xi_\\theta$，对观测位姿的优化实际上就是对scans的优化。平台采用IMU测量重力方向，将水平安装的LIDAR观测到的scans映射到2D平面。 \n\n> #### scan matching\n>\n> 局部方法中，将每个连续的scan点集和整个地图的一部分进行匹配，就是和submap $M$进行匹配。这个过程中使用了一种非线性的优化方法将submap和scan点集对齐，这也是scan matching的过程。局部方法积累的误差在全局方法消除，即回环检测。\n\n### A. Scans\n\nsubmap的构建是一个不断将scan和submap坐标系对齐的迭代过程。\n\n一个scan包含一个起点和很多个终点，起点称为scan origin，终点称为scan points，将scan表示为$H=\\{h_k\\}_{k=1,…,K},h_k \\in \\mathbb{R^2}$。在scan坐标系下，origin就是坐标原点，scan points就是在scan坐标系下的坐标。\n\n当把一个scans插入到一个submap中时，假设scan坐标系到submap坐标系的坐标转换表示为$T_\\xi$（即scan坐标系在submap坐标系下的位姿$\\xi$表示为变换矩阵$T_\\xi$），即激光传感器在submap坐标系下的位姿。\n\n每个$h_k$在submap坐标系下的坐标为：$T_{\\xi }h_k=\\underbrace{\\left(\\begin{matrix}cos\\xi_\\theta&-sin\\xi_\\theta\\\\sin\\xi_\\theta&cos\\xi_\\theta\\end{matrix} \\right)}_{R_\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\\\xi_y\\end{matrix}\\right)}_{t_\\xi}$\n\n### B. Submaps\n\n一些连续的scans组成submap。采用概率栅格地图的形式表示这些submaps，$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p_{min},p_{max}]$，以给定的分辨率（例如5cm）将离散栅格地图点映射到值，这些值可以记作栅格地图点被占用的概率。对于每个栅格地图点，都定义一个相应的pixel，这个piexl是针对于分辨率来说的，对于5cm的分辨率来说，一个pixel相当于一个5*5的方格，那么对应于scan中应该有很多个point，即论文中定义的：pixel包含了所有靠近这个栅格地图点的points。\n\n{% asset_img 栅格地图点和相关像素.png %}\n\n> #### 疑问\n>\n> 1. 这里栅格地图点和像素的定义不明白？\n>\n>    答：栅格地图点就是上图中的叉号处，像素定义为叉号周围所有的点的集合，即小方框。\n>\n> 2. submaps是扫描点的集合？？概率栅格地图表示submaps怎么理解？？\n>\n>    看源码理解。\n>\n\n对于每个要插入submap的scan，都会产生一组称为hits的grid point和一组称为misses的grid point。如下图所示。\n\n{% asset_img submap.png %}\n\n其中阴影带叉的是hit，加入hits集合；阴影不带叉的是miss（scan origin和scan points连线经过的grid points，排除在hits中的），加入misses集合。每个hits中的grid point被赋予初始值$M=p_{hit}$，每个misses中的grid point被赋予初始值$M=p_{miss}$。如果grid point已经有$p$值，则用下述公式更新：\n\n$odds(p)=\\frac{p}{1−p}$\n\n$M_{new(x)}=clamp(odds^{−1}(odds(M_{old}(x))⋅odds(p_{hit})))$\n\n> Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内，小于min的数值返回min，大于max的数值返回max。\n\nmiss集合的更新也是类似的。\n\n### C. Ceres scan matching\n\n将scan插入submap之前，需要通过scan matching对scan的位姿$ \\xi $进行优化（优化过程参照当前局部submap），优化过程使用基于Ceres库的scan matcher。scan matcher的任务就是找到一个scan的位姿，能够满足scan points在submap中有最大概率值。这里涉及到的优化问题为非线性最小二乘问题，通过Ceres库进行求解。使得scan在栅格地图中的概率值最大，那么就需要使得（cs）最小，非线性最小二乘问题目标函数构造形式如下：\n\n$\\mathop{\\arg\\min} \\limits_{\\xi}\\sum \\limits_{k=1}^K(1−M_{smooth}(T_{\\xi}h_k))^2 \\qquad\\qquad(CS)​$\n\n平滑函数$M_{smooth}$完成了局部submap中概率值从2D到1D的平滑，将值限制在$[0; 1]$范围内，使用双三次插值法（bicubic interpolation）。通常情况下，这种平滑函数的数学优化比栅格地图的分辨率能够提供更好的精度。\n\n对于局部优化问题，一个相对精确的初始估计非常重要。因此如果通过IMU提供角度信息（角速度），来估计scan matching中位姿的旋转分量$\\theta$，可以提高优化的准确性。在缺少IMU的情况下，高频率的scan matching或者pixel-accurate scan matching也可以提高准确性，但会增加时间复杂度。\n\n## Closing Loops\n\n> closing loop采用了 SPA（Sparse Pose Adjustment）进行后端loop closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，采用的算法是BBS（Branch-and-bound scan matching）, 它可大幅提高精度和速度。\n\n### SPA\n\n由于scans只和一个包含最近的几个scans的submap进行匹配，上面所讲的scan matcher会产生比较小的累计误差。\n\n系统通过创建一个个小的submaps实现大的场景地图构建，并使用Sparse Pose Adjustment方法[2]优化所有scans和submaps的位姿，提高精准度。\n\n### BBS\n\n将scans插入处的相关位姿保存在内存中，以便在回环检测优化时使用。此外，所有其他的包含一个scan和一个submap组合，一旦submap不再变化，都会被用于回环检测。一个scan matcher会在后台一直不断的运行，当一个好的scan match被找到，该匹配的约束也会被加入到优化问题（是指回环优化问题）中。\n\n> **上面这一段内容理解的还不是特别清楚？**\n>\n> 其实是下文要提到的$\\xi_{ij}$的求解过程。\n\n### A. 优化问题\n\n回环的优化问题与scan matching的优化问题类似，都是通过构造非线性最小二乘的方式进行的，允许方便地添加残差以考虑附加的数据。每隔几秒，就使用Ceres计算下式的解：\n\n{% raw %}\n\n$\\mathop{\\arg\\min} \\limits_{{\\Xi^m},{\\Xi^s}} \\frac{1}{2}\\sum \\limits_{ij}\\rho(E^2(\\xi^m_i,\\xi^s_j;\\sum \\limits_{ij},\\xi_{ij})) \\qquad(SPA)$ [15]\n\n{% endraw %}\n\n$\\rho$是一个损失函数，比如Huber loss等。使用损失函数的目的是减少加入到优化问题中的离群点对于系统的影响，这种情况在局部对称的环境，如办公室走廊容易发生，scan matching会将错误的约束加入到优化问题。\n\n$\\Xi^m=\\{\\xi^m_i\\}_{i=1,...,m}$是submap的位姿，$\\Xi^s=\\{\\xi^s_j\\}_{j=1,...,n}$是scan的位姿，submap位姿和scan位姿都是世界坐标系下的，并且它们之间存在约束条件（这个约束条件是指什么？）用于完成优化。\n\n对于submap $i$和scan $j$，$\\xi_{ij}$表示scan在匹配到的submap坐标系下的位姿（$j$在$i$坐标系下的位姿，求解方法在下一节介绍），$\\sum_{ij}$是相应的协方差矩阵，这个协方差矩阵可以通过[14]的方式获得，也可以通过(CS)公式获得。残差$E$的计算：\n\n$E^2(\\xi^m_i,\\xi^s_j;\\sum_{ij},\\xi_{ij})=e(\\xi^m_i,\\xi^s_j;\\xi_{ij})^T\\sum_{ij}^{-1}e(\\xi^m_i,\\xi^s_j;\\xi_{ij})$\n\n$e(\\xi^m_i,\\xi^s_j;\\xi_{ij})=\\xi_{ij}-\\left(\\begin{matrix}R^{-1}_{\\xi^m_i}(t_{\\xi^m_i}-t_{\\xi^s_j}) \\\\ \\xi^m_{i;\\theta}-\\xi^s_{j;\\theta}\\end{matrix}\\right)$\n\n> ### 协方差\n>\n> 统计学中，标准差、方差一般是用来描述一维数据的。对于多维数据，一般使用协方差度量两个随机变量关系。\n>\n> 方差定义：$var(X)=\\frac{\\sum \\limits_{i=1}^{n}(X_i-\\overline X)(X_i-\\overline X)}{n-1}$\n>\n> 协方差定义：$cov(X,Y)=\\frac{\\sum \\limits (X_i-\\overline X)(Y_i-\\overline Y)}{n-1}$\n>\n> 使用协方差来度量各个维度偏离其均值的程度。如果协方差为正，两个变量是正相关；为负，负相关；为0，无关，即相互独立。\n>\n> ### 协方差矩阵\n>\n> 协方差只能处理二维问题，对于多维数据，就需要计算多个协方差。一般使用协方差矩阵组织。\n>\n> 协方差矩阵定义：$C_{n\\times n}=(c_{i,j},c_{i,j}=cov(Dim_i,Dim_j))$\n>\n> 如三维数据的协方差矩阵为：$C=\\left(\\begin{matrix}cov(x,x)&cov(x,y)&cov(x,z)\\\\cov(y,x)&cov(y,y)&cov(y,z)\\\\cov(z,x)&cov(z,y)&cov(z,z)\\end{matrix}\\right)$\n>\n> 协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。\n\n### B. Branch-and-bound scan matching\n\n之前提到的回环约束关系$ξij$（scan $j$在submap $i$坐标系中的位姿）就是通过这里的方法得到的，也是整篇论文最核心的地方。首先看一下pixel-accurate match的匹配过程：\n\n$\\xi^*=\\mathop{\\arg\\max} \\limits_{\\xi \\in W}\\sum\\limits_{k=1}^{K}M_{nearest}(T_\\xi h_k)\\qquad\\ \\ (BBS)$  [14]\n\n其中$W$是搜索空间（搜索窗口），$M_{nearest}$就是该pixel对应的grid point的M值。之后可以通过(CS)公式进一步提高$\\xi$匹配的准确度。\n\n搜索空间和搜索步长的选择是决定pixel-accurate match是否高效的关键。搜索步长的计算方式：\n\n$d_{max}=\\mathop{max}\\limits_{k=1,...,K} \\ \\ \\| \\mathrm{h} _k\\|$\n\n$\\delta_\\theta=arccos(1-\\frac{r^2}{2d^2_{max}})$\n\n$w_x=\\lceil \\frac{W_x}{r} \\rceil$,  $w_y=\\lceil \\frac{W_y}{r} \\rceil$,  $w_\\theta=\\lceil \\frac{W_\\theta}{\\delta_\\theta} \\rceil$\n\n其中$d_{max}$是所有scan点集中跨度最大的那个值，$Wx=Wy=7m$，$W_θ=30^\\circ$，因此搜索空间就可以确定了。此时搜索空间的大小是7m*7m。\n\n$\\overline{W}=\\{-w_x,...,w_x\\}\\times\\{-w_y,...,w_y\\}\\times\\{-w_\\theta,...,w_\\theta\\}$\n\n$W=\\{\\xi_0+(rj_x,rj_y,\\delta_\\theta j_\\theta):(j_x,j_y,j_\\theta)\\in\\overline{W}\\}​$\n\n有了搜索空间和搜索步长，就可以得到最原始的暴力搜索方式。算法1如下图所示：\n\n{% asset_img 暴力搜索.png %}\n\n为了进一步提高搜索效率，Cartograoher采用了branch and bound approach的方式。branch and bound\napproach是一种在问题的解空间树上搜索问题的解的方法，被Google套用在最优位姿的搜索中，从而将无法实时化暴力解优化到可以满足实时化。分支上界法就是每个分支代表一种可能，使用DFS找到最佳位置即可，和算法1解决的是相同的问题。只不过这个节点的score是可能的最大值而已。\n\n分支上界法分为以下几步：**节点选择、分支、计算上限**。对于这三步，论文中有具体讲解。节点选择采用的是DFS，分支算法，采用的是算法2。算法3是将节点选择和分支结合到一起之后的算法。\n{% asset_img 算法2.png %}\n\n{% asset_img 算法3.png %}\n\n## 总结\n\n论文阐述了一个2D的SLAM系统，系统采用闭环检测的scan-to-submap matching，同时还有图优化（graph \noptimization）。一个submap的创建使用的是局部的、基于栅格地图的（grid-based）SLAM方法。在后台，所有的点集与相近的submap的匹配使用的是pixel-accurate scan matching的方法，然后建立闭环检测的约束。这个约束图（基于submap和scan pose的）都会周期性的被后台更改。这个操作是采用GPU加速将已完成的submap和当前的submap进行结合。系统图引用的[博客](https://blog.csdn.net/jsgaobiao/article/details/53116042)中的。\n\n{% asset_img 系统图.png %}\n\nScan是激光扫描的单帧数据，通过累加Scan来构建局部地图（Submap），采用的是grid-based 的SLAM方法。生成约束关系的scan和submap的匹配算法采用的是pixel-accurate scan matching的方法。Cartographer的实现并没有采用滤波方法，而是采用了类似图优化的模型进行Pose estimation，具体的实现是用了Ceres scan matching(Ceres是Google自家的库) 。 这样构造出来的很多很多submap是会产生累计误差的，最后通过Loop closing来消除这些误差，完成闭环。\n\n## 参考资料\n\n1. Real-time loop closure in 2D LIDAR SLAM\n2. [google cartographer的论文《real-time loop closure in 2D LIDAR SLAM》翻译](https://blog.csdn.net/lilynothing/article/details/60875825)\n3. [cartographer对应论文的琢磨(2)](https://note.youdao.com/share/?id=d8d15963d4577236399aa52c2cd968a7&type=note#/)\n4. [Real-Time Loop Closure in 2D LIDAR SLAM 论文笔记](https://zhehangt.github.io/2017/05/01/SLAM/CartographerPaper/)\n5. [cartographer算法简析](https://blog.csdn.net/sean_xyz/article/details/68957747)\n6. [【SLAM】（一）Google Cartographer的初步尝试](https://blog.csdn.net/jsgaobiao/article/details/53116042)\n7. [[转\\]浅谈协方差矩阵](https://www.cnblogs.com/chaosimple/p/3182157.html) \n\n## 相关文献\n\n[1] E. Olson, “M3RSM: Many-to-many multi-resolution scan matching,” in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), June 2015.\n[2] K. Konolige, G. Grisetti, R. Kümmerle, W. Burgard, B. Limketkai, and R. Vincent, “Sparse pose adjustment for 2D mapping,” in IROS, Taipei, Taiwan, 10/2010 2010.\n[3] F. Lu and E. Milios, “Globally consistent range scan alignment for environment mapping,” Autonomous robots, vol. 4, no. 4, pp. 333–349, 1997.\n[4] F. Martı́n, R. Triebel, L. Moreno, and R. Siegwart, “Two different tools for three-dimensional mapping: DE-based scan matching and feature-based loop detection,” Robotica, vol. 32, no. 01, pp. 19–41,2014.\n[5] S. Kohlbrecher, J. Meyer, O. von Stryk, and U. Klingauf, “A flexible and scalable SLAM system with full 3D motion \nestimation,” in Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR). IEEE, November 2011.\n[6] M. Himstedt, J. Frost, S. Hellbach, H.-J. Böhme, and E. Maehle, “Large scale place recognition in 2D LIDAR scans using geometrical landmark relations,” in Intelligent Robots and Systems (IROS 2014),2014 IEEE/RSJ International \nConference on. IEEE, 2014, pp. 5030–5035.\n[7] K. Granström, T. B. Schön, J. I. Nieto, and F. T. Ramos, “Learning to close loops from range data,” The International Journal of Robotics Research, vol. 30, no. 14, pp. 1728–1754, 2011.\n[8] G. Grisetti, C. Stachniss, and W. Burgard, “Improving grid-based SLAM with Rao-Blackwellized particle filters by adaptive proposals and selective resampling,” in Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on. IEEE, 2005, pp. 2432–2437.\n[9] G. D. Tipaldi, M. Braun, and K. O. Arras, “FLIRT: Interest regions for 2D range data with applications to robot navigation,” in Experimental Robotics. Springer, 2014, pp. 695–710.\n[10] J. Strom and E. Olson, “Occupancy grid rasterization in large environments for teams of robots,” in Intelligent\n Robots and Systems (IROS),2011 IEEE/RSJ International Conference on. IEEE, 2011, pp. 4271–4276.\n[11] R. Kümmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard,“g2o: A general framework for graph optimization,” in Robotics and Automation (ICRA), 2011 IEEE International Conference on. IEEE,2011, pp. 3607–3613.\n[12] L. Carlone, R. Aragues, J. A. Castellanos, and B. Bona, “A fast and accurate approximation for planar pose graph optimization,” The International Journal of Robotics Research, pp. 965–987, 2014.\n[13] M. Bosse and R. Zlot, “Map matching and data association for large-scale two-dimensional laser scan-based SLAM,” The International Journal of Robotics Research, vol. 27, no. 6, pp. 667–691, 2008.\n[14] E. B. Olson, “Real-time correlative scan matching,” in Robotics and Automation, 2009. ICRA’09. IEEE International Conference on. IEEE, 2009, pp. 4387–4393.\n\n[15]Efficient Sparse Pose Adjustment for 2D Mapping\n\n","slug":"Cartographer学习一论文阅读","published":1,"updated":"2019-05-30T12:29:26.267Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc1h00f0qlcrp4bcab1x","content":"<hr>\n<p>本篇文章记录阅读Google开源Cartographer SLAM系统论文过程中的学习内容。</p>\n<a id=\"more\"></a>\n<h2 id=\"概况\"><a href=\"#概况\" class=\"headerlink\" title=\"概况\"></a>概况</h2><p><code>Real-time loop closure in 2D LIDAR SLAM</code>是Google发表在ICRA2016上的一篇论文，开源的系统是大名鼎鼎的Cartographer，目前该系统已经有大神改到Cartographer-ROS版本。本文在阅读论文的基础上，参考其他网络博客资料，学习并记录论文的一些要点，通过这个过程希望能够理解论文的核心内容和系统的实现。</p>\n<h3 id=\"主要论文\"><a href=\"#主要论文\" class=\"headerlink\" title=\"主要论文\"></a>主要论文</h3><ul>\n<li><p>Real-Time Loop Closure in 2D LIDAR SLAM , ICRA 2016</p>\n</li>\n<li><p>Efficient Sparse Pose Adjustment for 2D Mapping  (SPA)</p>\n</li>\n<li><p>Real-Time Correlative Scan Matching  (BBS)</p>\n</li>\n</ul>\n<h3 id=\"文章重点\"><a href=\"#文章重点\" class=\"headerlink\" title=\"文章重点\"></a>文章重点</h3><ul>\n<li><p>第四部分：local 2d slam，主要是将局部地图的scan matching作为一个最小二乘优化问题，由ceres slover解决。       </p>\n</li>\n<li><p>第五部分： closing loop， 采用了 SPA（Sparse Pose Adjustment）进行后端loop  closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，这里采用了BBS（Branch-and-bound scan  matching）, 它可大幅提高精度和速度。</p>\n</li>\n</ul>\n<h2 id=\"文章贡献\"><a href=\"#文章贡献\" class=\"headerlink\" title=\"文章贡献\"></a>文章贡献</h2><p>文章的重点不是关注SLAM本身，而是提出了一种基于激光的5cm分辨率实时建图和回环检测方法，减少了计算量，满足实时的大场景地图构建以及大规模的实时优化的性能需求。</p>\n<p>为了达到实时闭环检测，文章使用了分支上界法来计算scan-to-submap的匹配作为约束。</p>\n<h2 id=\"Scan-Matching方法介绍\"><a href=\"#Scan-Matching方法介绍\" class=\"headerlink\" title=\"Scan Matching方法介绍\"></a>Scan Matching方法介绍</h2><p>涉及到的相关文献在文后列出，以便以后学习。</p>\n<ol>\n<li><p>scan-to-scan matching：基于激光的SLAM中最常用来估计相关位姿的方法。但是非常容易造成累积误差。[1,2,3,4]</p>\n</li>\n<li><p>scan-to-map matching：可以较少累计误差。其中一种方法是使用Gauss-Newton法在线性插值地图上找到局部最优值，前提是获取到了最优的初始位姿估计，这就需要使用有足够高数据获取速率的激光雷达，以保证局部优化的scan-to-map匹配是高效并且鲁棒的。在不稳定的平台上，需要使用惯性测量单元（IMU）将激光扫描投影到水平面上以估计重力方向。[5]</p>\n</li>\n<li><p>pixel-accurate scan matching：可以进一步减少局部误差，但是计算量比较大。这个方法同样可以用来检测回环。[1]</p>\n</li>\n<li><p>从laser scans中提取特征做匹配，从而减少计算量[4]。</p>\n</li>\n<li><p>histogram-based matching用于回环检测[6]。</p>\n</li>\n<li><p>用机器学习做laser scan data的特征检测[7]。</p>\n</li>\n</ol>\n<h2 id=\"累积误差处理方式\"><a href=\"#累积误差处理方式\" class=\"headerlink\" title=\"累积误差处理方式\"></a>累积误差处理方式</h2><ol>\n<li><p>基于粒子滤波（Particle Filter）的优化。粒子滤波在处理大场景地图时，由于粒子数的极具增长造成资源密集。[8,9,10]</p>\n</li>\n<li><p>基于位姿图的优化（<strong>Graph-based SLAM</strong>）。与视觉SLAM的位姿图优化大同小异，主要是在观测方程上的区别。[2,11,12,13]</p>\n</li>\n</ol>\n<h2 id=\"系统概述\"><a href=\"#系统概述\" class=\"headerlink\" title=\"系统概述\"></a>系统概述</h2><ol>\n<li><p>Cartographer是实时的室内建图系统，系统生成5cm分辨率的2D栅格地图地图。</p>\n</li>\n<li><p>laser scans数据被插入到submap中的最佳估计位置，并假定最佳估计位置在短时间内足够准确。</p>\n</li>\n<li><p>scan matching针对最近的submap发生，因此它只取决于最近的scans和全局帧位姿估计中累计的误差。</p>\n</li>\n<li><p>系统使用pose optimization处理误差累计。</p>\n</li>\n<li><p>submap一旦构建完成，就不会再插入新的scans。submap会用于回环检测过程的scan matching，其实回环检测会将所有已经构建完成的submaps和scans考虑在内。</p>\n<p>如果scan和submap在当前位姿估计下足够接近的话，scan matcher会尝试在submap中寻找回环scan。</p>\n<blockquote>\n<p>当一个新的laser scan加入到地图中时，如果该laser scan的估计位姿与地图中某个submap的某个laser scan的位姿比较接近的话，那么通过某种 scan match策略就会找到该闭环。</p>\n</blockquote>\n<p>为了减少计算量，Cartographer设计了特殊的策略来找到回环scan。这个策略就是在当前的位姿估计附近设置搜索窗口，在这个搜索窗口内执行branch-and-bound方法来寻找回环scan，如果在搜索窗口中找到了一个足够好的匹配，则会将该匹配作为回环检测约束条件添加到优化问题中。</p>\n</li>\n<li><p>系统通过使用branch-and-bound方法，并对每个生成的submap预计算出几个栅格地图，保证回环优化的快速完成，快到可以在加入新的scans之前就完成优化，从而保证了一种软实时约束。</p>\n</li>\n<li><p>cartographer的整体架构是典型的 前端建图 （局部地图）+后端优化。 </p>\n</li>\n</ol>\n<h2 id=\"符号说明\"><a href=\"#符号说明\" class=\"headerlink\" title=\"符号说明\"></a>符号说明</h2><ul>\n<li>位姿表示：$\\xi=(\\xi<em>x,\\xi_y,\\xi</em>{\\theta})$</li>\n<li>扫描scan：$H={h<em>k}</em>{k=1,…,K},h_k \\in \\mathbb{R^2}​$</li>\n<li>scan-to-submap变换矩阵：$T_\\xi​$</li>\n<li>scan-to-submap变换：$T<em>{\\xi }h_k=\\underbrace{\\left(\\begin{matrix}cos\\xi</em>\\theta&amp;-sin\\xi<em>\\theta\\sin\\xi</em>\\theta&amp;cos\\xi<em>\\theta\\end{matrix} \\right)}</em>{R<em>\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\xi_y\\end{matrix}\\right)}</em>{t_\\xi}​$</li>\n<li>概率栅格地图概率值：$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p<em>{min},p</em>{max}]$</li>\n<li>submap世界坐标系下的位姿（m代表map）：$\\Xi^m={\\xi^m<em>i}</em>{i=1,…,m}​$</li>\n<li>scan世界坐标系下的位姿（s代表scan）：$\\Xi^s={\\xi^s<em>j}</em>{j=1,…,n}​$</li>\n<li>scan $i​$在匹配到的submap $j​$坐标系下的位姿：$\\xi_{ij}​$</li>\n<li>与scan $i​$和submap $j​$相对应的协方差矩阵：$\\sum_{ij}​$</li>\n</ul>\n<h2 id=\"Local-2D-SLAM\"><a href=\"#Local-2D-SLAM\" class=\"headerlink\" title=\"Local 2D SLAM\"></a>Local 2D SLAM</h2><p>系统将局部和全局方法结合到2D SLAM中，两种方法都对LIDAR观测到的位姿进行了优化。这一部分介绍局部地图的scan matching，该问题被构造成最小二乘问题，使用ceres solver解决。</p>\n<p>位姿表示为$\\xi=(\\xi<em>x,\\xi_y,\\xi</em>{\\theta})$，这个位姿表示包括$(x,y)$坐标变换（注意这里是二维坐标），以及角度的旋转$\\xi_\\theta$，对观测位姿的优化实际上就是对scans的优化。平台采用IMU测量重力方向，将水平安装的LIDAR观测到的scans映射到2D平面。 </p>\n<blockquote>\n<h4 id=\"scan-matching\"><a href=\"#scan-matching\" class=\"headerlink\" title=\"scan matching\"></a>scan matching</h4><p>局部方法中，将每个连续的scan点集和整个地图的一部分进行匹配，就是和submap $M$进行匹配。这个过程中使用了一种非线性的优化方法将submap和scan点集对齐，这也是scan matching的过程。局部方法积累的误差在全局方法消除，即回环检测。</p>\n</blockquote>\n<h3 id=\"A-Scans\"><a href=\"#A-Scans\" class=\"headerlink\" title=\"A. Scans\"></a>A. Scans</h3><p>submap的构建是一个不断将scan和submap坐标系对齐的迭代过程。</p>\n<p>一个scan包含一个起点和很多个终点，起点称为scan origin，终点称为scan points，将scan表示为$H={h<em>k}</em>{k=1,…,K},h_k \\in \\mathbb{R^2}$。在scan坐标系下，origin就是坐标原点，scan points就是在scan坐标系下的坐标。</p>\n<p>当把一个scans插入到一个submap中时，假设scan坐标系到submap坐标系的坐标转换表示为$T<em>\\xi$（即scan坐标系在submap坐标系下的位姿$\\xi$表示为变换矩阵$T</em>\\xi$），即激光传感器在submap坐标系下的位姿。</p>\n<p>每个$h<em>k$在submap坐标系下的坐标为：$T</em>{\\xi }h<em>k=\\underbrace{\\left(\\begin{matrix}cos\\xi</em>\\theta&amp;-sin\\xi<em>\\theta\\sin\\xi</em>\\theta&amp;cos\\xi<em>\\theta\\end{matrix} \\right)}</em>{R<em>\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\xi_y\\end{matrix}\\right)}</em>{t_\\xi}$</p>\n<h3 id=\"B-Submaps\"><a href=\"#B-Submaps\" class=\"headerlink\" title=\"B. Submaps\"></a>B. Submaps</h3><p>一些连续的scans组成submap。采用概率栅格地图的形式表示这些submaps，$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p<em>{min},p</em>{max}]$，以给定的分辨率（例如5cm）将离散栅格地图点映射到值，这些值可以记作栅格地图点被占用的概率。对于每个栅格地图点，都定义一个相应的pixel，这个piexl是针对于分辨率来说的，对于5cm的分辨率来说，一个pixel相当于一个5*5的方格，那么对应于scan中应该有很多个point，即论文中定义的：pixel包含了所有靠近这个栅格地图点的points。</p>\n\n<blockquote>\n<h4 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h4><ol>\n<li><p>这里栅格地图点和像素的定义不明白？</p>\n<p>答：栅格地图点就是上图中的叉号处，像素定义为叉号周围所有的点的集合，即小方框。</p>\n</li>\n<li><p>submaps是扫描点的集合？？概率栅格地图表示submaps怎么理解？？</p>\n<p>看源码理解。</p>\n</li>\n</ol>\n</blockquote>\n<p>对于每个要插入submap的scan，都会产生一组称为hits的grid point和一组称为misses的grid point。如下图所示。</p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/submap.png\">\n<p>其中阴影带叉的是hit，加入hits集合；阴影不带叉的是miss（scan origin和scan points连线经过的grid points，排除在hits中的），加入misses集合。每个hits中的grid point被赋予初始值$M=p<em>{hit}$，每个misses中的grid point被赋予初始值$M=p</em>{miss}$。如果grid point已经有$p$值，则用下述公式更新：</p>\n<p>$odds(p)=\\frac{p}{1−p}$</p>\n<p>$M<em>{new(x)}=clamp(odds^{−1}(odds(M</em>{old}(x))⋅odds(p_{hit})))$</p>\n<blockquote>\n<p>Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内，小于min的数值返回min，大于max的数值返回max。</p>\n</blockquote>\n<p>miss集合的更新也是类似的。</p>\n<h3 id=\"C-Ceres-scan-matching\"><a href=\"#C-Ceres-scan-matching\" class=\"headerlink\" title=\"C. Ceres scan matching\"></a>C. Ceres scan matching</h3><p>将scan插入submap之前，需要通过scan matching对scan的位姿$ \\xi $进行优化（优化过程参照当前局部submap），优化过程使用基于Ceres库的scan matcher。scan matcher的任务就是找到一个scan的位姿，能够满足scan points在submap中有最大概率值。这里涉及到的优化问题为非线性最小二乘问题，通过Ceres库进行求解。使得scan在栅格地图中的概率值最大，那么就需要使得（cs）最小，非线性最小二乘问题目标函数构造形式如下：</p>\n<p>$\\mathop{\\arg\\min} \\limits<em>{\\xi}\\sum \\limits</em>{k=1}^K(1−M<em>{smooth}(T</em>{\\xi}h_k))^2 \\qquad\\qquad(CS)​$</p>\n<p>平滑函数$M_{smooth}$完成了局部submap中概率值从2D到1D的平滑，将值限制在$[0; 1]$范围内，使用双三次插值法（bicubic interpolation）。通常情况下，这种平滑函数的数学优化比栅格地图的分辨率能够提供更好的精度。</p>\n<p>对于局部优化问题，一个相对精确的初始估计非常重要。因此如果通过IMU提供角度信息（角速度），来估计scan matching中位姿的旋转分量$\\theta$，可以提高优化的准确性。在缺少IMU的情况下，高频率的scan matching或者pixel-accurate scan matching也可以提高准确性，但会增加时间复杂度。</p>\n<h2 id=\"Closing-Loops\"><a href=\"#Closing-Loops\" class=\"headerlink\" title=\"Closing Loops\"></a>Closing Loops</h2><blockquote>\n<p>closing loop采用了 SPA（Sparse Pose Adjustment）进行后端loop closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，采用的算法是BBS（Branch-and-bound scan matching）, 它可大幅提高精度和速度。</p>\n</blockquote>\n<h3 id=\"SPA\"><a href=\"#SPA\" class=\"headerlink\" title=\"SPA\"></a>SPA</h3><p>由于scans只和一个包含最近的几个scans的submap进行匹配，上面所讲的scan matcher会产生比较小的累计误差。</p>\n<p>系统通过创建一个个小的submaps实现大的场景地图构建，并使用Sparse Pose Adjustment方法[2]优化所有scans和submaps的位姿，提高精准度。</p>\n<h3 id=\"BBS\"><a href=\"#BBS\" class=\"headerlink\" title=\"BBS\"></a>BBS</h3><p>将scans插入处的相关位姿保存在内存中，以便在回环检测优化时使用。此外，所有其他的包含一个scan和一个submap组合，一旦submap不再变化，都会被用于回环检测。一个scan matcher会在后台一直不断的运行，当一个好的scan match被找到，该匹配的约束也会被加入到优化问题（是指回环优化问题）中。</p>\n<blockquote>\n<p><strong>上面这一段内容理解的还不是特别清楚？</strong></p>\n<p>其实是下文要提到的$\\xi_{ij}$的求解过程。</p>\n</blockquote>\n<h3 id=\"A-优化问题\"><a href=\"#A-优化问题\" class=\"headerlink\" title=\"A. 优化问题\"></a>A. 优化问题</h3><p>回环的优化问题与scan matching的优化问题类似，都是通过构造非线性最小二乘的方式进行的，允许方便地添加残差以考虑附加的数据。每隔几秒，就使用Ceres计算下式的解：</p>\n\n\n$\\mathop{\\arg\\min} \\limits_{{\\Xi^m},{\\Xi^s}} \\frac{1}{2}\\sum \\limits_{ij}\\rho(E^2(\\xi^m_i,\\xi^s_j;\\sum \\limits_{ij},\\xi_{ij})) \\qquad(SPA)$ [15]\n\n\n<p>$\\rho$是一个损失函数，比如Huber loss等。使用损失函数的目的是减少加入到优化问题中的离群点对于系统的影响，这种情况在局部对称的环境，如办公室走廊容易发生，scan matching会将错误的约束加入到优化问题。</p>\n<p>$\\Xi^m={\\xi^m<em>i}</em>{i=1,…,m}$是submap的位姿，$\\Xi^s={\\xi^s<em>j}</em>{j=1,…,n}$是scan的位姿，submap位姿和scan位姿都是世界坐标系下的，并且它们之间存在约束条件（这个约束条件是指什么？）用于完成优化。</p>\n<p>对于submap $i$和scan $j$，$\\xi<em>{ij}$表示scan在匹配到的submap坐标系下的位姿（$j$在$i$坐标系下的位姿，求解方法在下一节介绍），$\\sum</em>{ij}$是相应的协方差矩阵，这个协方差矩阵可以通过[14]的方式获得，也可以通过(CS)公式获得。残差$E$的计算：</p>\n<p>$E^2(\\xi^m<em>i,\\xi^s_j;\\sum</em>{ij},\\xi<em>{ij})=e(\\xi^m_i,\\xi^s_j;\\xi</em>{ij})^T\\sum<em>{ij}^{-1}e(\\xi^m_i,\\xi^s_j;\\xi</em>{ij})$</p>\n<p>$e(\\xi^m<em>i,\\xi^s_j;\\xi</em>{ij})=\\xi<em>{ij}-\\left(\\begin{matrix}R^{-1}</em>{\\xi^m<em>i}(t</em>{\\xi^m<em>i}-t</em>{\\xi^s<em>j}) \\ \\xi^m</em>{i;\\theta}-\\xi^s_{j;\\theta}\\end{matrix}\\right)$</p>\n<blockquote>\n<h3 id=\"协方差\"><a href=\"#协方差\" class=\"headerlink\" title=\"协方差\"></a>协方差</h3><p>统计学中，标准差、方差一般是用来描述一维数据的。对于多维数据，一般使用协方差度量两个随机变量关系。</p>\n<p>方差定义：$var(X)=\\frac{\\sum \\limits_{i=1}^{n}(X_i-\\overline X)(X_i-\\overline X)}{n-1}$</p>\n<p>协方差定义：$cov(X,Y)=\\frac{\\sum \\limits (X_i-\\overline X)(Y_i-\\overline Y)}{n-1}$</p>\n<p>使用协方差来度量各个维度偏离其均值的程度。如果协方差为正，两个变量是正相关；为负，负相关；为0，无关，即相互独立。</p>\n<h3 id=\"协方差矩阵\"><a href=\"#协方差矩阵\" class=\"headerlink\" title=\"协方差矩阵\"></a>协方差矩阵</h3><p>协方差只能处理二维问题，对于多维数据，就需要计算多个协方差。一般使用协方差矩阵组织。</p>\n<p>协方差矩阵定义：$C<em>{n\\times n}=(c</em>{i,j},c_{i,j}=cov(Dim_i,Dim_j))$</p>\n<p>如三维数据的协方差矩阵为：$C=\\left(\\begin{matrix}cov(x,x)&amp;cov(x,y)&amp;cov(x,z)\\cov(y,x)&amp;cov(y,y)&amp;cov(y,z)\\cov(z,x)&amp;cov(z,y)&amp;cov(z,z)\\end{matrix}\\right)$</p>\n<p>协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。</p>\n</blockquote>\n<h3 id=\"B-Branch-and-bound-scan-matching\"><a href=\"#B-Branch-and-bound-scan-matching\" class=\"headerlink\" title=\"B. Branch-and-bound scan matching\"></a>B. Branch-and-bound scan matching</h3><p>之前提到的回环约束关系$ξij$（scan $j$在submap $i$坐标系中的位姿）就是通过这里的方法得到的，也是整篇论文最核心的地方。首先看一下pixel-accurate match的匹配过程：</p>\n<p>$\\xi^*=\\mathop{\\arg\\max} \\limits<em>{\\xi \\in W}\\sum\\limits</em>{k=1}^{K}M<em>{nearest}(T</em>\\xi h_k)\\qquad\\ \\ (BBS)$  [14]</p>\n<p>其中$W$是搜索空间（搜索窗口），$M_{nearest}$就是该pixel对应的grid point的M值。之后可以通过(CS)公式进一步提高$\\xi$匹配的准确度。</p>\n<p>搜索空间和搜索步长的选择是决定pixel-accurate match是否高效的关键。搜索步长的计算方式：</p>\n<p>$d<em>{max}=\\mathop{max}\\limits</em>{k=1,…,K} \\ \\ | \\mathrm{h} _k|$</p>\n<p>$\\delta<em>\\theta=arccos(1-\\frac{r^2}{2d^2</em>{max}})$</p>\n<p>$w<em>x=\\lceil \\frac{W_x}{r} \\rceil$,  $w_y=\\lceil \\frac{W_y}{r} \\rceil$,  $w</em>\\theta=\\lceil \\frac{W<em>\\theta}{\\delta</em>\\theta} \\rceil$</p>\n<p>其中$d<em>{max}$是所有scan点集中跨度最大的那个值，$Wx=Wy=7m$，$W</em>θ=30^\\circ$，因此搜索空间就可以确定了。此时搜索空间的大小是7m*7m。</p>\n<p>$\\overline{W}={-w<em>x,…,w_x}\\times{-w_y,…,w_y}\\times{-w</em>\\theta,…,w_\\theta}$</p>\n<p>$W={\\xi<em>0+(rj_x,rj_y,\\delta</em>\\theta j<em>\\theta):(j_x,j_y,j</em>\\theta)\\in\\overline{W}}​$</p>\n<p>有了搜索空间和搜索步长，就可以得到最原始的暴力搜索方式。算法1如下图所示：</p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/暴力搜索.png\">\n<p>为了进一步提高搜索效率，Cartograoher采用了branch and bound approach的方式。branch and bound<br>approach是一种在问题的解空间树上搜索问题的解的方法，被Google套用在最优位姿的搜索中，从而将无法实时化暴力解优化到可以满足实时化。分支上界法就是每个分支代表一种可能，使用DFS找到最佳位置即可，和算法1解决的是相同的问题。只不过这个节点的score是可能的最大值而已。</p>\n<p>分支上界法分为以下几步：<strong>节点选择、分支、计算上限</strong>。对于这三步，论文中有具体讲解。节点选择采用的是DFS，分支算法，采用的是算法2。算法3是将节点选择和分支结合到一起之后的算法。<br><img src=\"/2018/09/12/Cartographer学习一论文阅读/算法2.png\"></p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/算法3.png\">\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>论文阐述了一个2D的SLAM系统，系统采用闭环检测的scan-to-submap matching，同时还有图优化（graph<br>optimization）。一个submap的创建使用的是局部的、基于栅格地图的（grid-based）SLAM方法。在后台，所有的点集与相近的submap的匹配使用的是pixel-accurate scan matching的方法，然后建立闭环检测的约束。这个约束图（基于submap和scan pose的）都会周期性的被后台更改。这个操作是采用GPU加速将已完成的submap和当前的submap进行结合。系统图引用的<a href=\"https://blog.csdn.net/jsgaobiao/article/details/53116042\" target=\"_blank\" rel=\"noopener\">博客</a>中的。</p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/系统图.png\">\n<p>Scan是激光扫描的单帧数据，通过累加Scan来构建局部地图（Submap），采用的是grid-based 的SLAM方法。生成约束关系的scan和submap的匹配算法采用的是pixel-accurate scan matching的方法。Cartographer的实现并没有采用滤波方法，而是采用了类似图优化的模型进行Pose estimation，具体的实现是用了Ceres scan matching(Ceres是Google自家的库) 。 这样构造出来的很多很多submap是会产生累计误差的，最后通过Loop closing来消除这些误差，完成闭环。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>Real-time loop closure in 2D LIDAR SLAM</li>\n<li><a href=\"https://blog.csdn.net/lilynothing/article/details/60875825\" target=\"_blank\" rel=\"noopener\">google cartographer的论文《real-time loop closure in 2D LIDAR SLAM》翻译</a></li>\n<li><a href=\"https://note.youdao.com/share/?id=d8d15963d4577236399aa52c2cd968a7&amp;type=note#/\" target=\"_blank\" rel=\"noopener\">cartographer对应论文的琢磨(2)</a></li>\n<li><a href=\"https://zhehangt.github.io/2017/05/01/SLAM/CartographerPaper/\" target=\"_blank\" rel=\"noopener\">Real-Time Loop Closure in 2D LIDAR SLAM 论文笔记</a></li>\n<li><a href=\"https://blog.csdn.net/sean_xyz/article/details/68957747\" target=\"_blank\" rel=\"noopener\">cartographer算法简析</a></li>\n<li><a href=\"https://blog.csdn.net/jsgaobiao/article/details/53116042\" target=\"_blank\" rel=\"noopener\">【SLAM】（一）Google Cartographer的初步尝试</a></li>\n<li><a href=\"https://www.cnblogs.com/chaosimple/p/3182157.html\" target=\"_blank\" rel=\"noopener\">[转]浅谈协方差矩阵</a> </li>\n</ol>\n<h2 id=\"相关文献\"><a href=\"#相关文献\" class=\"headerlink\" title=\"相关文献\"></a>相关文献</h2><p>[1] E. Olson, “M3RSM: Many-to-many multi-resolution scan matching,” in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), June 2015.<br>[2] K. Konolige, G. Grisetti, R. Kümmerle, W. Burgard, B. Limketkai, and R. Vincent, “Sparse pose adjustment for 2D mapping,” in IROS, Taipei, Taiwan, 10/2010 2010.<br>[3] F. Lu and E. Milios, “Globally consistent range scan alignment for environment mapping,” Autonomous robots, vol. 4, no. 4, pp. 333–349, 1997.<br>[4] F. Martı́n, R. Triebel, L. Moreno, and R. Siegwart, “Two different tools for three-dimensional mapping: DE-based scan matching and feature-based loop detection,” Robotica, vol. 32, no. 01, pp. 19–41,2014.<br>[5] S. Kohlbrecher, J. Meyer, O. von Stryk, and U. Klingauf, “A flexible and scalable SLAM system with full 3D motion<br>estimation,” in Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR). IEEE, November 2011.<br>[6] M. Himstedt, J. Frost, S. Hellbach, H.-J. Böhme, and E. Maehle, “Large scale place recognition in 2D LIDAR scans using geometrical landmark relations,” in Intelligent Robots and Systems (IROS 2014),2014 IEEE/RSJ International<br>Conference on. IEEE, 2014, pp. 5030–5035.<br>[7] K. Granström, T. B. Schön, J. I. Nieto, and F. T. Ramos, “Learning to close loops from range data,” The International Journal of Robotics Research, vol. 30, no. 14, pp. 1728–1754, 2011.<br>[8] G. Grisetti, C. Stachniss, and W. Burgard, “Improving grid-based SLAM with Rao-Blackwellized particle filters by adaptive proposals and selective resampling,” in Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on. IEEE, 2005, pp. 2432–2437.<br>[9] G. D. Tipaldi, M. Braun, and K. O. Arras, “FLIRT: Interest regions for 2D range data with applications to robot navigation,” in Experimental Robotics. Springer, 2014, pp. 695–710.<br>[10] J. Strom and E. Olson, “Occupancy grid rasterization in large environments for teams of robots,” in Intelligent<br> Robots and Systems (IROS),2011 IEEE/RSJ International Conference on. IEEE, 2011, pp. 4271–4276.<br>[11] R. Kümmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard,“g2o: A general framework for graph optimization,” in Robotics and Automation (ICRA), 2011 IEEE International Conference on. IEEE,2011, pp. 3607–3613.<br>[12] L. Carlone, R. Aragues, J. A. Castellanos, and B. Bona, “A fast and accurate approximation for planar pose graph optimization,” The International Journal of Robotics Research, pp. 965–987, 2014.<br>[13] M. Bosse and R. Zlot, “Map matching and data association for large-scale two-dimensional laser scan-based SLAM,” The International Journal of Robotics Research, vol. 27, no. 6, pp. 667–691, 2008.<br>[14] E. B. Olson, “Real-time correlative scan matching,” in Robotics and Automation, 2009. ICRA’09. IEEE International Conference on. IEEE, 2009, pp. 4387–4393.</p>\n<p>[15]Efficient Sparse Pose Adjustment for 2D Mapping</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本篇文章记录阅读Google开源Cartographer SLAM系统论文过程中的学习内容。</p>","more":"<h2 id=\"概况\"><a href=\"#概况\" class=\"headerlink\" title=\"概况\"></a>概况</h2><p><code>Real-time loop closure in 2D LIDAR SLAM</code>是Google发表在ICRA2016上的一篇论文，开源的系统是大名鼎鼎的Cartographer，目前该系统已经有大神改到Cartographer-ROS版本。本文在阅读论文的基础上，参考其他网络博客资料，学习并记录论文的一些要点，通过这个过程希望能够理解论文的核心内容和系统的实现。</p>\n<h3 id=\"主要论文\"><a href=\"#主要论文\" class=\"headerlink\" title=\"主要论文\"></a>主要论文</h3><ul>\n<li><p>Real-Time Loop Closure in 2D LIDAR SLAM , ICRA 2016</p>\n</li>\n<li><p>Efficient Sparse Pose Adjustment for 2D Mapping  (SPA)</p>\n</li>\n<li><p>Real-Time Correlative Scan Matching  (BBS)</p>\n</li>\n</ul>\n<h3 id=\"文章重点\"><a href=\"#文章重点\" class=\"headerlink\" title=\"文章重点\"></a>文章重点</h3><ul>\n<li><p>第四部分：local 2d slam，主要是将局部地图的scan matching作为一个最小二乘优化问题，由ceres slover解决。       </p>\n</li>\n<li><p>第五部分： closing loop， 采用了 SPA（Sparse Pose Adjustment）进行后端loop  closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，这里采用了BBS（Branch-and-bound scan  matching）, 它可大幅提高精度和速度。</p>\n</li>\n</ul>\n<h2 id=\"文章贡献\"><a href=\"#文章贡献\" class=\"headerlink\" title=\"文章贡献\"></a>文章贡献</h2><p>文章的重点不是关注SLAM本身，而是提出了一种基于激光的5cm分辨率实时建图和回环检测方法，减少了计算量，满足实时的大场景地图构建以及大规模的实时优化的性能需求。</p>\n<p>为了达到实时闭环检测，文章使用了分支上界法来计算scan-to-submap的匹配作为约束。</p>\n<h2 id=\"Scan-Matching方法介绍\"><a href=\"#Scan-Matching方法介绍\" class=\"headerlink\" title=\"Scan Matching方法介绍\"></a>Scan Matching方法介绍</h2><p>涉及到的相关文献在文后列出，以便以后学习。</p>\n<ol>\n<li><p>scan-to-scan matching：基于激光的SLAM中最常用来估计相关位姿的方法。但是非常容易造成累积误差。[1,2,3,4]</p>\n</li>\n<li><p>scan-to-map matching：可以较少累计误差。其中一种方法是使用Gauss-Newton法在线性插值地图上找到局部最优值，前提是获取到了最优的初始位姿估计，这就需要使用有足够高数据获取速率的激光雷达，以保证局部优化的scan-to-map匹配是高效并且鲁棒的。在不稳定的平台上，需要使用惯性测量单元（IMU）将激光扫描投影到水平面上以估计重力方向。[5]</p>\n</li>\n<li><p>pixel-accurate scan matching：可以进一步减少局部误差，但是计算量比较大。这个方法同样可以用来检测回环。[1]</p>\n</li>\n<li><p>从laser scans中提取特征做匹配，从而减少计算量[4]。</p>\n</li>\n<li><p>histogram-based matching用于回环检测[6]。</p>\n</li>\n<li><p>用机器学习做laser scan data的特征检测[7]。</p>\n</li>\n</ol>\n<h2 id=\"累积误差处理方式\"><a href=\"#累积误差处理方式\" class=\"headerlink\" title=\"累积误差处理方式\"></a>累积误差处理方式</h2><ol>\n<li><p>基于粒子滤波（Particle Filter）的优化。粒子滤波在处理大场景地图时，由于粒子数的极具增长造成资源密集。[8,9,10]</p>\n</li>\n<li><p>基于位姿图的优化（<strong>Graph-based SLAM</strong>）。与视觉SLAM的位姿图优化大同小异，主要是在观测方程上的区别。[2,11,12,13]</p>\n</li>\n</ol>\n<h2 id=\"系统概述\"><a href=\"#系统概述\" class=\"headerlink\" title=\"系统概述\"></a>系统概述</h2><ol>\n<li><p>Cartographer是实时的室内建图系统，系统生成5cm分辨率的2D栅格地图地图。</p>\n</li>\n<li><p>laser scans数据被插入到submap中的最佳估计位置，并假定最佳估计位置在短时间内足够准确。</p>\n</li>\n<li><p>scan matching针对最近的submap发生，因此它只取决于最近的scans和全局帧位姿估计中累计的误差。</p>\n</li>\n<li><p>系统使用pose optimization处理误差累计。</p>\n</li>\n<li><p>submap一旦构建完成，就不会再插入新的scans。submap会用于回环检测过程的scan matching，其实回环检测会将所有已经构建完成的submaps和scans考虑在内。</p>\n<p>如果scan和submap在当前位姿估计下足够接近的话，scan matcher会尝试在submap中寻找回环scan。</p>\n<blockquote>\n<p>当一个新的laser scan加入到地图中时，如果该laser scan的估计位姿与地图中某个submap的某个laser scan的位姿比较接近的话，那么通过某种 scan match策略就会找到该闭环。</p>\n</blockquote>\n<p>为了减少计算量，Cartographer设计了特殊的策略来找到回环scan。这个策略就是在当前的位姿估计附近设置搜索窗口，在这个搜索窗口内执行branch-and-bound方法来寻找回环scan，如果在搜索窗口中找到了一个足够好的匹配，则会将该匹配作为回环检测约束条件添加到优化问题中。</p>\n</li>\n<li><p>系统通过使用branch-and-bound方法，并对每个生成的submap预计算出几个栅格地图，保证回环优化的快速完成，快到可以在加入新的scans之前就完成优化，从而保证了一种软实时约束。</p>\n</li>\n<li><p>cartographer的整体架构是典型的 前端建图 （局部地图）+后端优化。 </p>\n</li>\n</ol>\n<h2 id=\"符号说明\"><a href=\"#符号说明\" class=\"headerlink\" title=\"符号说明\"></a>符号说明</h2><ul>\n<li>位姿表示：$\\xi=(\\xi<em>x,\\xi_y,\\xi</em>{\\theta})$</li>\n<li>扫描scan：$H={h<em>k}</em>{k=1,…,K},h_k \\in \\mathbb{R^2}​$</li>\n<li>scan-to-submap变换矩阵：$T_\\xi​$</li>\n<li>scan-to-submap变换：$T<em>{\\xi }h_k=\\underbrace{\\left(\\begin{matrix}cos\\xi</em>\\theta&amp;-sin\\xi<em>\\theta\\sin\\xi</em>\\theta&amp;cos\\xi<em>\\theta\\end{matrix} \\right)}</em>{R<em>\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\xi_y\\end{matrix}\\right)}</em>{t_\\xi}​$</li>\n<li>概率栅格地图概率值：$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p<em>{min},p</em>{max}]$</li>\n<li>submap世界坐标系下的位姿（m代表map）：$\\Xi^m={\\xi^m<em>i}</em>{i=1,…,m}​$</li>\n<li>scan世界坐标系下的位姿（s代表scan）：$\\Xi^s={\\xi^s<em>j}</em>{j=1,…,n}​$</li>\n<li>scan $i​$在匹配到的submap $j​$坐标系下的位姿：$\\xi_{ij}​$</li>\n<li>与scan $i​$和submap $j​$相对应的协方差矩阵：$\\sum_{ij}​$</li>\n</ul>\n<h2 id=\"Local-2D-SLAM\"><a href=\"#Local-2D-SLAM\" class=\"headerlink\" title=\"Local 2D SLAM\"></a>Local 2D SLAM</h2><p>系统将局部和全局方法结合到2D SLAM中，两种方法都对LIDAR观测到的位姿进行了优化。这一部分介绍局部地图的scan matching，该问题被构造成最小二乘问题，使用ceres solver解决。</p>\n<p>位姿表示为$\\xi=(\\xi<em>x,\\xi_y,\\xi</em>{\\theta})$，这个位姿表示包括$(x,y)$坐标变换（注意这里是二维坐标），以及角度的旋转$\\xi_\\theta$，对观测位姿的优化实际上就是对scans的优化。平台采用IMU测量重力方向，将水平安装的LIDAR观测到的scans映射到2D平面。 </p>\n<blockquote>\n<h4 id=\"scan-matching\"><a href=\"#scan-matching\" class=\"headerlink\" title=\"scan matching\"></a>scan matching</h4><p>局部方法中，将每个连续的scan点集和整个地图的一部分进行匹配，就是和submap $M$进行匹配。这个过程中使用了一种非线性的优化方法将submap和scan点集对齐，这也是scan matching的过程。局部方法积累的误差在全局方法消除，即回环检测。</p>\n</blockquote>\n<h3 id=\"A-Scans\"><a href=\"#A-Scans\" class=\"headerlink\" title=\"A. Scans\"></a>A. Scans</h3><p>submap的构建是一个不断将scan和submap坐标系对齐的迭代过程。</p>\n<p>一个scan包含一个起点和很多个终点，起点称为scan origin，终点称为scan points，将scan表示为$H={h<em>k}</em>{k=1,…,K},h_k \\in \\mathbb{R^2}$。在scan坐标系下，origin就是坐标原点，scan points就是在scan坐标系下的坐标。</p>\n<p>当把一个scans插入到一个submap中时，假设scan坐标系到submap坐标系的坐标转换表示为$T<em>\\xi$（即scan坐标系在submap坐标系下的位姿$\\xi$表示为变换矩阵$T</em>\\xi$），即激光传感器在submap坐标系下的位姿。</p>\n<p>每个$h<em>k$在submap坐标系下的坐标为：$T</em>{\\xi }h<em>k=\\underbrace{\\left(\\begin{matrix}cos\\xi</em>\\theta&amp;-sin\\xi<em>\\theta\\sin\\xi</em>\\theta&amp;cos\\xi<em>\\theta\\end{matrix} \\right)}</em>{R<em>\\xi}h_k+\\underbrace{\\left(\\begin{matrix}\\xi_x\\\\xi_y\\end{matrix}\\right)}</em>{t_\\xi}$</p>\n<h3 id=\"B-Submaps\"><a href=\"#B-Submaps\" class=\"headerlink\" title=\"B. Submaps\"></a>B. Submaps</h3><p>一些连续的scans组成submap。采用概率栅格地图的形式表示这些submaps，$M:r\\mathbb{Z}\\times r\\mathbb{Z} \\to [p<em>{min},p</em>{max}]$，以给定的分辨率（例如5cm）将离散栅格地图点映射到值，这些值可以记作栅格地图点被占用的概率。对于每个栅格地图点，都定义一个相应的pixel，这个piexl是针对于分辨率来说的，对于5cm的分辨率来说，一个pixel相当于一个5*5的方格，那么对应于scan中应该有很多个point，即论文中定义的：pixel包含了所有靠近这个栅格地图点的points。</p>\n\n<blockquote>\n<h4 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h4><ol>\n<li><p>这里栅格地图点和像素的定义不明白？</p>\n<p>答：栅格地图点就是上图中的叉号处，像素定义为叉号周围所有的点的集合，即小方框。</p>\n</li>\n<li><p>submaps是扫描点的集合？？概率栅格地图表示submaps怎么理解？？</p>\n<p>看源码理解。</p>\n</li>\n</ol>\n</blockquote>\n<p>对于每个要插入submap的scan，都会产生一组称为hits的grid point和一组称为misses的grid point。如下图所示。</p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/submap.png\">\n<p>其中阴影带叉的是hit，加入hits集合；阴影不带叉的是miss（scan origin和scan points连线经过的grid points，排除在hits中的），加入misses集合。每个hits中的grid point被赋予初始值$M=p<em>{hit}$，每个misses中的grid point被赋予初始值$M=p</em>{miss}$。如果grid point已经有$p$值，则用下述公式更新：</p>\n<p>$odds(p)=\\frac{p}{1−p}$</p>\n<p>$M<em>{new(x)}=clamp(odds^{−1}(odds(M</em>{old}(x))⋅odds(p_{hit})))$</p>\n<blockquote>\n<p>Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内，小于min的数值返回min，大于max的数值返回max。</p>\n</blockquote>\n<p>miss集合的更新也是类似的。</p>\n<h3 id=\"C-Ceres-scan-matching\"><a href=\"#C-Ceres-scan-matching\" class=\"headerlink\" title=\"C. Ceres scan matching\"></a>C. Ceres scan matching</h3><p>将scan插入submap之前，需要通过scan matching对scan的位姿$ \\xi $进行优化（优化过程参照当前局部submap），优化过程使用基于Ceres库的scan matcher。scan matcher的任务就是找到一个scan的位姿，能够满足scan points在submap中有最大概率值。这里涉及到的优化问题为非线性最小二乘问题，通过Ceres库进行求解。使得scan在栅格地图中的概率值最大，那么就需要使得（cs）最小，非线性最小二乘问题目标函数构造形式如下：</p>\n<p>$\\mathop{\\arg\\min} \\limits<em>{\\xi}\\sum \\limits</em>{k=1}^K(1−M<em>{smooth}(T</em>{\\xi}h_k))^2 \\qquad\\qquad(CS)​$</p>\n<p>平滑函数$M_{smooth}$完成了局部submap中概率值从2D到1D的平滑，将值限制在$[0; 1]$范围内，使用双三次插值法（bicubic interpolation）。通常情况下，这种平滑函数的数学优化比栅格地图的分辨率能够提供更好的精度。</p>\n<p>对于局部优化问题，一个相对精确的初始估计非常重要。因此如果通过IMU提供角度信息（角速度），来估计scan matching中位姿的旋转分量$\\theta$，可以提高优化的准确性。在缺少IMU的情况下，高频率的scan matching或者pixel-accurate scan matching也可以提高准确性，但会增加时间复杂度。</p>\n<h2 id=\"Closing-Loops\"><a href=\"#Closing-Loops\" class=\"headerlink\" title=\"Closing Loops\"></a>Closing Loops</h2><blockquote>\n<p>closing loop采用了 SPA（Sparse Pose Adjustment）进行后端loop closure。 这个过程中有一个很重要的过程是的scan和 submap的匹配，采用的算法是BBS（Branch-and-bound scan matching）, 它可大幅提高精度和速度。</p>\n</blockquote>\n<h3 id=\"SPA\"><a href=\"#SPA\" class=\"headerlink\" title=\"SPA\"></a>SPA</h3><p>由于scans只和一个包含最近的几个scans的submap进行匹配，上面所讲的scan matcher会产生比较小的累计误差。</p>\n<p>系统通过创建一个个小的submaps实现大的场景地图构建，并使用Sparse Pose Adjustment方法[2]优化所有scans和submaps的位姿，提高精准度。</p>\n<h3 id=\"BBS\"><a href=\"#BBS\" class=\"headerlink\" title=\"BBS\"></a>BBS</h3><p>将scans插入处的相关位姿保存在内存中，以便在回环检测优化时使用。此外，所有其他的包含一个scan和一个submap组合，一旦submap不再变化，都会被用于回环检测。一个scan matcher会在后台一直不断的运行，当一个好的scan match被找到，该匹配的约束也会被加入到优化问题（是指回环优化问题）中。</p>\n<blockquote>\n<p><strong>上面这一段内容理解的还不是特别清楚？</strong></p>\n<p>其实是下文要提到的$\\xi_{ij}$的求解过程。</p>\n</blockquote>\n<h3 id=\"A-优化问题\"><a href=\"#A-优化问题\" class=\"headerlink\" title=\"A. 优化问题\"></a>A. 优化问题</h3><p>回环的优化问题与scan matching的优化问题类似，都是通过构造非线性最小二乘的方式进行的，允许方便地添加残差以考虑附加的数据。每隔几秒，就使用Ceres计算下式的解：</p>\n\n\n$\\mathop{\\arg\\min} \\limits_{{\\Xi^m},{\\Xi^s}} \\frac{1}{2}\\sum \\limits_{ij}\\rho(E^2(\\xi^m_i,\\xi^s_j;\\sum \\limits_{ij},\\xi_{ij})) \\qquad(SPA)$ [15]\n\n\n<p>$\\rho$是一个损失函数，比如Huber loss等。使用损失函数的目的是减少加入到优化问题中的离群点对于系统的影响，这种情况在局部对称的环境，如办公室走廊容易发生，scan matching会将错误的约束加入到优化问题。</p>\n<p>$\\Xi^m={\\xi^m<em>i}</em>{i=1,…,m}$是submap的位姿，$\\Xi^s={\\xi^s<em>j}</em>{j=1,…,n}$是scan的位姿，submap位姿和scan位姿都是世界坐标系下的，并且它们之间存在约束条件（这个约束条件是指什么？）用于完成优化。</p>\n<p>对于submap $i$和scan $j$，$\\xi<em>{ij}$表示scan在匹配到的submap坐标系下的位姿（$j$在$i$坐标系下的位姿，求解方法在下一节介绍），$\\sum</em>{ij}$是相应的协方差矩阵，这个协方差矩阵可以通过[14]的方式获得，也可以通过(CS)公式获得。残差$E$的计算：</p>\n<p>$E^2(\\xi^m<em>i,\\xi^s_j;\\sum</em>{ij},\\xi<em>{ij})=e(\\xi^m_i,\\xi^s_j;\\xi</em>{ij})^T\\sum<em>{ij}^{-1}e(\\xi^m_i,\\xi^s_j;\\xi</em>{ij})$</p>\n<p>$e(\\xi^m<em>i,\\xi^s_j;\\xi</em>{ij})=\\xi<em>{ij}-\\left(\\begin{matrix}R^{-1}</em>{\\xi^m<em>i}(t</em>{\\xi^m<em>i}-t</em>{\\xi^s<em>j}) \\ \\xi^m</em>{i;\\theta}-\\xi^s_{j;\\theta}\\end{matrix}\\right)$</p>\n<blockquote>\n<h3 id=\"协方差\"><a href=\"#协方差\" class=\"headerlink\" title=\"协方差\"></a>协方差</h3><p>统计学中，标准差、方差一般是用来描述一维数据的。对于多维数据，一般使用协方差度量两个随机变量关系。</p>\n<p>方差定义：$var(X)=\\frac{\\sum \\limits_{i=1}^{n}(X_i-\\overline X)(X_i-\\overline X)}{n-1}$</p>\n<p>协方差定义：$cov(X,Y)=\\frac{\\sum \\limits (X_i-\\overline X)(Y_i-\\overline Y)}{n-1}$</p>\n<p>使用协方差来度量各个维度偏离其均值的程度。如果协方差为正，两个变量是正相关；为负，负相关；为0，无关，即相互独立。</p>\n<h3 id=\"协方差矩阵\"><a href=\"#协方差矩阵\" class=\"headerlink\" title=\"协方差矩阵\"></a>协方差矩阵</h3><p>协方差只能处理二维问题，对于多维数据，就需要计算多个协方差。一般使用协方差矩阵组织。</p>\n<p>协方差矩阵定义：$C<em>{n\\times n}=(c</em>{i,j},c_{i,j}=cov(Dim_i,Dim_j))$</p>\n<p>如三维数据的协方差矩阵为：$C=\\left(\\begin{matrix}cov(x,x)&amp;cov(x,y)&amp;cov(x,z)\\cov(y,x)&amp;cov(y,y)&amp;cov(y,z)\\cov(z,x)&amp;cov(z,y)&amp;cov(z,z)\\end{matrix}\\right)$</p>\n<p>协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。</p>\n</blockquote>\n<h3 id=\"B-Branch-and-bound-scan-matching\"><a href=\"#B-Branch-and-bound-scan-matching\" class=\"headerlink\" title=\"B. Branch-and-bound scan matching\"></a>B. Branch-and-bound scan matching</h3><p>之前提到的回环约束关系$ξij$（scan $j$在submap $i$坐标系中的位姿）就是通过这里的方法得到的，也是整篇论文最核心的地方。首先看一下pixel-accurate match的匹配过程：</p>\n<p>$\\xi^*=\\mathop{\\arg\\max} \\limits<em>{\\xi \\in W}\\sum\\limits</em>{k=1}^{K}M<em>{nearest}(T</em>\\xi h_k)\\qquad\\ \\ (BBS)$  [14]</p>\n<p>其中$W$是搜索空间（搜索窗口），$M_{nearest}$就是该pixel对应的grid point的M值。之后可以通过(CS)公式进一步提高$\\xi$匹配的准确度。</p>\n<p>搜索空间和搜索步长的选择是决定pixel-accurate match是否高效的关键。搜索步长的计算方式：</p>\n<p>$d<em>{max}=\\mathop{max}\\limits</em>{k=1,…,K} \\ \\ | \\mathrm{h} _k|$</p>\n<p>$\\delta<em>\\theta=arccos(1-\\frac{r^2}{2d^2</em>{max}})$</p>\n<p>$w<em>x=\\lceil \\frac{W_x}{r} \\rceil$,  $w_y=\\lceil \\frac{W_y}{r} \\rceil$,  $w</em>\\theta=\\lceil \\frac{W<em>\\theta}{\\delta</em>\\theta} \\rceil$</p>\n<p>其中$d<em>{max}$是所有scan点集中跨度最大的那个值，$Wx=Wy=7m$，$W</em>θ=30^\\circ$，因此搜索空间就可以确定了。此时搜索空间的大小是7m*7m。</p>\n<p>$\\overline{W}={-w<em>x,…,w_x}\\times{-w_y,…,w_y}\\times{-w</em>\\theta,…,w_\\theta}$</p>\n<p>$W={\\xi<em>0+(rj_x,rj_y,\\delta</em>\\theta j<em>\\theta):(j_x,j_y,j</em>\\theta)\\in\\overline{W}}​$</p>\n<p>有了搜索空间和搜索步长，就可以得到最原始的暴力搜索方式。算法1如下图所示：</p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/暴力搜索.png\">\n<p>为了进一步提高搜索效率，Cartograoher采用了branch and bound approach的方式。branch and bound<br>approach是一种在问题的解空间树上搜索问题的解的方法，被Google套用在最优位姿的搜索中，从而将无法实时化暴力解优化到可以满足实时化。分支上界法就是每个分支代表一种可能，使用DFS找到最佳位置即可，和算法1解决的是相同的问题。只不过这个节点的score是可能的最大值而已。</p>\n<p>分支上界法分为以下几步：<strong>节点选择、分支、计算上限</strong>。对于这三步，论文中有具体讲解。节点选择采用的是DFS，分支算法，采用的是算法2。算法3是将节点选择和分支结合到一起之后的算法。<br><img src=\"/2018/09/12/Cartographer学习一论文阅读/算法2.png\"></p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/算法3.png\">\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>论文阐述了一个2D的SLAM系统，系统采用闭环检测的scan-to-submap matching，同时还有图优化（graph<br>optimization）。一个submap的创建使用的是局部的、基于栅格地图的（grid-based）SLAM方法。在后台，所有的点集与相近的submap的匹配使用的是pixel-accurate scan matching的方法，然后建立闭环检测的约束。这个约束图（基于submap和scan pose的）都会周期性的被后台更改。这个操作是采用GPU加速将已完成的submap和当前的submap进行结合。系统图引用的<a href=\"https://blog.csdn.net/jsgaobiao/article/details/53116042\" target=\"_blank\" rel=\"noopener\">博客</a>中的。</p>\n<img src=\"/2018/09/12/Cartographer学习一论文阅读/系统图.png\">\n<p>Scan是激光扫描的单帧数据，通过累加Scan来构建局部地图（Submap），采用的是grid-based 的SLAM方法。生成约束关系的scan和submap的匹配算法采用的是pixel-accurate scan matching的方法。Cartographer的实现并没有采用滤波方法，而是采用了类似图优化的模型进行Pose estimation，具体的实现是用了Ceres scan matching(Ceres是Google自家的库) 。 这样构造出来的很多很多submap是会产生累计误差的，最后通过Loop closing来消除这些误差，完成闭环。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li>Real-time loop closure in 2D LIDAR SLAM</li>\n<li><a href=\"https://blog.csdn.net/lilynothing/article/details/60875825\" target=\"_blank\" rel=\"noopener\">google cartographer的论文《real-time loop closure in 2D LIDAR SLAM》翻译</a></li>\n<li><a href=\"https://note.youdao.com/share/?id=d8d15963d4577236399aa52c2cd968a7&amp;type=note#/\" target=\"_blank\" rel=\"noopener\">cartographer对应论文的琢磨(2)</a></li>\n<li><a href=\"https://zhehangt.github.io/2017/05/01/SLAM/CartographerPaper/\" target=\"_blank\" rel=\"noopener\">Real-Time Loop Closure in 2D LIDAR SLAM 论文笔记</a></li>\n<li><a href=\"https://blog.csdn.net/sean_xyz/article/details/68957747\" target=\"_blank\" rel=\"noopener\">cartographer算法简析</a></li>\n<li><a href=\"https://blog.csdn.net/jsgaobiao/article/details/53116042\" target=\"_blank\" rel=\"noopener\">【SLAM】（一）Google Cartographer的初步尝试</a></li>\n<li><a href=\"https://www.cnblogs.com/chaosimple/p/3182157.html\" target=\"_blank\" rel=\"noopener\">[转]浅谈协方差矩阵</a> </li>\n</ol>\n<h2 id=\"相关文献\"><a href=\"#相关文献\" class=\"headerlink\" title=\"相关文献\"></a>相关文献</h2><p>[1] E. Olson, “M3RSM: Many-to-many multi-resolution scan matching,” in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), June 2015.<br>[2] K. Konolige, G. Grisetti, R. Kümmerle, W. Burgard, B. Limketkai, and R. Vincent, “Sparse pose adjustment for 2D mapping,” in IROS, Taipei, Taiwan, 10/2010 2010.<br>[3] F. Lu and E. Milios, “Globally consistent range scan alignment for environment mapping,” Autonomous robots, vol. 4, no. 4, pp. 333–349, 1997.<br>[4] F. Martı́n, R. Triebel, L. Moreno, and R. Siegwart, “Two different tools for three-dimensional mapping: DE-based scan matching and feature-based loop detection,” Robotica, vol. 32, no. 01, pp. 19–41,2014.<br>[5] S. Kohlbrecher, J. Meyer, O. von Stryk, and U. Klingauf, “A flexible and scalable SLAM system with full 3D motion<br>estimation,” in Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR). IEEE, November 2011.<br>[6] M. Himstedt, J. Frost, S. Hellbach, H.-J. Böhme, and E. Maehle, “Large scale place recognition in 2D LIDAR scans using geometrical landmark relations,” in Intelligent Robots and Systems (IROS 2014),2014 IEEE/RSJ International<br>Conference on. IEEE, 2014, pp. 5030–5035.<br>[7] K. Granström, T. B. Schön, J. I. Nieto, and F. T. Ramos, “Learning to close loops from range data,” The International Journal of Robotics Research, vol. 30, no. 14, pp. 1728–1754, 2011.<br>[8] G. Grisetti, C. Stachniss, and W. Burgard, “Improving grid-based SLAM with Rao-Blackwellized particle filters by adaptive proposals and selective resampling,” in Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on. IEEE, 2005, pp. 2432–2437.<br>[9] G. D. Tipaldi, M. Braun, and K. O. Arras, “FLIRT: Interest regions for 2D range data with applications to robot navigation,” in Experimental Robotics. Springer, 2014, pp. 695–710.<br>[10] J. Strom and E. Olson, “Occupancy grid rasterization in large environments for teams of robots,” in Intelligent<br> Robots and Systems (IROS),2011 IEEE/RSJ International Conference on. IEEE, 2011, pp. 4271–4276.<br>[11] R. Kümmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard,“g2o: A general framework for graph optimization,” in Robotics and Automation (ICRA), 2011 IEEE International Conference on. IEEE,2011, pp. 3607–3613.<br>[12] L. Carlone, R. Aragues, J. A. Castellanos, and B. Bona, “A fast and accurate approximation for planar pose graph optimization,” The International Journal of Robotics Research, pp. 965–987, 2014.<br>[13] M. Bosse and R. Zlot, “Map matching and data association for large-scale two-dimensional laser scan-based SLAM,” The International Journal of Robotics Research, vol. 27, no. 6, pp. 667–691, 2008.<br>[14] E. B. Olson, “Real-time correlative scan matching,” in Robotics and Automation, 2009. ICRA’09. IEEE International Conference on. IEEE, 2009, pp. 4387–4393.</p>\n<p>[15]Efficient Sparse Pose Adjustment for 2D Mapping</p>"},{"title":"ORB_SLAM2学习之运行ROS模块","date":"2018-08-12T02:05:55.000Z","copyright":true,"_content":"\n---\n\n这篇文章是有关运行ORB_SLAM2系统ROS模块，包括单目和双目部分的学习内容。\n\n<!--more-->\n\nORB_SLAM2运行ROS模块需要从相应的话题接收图像用于SLAM系统，对于我这种不方便使用相机进行实时采集图像的渣渣来说，使用数据集图像是很好的选择。因此需要从本地数据集中获取图像，再利用ROS中的话题进行图像的发布和接收。下面的内容将介绍利用ROS进行简单的图像发布和接收操作，以及ORB_SLAM2系统ROS模块运行起来的整个过程。\n\n> 系统环境\n>\n> - Ubuntu 16.04\n> - ROS kinetic\n\n## 基于ROS话题发布、接收图像\n\n### 创建相关软件包\n\n在`catkin_ws/src`目录下新建软件包并编译：\n\n~~~shell\ncatkin_create_pkg my_image_transport image_transport cv_bridge\ncd ..\ncatkin_make -DCATKIN_WHITELIST_PACKAGES=\"my_image_transport\"\nsource devel/setup.bash\n~~~\n\n### 创建图像发布者程序\n\n新建`my_image_transport/src/my_publisher.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <cv_bridge/cv_bridge.h>\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"image_publisher\");\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"camera/image\", 1);\n  cv::Mat image = cv::imread(argv[1], CV_LOAD_IMAGE_COLOR);\n  cv::waitKey(30);//不断刷新图像，频率时间为delay，单位为ms\n  sensor_msgs::ImagePtr msg = cv_bridge::CvImage(std_msgs::Header(), \"bgr8\", image).toImageMsg();\n\n  ros::Rate loop_rate(5);\n  while (nh.ok()) {\n    pub.publish(msg);\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n}\n~~~\n\n代码解释：\n\n- line 1-4：`ros.h`头文件是所有的ros节点中必须要包含的，下面三个分别是实现图像的发布和订阅，调用opencv库，完成opencv图像格式转化为ROS图像格式所要用到的头文件；\n- line 11：告知结点管理器要在`camera/image`话题发布图像消息，参数1是话题名称，话题2是缓冲区大小（即消息队列的长度，在发布图像消息时消息队列的长度只能是1）；\n- line 12：根据运行时给定的参数（图像文件的路径）读取图像；\n- line 14：将opencv格式的图像转化为ROS所支持的消息类型，从而发布到相应的话题上；\n- line 16-21：发布图片消息，使消息类型匹配的节点订阅该消息。\n\n### 创建图像订阅者程序\n\n新建`my_image_transport/src/my_subscriber.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <cv_bridge/cv_bridge.h>\n\nvoid imageCallback(const sensor_msgs::ImageConstPtr& msg)\n{\n  try\n  {\n    cv::imshow(\"view\", cv_bridge::toCvShare(msg, \"bgr8\")->image);\n    cv::waitKey(30);\n  }\n  catch (cv_bridge::Exception& e)\n  {\n    ROS_ERROR(\"Could not convert from '%s' to 'bgr8'.\", msg->encoding.c_str());\n  }\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"image_listener\");\n  ros::NodeHandle nh;\n  cv::namedWindow(\"view\");\n  cv::startWindowThread();\n  image_transport::ImageTransport it(nh);\n  image_transport::Subscriber sub = it.subscribe(\"camera/image\", 1, imageCallback);\n  ros::spin();\n  cv::destroyWindow(\"view\");\n}\n~~~\n\n代码解释：\n\n- line 6：回调函数，当有新的图像消息到达`camera/image`时，该函数就会被调用；\n- line 10：显示捕捉到的图像，其中`cv_bridge::toCvShare(msg, \"bgr8\")->image`用于将ROS图像消息转化为Opencv支持的图像格式（采用BGR8编码方式）。这部分用法恰好与上一节中发布者节点中的`CvImage(std_msgs::Header(), \"bgr8\", image).toImageMsg();` 的作用相反\n- line 11：刷新图像的频率，实践过程中发现如果注释这一行图像将无法在窗口的显示\n\n### 相关配置文件\n\n1. `CMakeLists.txt`内容\n\n   ~~~cmake\n   cmake_minimum_required(VERSION 2.8.3)\n   project(my_image_transport)\n\n   ## Compile as C++11, supported in ROS Kinetic and newer\n   add_compile_options(-std=c++11)\n\n   find_package(catkin REQUIRED COMPONENTS\n     cv_bridge\n     image_transport\n   )\n   find_package(OpenCV REQUIRED)\n\n   set(LIBS\n   \t${OpenCV_LIBS} \n   \t${catkin_LIBRARIES})\n   \t\n   catkin_package(\n   #  INCLUDE_DIRS include\n   #  LIBRARIES my_image_transport\n   #  CATKIN_DEPENDS cv_bridge image_transport\n   #  DEPENDS system_lib\n   )\n\n   include_directories(\n   # include\n     ${catkin_INCLUDE_DIRS}\n     ${OpenCV_INCLUDE_DIRS}\n   )\n\n   add_executable(my_publisher src/my_publisher.cpp)\n   target_link_libraries(my_publisher ${LIBS})\n\n   add_executable(my_subscriber src/my_subscriber.cpp)\n   target_link_libraries(my_subscriber ${LIBS})\n   ~~~\n\n2. `package.xml`文件中添加\n\n   ~~~xml\n     <build_depend>opencv2</build_depend>\n     <exec_depend>opencv2</exec_depend>\n   ~~~\n\n### 编译软件包\n\n~~~shell\ncd ~/catkin_ws\ncatkin_make -DCATKIN_WHITHELIST_PACKAGES=\"my_image_transport\"\n~~~\n\n### 运行节点\n\n单独开启一个终端执行`roscore`，启动ros节点管理器。\n\n开启另一个终端，启动发布者节点：\n\n~~~shell\nrosrun my_image_transport my_publisher /home/eric/catkin_ws/src/my_image_transport/000.png\n~~~\n\n运行订阅者节点：\n\n~~~shell\nrosrun my_image_transport my_subscriber\n~~~\n\n运行结果如下所示：\n\n{% asset_img 1.png  %}\n\n### 查看当前活动节点及交互情况\n\n查看当前活动节点：\n\n```shell\nrosnode list\n```\n\n查看各节点交互情况：\n\n~~~powershell\nrosrun rqt_graph rqt_graph\n~~~\n\n![transport_graph.png](http://wiki.ros.org/image_transport/Tutorials/ExaminingImagePublisherSubscriber?action=AttachFile&do=get&target=transport_graph.png)\n\n可以执行`rosnode kill`命令关闭相关节点。\n\n## ORB_SLAM2 ROS模块结点的编译\n\n在环境变量`ROS_PACKAGE_PATH`中添加`Examples/ROS/ORB_SLAM2`的路径：\n\n~~~shell\necho \"source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh\" >> ~/.bashrc\n~~~\n\n在`~/slam/ORB_SLAM2`目录下执行：\n\n~~~shell\nchmod +x build_ros.sh\n./build_ros.sh\n~~~\n\n等待编译成功。\n\n## ROS Mono\n\n首先在`my_image_transport`目录下创建图像发布者程序`mono_tum.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/opencv.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <fstream>\n#include <iostream>\n#include <algorithm>\n\nusing namespace std;\n\nvoid LoadImages(const string &strFile, vector<string> &vstrImageFilenames,\n                vector<double> &vTimestamps);\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"mono_tum\");\n  if(argc != 2)\n  {\n      cerr << endl << \"Usage: rosrun my_image_transport mono_tum path_to_sequence\" << endl;\n      return 1;\n  }\n\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"/camera/image_raw\", 1);\n\n  vector<string> vstrImageFilenames;\n  vector<double> vTimestamps;\n  string strFile = string(argv[1])+\"/rgb.txt\";\n  LoadImages(strFile, vstrImageFilenames, vTimestamps);\n\n  int nImages = vstrImageFilenames.size();\n\n  cv::Mat im;\n  // double tframe;\n  sensor_msgs::ImagePtr msg;\n  std_msgs::Header header;\n  ros::Rate loop_rate(5);\n  for(int ni = 0; ni < nImages; ni++)\n  {\n    im = cv::imread(string(argv[1])+\"/\"+vstrImageFilenames[ni],CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(vTimestamps[ni]);\n\n    if(im.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(argv[1]) << \"/\" << vstrImageFilenames[ni] << endl;\n        return 1;\n    }\n\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"bgr8\", im).toImageMsg();\n\n    pub.publish(msg);\n    cv::waitKey(1);\n\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  \n  return 0;\n}\n\nvoid LoadImages(const string &strFile, vector<string> &vstrImageFilenames, vector<double> &vTimestamps)\n{\n    ifstream f;\n    f.open(strFile.c_str());\n\n    // skip first three lines\n    string s0;\n    getline(f,s0);\n    getline(f,s0);\n    getline(f,s0);\n\n    while(!f.eof())\n    {\n        string s;\n        getline(f,s);\n        if(!s.empty())\n        {\n            stringstream ss;\n            ss << s;\n            double t;\n            string sRGB;\n            ss >> t;\n            vTimestamps.push_back(t);\n            ss >> sRGB;\n            vstrImageFilenames.push_back(sRGB);\n        }\n    }\n}\n~~~\n\n在`CMakeLists.txt`文件中添加：\n\n~~~cmake\nadd_executable(mono_tum src/mono_tum.cpp)\ntarget_link_libraries(mono_tum ${LIBS})\n~~~\n\n下载TUM-rgbd_dataset_freiburg1_xyz数据集，保存`/media/eric/linux/DATA/TUM/rgbd_dataset_freiburg1_xyz`。\n\n测试系统，启动ORB_SLAM2 Mono：\n\n~~~powershell\nrosrun ORB_SLAM2 Mono /home/eric/slam/ORB_SLAM2/Vocabulary/ORBvoc.txt ~/slam/ORB_SLAM2/Examples/Monocular/TUM1.yaml\n~~~\n\n启动发布者节点：\n\n~~~powershell\nrosrun my_image_transport mono_tum /media/eric/linux/DATA/TUM/rgbd_dataset_freiburg1_xyz\n~~~\n\n测试效果：\n\n{% asset_img 2.png  %}\n\n## ROS Stereo\n\n首先在`my_image_transport`目录下创建图像发布者程序左相机节点`stereo_left_kitti.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <ros/package.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/opencv.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <fstream>\n#include <iostream>\n#include <algorithm>\n\nusing namespace std;\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageLeft, vector<double> &vTimestamps);\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"stereo_left_kitti\");\n\n  string packagePath = ros::package::getPath(\"my_image_transport\");\n  string configPath = packagePath + \"//config//stereo_kitti.yaml\";\n\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"/camera/left/image_raw\", 1);\n  \n  vector<string> vstrImageLeft;\n  vector<double> vTimestamps;\n  cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\n  if(!fsSettings.isOpened())\n  {\n      cerr << \"ERROR: Wrong path to settings\" << endl;\n      return -1;\n  }\n\n  string bagPath = fsSettings[\"bagPath\"];\n  LoadImages(bagPath, vstrImageLeft, vTimestamps);\n\n  int nImages = vstrImageLeft.size();\n\n  cv::Mat imLeft;\n  sensor_msgs::ImagePtr msg;\n  std_msgs::Header header;\n  ros::Rate loop_rate(5);\n  for(int ni = 0; ni < nImages; ni++)\n  {\n    imLeft = cv::imread(vstrImageLeft[ni],CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(vTimestamps[ni]);\n\n    if(imLeft.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(vstrImageLeft[ni]) << endl;\n        return 1;\n    }\n\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"mono8\", imLeft).toImageMsg();\n\n    pub.publish(msg);\n    cv::waitKey(1);\n\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  \n  return 0;\n}\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageLeft, vector<double> &vTimestamps)\n{\n    ifstream fTimes;\n    string strPathTimeFile = strPathToSequence + \"/times.txt\";\n    fTimes.open(strPathTimeFile.c_str());\n    while(!fTimes.eof())\n    {\n        string s;\n        getline(fTimes,s);\n        if(!s.empty())\n        {\n            stringstream ss;\n            ss << s;\n            double t;\n            ss >> t;\n            vTimestamps.push_back(t);\n        }\n    }\n\n    string strPrefixLeft = strPathToSequence + \"/image_0/\";\n\n    const int nTimes = vTimestamps.size();\n    vstrImageLeft.resize(nTimes);\n\n    for(int i=0; i<nTimes; i++)\n    {\n        stringstream ss;\n        ss << setfill('0') << setw(6) << i;\n        vstrImageLeft[i] = strPrefixLeft + ss.str() + \".png\";\n    }\n}\n~~~\n\n右相机节点`stereo_right_kitti`：\n\n~~~c++\n#include <ros/ros.h>\n#include <ros/package.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/opencv.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <fstream>\n#include <iostream>\n#include <algorithm>\n\nusing namespace std;\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageRight, vector<double> &vTimestamps);\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"stereo_right_kitti\");\n\n  string packagePath = ros::package::getPath(\"my_image_transport\");\n  string configPath = packagePath + \"//config//stereo_kitti.yaml\";\n\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"/camera/right/image_raw\", 1);\n\n  vector<string> vstrImageRight;\n  vector<double> vTimestamps;\n  cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\n  if(!fsSettings.isOpened())\n  {\n      cerr << \"ERROR: Wrong path to settings\" << endl;\n      return -1;\n  }\n\n  string bagPath = fsSettings[\"bagPath\"];\n  \n  LoadImages(bagPath, vstrImageRight, vTimestamps);\n\n  int nImages = vstrImageRight.size();\n\n  cv::Mat imRight;\n  sensor_msgs::ImagePtr msg;\n  std_msgs::Header header;\n  ros::Rate loop_rate(5);\n  for(int ni = 0; ni < nImages; ni++)\n  {\n    imRight = cv::imread(vstrImageRight[ni],CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(vTimestamps[ni]);\n\n    if(imRight.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(vstrImageRight[ni]) << endl;\n        return 1;\n    }\n\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"mono8\", imRight).toImageMsg();\n\n    pub.publish(msg);\n    cv::waitKey(1);\n\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  \n  return 0;\n}\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageRight, vector<double> &vTimestamps)\n{\n    ifstream fTimes;\n    string strPathTimeFile = strPathToSequence + \"/times.txt\";\n    fTimes.open(strPathTimeFile.c_str());\n    while(!fTimes.eof())\n    {\n        string s;\n        getline(fTimes,s);\n        if(!s.empty())\n        {\n            stringstream ss;\n            ss << s;\n            double t;\n            ss >> t;\n            vTimestamps.push_back(t);\n        }\n    }\n\n    string strPrefixRight = strPathToSequence + \"/image_1/\";\n\n    const int nTimes = vTimestamps.size();\n    vstrImageRight.resize(nTimes);\n\n    for(int i=0; i<nTimes; i++)\n    {\n        stringstream ss;\n        ss << setfill('0') << setw(6) << i;\n        vstrImageRight[i] = strPrefixRight + ss.str() + \".png\";\n    }\n}\n~~~\n\n在`CMakeLists.txt`文件中添加：\n\n```cmake\nadd_executable(stereo_left_kitti src/stereo_left_kitti.cpp)\ntarget_link_libraries(stereo_left_kitti ${LIBS})\n\nadd_executable(stereo_right_kitti src/stereo_right_kitti.cpp)\ntarget_link_libraries(stereo_right_kitti ${LIBS})\n```\n\n在`my_image_transport/config`目录下添加配置文件`stereo_kitti.yaml`，保存数据集路径：\n\n~~~yaml\n%YAML:1.0\nbagPath: \"/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray/sequences/03\"\n~~~\n\n这里需要启动三个节点，每个单独启动会比较麻烦，所以使用ROS Launch文件，同时启动左、右图像发布节点和ORB_SLAM2 Stereo_eric节点。在`my_image_transport/launch`目录下添加ROS节点启动文件`stereo_image_transport.yaml`：\n\n~~~xml\n<launch>\n  <node name=\"stereo_left_kitti\" pkg=\"my_image_transport\" type=\"stereo_left_kitti\">\n  </node>\n  <node name=\"stereo_right_kitti\" pkg=\"my_image_transport\" type=\"stereo_right_kitti\">\n  </node>\n  <node name=\"Stereo_eric\" pkg=\"ORB_SLAM2\" type=\"Stereo_eric\">\n  </node>\n</launch>\n~~~\n\n修改ORB_SLAM2的`ros_stereo.cc`文件，新建为`ros_stereo_eric.cc`：\n\n~~~c++\n#include<iostream>\n#include<algorithm>\n#include<fstream>\n#include<chrono>\n\n#include<ros/ros.h>\n#include <cv_bridge/cv_bridge.h>\n#include <message_filters/subscriber.h>\n#include <message_filters/time_synchronizer.h>\n#include <message_filters/sync_policies/approximate_time.h>\n\n#include<opencv2/core/core.hpp>\n#include <ros/package.h>\n#include\"../../../include/System.h\"\n\nusing namespace std;\n\nclass ImageGrabber\n{\npublic:\n    ImageGrabber(ORB_SLAM2::System* pSLAM):mpSLAM(pSLAM){}\n\n    void GrabStereo(const sensor_msgs::ImageConstPtr& msgLeft,const sensor_msgs::ImageConstPtr& msgRight);\n\n    ORB_SLAM2::System* mpSLAM;\n    bool do_rectify;\n    cv::Mat M1l,M2l,M1r,M2r;\n};\n\nint main(int argc, char **argv)\n{\n    ros::init(argc, argv, \"Stereo_eric\");\n    ros::start();\n\n    string packagePath = ros::package::getPath(\"ORB_SLAM2\");\n    string configPath = packagePath + \"//config//ros_stereo_eric.yaml\";\n\n    cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\n    if(!fsSettings.isOpened())\n    {\n      cerr << \"ERROR: Wrong path to settings\" << endl;\n      return -1;\n    }\n\n    string vocPath = fsSettings[\"vocPath\"];\n    string settingPath = fsSettings[\"settingPath\"];\n    // Create SLAM system. It initializes all system threads and gets ready to process frames.\n    ORB_SLAM2::System SLAM(vocPath,settingPath,ORB_SLAM2::System::STEREO,true);\n\n    ImageGrabber igb(&SLAM);\n\n    string do_rectify = fsSettings[\"do_rectify\"];\n    stringstream ss(do_rectify);\n\tss >> boolalpha >> igb.do_rectify;//boolalpha函数把bool值显示为true或false\n\n    if(igb.do_rectify)\n    {      \n        // Load settings related to stereo calibration\n        cv::FileStorage fsSettings(settingPath, cv::FileStorage::READ);\n        if(!fsSettings.isOpened())\n        {\n            cerr << \"ERROR: Wrong path to settings\" << endl;\n            return -1;\n        }\n\n        cv::Mat K_l, K_r, P_l, P_r, R_l, R_r, D_l, D_r;\n        fsSettings[\"LEFT.K\"] >> K_l;\n        fsSettings[\"RIGHT.K\"] >> K_r;\n\n        fsSettings[\"LEFT.P\"] >> P_l;\n        fsSettings[\"RIGHT.P\"] >> P_r;\n\n        fsSettings[\"LEFT.R\"] >> R_l;\n        fsSettings[\"RIGHT.R\"] >> R_r;\n\n        fsSettings[\"LEFT.D\"] >> D_l;\n        fsSettings[\"RIGHT.D\"] >> D_r;\n\n        int rows_l = fsSettings[\"LEFT.height\"];\n        int cols_l = fsSettings[\"LEFT.width\"];\n        int rows_r = fsSettings[\"RIGHT.height\"];\n        int cols_r = fsSettings[\"RIGHT.width\"];\n\n        if(K_l.empty() || K_r.empty() || P_l.empty() || P_r.empty() || R_l.empty() || R_r.empty() || D_l.empty() || D_r.empty() ||\n                rows_l==0 || rows_r==0 || cols_l==0 || cols_r==0)\n        {\n            cerr << \"ERROR: Calibration parameters to rectify stereo are missing!\" << endl;\n            return -1;\n        }\n\n        cv::initUndistortRectifyMap(K_l,D_l,R_l,P_l.rowRange(0,3).colRange(0,3),cv::Size(cols_l,rows_l),CV_32F,igb.M1l,igb.M2l);\n        cv::initUndistortRectifyMap(K_r,D_r,R_r,P_r.rowRange(0,3).colRange(0,3),cv::Size(cols_r,rows_r),CV_32F,igb.M1r,igb.M2r);\n    }\n\n    ros::NodeHandle nh;\n\n    message_filters::Subscriber<sensor_msgs::Image> left_sub(nh, \"/camera/left/image_raw\", 1);\n    message_filters::Subscriber<sensor_msgs::Image> right_sub(nh, \"camera/right/image_raw\", 1);\n    typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> sync_pol;\n    message_filters::Synchronizer<sync_pol> sync(sync_pol(10), left_sub,right_sub);\n    sync.registerCallback(boost::bind(&ImageGrabber::GrabStereo,&igb,_1,_2));\n\n    ros::spin();\n\n    // Stop all threads\n    SLAM.Shutdown();\n\n    // Save camera trajectory\n    SLAM.SaveKeyFrameTrajectoryTUM(\"KeyFrameTrajectory_TUM_Format.txt\");\n    SLAM.SaveTrajectoryTUM(\"FrameTrajectory_TUM_Format.txt\");\n    SLAM.SaveTrajectoryKITTI(\"FrameTrajectory_KITTI_Format.txt\");\n\n    ros::shutdown();\n\n    return 0;\n}\n\nvoid ImageGrabber::GrabStereo(const sensor_msgs::ImageConstPtr& msgLeft,const sensor_msgs::ImageConstPtr& msgRight)\n{\n    // Copy the ros image message to cv::Mat.\n    cv_bridge::CvImageConstPtr cv_ptrLeft;\n    try\n    {\n        cv_ptrLeft = cv_bridge::toCvShare(msgLeft);\n    }\n    catch (cv_bridge::Exception& e)\n    {\n        ROS_ERROR(\"cv_bridge exception: %s\", e.what());\n        return;\n    }\n\n    cv_bridge::CvImageConstPtr cv_ptrRight;\n    try\n    {\n        cv_ptrRight = cv_bridge::toCvShare(msgRight);\n    }\n    catch (cv_bridge::Exception& e)\n    {\n        ROS_ERROR(\"cv_bridge exception: %s\", e.what());\n        return;\n    }\n\n    if(do_rectify)\n    {\n        cv::Mat imLeft, imRight;\n        cv::remap(cv_ptrLeft->image,imLeft,M1l,M2l,cv::INTER_LINEAR);\n        cv::remap(cv_ptrRight->image,imRight,M1r,M2r,cv::INTER_LINEAR);\n        mpSLAM->TrackStereo(imLeft,imRight,cv_ptrLeft->header.stamp.toSec());\n    }\n    else\n    {   //cv_ptrLeft->image  is  cv::Mat\n        mpSLAM->TrackStereo(cv_ptrLeft->image,cv_ptrRight->image,cv_ptrLeft->header.stamp.toSec());\n    }\n\n}\n~~~\n\n`ROS/ORB_SLAM2/config`目录下添加配置文件`ros_stereo_eric.yaml`：\n\n~~~yaml\n%YAML:1.0\nvocPath: \"/home/eric/slam/ORB_SLAM2/Vocabulary/ORBvoc.txt\"\nsettingPath: \"/home/eric/slam/ORB_SLAM2/Examples/Stereo/KITTI03.yaml\"\ndo_rectify: \"false\"\n~~~\n\n下载KITTI-odometry/data_odometry_gray数据集，保存`/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray`。\n\n测试系统，启动launch文件，同时启动图像发布者节点和ORB_SLAM2 Stereo_eric节点：\n\n```powershell\nroslaunch my_image_transport stereo_image_transport.launch\n```\n\n测试效果：\n\n{% asset_img 3.png  %}\n\n## 参考资料\n\n1. http://wiki.ros.org/image_transport/Tutorials/PublishingImages\n2. http://wiki.ros.org/image_transport/Tutorials/SubscribingToImages\n3. https://blog.csdn.net/github_30605157/article/details/50990493","source":"_posts/ORB_SLAM2学习之运行ROS模块.md","raw":"---\ntitle: ORB_SLAM2学习之运行ROS模块\ndate: 2018-08-12 10:05:55\ntags: \n  - ORB_SLAM2\ncategories:\n  - 机器人 \n  - SLAM\n  - ORB_SLAM2\ncopyright: true\n---\n\n---\n\n这篇文章是有关运行ORB_SLAM2系统ROS模块，包括单目和双目部分的学习内容。\n\n<!--more-->\n\nORB_SLAM2运行ROS模块需要从相应的话题接收图像用于SLAM系统，对于我这种不方便使用相机进行实时采集图像的渣渣来说，使用数据集图像是很好的选择。因此需要从本地数据集中获取图像，再利用ROS中的话题进行图像的发布和接收。下面的内容将介绍利用ROS进行简单的图像发布和接收操作，以及ORB_SLAM2系统ROS模块运行起来的整个过程。\n\n> 系统环境\n>\n> - Ubuntu 16.04\n> - ROS kinetic\n\n## 基于ROS话题发布、接收图像\n\n### 创建相关软件包\n\n在`catkin_ws/src`目录下新建软件包并编译：\n\n~~~shell\ncatkin_create_pkg my_image_transport image_transport cv_bridge\ncd ..\ncatkin_make -DCATKIN_WHITELIST_PACKAGES=\"my_image_transport\"\nsource devel/setup.bash\n~~~\n\n### 创建图像发布者程序\n\n新建`my_image_transport/src/my_publisher.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <cv_bridge/cv_bridge.h>\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"image_publisher\");\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"camera/image\", 1);\n  cv::Mat image = cv::imread(argv[1], CV_LOAD_IMAGE_COLOR);\n  cv::waitKey(30);//不断刷新图像，频率时间为delay，单位为ms\n  sensor_msgs::ImagePtr msg = cv_bridge::CvImage(std_msgs::Header(), \"bgr8\", image).toImageMsg();\n\n  ros::Rate loop_rate(5);\n  while (nh.ok()) {\n    pub.publish(msg);\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n}\n~~~\n\n代码解释：\n\n- line 1-4：`ros.h`头文件是所有的ros节点中必须要包含的，下面三个分别是实现图像的发布和订阅，调用opencv库，完成opencv图像格式转化为ROS图像格式所要用到的头文件；\n- line 11：告知结点管理器要在`camera/image`话题发布图像消息，参数1是话题名称，话题2是缓冲区大小（即消息队列的长度，在发布图像消息时消息队列的长度只能是1）；\n- line 12：根据运行时给定的参数（图像文件的路径）读取图像；\n- line 14：将opencv格式的图像转化为ROS所支持的消息类型，从而发布到相应的话题上；\n- line 16-21：发布图片消息，使消息类型匹配的节点订阅该消息。\n\n### 创建图像订阅者程序\n\n新建`my_image_transport/src/my_subscriber.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <cv_bridge/cv_bridge.h>\n\nvoid imageCallback(const sensor_msgs::ImageConstPtr& msg)\n{\n  try\n  {\n    cv::imshow(\"view\", cv_bridge::toCvShare(msg, \"bgr8\")->image);\n    cv::waitKey(30);\n  }\n  catch (cv_bridge::Exception& e)\n  {\n    ROS_ERROR(\"Could not convert from '%s' to 'bgr8'.\", msg->encoding.c_str());\n  }\n}\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \"image_listener\");\n  ros::NodeHandle nh;\n  cv::namedWindow(\"view\");\n  cv::startWindowThread();\n  image_transport::ImageTransport it(nh);\n  image_transport::Subscriber sub = it.subscribe(\"camera/image\", 1, imageCallback);\n  ros::spin();\n  cv::destroyWindow(\"view\");\n}\n~~~\n\n代码解释：\n\n- line 6：回调函数，当有新的图像消息到达`camera/image`时，该函数就会被调用；\n- line 10：显示捕捉到的图像，其中`cv_bridge::toCvShare(msg, \"bgr8\")->image`用于将ROS图像消息转化为Opencv支持的图像格式（采用BGR8编码方式）。这部分用法恰好与上一节中发布者节点中的`CvImage(std_msgs::Header(), \"bgr8\", image).toImageMsg();` 的作用相反\n- line 11：刷新图像的频率，实践过程中发现如果注释这一行图像将无法在窗口的显示\n\n### 相关配置文件\n\n1. `CMakeLists.txt`内容\n\n   ~~~cmake\n   cmake_minimum_required(VERSION 2.8.3)\n   project(my_image_transport)\n\n   ## Compile as C++11, supported in ROS Kinetic and newer\n   add_compile_options(-std=c++11)\n\n   find_package(catkin REQUIRED COMPONENTS\n     cv_bridge\n     image_transport\n   )\n   find_package(OpenCV REQUIRED)\n\n   set(LIBS\n   \t${OpenCV_LIBS} \n   \t${catkin_LIBRARIES})\n   \t\n   catkin_package(\n   #  INCLUDE_DIRS include\n   #  LIBRARIES my_image_transport\n   #  CATKIN_DEPENDS cv_bridge image_transport\n   #  DEPENDS system_lib\n   )\n\n   include_directories(\n   # include\n     ${catkin_INCLUDE_DIRS}\n     ${OpenCV_INCLUDE_DIRS}\n   )\n\n   add_executable(my_publisher src/my_publisher.cpp)\n   target_link_libraries(my_publisher ${LIBS})\n\n   add_executable(my_subscriber src/my_subscriber.cpp)\n   target_link_libraries(my_subscriber ${LIBS})\n   ~~~\n\n2. `package.xml`文件中添加\n\n   ~~~xml\n     <build_depend>opencv2</build_depend>\n     <exec_depend>opencv2</exec_depend>\n   ~~~\n\n### 编译软件包\n\n~~~shell\ncd ~/catkin_ws\ncatkin_make -DCATKIN_WHITHELIST_PACKAGES=\"my_image_transport\"\n~~~\n\n### 运行节点\n\n单独开启一个终端执行`roscore`，启动ros节点管理器。\n\n开启另一个终端，启动发布者节点：\n\n~~~shell\nrosrun my_image_transport my_publisher /home/eric/catkin_ws/src/my_image_transport/000.png\n~~~\n\n运行订阅者节点：\n\n~~~shell\nrosrun my_image_transport my_subscriber\n~~~\n\n运行结果如下所示：\n\n{% asset_img 1.png  %}\n\n### 查看当前活动节点及交互情况\n\n查看当前活动节点：\n\n```shell\nrosnode list\n```\n\n查看各节点交互情况：\n\n~~~powershell\nrosrun rqt_graph rqt_graph\n~~~\n\n![transport_graph.png](http://wiki.ros.org/image_transport/Tutorials/ExaminingImagePublisherSubscriber?action=AttachFile&do=get&target=transport_graph.png)\n\n可以执行`rosnode kill`命令关闭相关节点。\n\n## ORB_SLAM2 ROS模块结点的编译\n\n在环境变量`ROS_PACKAGE_PATH`中添加`Examples/ROS/ORB_SLAM2`的路径：\n\n~~~shell\necho \"source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh\" >> ~/.bashrc\n~~~\n\n在`~/slam/ORB_SLAM2`目录下执行：\n\n~~~shell\nchmod +x build_ros.sh\n./build_ros.sh\n~~~\n\n等待编译成功。\n\n## ROS Mono\n\n首先在`my_image_transport`目录下创建图像发布者程序`mono_tum.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/opencv.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <fstream>\n#include <iostream>\n#include <algorithm>\n\nusing namespace std;\n\nvoid LoadImages(const string &strFile, vector<string> &vstrImageFilenames,\n                vector<double> &vTimestamps);\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"mono_tum\");\n  if(argc != 2)\n  {\n      cerr << endl << \"Usage: rosrun my_image_transport mono_tum path_to_sequence\" << endl;\n      return 1;\n  }\n\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"/camera/image_raw\", 1);\n\n  vector<string> vstrImageFilenames;\n  vector<double> vTimestamps;\n  string strFile = string(argv[1])+\"/rgb.txt\";\n  LoadImages(strFile, vstrImageFilenames, vTimestamps);\n\n  int nImages = vstrImageFilenames.size();\n\n  cv::Mat im;\n  // double tframe;\n  sensor_msgs::ImagePtr msg;\n  std_msgs::Header header;\n  ros::Rate loop_rate(5);\n  for(int ni = 0; ni < nImages; ni++)\n  {\n    im = cv::imread(string(argv[1])+\"/\"+vstrImageFilenames[ni],CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(vTimestamps[ni]);\n\n    if(im.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(argv[1]) << \"/\" << vstrImageFilenames[ni] << endl;\n        return 1;\n    }\n\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"bgr8\", im).toImageMsg();\n\n    pub.publish(msg);\n    cv::waitKey(1);\n\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  \n  return 0;\n}\n\nvoid LoadImages(const string &strFile, vector<string> &vstrImageFilenames, vector<double> &vTimestamps)\n{\n    ifstream f;\n    f.open(strFile.c_str());\n\n    // skip first three lines\n    string s0;\n    getline(f,s0);\n    getline(f,s0);\n    getline(f,s0);\n\n    while(!f.eof())\n    {\n        string s;\n        getline(f,s);\n        if(!s.empty())\n        {\n            stringstream ss;\n            ss << s;\n            double t;\n            string sRGB;\n            ss >> t;\n            vTimestamps.push_back(t);\n            ss >> sRGB;\n            vstrImageFilenames.push_back(sRGB);\n        }\n    }\n}\n~~~\n\n在`CMakeLists.txt`文件中添加：\n\n~~~cmake\nadd_executable(mono_tum src/mono_tum.cpp)\ntarget_link_libraries(mono_tum ${LIBS})\n~~~\n\n下载TUM-rgbd_dataset_freiburg1_xyz数据集，保存`/media/eric/linux/DATA/TUM/rgbd_dataset_freiburg1_xyz`。\n\n测试系统，启动ORB_SLAM2 Mono：\n\n~~~powershell\nrosrun ORB_SLAM2 Mono /home/eric/slam/ORB_SLAM2/Vocabulary/ORBvoc.txt ~/slam/ORB_SLAM2/Examples/Monocular/TUM1.yaml\n~~~\n\n启动发布者节点：\n\n~~~powershell\nrosrun my_image_transport mono_tum /media/eric/linux/DATA/TUM/rgbd_dataset_freiburg1_xyz\n~~~\n\n测试效果：\n\n{% asset_img 2.png  %}\n\n## ROS Stereo\n\n首先在`my_image_transport`目录下创建图像发布者程序左相机节点`stereo_left_kitti.cpp`：\n\n~~~c++\n#include <ros/ros.h>\n#include <ros/package.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/opencv.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <fstream>\n#include <iostream>\n#include <algorithm>\n\nusing namespace std;\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageLeft, vector<double> &vTimestamps);\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"stereo_left_kitti\");\n\n  string packagePath = ros::package::getPath(\"my_image_transport\");\n  string configPath = packagePath + \"//config//stereo_kitti.yaml\";\n\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"/camera/left/image_raw\", 1);\n  \n  vector<string> vstrImageLeft;\n  vector<double> vTimestamps;\n  cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\n  if(!fsSettings.isOpened())\n  {\n      cerr << \"ERROR: Wrong path to settings\" << endl;\n      return -1;\n  }\n\n  string bagPath = fsSettings[\"bagPath\"];\n  LoadImages(bagPath, vstrImageLeft, vTimestamps);\n\n  int nImages = vstrImageLeft.size();\n\n  cv::Mat imLeft;\n  sensor_msgs::ImagePtr msg;\n  std_msgs::Header header;\n  ros::Rate loop_rate(5);\n  for(int ni = 0; ni < nImages; ni++)\n  {\n    imLeft = cv::imread(vstrImageLeft[ni],CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(vTimestamps[ni]);\n\n    if(imLeft.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(vstrImageLeft[ni]) << endl;\n        return 1;\n    }\n\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"mono8\", imLeft).toImageMsg();\n\n    pub.publish(msg);\n    cv::waitKey(1);\n\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  \n  return 0;\n}\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageLeft, vector<double> &vTimestamps)\n{\n    ifstream fTimes;\n    string strPathTimeFile = strPathToSequence + \"/times.txt\";\n    fTimes.open(strPathTimeFile.c_str());\n    while(!fTimes.eof())\n    {\n        string s;\n        getline(fTimes,s);\n        if(!s.empty())\n        {\n            stringstream ss;\n            ss << s;\n            double t;\n            ss >> t;\n            vTimestamps.push_back(t);\n        }\n    }\n\n    string strPrefixLeft = strPathToSequence + \"/image_0/\";\n\n    const int nTimes = vTimestamps.size();\n    vstrImageLeft.resize(nTimes);\n\n    for(int i=0; i<nTimes; i++)\n    {\n        stringstream ss;\n        ss << setfill('0') << setw(6) << i;\n        vstrImageLeft[i] = strPrefixLeft + ss.str() + \".png\";\n    }\n}\n~~~\n\n右相机节点`stereo_right_kitti`：\n\n~~~c++\n#include <ros/ros.h>\n#include <ros/package.h>\n#include <image_transport/image_transport.h>\n#include <opencv2/opencv.hpp>\n#include <cv_bridge/cv_bridge.h>\n#include <fstream>\n#include <iostream>\n#include <algorithm>\n\nusing namespace std;\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageRight, vector<double> &vTimestamps);\n\nint main(int argc, char** argv)\n{\n  ros::init(argc, argv, \"stereo_right_kitti\");\n\n  string packagePath = ros::package::getPath(\"my_image_transport\");\n  string configPath = packagePath + \"//config//stereo_kitti.yaml\";\n\n  ros::NodeHandle nh;\n  image_transport::ImageTransport it(nh);\n  image_transport::Publisher pub = it.advertise(\"/camera/right/image_raw\", 1);\n\n  vector<string> vstrImageRight;\n  vector<double> vTimestamps;\n  cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\n  if(!fsSettings.isOpened())\n  {\n      cerr << \"ERROR: Wrong path to settings\" << endl;\n      return -1;\n  }\n\n  string bagPath = fsSettings[\"bagPath\"];\n  \n  LoadImages(bagPath, vstrImageRight, vTimestamps);\n\n  int nImages = vstrImageRight.size();\n\n  cv::Mat imRight;\n  sensor_msgs::ImagePtr msg;\n  std_msgs::Header header;\n  ros::Rate loop_rate(5);\n  for(int ni = 0; ni < nImages; ni++)\n  {\n    imRight = cv::imread(vstrImageRight[ni],CV_LOAD_IMAGE_UNCHANGED);\n    header.stamp = ros::Time(vTimestamps[ni]);\n\n    if(imRight.empty())\n    {\n        cerr << endl << \"Failed to load image at: \"\n             << string(vstrImageRight[ni]) << endl;\n        return 1;\n    }\n\n    cv::waitKey(30);\n    msg = cv_bridge::CvImage(header, \"mono8\", imRight).toImageMsg();\n\n    pub.publish(msg);\n    cv::waitKey(1);\n\n    ros::spinOnce();\n    loop_rate.sleep();\n  }\n  \n  return 0;\n}\n\nvoid LoadImages(const string &strPathToSequence,\n                vector<string> &vstrImageRight, vector<double> &vTimestamps)\n{\n    ifstream fTimes;\n    string strPathTimeFile = strPathToSequence + \"/times.txt\";\n    fTimes.open(strPathTimeFile.c_str());\n    while(!fTimes.eof())\n    {\n        string s;\n        getline(fTimes,s);\n        if(!s.empty())\n        {\n            stringstream ss;\n            ss << s;\n            double t;\n            ss >> t;\n            vTimestamps.push_back(t);\n        }\n    }\n\n    string strPrefixRight = strPathToSequence + \"/image_1/\";\n\n    const int nTimes = vTimestamps.size();\n    vstrImageRight.resize(nTimes);\n\n    for(int i=0; i<nTimes; i++)\n    {\n        stringstream ss;\n        ss << setfill('0') << setw(6) << i;\n        vstrImageRight[i] = strPrefixRight + ss.str() + \".png\";\n    }\n}\n~~~\n\n在`CMakeLists.txt`文件中添加：\n\n```cmake\nadd_executable(stereo_left_kitti src/stereo_left_kitti.cpp)\ntarget_link_libraries(stereo_left_kitti ${LIBS})\n\nadd_executable(stereo_right_kitti src/stereo_right_kitti.cpp)\ntarget_link_libraries(stereo_right_kitti ${LIBS})\n```\n\n在`my_image_transport/config`目录下添加配置文件`stereo_kitti.yaml`，保存数据集路径：\n\n~~~yaml\n%YAML:1.0\nbagPath: \"/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray/sequences/03\"\n~~~\n\n这里需要启动三个节点，每个单独启动会比较麻烦，所以使用ROS Launch文件，同时启动左、右图像发布节点和ORB_SLAM2 Stereo_eric节点。在`my_image_transport/launch`目录下添加ROS节点启动文件`stereo_image_transport.yaml`：\n\n~~~xml\n<launch>\n  <node name=\"stereo_left_kitti\" pkg=\"my_image_transport\" type=\"stereo_left_kitti\">\n  </node>\n  <node name=\"stereo_right_kitti\" pkg=\"my_image_transport\" type=\"stereo_right_kitti\">\n  </node>\n  <node name=\"Stereo_eric\" pkg=\"ORB_SLAM2\" type=\"Stereo_eric\">\n  </node>\n</launch>\n~~~\n\n修改ORB_SLAM2的`ros_stereo.cc`文件，新建为`ros_stereo_eric.cc`：\n\n~~~c++\n#include<iostream>\n#include<algorithm>\n#include<fstream>\n#include<chrono>\n\n#include<ros/ros.h>\n#include <cv_bridge/cv_bridge.h>\n#include <message_filters/subscriber.h>\n#include <message_filters/time_synchronizer.h>\n#include <message_filters/sync_policies/approximate_time.h>\n\n#include<opencv2/core/core.hpp>\n#include <ros/package.h>\n#include\"../../../include/System.h\"\n\nusing namespace std;\n\nclass ImageGrabber\n{\npublic:\n    ImageGrabber(ORB_SLAM2::System* pSLAM):mpSLAM(pSLAM){}\n\n    void GrabStereo(const sensor_msgs::ImageConstPtr& msgLeft,const sensor_msgs::ImageConstPtr& msgRight);\n\n    ORB_SLAM2::System* mpSLAM;\n    bool do_rectify;\n    cv::Mat M1l,M2l,M1r,M2r;\n};\n\nint main(int argc, char **argv)\n{\n    ros::init(argc, argv, \"Stereo_eric\");\n    ros::start();\n\n    string packagePath = ros::package::getPath(\"ORB_SLAM2\");\n    string configPath = packagePath + \"//config//ros_stereo_eric.yaml\";\n\n    cv::FileStorage fsSettings(configPath, cv::FileStorage::READ);\n    if(!fsSettings.isOpened())\n    {\n      cerr << \"ERROR: Wrong path to settings\" << endl;\n      return -1;\n    }\n\n    string vocPath = fsSettings[\"vocPath\"];\n    string settingPath = fsSettings[\"settingPath\"];\n    // Create SLAM system. It initializes all system threads and gets ready to process frames.\n    ORB_SLAM2::System SLAM(vocPath,settingPath,ORB_SLAM2::System::STEREO,true);\n\n    ImageGrabber igb(&SLAM);\n\n    string do_rectify = fsSettings[\"do_rectify\"];\n    stringstream ss(do_rectify);\n\tss >> boolalpha >> igb.do_rectify;//boolalpha函数把bool值显示为true或false\n\n    if(igb.do_rectify)\n    {      \n        // Load settings related to stereo calibration\n        cv::FileStorage fsSettings(settingPath, cv::FileStorage::READ);\n        if(!fsSettings.isOpened())\n        {\n            cerr << \"ERROR: Wrong path to settings\" << endl;\n            return -1;\n        }\n\n        cv::Mat K_l, K_r, P_l, P_r, R_l, R_r, D_l, D_r;\n        fsSettings[\"LEFT.K\"] >> K_l;\n        fsSettings[\"RIGHT.K\"] >> K_r;\n\n        fsSettings[\"LEFT.P\"] >> P_l;\n        fsSettings[\"RIGHT.P\"] >> P_r;\n\n        fsSettings[\"LEFT.R\"] >> R_l;\n        fsSettings[\"RIGHT.R\"] >> R_r;\n\n        fsSettings[\"LEFT.D\"] >> D_l;\n        fsSettings[\"RIGHT.D\"] >> D_r;\n\n        int rows_l = fsSettings[\"LEFT.height\"];\n        int cols_l = fsSettings[\"LEFT.width\"];\n        int rows_r = fsSettings[\"RIGHT.height\"];\n        int cols_r = fsSettings[\"RIGHT.width\"];\n\n        if(K_l.empty() || K_r.empty() || P_l.empty() || P_r.empty() || R_l.empty() || R_r.empty() || D_l.empty() || D_r.empty() ||\n                rows_l==0 || rows_r==0 || cols_l==0 || cols_r==0)\n        {\n            cerr << \"ERROR: Calibration parameters to rectify stereo are missing!\" << endl;\n            return -1;\n        }\n\n        cv::initUndistortRectifyMap(K_l,D_l,R_l,P_l.rowRange(0,3).colRange(0,3),cv::Size(cols_l,rows_l),CV_32F,igb.M1l,igb.M2l);\n        cv::initUndistortRectifyMap(K_r,D_r,R_r,P_r.rowRange(0,3).colRange(0,3),cv::Size(cols_r,rows_r),CV_32F,igb.M1r,igb.M2r);\n    }\n\n    ros::NodeHandle nh;\n\n    message_filters::Subscriber<sensor_msgs::Image> left_sub(nh, \"/camera/left/image_raw\", 1);\n    message_filters::Subscriber<sensor_msgs::Image> right_sub(nh, \"camera/right/image_raw\", 1);\n    typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> sync_pol;\n    message_filters::Synchronizer<sync_pol> sync(sync_pol(10), left_sub,right_sub);\n    sync.registerCallback(boost::bind(&ImageGrabber::GrabStereo,&igb,_1,_2));\n\n    ros::spin();\n\n    // Stop all threads\n    SLAM.Shutdown();\n\n    // Save camera trajectory\n    SLAM.SaveKeyFrameTrajectoryTUM(\"KeyFrameTrajectory_TUM_Format.txt\");\n    SLAM.SaveTrajectoryTUM(\"FrameTrajectory_TUM_Format.txt\");\n    SLAM.SaveTrajectoryKITTI(\"FrameTrajectory_KITTI_Format.txt\");\n\n    ros::shutdown();\n\n    return 0;\n}\n\nvoid ImageGrabber::GrabStereo(const sensor_msgs::ImageConstPtr& msgLeft,const sensor_msgs::ImageConstPtr& msgRight)\n{\n    // Copy the ros image message to cv::Mat.\n    cv_bridge::CvImageConstPtr cv_ptrLeft;\n    try\n    {\n        cv_ptrLeft = cv_bridge::toCvShare(msgLeft);\n    }\n    catch (cv_bridge::Exception& e)\n    {\n        ROS_ERROR(\"cv_bridge exception: %s\", e.what());\n        return;\n    }\n\n    cv_bridge::CvImageConstPtr cv_ptrRight;\n    try\n    {\n        cv_ptrRight = cv_bridge::toCvShare(msgRight);\n    }\n    catch (cv_bridge::Exception& e)\n    {\n        ROS_ERROR(\"cv_bridge exception: %s\", e.what());\n        return;\n    }\n\n    if(do_rectify)\n    {\n        cv::Mat imLeft, imRight;\n        cv::remap(cv_ptrLeft->image,imLeft,M1l,M2l,cv::INTER_LINEAR);\n        cv::remap(cv_ptrRight->image,imRight,M1r,M2r,cv::INTER_LINEAR);\n        mpSLAM->TrackStereo(imLeft,imRight,cv_ptrLeft->header.stamp.toSec());\n    }\n    else\n    {   //cv_ptrLeft->image  is  cv::Mat\n        mpSLAM->TrackStereo(cv_ptrLeft->image,cv_ptrRight->image,cv_ptrLeft->header.stamp.toSec());\n    }\n\n}\n~~~\n\n`ROS/ORB_SLAM2/config`目录下添加配置文件`ros_stereo_eric.yaml`：\n\n~~~yaml\n%YAML:1.0\nvocPath: \"/home/eric/slam/ORB_SLAM2/Vocabulary/ORBvoc.txt\"\nsettingPath: \"/home/eric/slam/ORB_SLAM2/Examples/Stereo/KITTI03.yaml\"\ndo_rectify: \"false\"\n~~~\n\n下载KITTI-odometry/data_odometry_gray数据集，保存`/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray`。\n\n测试系统，启动launch文件，同时启动图像发布者节点和ORB_SLAM2 Stereo_eric节点：\n\n```powershell\nroslaunch my_image_transport stereo_image_transport.launch\n```\n\n测试效果：\n\n{% asset_img 3.png  %}\n\n## 参考资料\n\n1. http://wiki.ros.org/image_transport/Tutorials/PublishingImages\n2. http://wiki.ros.org/image_transport/Tutorials/SubscribingToImages\n3. https://blog.csdn.net/github_30605157/article/details/50990493","slug":"ORB_SLAM2学习之运行ROS模块","published":1,"updated":"2019-05-30T12:29:26.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc1o00f2qlcrjvgtwfgp","content":"<hr>\n<p>这篇文章是有关运行ORB_SLAM2系统ROS模块，包括单目和双目部分的学习内容。</p>\n<a id=\"more\"></a>\n<p>ORB_SLAM2运行ROS模块需要从相应的话题接收图像用于SLAM系统，对于我这种不方便使用相机进行实时采集图像的渣渣来说，使用数据集图像是很好的选择。因此需要从本地数据集中获取图像，再利用ROS中的话题进行图像的发布和接收。下面的内容将介绍利用ROS进行简单的图像发布和接收操作，以及ORB_SLAM2系统ROS模块运行起来的整个过程。</p>\n<blockquote>\n<p>系统环境</p>\n<ul>\n<li>Ubuntu 16.04</li>\n<li>ROS kinetic</li>\n</ul>\n</blockquote>\n<h2 id=\"基于ROS话题发布、接收图像\"><a href=\"#基于ROS话题发布、接收图像\" class=\"headerlink\" title=\"基于ROS话题发布、接收图像\"></a>基于ROS话题发布、接收图像</h2><h3 id=\"创建相关软件包\"><a href=\"#创建相关软件包\" class=\"headerlink\" title=\"创建相关软件包\"></a>创建相关软件包</h3><p>在<code>catkin_ws/src</code>目录下新建软件包并编译：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_create_pkg my_image_transport image_transport cv_bridge</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">catkin_make -DCATKIN_WHITELIST_PACKAGES=\"my_image_transport\"</span><br><span class=\"line\">source devel/setup.bash</span><br></pre></td></tr></table></figure>\n<h3 id=\"创建图像发布者程序\"><a href=\"#创建图像发布者程序\" class=\"headerlink\" title=\"创建图像发布者程序\"></a>创建图像发布者程序</h3><p>新建<code>my_image_transport/src/my_publisher.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;image_transport/image_transport.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"image_publisher\"</span>);</span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  image_transport::<span class=\"function\">ImageTransport <span class=\"title\">it</span><span class=\"params\">(nh)</span></span>;</span><br><span class=\"line\">  image_transport::Publisher pub = it.advertise(<span class=\"string\">\"camera/image\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">  cv::Mat image = cv::imread(argv[<span class=\"number\">1</span>], CV_LOAD_IMAGE_COLOR);</span><br><span class=\"line\">  cv::waitKey(<span class=\"number\">30</span>);<span class=\"comment\">//不断刷新图像，频率时间为delay，单位为ms</span></span><br><span class=\"line\">  sensor_msgs::ImagePtr msg = cv_bridge::CvImage(std_msgs::Header(), <span class=\"string\">\"bgr8\"</span>, image).toImageMsg();</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::<span class=\"function\">Rate <span class=\"title\">loop_rate</span><span class=\"params\">(<span class=\"number\">5</span>)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">while</span> (nh.ok()) &#123;</span><br><span class=\"line\">    pub.publish(msg);</span><br><span class=\"line\">    ros::spinOnce();</span><br><span class=\"line\">    loop_rate.sleep();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>代码解释：</p>\n<ul>\n<li>line 1-4：<code>ros.h</code>头文件是所有的ros节点中必须要包含的，下面三个分别是实现图像的发布和订阅，调用opencv库，完成opencv图像格式转化为ROS图像格式所要用到的头文件；</li>\n<li>line 11：告知结点管理器要在<code>camera/image</code>话题发布图像消息，参数1是话题名称，话题2是缓冲区大小（即消息队列的长度，在发布图像消息时消息队列的长度只能是1）；</li>\n<li>line 12：根据运行时给定的参数（图像文件的路径）读取图像；</li>\n<li>line 14：将opencv格式的图像转化为ROS所支持的消息类型，从而发布到相应的话题上；</li>\n<li>line 16-21：发布图片消息，使消息类型匹配的节点订阅该消息。</li>\n</ul>\n<h3 id=\"创建图像订阅者程序\"><a href=\"#创建图像订阅者程序\" class=\"headerlink\" title=\"创建图像订阅者程序\"></a>创建图像订阅者程序</h3><p>新建<code>my_image_transport/src/my_subscriber.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;image_transport/image_transport.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">imageCallback</span><span class=\"params\">(<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr&amp; msg)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">try</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    cv::imshow(<span class=\"string\">\"view\"</span>, cv_bridge::toCvShare(msg, <span class=\"string\">\"bgr8\"</span>)-&gt;image);</span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">30</span>);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">catch</span> (cv_bridge::Exception&amp; e)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    ROS_ERROR(<span class=\"string\">\"Could not convert from '%s' to 'bgr8'.\"</span>, msg-&gt;encoding.c_str());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"image_listener\"</span>);</span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  cv::namedWindow(<span class=\"string\">\"view\"</span>);</span><br><span class=\"line\">  cv::startWindowThread();</span><br><span class=\"line\">  image_transport::<span class=\"function\">ImageTransport <span class=\"title\">it</span><span class=\"params\">(nh)</span></span>;</span><br><span class=\"line\">  image_transport::Subscriber sub = it.subscribe(<span class=\"string\">\"camera/image\"</span>, <span class=\"number\">1</span>, imageCallback);</span><br><span class=\"line\">  ros::spin();</span><br><span class=\"line\">  cv::destroyWindow(<span class=\"string\">\"view\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>代码解释：</p>\n<ul>\n<li>line 6：回调函数，当有新的图像消息到达<code>camera/image</code>时，该函数就会被调用；</li>\n<li>line 10：显示捕捉到的图像，其中<code>cv_bridge::toCvShare(msg, &quot;bgr8&quot;)-&gt;image</code>用于将ROS图像消息转化为Opencv支持的图像格式（采用BGR8编码方式）。这部分用法恰好与上一节中发布者节点中的<code>CvImage(std_msgs::Header(), &quot;bgr8&quot;, image).toImageMsg();</code> 的作用相反</li>\n<li>line 11：刷新图像的频率，实践过程中发现如果注释这一行图像将无法在窗口的显示</li>\n</ul>\n<h3 id=\"相关配置文件\"><a href=\"#相关配置文件\" class=\"headerlink\" title=\"相关配置文件\"></a>相关配置文件</h3><ol>\n<li><p><code>CMakeLists.txt</code>内容</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.8</span>.<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(my_image_transport)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Compile as C++11, supported in ROS Kinetic and newer</span></span><br><span class=\"line\">add_compile_options(-std=c++<span class=\"number\">11</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  cv_bridge</span><br><span class=\"line\">  image_transport</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(OpenCV REQUIRED)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">set</span>(LIBS</span><br><span class=\"line\">\t<span class=\"variable\">$&#123;OpenCV_LIBS&#125;</span> </span><br><span class=\"line\">\t<span class=\"variable\">$&#123;catkin_LIBRARIES&#125;</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\"><span class=\"comment\">#  INCLUDE_DIRS include</span></span><br><span class=\"line\"><span class=\"comment\">#  LIBRARIES my_image_transport</span></span><br><span class=\"line\"><span class=\"comment\">#  CATKIN_DEPENDS cv_bridge image_transport</span></span><br><span class=\"line\"><span class=\"comment\">#  DEPENDS system_lib</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(</span><br><span class=\"line\"><span class=\"comment\"># include</span></span><br><span class=\"line\">  <span class=\"variable\">$&#123;catkin_INCLUDE_DIRS&#125;</span></span><br><span class=\"line\">  <span class=\"variable\">$&#123;OpenCV_INCLUDE_DIRS&#125;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(my_publisher src/my_publisher.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(my_publisher <span class=\"variable\">$&#123;LIBS&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(my_subscriber src/my_subscriber.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(my_subscriber <span class=\"variable\">$&#123;LIBS&#125;</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>package.xml</code>文件中添加</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build_depend</span>&gt;</span>opencv2<span class=\"tag\">&lt;/<span class=\"name\">build_depend</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">exec_depend</span>&gt;</span>opencv2<span class=\"tag\">&lt;/<span class=\"name\">exec_depend</span>&gt;</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"编译软件包\"><a href=\"#编译软件包\" class=\"headerlink\" title=\"编译软件包\"></a>编译软件包</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~/catkin_ws</span><br><span class=\"line\">catkin_make -DCATKIN_WHITHELIST_PACKAGES=\"my_image_transport\"</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h3><p>单独开启一个终端执行<code>roscore</code>，启动ros节点管理器。</p>\n<p>开启另一个终端，启动发布者节点：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun my_image_transport my_publisher /home/eric/catkin_ws/src/my_image_transport/000.png</span><br></pre></td></tr></table></figure>\n<p>运行订阅者节点：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun my_image_transport my_subscriber</span><br></pre></td></tr></table></figure>\n<p>运行结果如下所示：</p>\n\n<h3 id=\"查看当前活动节点及交互情况\"><a href=\"#查看当前活动节点及交互情况\" class=\"headerlink\" title=\"查看当前活动节点及交互情况\"></a>查看当前活动节点及交互情况</h3><p>查看当前活动节点：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosnode list</span><br></pre></td></tr></table></figure>\n<p>查看各节点交互情况：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun rqt_graph rqt_graph</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://wiki.ros.org/image_transport/Tutorials/ExaminingImagePublisherSubscriber?action=AttachFile&amp;do=get&amp;target=transport_graph.png\" alt=\"transport_graph.png\"></p>\n<p>可以执行<code>rosnode kill</code>命令关闭相关节点。</p>\n<h2 id=\"ORB-SLAM2-ROS模块结点的编译\"><a href=\"#ORB-SLAM2-ROS模块结点的编译\" class=\"headerlink\" title=\"ORB_SLAM2 ROS模块结点的编译\"></a>ORB_SLAM2 ROS模块结点的编译</h2><p>在环境变量<code>ROS_PACKAGE_PATH</code>中添加<code>Examples/ROS/ORB_SLAM2</code>的路径：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo \"source ~/slam/ORB_SLAM2/Examples/ROS/ORB_SLAM2/build/devel/setup.sh\" &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>\n<p>在<code>~/slam/ORB_SLAM2</code>目录下执行：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod +x build_ros.sh</span><br><span class=\"line\">./build_ros.sh</span><br></pre></td></tr></table></figure>\n<p>等待编译成功。</p>\n<h2 id=\"ROS-Mono\"><a href=\"#ROS-Mono\" class=\"headerlink\" title=\"ROS Mono\"></a>ROS Mono</h2><p>首先在<code>my_image_transport</code>目录下创建图像发布者程序<code>mono_tum.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;image_transport/image_transport.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;fstream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">LoadImages</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span> &amp;strFile, <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; &amp;vstrImageFilenames,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; &amp;vTimestamps)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"mono_tum\"</span>);</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(argc != <span class=\"number\">2</span>)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"built_in\">endl</span> &lt;&lt; <span class=\"string\">\"Usage: rosrun my_image_transport mono_tum path_to_sequence\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  image_transport::<span class=\"function\">ImageTransport <span class=\"title\">it</span><span class=\"params\">(nh)</span></span>;</span><br><span class=\"line\">  image_transport::Publisher pub = it.advertise(<span class=\"string\">\"/camera/image_raw\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; vstrImageFilenames;</span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; vTimestamps;</span><br><span class=\"line\">  <span class=\"built_in\">string</span> strFile = <span class=\"built_in\">string</span>(argv[<span class=\"number\">1</span>])+<span class=\"string\">\"/rgb.txt\"</span>;</span><br><span class=\"line\">  LoadImages(strFile, vstrImageFilenames, vTimestamps);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">int</span> nImages = vstrImageFilenames.size();</span><br><span class=\"line\"></span><br><span class=\"line\">  cv::Mat im;</span><br><span class=\"line\">  <span class=\"comment\">// double tframe;</span></span><br><span class=\"line\">  sensor_msgs::ImagePtr msg;</span><br><span class=\"line\">  std_msgs::Header header;</span><br><span class=\"line\">  ros::<span class=\"function\">Rate <span class=\"title\">loop_rate</span><span class=\"params\">(<span class=\"number\">5</span>)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> ni = <span class=\"number\">0</span>; ni &lt; nImages; ni++)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    im = cv::imread(<span class=\"built_in\">string</span>(argv[<span class=\"number\">1</span>])+<span class=\"string\">\"/\"</span>+vstrImageFilenames[ni],CV_LOAD_IMAGE_UNCHANGED);</span><br><span class=\"line\">    header.stamp = ros::Time(vTimestamps[ni]);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(im.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"built_in\">endl</span> &lt;&lt; <span class=\"string\">\"Failed to load image at: \"</span></span><br><span class=\"line\">             &lt;&lt; <span class=\"built_in\">string</span>(argv[<span class=\"number\">1</span>]) &lt;&lt; <span class=\"string\">\"/\"</span> &lt;&lt; vstrImageFilenames[ni] &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">30</span>);</span><br><span class=\"line\">    msg = cv_bridge::CvImage(header, <span class=\"string\">\"bgr8\"</span>, im).toImageMsg();</span><br><span class=\"line\"></span><br><span class=\"line\">    pub.publish(msg);</span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    ros::spinOnce();</span><br><span class=\"line\">    loop_rate.sleep();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">LoadImages</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span> &amp;strFile, <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; &amp;vstrImageFilenames, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; &amp;vTimestamps)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ifstream f;</span><br><span class=\"line\">    f.open(strFile.c_str());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// skip first three lines</span></span><br><span class=\"line\">    <span class=\"built_in\">string</span> s0;</span><br><span class=\"line\">    getline(f,s0);</span><br><span class=\"line\">    getline(f,s0);</span><br><span class=\"line\">    getline(f,s0);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(!f.eof())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> s;</span><br><span class=\"line\">        getline(f,s);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">stringstream</span> ss;</span><br><span class=\"line\">            ss &lt;&lt; s;</span><br><span class=\"line\">            <span class=\"keyword\">double</span> t;</span><br><span class=\"line\">            <span class=\"built_in\">string</span> sRGB;</span><br><span class=\"line\">            ss &gt;&gt; t;</span><br><span class=\"line\">            vTimestamps.push_back(t);</span><br><span class=\"line\">            ss &gt;&gt; sRGB;</span><br><span class=\"line\">            vstrImageFilenames.push_back(sRGB);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在<code>CMakeLists.txt</code>文件中添加：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(mono_tum src/mono_tum.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(mono_tum <span class=\"variable\">$&#123;LIBS&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>下载TUM-rgbd_dataset_freiburg1_xyz数据集，保存<code>/media/eric/linux/DATA/TUM/rgbd_dataset_freiburg1_xyz</code>。</p>\n<p>测试系统，启动ORB_SLAM2 Mono：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun ORB_SLAM2 Mono /home/eric/slam/ORB_SLAM2/Vocabulary/ORBvoc.txt ~/slam/ORB_SLAM2/Examples/Monocular/TUM1.yaml</span><br></pre></td></tr></table></figure>\n<p>启动发布者节点：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rosrun my_image_transport mono_tum /media/eric/linux/<span class=\"keyword\">DATA</span>/TUM/rgbd_dataset_freiburg1_xyz</span><br></pre></td></tr></table></figure>\n<p>测试效果：</p>\n\n<h2 id=\"ROS-Stereo\"><a href=\"#ROS-Stereo\" class=\"headerlink\" title=\"ROS Stereo\"></a>ROS Stereo</h2><p>首先在<code>my_image_transport</code>目录下创建图像发布者程序左相机节点<code>stereo_left_kitti.cpp</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/package.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;image_transport/image_transport.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;fstream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">LoadImages</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span> &amp;strPathToSequence,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; &amp;vstrImageLeft, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; &amp;vTimestamps)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"stereo_left_kitti\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">string</span> packagePath = ros::package::getPath(<span class=\"string\">\"my_image_transport\"</span>);</span><br><span class=\"line\">  <span class=\"built_in\">string</span> configPath = packagePath + <span class=\"string\">\"//config//stereo_kitti.yaml\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  image_transport::<span class=\"function\">ImageTransport <span class=\"title\">it</span><span class=\"params\">(nh)</span></span>;</span><br><span class=\"line\">  image_transport::Publisher pub = it.advertise(<span class=\"string\">\"/camera/left/image_raw\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; vstrImageLeft;</span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; vTimestamps;</span><br><span class=\"line\">  cv::<span class=\"function\">FileStorage <span class=\"title\">fsSettings</span><span class=\"params\">(configPath, cv::FileStorage::READ)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(!fsSettings.isOpened())</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"string\">\"ERROR: Wrong path to settings\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">string</span> bagPath = fsSettings[<span class=\"string\">\"bagPath\"</span>];</span><br><span class=\"line\">  LoadImages(bagPath, vstrImageLeft, vTimestamps);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">int</span> nImages = vstrImageLeft.size();</span><br><span class=\"line\"></span><br><span class=\"line\">  cv::Mat imLeft;</span><br><span class=\"line\">  sensor_msgs::ImagePtr msg;</span><br><span class=\"line\">  std_msgs::Header header;</span><br><span class=\"line\">  ros::<span class=\"function\">Rate <span class=\"title\">loop_rate</span><span class=\"params\">(<span class=\"number\">5</span>)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> ni = <span class=\"number\">0</span>; ni &lt; nImages; ni++)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    imLeft = cv::imread(vstrImageLeft[ni],CV_LOAD_IMAGE_UNCHANGED);</span><br><span class=\"line\">    header.stamp = ros::Time(vTimestamps[ni]);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(imLeft.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"built_in\">endl</span> &lt;&lt; <span class=\"string\">\"Failed to load image at: \"</span></span><br><span class=\"line\">             &lt;&lt; <span class=\"built_in\">string</span>(vstrImageLeft[ni]) &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">30</span>);</span><br><span class=\"line\">    msg = cv_bridge::CvImage(header, <span class=\"string\">\"mono8\"</span>, imLeft).toImageMsg();</span><br><span class=\"line\"></span><br><span class=\"line\">    pub.publish(msg);</span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    ros::spinOnce();</span><br><span class=\"line\">    loop_rate.sleep();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">LoadImages</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span> &amp;strPathToSequence,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; &amp;vstrImageLeft, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; &amp;vTimestamps)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ifstream fTimes;</span><br><span class=\"line\">    <span class=\"built_in\">string</span> strPathTimeFile = strPathToSequence + <span class=\"string\">\"/times.txt\"</span>;</span><br><span class=\"line\">    fTimes.open(strPathTimeFile.c_str());</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(!fTimes.eof())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> s;</span><br><span class=\"line\">        getline(fTimes,s);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">stringstream</span> ss;</span><br><span class=\"line\">            ss &lt;&lt; s;</span><br><span class=\"line\">            <span class=\"keyword\">double</span> t;</span><br><span class=\"line\">            ss &gt;&gt; t;</span><br><span class=\"line\">            vTimestamps.push_back(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">string</span> strPrefixLeft = strPathToSequence + <span class=\"string\">\"/image_0/\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> nTimes = vTimestamps.size();</span><br><span class=\"line\">    vstrImageLeft.resize(nTimes);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;nTimes; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">stringstream</span> ss;</span><br><span class=\"line\">        ss &lt;&lt; setfill(<span class=\"string\">'0'</span>) &lt;&lt; setw(<span class=\"number\">6</span>) &lt;&lt; i;</span><br><span class=\"line\">        vstrImageLeft[i] = strPrefixLeft + ss.str() + <span class=\"string\">\".png\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>右相机节点<code>stereo_right_kitti</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/package.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;image_transport/image_transport.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;fstream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">LoadImages</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span> &amp;strPathToSequence,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; &amp;vstrImageRight, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; &amp;vTimestamps)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  ros::init(argc, argv, <span class=\"string\">\"stereo_right_kitti\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">string</span> packagePath = ros::package::getPath(<span class=\"string\">\"my_image_transport\"</span>);</span><br><span class=\"line\">  <span class=\"built_in\">string</span> configPath = packagePath + <span class=\"string\">\"//config//stereo_kitti.yaml\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  ros::NodeHandle nh;</span><br><span class=\"line\">  image_transport::<span class=\"function\">ImageTransport <span class=\"title\">it</span><span class=\"params\">(nh)</span></span>;</span><br><span class=\"line\">  image_transport::Publisher pub = it.advertise(<span class=\"string\">\"/camera/right/image_raw\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; vstrImageRight;</span><br><span class=\"line\">  <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; vTimestamps;</span><br><span class=\"line\">  cv::<span class=\"function\">FileStorage <span class=\"title\">fsSettings</span><span class=\"params\">(configPath, cv::FileStorage::READ)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(!fsSettings.isOpened())</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"string\">\"ERROR: Wrong path to settings\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">string</span> bagPath = fsSettings[<span class=\"string\">\"bagPath\"</span>];</span><br><span class=\"line\">  </span><br><span class=\"line\">  LoadImages(bagPath, vstrImageRight, vTimestamps);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">int</span> nImages = vstrImageRight.size();</span><br><span class=\"line\"></span><br><span class=\"line\">  cv::Mat imRight;</span><br><span class=\"line\">  sensor_msgs::ImagePtr msg;</span><br><span class=\"line\">  std_msgs::Header header;</span><br><span class=\"line\">  ros::<span class=\"function\">Rate <span class=\"title\">loop_rate</span><span class=\"params\">(<span class=\"number\">5</span>)</span></span>;</span><br><span class=\"line\">  <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> ni = <span class=\"number\">0</span>; ni &lt; nImages; ni++)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    imRight = cv::imread(vstrImageRight[ni],CV_LOAD_IMAGE_UNCHANGED);</span><br><span class=\"line\">    header.stamp = ros::Time(vTimestamps[ni]);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(imRight.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"built_in\">endl</span> &lt;&lt; <span class=\"string\">\"Failed to load image at: \"</span></span><br><span class=\"line\">             &lt;&lt; <span class=\"built_in\">string</span>(vstrImageRight[ni]) &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">30</span>);</span><br><span class=\"line\">    msg = cv_bridge::CvImage(header, <span class=\"string\">\"mono8\"</span>, imRight).toImageMsg();</span><br><span class=\"line\"></span><br><span class=\"line\">    pub.publish(msg);</span><br><span class=\"line\">    cv::waitKey(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    ros::spinOnce();</span><br><span class=\"line\">    loop_rate.sleep();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">LoadImages</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span> &amp;strPathToSequence,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">string</span>&gt; &amp;vstrImageRight, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">double</span>&gt; &amp;vTimestamps)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ifstream fTimes;</span><br><span class=\"line\">    <span class=\"built_in\">string</span> strPathTimeFile = strPathToSequence + <span class=\"string\">\"/times.txt\"</span>;</span><br><span class=\"line\">    fTimes.open(strPathTimeFile.c_str());</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(!fTimes.eof())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> s;</span><br><span class=\"line\">        getline(fTimes,s);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">stringstream</span> ss;</span><br><span class=\"line\">            ss &lt;&lt; s;</span><br><span class=\"line\">            <span class=\"keyword\">double</span> t;</span><br><span class=\"line\">            ss &gt;&gt; t;</span><br><span class=\"line\">            vTimestamps.push_back(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">string</span> strPrefixRight = strPathToSequence + <span class=\"string\">\"/image_1/\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> nTimes = vTimestamps.size();</span><br><span class=\"line\">    vstrImageRight.resize(nTimes);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;nTimes; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">stringstream</span> ss;</span><br><span class=\"line\">        ss &lt;&lt; setfill(<span class=\"string\">'0'</span>) &lt;&lt; setw(<span class=\"number\">6</span>) &lt;&lt; i;</span><br><span class=\"line\">        vstrImageRight[i] = strPrefixRight + ss.str() + <span class=\"string\">\".png\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在<code>CMakeLists.txt</code>文件中添加：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(stereo_left_kitti src/stereo_left_kitti.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(stereo_left_kitti <span class=\"variable\">$&#123;LIBS&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(stereo_right_kitti src/stereo_right_kitti.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(stereo_right_kitti <span class=\"variable\">$&#123;LIBS&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>在<code>my_image_transport/config</code>目录下添加配置文件<code>stereo_kitti.yaml</code>，保存数据集路径：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">%YAML:1.0</span></span><br><span class=\"line\"><span class=\"attr\">bagPath:</span> <span class=\"string\">\"/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray/sequences/03\"</span></span><br></pre></td></tr></table></figure>\n<p>这里需要启动三个节点，每个单独启动会比较麻烦，所以使用ROS Launch文件，同时启动左、右图像发布节点和ORB_SLAM2 Stereo_eric节点。在<code>my_image_transport/launch</code>目录下添加ROS节点启动文件<code>stereo_image_transport.yaml</code>：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">launch</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"stereo_left_kitti\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"my_image_transport\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"stereo_left_kitti\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"stereo_right_kitti\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"my_image_transport\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"stereo_right_kitti\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">node</span> <span class=\"attr\">name</span>=<span class=\"string\">\"Stereo_eric\"</span> <span class=\"attr\">pkg</span>=<span class=\"string\">\"ORB_SLAM2\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"Stereo_eric\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">node</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">launch</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>修改ORB_SLAM2的<code>ros_stereo.cc</code>文件，新建为<code>ros_stereo_eric.cc</code>：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;algorithm&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;fstream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;chrono&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;ros/ros.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cv_bridge/cv_bridge.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/subscriber.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/time_synchronizer.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;message_filters/sync_policies/approximate_time.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;ros/package.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">\"../../../include/System.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ImageGrabber</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    ImageGrabber(ORB_SLAM2::System* pSLAM):mpSLAM(pSLAM)&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">GrabStereo</span><span class=\"params\">(<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr&amp; msgLeft,<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr&amp; msgRight)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    ORB_SLAM2::System* mpSLAM;</span><br><span class=\"line\">    <span class=\"keyword\">bool</span> do_rectify;</span><br><span class=\"line\">    cv::Mat M1l,M2l,M1r,M2r;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ros::init(argc, argv, <span class=\"string\">\"Stereo_eric\"</span>);</span><br><span class=\"line\">    ros::start();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">string</span> packagePath = ros::package::getPath(<span class=\"string\">\"ORB_SLAM2\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">string</span> configPath = packagePath + <span class=\"string\">\"//config//ros_stereo_eric.yaml\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    cv::<span class=\"function\">FileStorage <span class=\"title\">fsSettings</span><span class=\"params\">(configPath, cv::FileStorage::READ)</span></span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!fsSettings.isOpened())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"string\">\"ERROR: Wrong path to settings\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">string</span> vocPath = fsSettings[<span class=\"string\">\"vocPath\"</span>];</span><br><span class=\"line\">    <span class=\"built_in\">string</span> settingPath = fsSettings[<span class=\"string\">\"settingPath\"</span>];</span><br><span class=\"line\">    <span class=\"comment\">// Create SLAM system. It initializes all system threads and gets ready to process frames.</span></span><br><span class=\"line\">    ORB_SLAM2::<span class=\"function\">System <span class=\"title\">SLAM</span><span class=\"params\">(vocPath,settingPath,ORB_SLAM2::System::STEREO,<span class=\"literal\">true</span>)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">ImageGrabber <span class=\"title\">igb</span><span class=\"params\">(&amp;SLAM)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">string</span> do_rectify = fsSettings[<span class=\"string\">\"do_rectify\"</span>];</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">stringstream</span> <span class=\"title\">ss</span><span class=\"params\">(do_rectify)</span></span>;</span><br><span class=\"line\">\tss &gt;&gt; boolalpha &gt;&gt; igb.do_rectify;<span class=\"comment\">//boolalpha函数把bool值显示为true或false</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(igb.do_rectify)</span><br><span class=\"line\">    &#123;      </span><br><span class=\"line\">        <span class=\"comment\">// Load settings related to stereo calibration</span></span><br><span class=\"line\">        cv::<span class=\"function\">FileStorage <span class=\"title\">fsSettings</span><span class=\"params\">(settingPath, cv::FileStorage::READ)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!fsSettings.isOpened())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"string\">\"ERROR: Wrong path to settings\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        cv::Mat K_l, K_r, P_l, P_r, R_l, R_r, D_l, D_r;</span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"LEFT.K\"</span>] &gt;&gt; K_l;</span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"RIGHT.K\"</span>] &gt;&gt; K_r;</span><br><span class=\"line\"></span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"LEFT.P\"</span>] &gt;&gt; P_l;</span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"RIGHT.P\"</span>] &gt;&gt; P_r;</span><br><span class=\"line\"></span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"LEFT.R\"</span>] &gt;&gt; R_l;</span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"RIGHT.R\"</span>] &gt;&gt; R_r;</span><br><span class=\"line\"></span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"LEFT.D\"</span>] &gt;&gt; D_l;</span><br><span class=\"line\">        fsSettings[<span class=\"string\">\"RIGHT.D\"</span>] &gt;&gt; D_r;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">int</span> rows_l = fsSettings[<span class=\"string\">\"LEFT.height\"</span>];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> cols_l = fsSettings[<span class=\"string\">\"LEFT.width\"</span>];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rows_r = fsSettings[<span class=\"string\">\"RIGHT.height\"</span>];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> cols_r = fsSettings[<span class=\"string\">\"RIGHT.width\"</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(K_l.empty() || K_r.empty() || P_l.empty() || P_r.empty() || R_l.empty() || R_r.empty() || D_l.empty() || D_r.empty() ||</span><br><span class=\"line\">                rows_l==<span class=\"number\">0</span> || rows_r==<span class=\"number\">0</span> || cols_l==<span class=\"number\">0</span> || cols_r==<span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cerr</span> &lt;&lt; <span class=\"string\">\"ERROR: Calibration parameters to rectify stereo are missing!\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        cv::initUndistortRectifyMap(K_l,D_l,R_l,P_l.rowRange(<span class=\"number\">0</span>,<span class=\"number\">3</span>).colRange(<span class=\"number\">0</span>,<span class=\"number\">3</span>),cv::Size(cols_l,rows_l),CV_32F,igb.M1l,igb.M2l);</span><br><span class=\"line\">        cv::initUndistortRectifyMap(K_r,D_r,R_r,P_r.rowRange(<span class=\"number\">0</span>,<span class=\"number\">3</span>).colRange(<span class=\"number\">0</span>,<span class=\"number\">3</span>),cv::Size(cols_r,rows_r),CV_32F,igb.M1r,igb.M2r);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ros::NodeHandle nh;</span><br><span class=\"line\"></span><br><span class=\"line\">    message_filters::Subscriber&lt;sensor_msgs::Image&gt; left_sub(nh, <span class=\"string\">\"/camera/left/image_raw\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">    message_filters::Subscriber&lt;sensor_msgs::Image&gt; right_sub(nh, <span class=\"string\">\"camera/right/image_raw\"</span>, <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> message_filters::sync_policies::ApproximateTime&lt;sensor_msgs::Image, sensor_msgs::Image&gt; sync_pol;</span><br><span class=\"line\">    message_filters::Synchronizer&lt;sync_pol&gt; sync(sync_pol(<span class=\"number\">10</span>), left_sub,right_sub);</span><br><span class=\"line\">    sync.registerCallback(boost::bind(&amp;ImageGrabber::GrabStereo,&amp;igb,_1,_2));</span><br><span class=\"line\"></span><br><span class=\"line\">    ros::spin();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Stop all threads</span></span><br><span class=\"line\">    SLAM.Shutdown();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Save camera trajectory</span></span><br><span class=\"line\">    SLAM.SaveKeyFrameTrajectoryTUM(<span class=\"string\">\"KeyFrameTrajectory_TUM_Format.txt\"</span>);</span><br><span class=\"line\">    SLAM.SaveTrajectoryTUM(<span class=\"string\">\"FrameTrajectory_TUM_Format.txt\"</span>);</span><br><span class=\"line\">    SLAM.SaveTrajectoryKITTI(<span class=\"string\">\"FrameTrajectory_KITTI_Format.txt\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    ros::shutdown();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> ImageGrabber::GrabStereo(<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr&amp; msgLeft,<span class=\"keyword\">const</span> sensor_msgs::ImageConstPtr&amp; msgRight)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Copy the ros image message to cv::Mat.</span></span><br><span class=\"line\">    cv_bridge::CvImageConstPtr cv_ptrLeft;</span><br><span class=\"line\">    <span class=\"keyword\">try</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        cv_ptrLeft = cv_bridge::toCvShare(msgLeft);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (cv_bridge::Exception&amp; e)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        ROS_ERROR(<span class=\"string\">\"cv_bridge exception: %s\"</span>, e.what());</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    cv_bridge::CvImageConstPtr cv_ptrRight;</span><br><span class=\"line\">    <span class=\"keyword\">try</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        cv_ptrRight = cv_bridge::toCvShare(msgRight);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (cv_bridge::Exception&amp; e)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        ROS_ERROR(<span class=\"string\">\"cv_bridge exception: %s\"</span>, e.what());</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(do_rectify)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        cv::Mat imLeft, imRight;</span><br><span class=\"line\">        cv::remap(cv_ptrLeft-&gt;image,imLeft,M1l,M2l,cv::INTER_LINEAR);</span><br><span class=\"line\">        cv::remap(cv_ptrRight-&gt;image,imRight,M1r,M2r,cv::INTER_LINEAR);</span><br><span class=\"line\">        mpSLAM-&gt;TrackStereo(imLeft,imRight,cv_ptrLeft-&gt;header.stamp.toSec());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">    &#123;   <span class=\"comment\">//cv_ptrLeft-&gt;image  is  cv::Mat</span></span><br><span class=\"line\">        mpSLAM-&gt;TrackStereo(cv_ptrLeft-&gt;image,cv_ptrRight-&gt;image,cv_ptrLeft-&gt;header.stamp.toSec());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>ROS/ORB_SLAM2/config</code>目录下添加配置文件<code>ros_stereo_eric.yaml</code>：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">%YAML:1.0</span></span><br><span class=\"line\"><span class=\"attr\">vocPath:</span> <span class=\"string\">\"/home/eric/slam/ORB_SLAM2/Vocabulary/ORBvoc.txt\"</span></span><br><span class=\"line\"><span class=\"attr\">settingPath:</span> <span class=\"string\">\"/home/eric/slam/ORB_SLAM2/Examples/Stereo/KITTI03.yaml\"</span></span><br><span class=\"line\"><span class=\"attr\">do_rectify:</span> <span class=\"string\">\"false\"</span></span><br></pre></td></tr></table></figure>\n<p>下载KITTI-odometry/data_odometry_gray数据集，保存<code>/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray</code>。</p>\n<p>测试系统，启动launch文件，同时启动图像发布者节点和ORB_SLAM2 Stereo_eric节点：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roslaunch my_image_transport stereo_image_transport.launch</span><br></pre></td></tr></table></figure>\n<p>测试效果：</p>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://wiki.ros.org/image_transport/Tutorials/PublishingImages\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/image_transport/Tutorials/PublishingImages</a></li>\n<li><a href=\"http://wiki.ros.org/image_transport/Tutorials/SubscribingToImages\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/image_transport/Tutorials/SubscribingToImages</a></li>\n<li><a href=\"https://blog.csdn.net/github_30605157/article/details/50990493\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/github_30605157/article/details/50990493</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关运行ORB_SLAM2系统ROS模块，包括单目和双目部分的学习内容。</p>","more":"<p>ORB_SLAM2运行ROS模块需要从相应的话题接收图像用于SLAM系统，对于我这种不方便使用相机进行实时采集图像的渣渣来说，使用数据集图像是很好的选择。因此需要从本地数据集中获取图像，再利用ROS中的话题进行图像的发布和接收。下面的内容将介绍利用ROS进行简单的图像发布和接收操作，以及ORB_SLAM2系统ROS模块运行起来的整个过程。</p>\n<blockquote>\n<p>系统环境</p>\n<ul>\n<li>Ubuntu 16.04</li>\n<li>ROS kinetic</li>\n</ul>\n</blockquote>\n<h2 id=\"基于ROS话题发布、接收图像\"><a href=\"#基于ROS话题发布、接收图像\" class=\"headerlink\" title=\"基于ROS话题发布、接收图像\"></a>基于ROS话题发布、接收图像</h2><h3 id=\"创建相关软件包\"><a href=\"#创建相关软件包\" class=\"headerlink\" title=\"创建相关软件包\"></a>创建相关软件包</h3><p>在<code>catkin_ws/src</code>目录下新建软件包并编译：</p>\n<!--�330-->\n<h3 id=\"创建图像发布者程序\"><a href=\"#创建图像发布者程序\" class=\"headerlink\" title=\"创建图像发布者程序\"></a>创建图像发布者程序</h3><p>新建<code>my_image_transport/src/my_publisher.cpp</code>：</p>\n<!--�331-->\n<p>代码解释：</p>\n<ul>\n<li>line 1-4：<code>ros.h</code>头文件是所有的ros节点中必须要包含的，下面三个分别是实现图像的发布和订阅，调用opencv库，完成opencv图像格式转化为ROS图像格式所要用到的头文件；</li>\n<li>line 11：告知结点管理器要在<code>camera/image</code>话题发布图像消息，参数1是话题名称，话题2是缓冲区大小（即消息队列的长度，在发布图像消息时消息队列的长度只能是1）；</li>\n<li>line 12：根据运行时给定的参数（图像文件的路径）读取图像；</li>\n<li>line 14：将opencv格式的图像转化为ROS所支持的消息类型，从而发布到相应的话题上；</li>\n<li>line 16-21：发布图片消息，使消息类型匹配的节点订阅该消息。</li>\n</ul>\n<h3 id=\"创建图像订阅者程序\"><a href=\"#创建图像订阅者程序\" class=\"headerlink\" title=\"创建图像订阅者程序\"></a>创建图像订阅者程序</h3><p>新建<code>my_image_transport/src/my_subscriber.cpp</code>：</p>\n<!--�332-->\n<p>代码解释：</p>\n<ul>\n<li>line 6：回调函数，当有新的图像消息到达<code>camera/image</code>时，该函数就会被调用；</li>\n<li>line 10：显示捕捉到的图像，其中<code>cv_bridge::toCvShare(msg, &quot;bgr8&quot;)-&gt;image</code>用于将ROS图像消息转化为Opencv支持的图像格式（采用BGR8编码方式）。这部分用法恰好与上一节中发布者节点中的<code>CvImage(std_msgs::Header(), &quot;bgr8&quot;, image).toImageMsg();</code> 的作用相反</li>\n<li>line 11：刷新图像的频率，实践过程中发现如果注释这一行图像将无法在窗口的显示</li>\n</ul>\n<h3 id=\"相关配置文件\"><a href=\"#相关配置文件\" class=\"headerlink\" title=\"相关配置文件\"></a>相关配置文件</h3><ol>\n<li><p><code>CMakeLists.txt</code>内容</p>\n<!--�333-->\n</li>\n<li><p><code>package.xml</code>文件中添加</p>\n<!--�334-->\n</li>\n</ol>\n<h3 id=\"编译软件包\"><a href=\"#编译软件包\" class=\"headerlink\" title=\"编译软件包\"></a>编译软件包</h3><!--�335-->\n<h3 id=\"运行节点\"><a href=\"#运行节点\" class=\"headerlink\" title=\"运行节点\"></a>运行节点</h3><p>单独开启一个终端执行<code>roscore</code>，启动ros节点管理器。</p>\n<p>开启另一个终端，启动发布者节点：</p>\n<!--�336-->\n<p>运行订阅者节点：</p>\n<!--�337-->\n<p>运行结果如下所示：</p>\n\n<h3 id=\"查看当前活动节点及交互情况\"><a href=\"#查看当前活动节点及交互情况\" class=\"headerlink\" title=\"查看当前活动节点及交互情况\"></a>查看当前活动节点及交互情况</h3><p>查看当前活动节点：</p>\n<!--�338-->\n<p>查看各节点交互情况：</p>\n<!--�339-->\n<p><img src=\"http://wiki.ros.org/image_transport/Tutorials/ExaminingImagePublisherSubscriber?action=AttachFile&amp;do=get&amp;target=transport_graph.png\" alt=\"transport_graph.png\"></p>\n<p>可以执行<code>rosnode kill</code>命令关闭相关节点。</p>\n<h2 id=\"ORB-SLAM2-ROS模块结点的编译\"><a href=\"#ORB-SLAM2-ROS模块结点的编译\" class=\"headerlink\" title=\"ORB_SLAM2 ROS模块结点的编译\"></a>ORB_SLAM2 ROS模块结点的编译</h2><p>在环境变量<code>ROS_PACKAGE_PATH</code>中添加<code>Examples/ROS/ORB_SLAM2</code>的路径：</p>\n<!--�340-->\n<p>在<code>~/slam/ORB_SLAM2</code>目录下执行：</p>\n<!--�341-->\n<p>等待编译成功。</p>\n<h2 id=\"ROS-Mono\"><a href=\"#ROS-Mono\" class=\"headerlink\" title=\"ROS Mono\"></a>ROS Mono</h2><p>首先在<code>my_image_transport</code>目录下创建图像发布者程序<code>mono_tum.cpp</code>：</p>\n<!--�342-->\n<p>在<code>CMakeLists.txt</code>文件中添加：</p>\n<!--�343-->\n<p>下载TUM-rgbd_dataset_freiburg1_xyz数据集，保存<code>/media/eric/linux/DATA/TUM/rgbd_dataset_freiburg1_xyz</code>。</p>\n<p>测试系统，启动ORB_SLAM2 Mono：</p>\n<!--�344-->\n<p>启动发布者节点：</p>\n<!--�345-->\n<p>测试效果：</p>\n\n<h2 id=\"ROS-Stereo\"><a href=\"#ROS-Stereo\" class=\"headerlink\" title=\"ROS Stereo\"></a>ROS Stereo</h2><p>首先在<code>my_image_transport</code>目录下创建图像发布者程序左相机节点<code>stereo_left_kitti.cpp</code>：</p>\n<!--�346-->\n<p>右相机节点<code>stereo_right_kitti</code>：</p>\n<!--�347-->\n<p>在<code>CMakeLists.txt</code>文件中添加：</p>\n<!--�348-->\n<p>在<code>my_image_transport/config</code>目录下添加配置文件<code>stereo_kitti.yaml</code>，保存数据集路径：</p>\n<!--�349-->\n<p>这里需要启动三个节点，每个单独启动会比较麻烦，所以使用ROS Launch文件，同时启动左、右图像发布节点和ORB_SLAM2 Stereo_eric节点。在<code>my_image_transport/launch</code>目录下添加ROS节点启动文件<code>stereo_image_transport.yaml</code>：</p>\n<!--�350-->\n<p>修改ORB_SLAM2的<code>ros_stereo.cc</code>文件，新建为<code>ros_stereo_eric.cc</code>：</p>\n<!--�351-->\n<p><code>ROS/ORB_SLAM2/config</code>目录下添加配置文件<code>ros_stereo_eric.yaml</code>：</p>\n<!--�352-->\n<p>下载KITTI-odometry/data_odometry_gray数据集，保存<code>/media/eric/linux/DATA/KITTI/odometry/data_odometry_gray</code>。</p>\n<p>测试系统，启动launch文件，同时启动图像发布者节点和ORB_SLAM2 Stereo_eric节点：</p>\n<!--�353-->\n<p>测试效果：</p>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ol>\n<li><a href=\"http://wiki.ros.org/image_transport/Tutorials/PublishingImages\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/image_transport/Tutorials/PublishingImages</a></li>\n<li><a href=\"http://wiki.ros.org/image_transport/Tutorials/SubscribingToImages\" target=\"_blank\" rel=\"noopener\">http://wiki.ros.org/image_transport/Tutorials/SubscribingToImages</a></li>\n<li><a href=\"https://blog.csdn.net/github_30605157/article/details/50990493\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/github_30605157/article/details/50990493</a></li>\n</ol>"},{"title":"论文阅读之《Past, Present, and Future of SLAM》","date":"2018-10-17T14:48:59.000Z","copyright":true,"_content":"\n---\n\n本篇文章记录SLAM综述性文章《Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age》，只对重点部分作详细翻译，其余为本人根据自己的理解对内容概括性的总结。\n\n<!--more--->\n\n## 概述\n\n一、介绍SLAM现行制定的标准\n\n二、总结相关工作（包括一系列关于**长时间建图中的鲁棒性和可扩展性**、**用于建图的度量和语义表示**、理论上的性能保证、主动SLAM和探索、以及其他的前沿技术）\n\n三、介绍开放的挑战和新的研究问题\n\n四、作者对两个问题的看法，即机器人需要SLAM吗？SLAM问题解决了嘛？\n\n## **Introduciton**\n\nSLAM包括同时的机器人状态估计和环境模型（地图）重建，机器人配置片上传感器，重建的环境是由机器人传感器感知到的。简单的情况下，机器人的状态使用其位姿（位置和方向/姿态）表示，当然机器人的状态还会包含其他的量，如机器人速度、传感器偏差、校准参数。地图是用于描述机器人所处环境的我们感兴趣部分（如路标点位置、障碍物）的表示。\n\n需要构建环境地图的原因包括两方面。首先，地图经常被用于支撑其他任务；例如，一个地图可以通知路径规划或者提供可供用户操作的直观的可视化。其次地图能够限制机器人状态估计中积累的误差。没有地图时轨迹估计很快就会发生漂移；如果由地图，机器人就可以通过再次访问已访问的区域对位置错误进行重置，即所谓的回环检测。SLAM适用于所有没有先验经验需要创建地图的场景应用。\n\n一些机器人的应用中环境地图是作为已知的先验经验。\n\nSLAM问题的普及源于移动机器人的室内应用的出现。室内的操作就要排除GPS的使用，GPS是可以用于限制位置偏差的。SLAM为用户构建的地图提供了一个吸引人的替代方案，显示出在没有专门的本地化基础架构的情况下，机器人操作是可能的。\n\n**古典时代**（1986-2004）（**the** **classical** **age**）：对SLAM的主要概率公式进行了介绍，包括基于扩展卡尔曼滤波器的方法、RaoBlackwellised粒子滤波器和最大似然估计；而且还描绘了与效率和强大数据关联相关的基本挑战。[14、94、299、298]\n\n**算法分析时代**（2004-2015）（**the** **algorithmic-analysis** **age**）：研究了SLAM的基本性质，包括可观测性、收敛性和一致性。该时期对稀疏性对于高效SLAM求解器的关键作用有了理解，并发展出主要的开源SLAM库。[89]\n\n- 底层SLAM（前端）涵盖了其他的研究领域，如机器视觉和信号处理；\n\n- 在高层的后端，SLAM是几何学、图论、优化和概率的组合。而且，对于一个SLAM专家必须处理实际的从传感器建模到系统集成等各个方面的问题。\n\n**Do autonomous robots really need SLAM?**\n\n本文对SLAM的现状进行了广泛的概述，并提供了部分社区对SLAM研究的开放性问题和未来发展方向的看法。其他关于SLAM的综述性文章：\n\n| Year | Topic                                         |              Reference               |\n| ---- | --------------------------------------------- | :----------------------------------: |\n| 2006 | Probabilistic approaches and data association |  Durrant-Whyte and Bailey [14, 94]   |\n| 2008 | Filtering approaches                          |         Aulinas et al. [12]          |\n| 2008 | Visual SLAM                                   |  Neira et al. (special issue) [220]  |\n| 2011 | SLAM back-end                                 |        Grisetti et al. [129]         |\n| 2011 | Observability, consistency and convergence    |       Dissanayake et al. [89]        |\n| 2012 | Visual odometry                               | Scaramuzza and Fraundofer [115, 274] |\n| 2016 | Multi robot SLAM                              |         Saeedi et al. [271]          |\n| 2016 | Visual place recognition                      |          Lowry et al. [198]          |\n\n### **Do autonomous robots really need SLAM?**\n\n回答这个问题需要理解SLAM特殊在哪。SLAM旨在利用自身运动的测量和回环检测建立场景的全局一致的表示。关键点在于回环检测：如果忽略了回环检测，SLAM退化为里程计。在早期的应用中，里程计是通过整合在车轮上的编码器获取到的，通过车轮里程计获取到的位姿检测很快就会发生漂移，使得估计在运动数米后就不可用。这也是推动SLAM发展的主要原因之一：外界场景路标点的观测对于消除轨迹漂移是有帮助的，能够尽可能的矫正轨迹。然而，目前更多的里程计算法都是基于视觉和惯性信息，具有很少的漂移（<轨迹长度的0.5%）。这种情况下是否需要SLAM呢？分三方面回答。\n\n- 过去十年中完成的SLAM研究工作是产生目前代表现有技术状态的视觉-惯性里程计算法；在这个意义上，视觉惯性导航（VIN）就是SLAM：VIN可以看作是忽略掉回环检测或者位置识别模块的简化SLAM系统。更一般意义上，SLAM导致在比其他知识领域（例如，航天工程中的惯性导航）更早地考虑到的更具挑战性配置（即，没有GPS，低质量传感器）下研究传感器融合。\n- 关于回环检测。忽略回环检测执行里程计的情况下，机器人会把世界解释成一个没有尽头的走廊，机器人在里面一直无限地对新的区域进行探测。回环检测事件能够告诉机器人该走廊是保持相交的。这样回环检测的好处就清楚了：通过回环检测，机器人能够理解环境真实的拓扑结构，并且能够找到位置间的快捷/最短路径。因此，如果得到正确的环境拓扑结构是SLAM的优点之一，为什么不简单地忽略度量信息，只是做位置识别/回环检测呢？答案是：度量信息使得位置识别更简单、更健壮；度量重建使得机器人有闭环检测的机会，并允许丢弃虚假闭环。因此，SLAM在原则上是多余的（一个oracle位置识别模块就足以进行拓扑映射），SLAM为错误的数据关联和感知别名提供了一个自然的防御，与环境中的不同位置相对应的相似的场景会欺骗位置识别模块。SLAM地图提供了一种预测并验证未来的测量的机制：该机制对于健壮性测量是关键的。\n- 由于许多应用隐式或显式地需要全局一致的地图，因此需要使用SLAM。例如在很多军事和民用应用中，机器人的目标是探测环境，并提供一个可供用户操作的地图。另一个例子是，机器人必须执行结构检测（例如建筑、桥梁等）；还有需要进行全局一致的3D重建时。\n\n因此，机器人研究者需要设计一个SLAM系统时，他将面对多种设计选择。例如，一个拓扑地图能够用于分析给定地点的可达性，但是并不适合于路径规划和底层的控制；一个局部一致的度量地图非常适合用于避障以及局部与环境的交互作用，但牺牲了精确性；一个全局一致的度量地图允许机器人执行全局的路径规划，但是计算和维护地图又是高计算复杂度性的。一个更通用的选择更合适的SLAM系统的方法是将SLAM看作是一种机制，完成足够的统计计算来总结机器人的所有已观测到的数据，在这种情况下，在这个压缩表示中保留哪些信息是非常依赖于任务本身的。\n\n### **Is SLAM solved?**\n\n这是机器人社区经常被问到的问题。回答该问题的难度在于问题本身：SLAM是一个非常开放的话题，这个问题只适用于给定的机器人/环境/性能组合。尤其是，一旦下面几方面内容明确了，我们就可以评估SLAM问题的成熟度：\n\n- **机器人**(**robot**)：运动的类型（例如动态、最大速度）、可用传感器（例如分辨率、采样率）、可用的计算资源；\n- **场景**/**环境**（**environment**）：平面或三维空间、自然或人造路标点的存在、动态元素的数量、对称性的量和感知混叠的风险。请注意，这些中的许多方面实际上取决于传感器-环境对：例如，对于2D激光扫描仪，两个房间可能看起来相同（感知别名），而相机可能会根据外观线索辨别；\n- **性能要求**（**performance requirements**）：机器人状态估计中的精确性要求、环境表示的精确性和类型（例如基于路标点的或稠密的）、成功率（满足精度范围的测试的百分比）、估计延迟、最大可操作时间、建图区域的最大尺寸范围。\n\n例如，在保证足够的精确性（<10cm）以及足够的健壮性（即低错误率）的前提下，使用一个装有车轮编码器和激光扫描器的机器人构建2D室内场景的地图，可以认为是基本可以解决的（一个工业系统执行SLAM的例子是the *Kuka Navigation Solution*）。同样地，基于缓慢移动的机器人的视觉SLAM和视觉-惯性测量法都可以认为是成熟的研究领域。另一方面，其他的机器人/环境/性能组合仍需要大量的基础性研究。在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易就会失败。同时，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。本文将提供这些公开问题的综合概述，等等。\n\n我们在这一节最后对SLAM的未来进行更广泛的考虑。我们认为，SLAM正在进入第三个时代，即**鲁棒感知时代**（**the** **robust-perception** **age**），其特点是具有以下关键要求：\n\n- **性能强劲**（**robust performance**）：SLAM系统能够在广泛的环境中以较低的故障率长时间运行；系统具备故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择；\n- **高层次的理解力**（**high-level understanding**）：SLAM系统超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；\n- **资源意识**（**resource awareness**）：SLAM系统可以针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；\n- **任务驱动推理**（**task-driven inference**）：SLAM系统产生自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。\n\n### 论文组织结构\n\n**SectionII：**SLAM标准的制定和体系结构\n\n**Section III：**解决终身（长时间）SLAM中的鲁棒性\n\n**Section IV：**处理可扩展性\n\n**Section V：**讨论如何表示环境的几何形状\n\n**Section VI：**将环境表征的问题扩展到语义信息的建模。\n\n**Section VII：**提供了关于SLAM的理论方面的当前成就的概述\n\n**Section VIII：**扩大了讨论范围，并回顾了使用决策来改善SLAM结果质量的活动SLAM问题\n\n**Section IX：**概述了SLAM的最新趋势，包括非常规传感器的使用\n\n**Section X：**提供最后的评论 \n\n尽管SLAM有其独特的特性，但它是与计算机视觉、计算几何、控制理论中有关问题相关的，这些领域的交叉使用是实现快速发展的必要条件。\n\n## III. LONG-TERM AUTONOMY I: ROBUSTNESS\n\n影响SLAM系统鲁棒性因素：算法层面、硬件层面、软件层面。\n\n### 算法层面\n现有SLAM算法的限制，如无法处理动态环境、极端场景。\n#### 数据关联（data association）与感知混淆\n涉及的一个重要原因就是数据关联错误。如基于特征的vSLAM需要关联每一个视觉特征点到确定的路标点，**感知混淆（Perceptual aliasing）**（即对于不同的传感器输入引起相同的传感器信号）会使得问题解决变得困难，导致产生错误测量状态匹配（外点、错误匹配等），进一步影响后端优化；另外，数据关联如果错误地将测量数据判断为错误测量，就只能以估算的精度为代价，使用较少的测量值进行估算了。\n##### short-term数据关联\n传感器采样速率相对于机器人运动变化足够大，直观上可以认为传感器视角不会发生剧烈的变化，因此可以完成诸如特征匹配或光流法，从而避免错误的数据关联。\n##### long-term数据关联\n更具挑战性，涉及到闭合回环检测及验证。\n蛮力的方法处理回环检测是不切实际的。基于视觉特征的Bag-of-words方法[282]通过引入分层的词汇树、量化特征空间，使得搜索更加高效。但是不能处理严重的照明变化。因此提出了一些新的方式，如匹配序列[213]，将不同的视觉外观聚集成统一的表示[69]，或使用空间和外观信息[140]，关于此类的综述见[198]。\n闭合回环验证使用几何验证的方法确定闭合回环的质量。基于视觉的应用中，RANSAC[274]用于几何验证和异常值剔除。基于激光的方法可以通过检测当前scan与已有的地图的匹配度验证闭合回环，例如**残差**。\n当然，错误的闭合回环也是无法避免的。\n\n#### 动态场景\n挑战一：SLAM系统必须要检测、剔除、追踪环境的变化，主流的方法就是剔除场景的动态变化部分，一些方法将动态元素一同建模。\n挑战二：SLAM系统必须对永久性或半永久性变化进行建模，并理解如何、何时更新地图。\n\n### 硬件层面\n传感器本身、执行器退化引起。如何检测降级的传感器操作？ 如何调整传感器噪声统计数据（协方差，偏见）？\n\n### 软件层面\n集成和测试是SLAM和机器人技术的关键方面，它们同样会引起误差。\n\n## V. REPRESENTATION I: METRIC REASONING\n介绍SLAM中的模型几何，即度量表达方法。2D情况有基于路标的地图表达和占用网格地图表达。\n- 基于路标的稀疏表达方式。可以是环境中可分辨特征相关联的3D路标点，例如线、角。前提是路标是可区分的，例如描述子。目前大部分的研究关注点特征的估计，也扩展到线、线段、圆弧[200]。\n\n- 低层次的原始稠密表达。可以提供3D物体的高分辨率模型，适用于机器人研究中的避障和路径规划或者可视化、渲染。原始表达使用点云或多边形、面元地图（surfels maps）描述3D几何物体。这种方式比较笨重，因为需要存储大量的数据信息。\n\n- 边界和空间划分密集表示。明确地表示surfaces (or boundaries) and volumes。空间划分表示方法最具代表性的是spatial-occupancy enumeration，该方法将三维空间划分为相同的立方体（体素）并排列在规则的3D网格中。其他方法还包括octree（应用于3D）、Polygonal Map octree和Binary Space-Partitioning tree等。\n\n  > vSLAM中关于稀疏（基于特征的）表达方式与稠密表达方式、直接法的比较。\n  >\n  > - 基于特征的方法取决于特征的类型。\n  > - 稠密、直接表达方式更适用于低纹理、散焦和运动模糊的场景，但需要高计算能力和实时性能。\n  >\n  > - 半稠密方法克服了稠密法高计算需求的缺点。\n  > - 半直接法一定程度上同时使用了稀疏特征和直接法（被证明更高效，SVO[113]），允许结构和运动同时估计。\n\n- 高层次的基于物体的表达。\nSLAM++。\n## VI. REPRESENTATION II: SEMANTIC REASONING\n\n基于视觉的拓扑地图SLAM系统综述[198]。\n\n### SLAM help Semantics\n比较早的关于分割度量地图的方法[215]，offline的方法，使用2D激光扫描器构建几何地图。\nonline语义地图构建系统[257、258]，将传感、分类、位置识别组合，使用激光和相机构建环境的语义地图。\n[41]使用了运动优化，将粗略的语义分割与不同的对象检测器互。\n[249]使用单目SLAM系统提高视频中对象识别任务的性能。\n### Semantics helps SLAM\n既然可以在SLAM构建的地图中识别物体，那也可以使用关于物体的几何先验知识去优化地图的估计。这方面的研究：\n[63、71]基于稀疏特征的单目SLAM系统，应用于小尺度环境中。\n[84]稠密的地图表达。\n[272]使用RGB-D传感器提出一个SLAM系统，该系统是基于对环境中的已知物体的检测。\n\n### Joint SLAM and Semantics inference\n\n将单目SLAM和地图分割联合。\n\nonline系统[106]构建模型，使用曼哈顿世界假设，针对室内环境分割主要平面部分的地图。\n\n[16]提出使用场景的几何和语义属性估计相机参数和场景点、物体标签，offline。\n\n[136、184、275]offline、[310]online。\n\n\n## 研究点思考\n\n首先，对于SLAM问题，我们需要考虑的四个方面：\n- 机器人\n- 环境\n- 传感器-环境组合\n- 性能需求\n\n因此可以考虑不同的机器人/环境/性能组合进行基础性研究的可能性。同时，在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易失败。此外，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。\n目前，针对SLAM系统的研究可以从下面几个方面中开展：\n- **鲁棒性性能研究**：故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择\n- 高层次的提升研究：超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；\n- **资源利用研究**：针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；\n- **任务驱动方向研究**：自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。\n\n具体的研究点思考如下。\n### 鲁棒性研究\n动态环境下的处理，如何检测、提出、追踪变化，可以将变化剔除[221]、考虑到模型[266, 312, 313]\n如何应对白天和晚上剧烈的光照变化、季节的变化、环境结构的变化（新建筑物->旧建筑物）白天、夜晚回环检测的应对方法[69, 213、223]\n对于数据异常情况（外点的出现）的处理，目前SLAM系统不具备提前感知即将面临的失败的能力、无法提供恢复机制应对已经发生的失败情况\n硬件环境、传感器异常情况的处理？如何检测？如何调整？\n极端环境下的研究，例如水下[20, 100, 102, 166]\n非刚性物体的应对方法，非刚性地图的研究[245, 246] 、[36] and [304]、[4, 5, 128]、[225]\n\n### 可扩展性研究\n因子图优化复杂性降低方法\n地图的存储[201、172]\n多机器人[271]\n多机器人回环检测的研究，机器人之间可能无法共享同一个参考图像帧，机器人传感器探测视角也有所不同[151]\n地图中哪些信息需要丢弃、更新、保存，该以怎样的频率更新地图信息？？？\n在面对严格的带宽限制和通信中断时，保证多机器人团队的可靠运行？？？ [70] \n\n### 度量表达研究\n基于路标的地图\n占用网格地图，地图标准[147]\n高层次的表达方式，机器人不能识别出自己所处的环境类型，例如room vs. corridor，当然可以使用更复杂的模型（如parameterized primitive instancing）解决这种问题。\n更紧凑的表达方法可以降低大尺度环境的地图大小。\n最佳的（可选择性的）表示，简单的室内环境使用参数化的原语、负责的室外环境选择mesh模型，如何比较不同的表达方式、如何选择最有的表达方式？？？[262、285]\n自动的自适应的表达方式，希望机器人可以根据人物和环境的复杂性自主地选择更复杂或更简单的表达方式。这将对长时间的导航带来很大的帮助。\n\n### 语义表达\n\n不仅仅是分类。\n\n## 引用文献\n14\n299\n298\n89\n94\n12\n220\n129\n115\n274\n271\n198\n282","source":"_posts/论文阅读之《Past, Present, and Future of SLAM》.md","raw":"---\ntitle: 论文阅读之《Past, Present, and Future of SLAM》\ndate: 2018-10-17 22:48:59\ntags: \n  - SLAM\ncategories: \n  - 机器人\n  - SLAM\n  - 论文阅读\ncopyright: true\n---\n\n---\n\n本篇文章记录SLAM综述性文章《Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age》，只对重点部分作详细翻译，其余为本人根据自己的理解对内容概括性的总结。\n\n<!--more--->\n\n## 概述\n\n一、介绍SLAM现行制定的标准\n\n二、总结相关工作（包括一系列关于**长时间建图中的鲁棒性和可扩展性**、**用于建图的度量和语义表示**、理论上的性能保证、主动SLAM和探索、以及其他的前沿技术）\n\n三、介绍开放的挑战和新的研究问题\n\n四、作者对两个问题的看法，即机器人需要SLAM吗？SLAM问题解决了嘛？\n\n## **Introduciton**\n\nSLAM包括同时的机器人状态估计和环境模型（地图）重建，机器人配置片上传感器，重建的环境是由机器人传感器感知到的。简单的情况下，机器人的状态使用其位姿（位置和方向/姿态）表示，当然机器人的状态还会包含其他的量，如机器人速度、传感器偏差、校准参数。地图是用于描述机器人所处环境的我们感兴趣部分（如路标点位置、障碍物）的表示。\n\n需要构建环境地图的原因包括两方面。首先，地图经常被用于支撑其他任务；例如，一个地图可以通知路径规划或者提供可供用户操作的直观的可视化。其次地图能够限制机器人状态估计中积累的误差。没有地图时轨迹估计很快就会发生漂移；如果由地图，机器人就可以通过再次访问已访问的区域对位置错误进行重置，即所谓的回环检测。SLAM适用于所有没有先验经验需要创建地图的场景应用。\n\n一些机器人的应用中环境地图是作为已知的先验经验。\n\nSLAM问题的普及源于移动机器人的室内应用的出现。室内的操作就要排除GPS的使用，GPS是可以用于限制位置偏差的。SLAM为用户构建的地图提供了一个吸引人的替代方案，显示出在没有专门的本地化基础架构的情况下，机器人操作是可能的。\n\n**古典时代**（1986-2004）（**the** **classical** **age**）：对SLAM的主要概率公式进行了介绍，包括基于扩展卡尔曼滤波器的方法、RaoBlackwellised粒子滤波器和最大似然估计；而且还描绘了与效率和强大数据关联相关的基本挑战。[14、94、299、298]\n\n**算法分析时代**（2004-2015）（**the** **algorithmic-analysis** **age**）：研究了SLAM的基本性质，包括可观测性、收敛性和一致性。该时期对稀疏性对于高效SLAM求解器的关键作用有了理解，并发展出主要的开源SLAM库。[89]\n\n- 底层SLAM（前端）涵盖了其他的研究领域，如机器视觉和信号处理；\n\n- 在高层的后端，SLAM是几何学、图论、优化和概率的组合。而且，对于一个SLAM专家必须处理实际的从传感器建模到系统集成等各个方面的问题。\n\n**Do autonomous robots really need SLAM?**\n\n本文对SLAM的现状进行了广泛的概述，并提供了部分社区对SLAM研究的开放性问题和未来发展方向的看法。其他关于SLAM的综述性文章：\n\n| Year | Topic                                         |              Reference               |\n| ---- | --------------------------------------------- | :----------------------------------: |\n| 2006 | Probabilistic approaches and data association |  Durrant-Whyte and Bailey [14, 94]   |\n| 2008 | Filtering approaches                          |         Aulinas et al. [12]          |\n| 2008 | Visual SLAM                                   |  Neira et al. (special issue) [220]  |\n| 2011 | SLAM back-end                                 |        Grisetti et al. [129]         |\n| 2011 | Observability, consistency and convergence    |       Dissanayake et al. [89]        |\n| 2012 | Visual odometry                               | Scaramuzza and Fraundofer [115, 274] |\n| 2016 | Multi robot SLAM                              |         Saeedi et al. [271]          |\n| 2016 | Visual place recognition                      |          Lowry et al. [198]          |\n\n### **Do autonomous robots really need SLAM?**\n\n回答这个问题需要理解SLAM特殊在哪。SLAM旨在利用自身运动的测量和回环检测建立场景的全局一致的表示。关键点在于回环检测：如果忽略了回环检测，SLAM退化为里程计。在早期的应用中，里程计是通过整合在车轮上的编码器获取到的，通过车轮里程计获取到的位姿检测很快就会发生漂移，使得估计在运动数米后就不可用。这也是推动SLAM发展的主要原因之一：外界场景路标点的观测对于消除轨迹漂移是有帮助的，能够尽可能的矫正轨迹。然而，目前更多的里程计算法都是基于视觉和惯性信息，具有很少的漂移（<轨迹长度的0.5%）。这种情况下是否需要SLAM呢？分三方面回答。\n\n- 过去十年中完成的SLAM研究工作是产生目前代表现有技术状态的视觉-惯性里程计算法；在这个意义上，视觉惯性导航（VIN）就是SLAM：VIN可以看作是忽略掉回环检测或者位置识别模块的简化SLAM系统。更一般意义上，SLAM导致在比其他知识领域（例如，航天工程中的惯性导航）更早地考虑到的更具挑战性配置（即，没有GPS，低质量传感器）下研究传感器融合。\n- 关于回环检测。忽略回环检测执行里程计的情况下，机器人会把世界解释成一个没有尽头的走廊，机器人在里面一直无限地对新的区域进行探测。回环检测事件能够告诉机器人该走廊是保持相交的。这样回环检测的好处就清楚了：通过回环检测，机器人能够理解环境真实的拓扑结构，并且能够找到位置间的快捷/最短路径。因此，如果得到正确的环境拓扑结构是SLAM的优点之一，为什么不简单地忽略度量信息，只是做位置识别/回环检测呢？答案是：度量信息使得位置识别更简单、更健壮；度量重建使得机器人有闭环检测的机会，并允许丢弃虚假闭环。因此，SLAM在原则上是多余的（一个oracle位置识别模块就足以进行拓扑映射），SLAM为错误的数据关联和感知别名提供了一个自然的防御，与环境中的不同位置相对应的相似的场景会欺骗位置识别模块。SLAM地图提供了一种预测并验证未来的测量的机制：该机制对于健壮性测量是关键的。\n- 由于许多应用隐式或显式地需要全局一致的地图，因此需要使用SLAM。例如在很多军事和民用应用中，机器人的目标是探测环境，并提供一个可供用户操作的地图。另一个例子是，机器人必须执行结构检测（例如建筑、桥梁等）；还有需要进行全局一致的3D重建时。\n\n因此，机器人研究者需要设计一个SLAM系统时，他将面对多种设计选择。例如，一个拓扑地图能够用于分析给定地点的可达性，但是并不适合于路径规划和底层的控制；一个局部一致的度量地图非常适合用于避障以及局部与环境的交互作用，但牺牲了精确性；一个全局一致的度量地图允许机器人执行全局的路径规划，但是计算和维护地图又是高计算复杂度性的。一个更通用的选择更合适的SLAM系统的方法是将SLAM看作是一种机制，完成足够的统计计算来总结机器人的所有已观测到的数据，在这种情况下，在这个压缩表示中保留哪些信息是非常依赖于任务本身的。\n\n### **Is SLAM solved?**\n\n这是机器人社区经常被问到的问题。回答该问题的难度在于问题本身：SLAM是一个非常开放的话题，这个问题只适用于给定的机器人/环境/性能组合。尤其是，一旦下面几方面内容明确了，我们就可以评估SLAM问题的成熟度：\n\n- **机器人**(**robot**)：运动的类型（例如动态、最大速度）、可用传感器（例如分辨率、采样率）、可用的计算资源；\n- **场景**/**环境**（**environment**）：平面或三维空间、自然或人造路标点的存在、动态元素的数量、对称性的量和感知混叠的风险。请注意，这些中的许多方面实际上取决于传感器-环境对：例如，对于2D激光扫描仪，两个房间可能看起来相同（感知别名），而相机可能会根据外观线索辨别；\n- **性能要求**（**performance requirements**）：机器人状态估计中的精确性要求、环境表示的精确性和类型（例如基于路标点的或稠密的）、成功率（满足精度范围的测试的百分比）、估计延迟、最大可操作时间、建图区域的最大尺寸范围。\n\n例如，在保证足够的精确性（<10cm）以及足够的健壮性（即低错误率）的前提下，使用一个装有车轮编码器和激光扫描器的机器人构建2D室内场景的地图，可以认为是基本可以解决的（一个工业系统执行SLAM的例子是the *Kuka Navigation Solution*）。同样地，基于缓慢移动的机器人的视觉SLAM和视觉-惯性测量法都可以认为是成熟的研究领域。另一方面，其他的机器人/环境/性能组合仍需要大量的基础性研究。在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易就会失败。同时，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。本文将提供这些公开问题的综合概述，等等。\n\n我们在这一节最后对SLAM的未来进行更广泛的考虑。我们认为，SLAM正在进入第三个时代，即**鲁棒感知时代**（**the** **robust-perception** **age**），其特点是具有以下关键要求：\n\n- **性能强劲**（**robust performance**）：SLAM系统能够在广泛的环境中以较低的故障率长时间运行；系统具备故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择；\n- **高层次的理解力**（**high-level understanding**）：SLAM系统超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；\n- **资源意识**（**resource awareness**）：SLAM系统可以针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；\n- **任务驱动推理**（**task-driven inference**）：SLAM系统产生自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。\n\n### 论文组织结构\n\n**SectionII：**SLAM标准的制定和体系结构\n\n**Section III：**解决终身（长时间）SLAM中的鲁棒性\n\n**Section IV：**处理可扩展性\n\n**Section V：**讨论如何表示环境的几何形状\n\n**Section VI：**将环境表征的问题扩展到语义信息的建模。\n\n**Section VII：**提供了关于SLAM的理论方面的当前成就的概述\n\n**Section VIII：**扩大了讨论范围，并回顾了使用决策来改善SLAM结果质量的活动SLAM问题\n\n**Section IX：**概述了SLAM的最新趋势，包括非常规传感器的使用\n\n**Section X：**提供最后的评论 \n\n尽管SLAM有其独特的特性，但它是与计算机视觉、计算几何、控制理论中有关问题相关的，这些领域的交叉使用是实现快速发展的必要条件。\n\n## III. LONG-TERM AUTONOMY I: ROBUSTNESS\n\n影响SLAM系统鲁棒性因素：算法层面、硬件层面、软件层面。\n\n### 算法层面\n现有SLAM算法的限制，如无法处理动态环境、极端场景。\n#### 数据关联（data association）与感知混淆\n涉及的一个重要原因就是数据关联错误。如基于特征的vSLAM需要关联每一个视觉特征点到确定的路标点，**感知混淆（Perceptual aliasing）**（即对于不同的传感器输入引起相同的传感器信号）会使得问题解决变得困难，导致产生错误测量状态匹配（外点、错误匹配等），进一步影响后端优化；另外，数据关联如果错误地将测量数据判断为错误测量，就只能以估算的精度为代价，使用较少的测量值进行估算了。\n##### short-term数据关联\n传感器采样速率相对于机器人运动变化足够大，直观上可以认为传感器视角不会发生剧烈的变化，因此可以完成诸如特征匹配或光流法，从而避免错误的数据关联。\n##### long-term数据关联\n更具挑战性，涉及到闭合回环检测及验证。\n蛮力的方法处理回环检测是不切实际的。基于视觉特征的Bag-of-words方法[282]通过引入分层的词汇树、量化特征空间，使得搜索更加高效。但是不能处理严重的照明变化。因此提出了一些新的方式，如匹配序列[213]，将不同的视觉外观聚集成统一的表示[69]，或使用空间和外观信息[140]，关于此类的综述见[198]。\n闭合回环验证使用几何验证的方法确定闭合回环的质量。基于视觉的应用中，RANSAC[274]用于几何验证和异常值剔除。基于激光的方法可以通过检测当前scan与已有的地图的匹配度验证闭合回环，例如**残差**。\n当然，错误的闭合回环也是无法避免的。\n\n#### 动态场景\n挑战一：SLAM系统必须要检测、剔除、追踪环境的变化，主流的方法就是剔除场景的动态变化部分，一些方法将动态元素一同建模。\n挑战二：SLAM系统必须对永久性或半永久性变化进行建模，并理解如何、何时更新地图。\n\n### 硬件层面\n传感器本身、执行器退化引起。如何检测降级的传感器操作？ 如何调整传感器噪声统计数据（协方差，偏见）？\n\n### 软件层面\n集成和测试是SLAM和机器人技术的关键方面，它们同样会引起误差。\n\n## V. REPRESENTATION I: METRIC REASONING\n介绍SLAM中的模型几何，即度量表达方法。2D情况有基于路标的地图表达和占用网格地图表达。\n- 基于路标的稀疏表达方式。可以是环境中可分辨特征相关联的3D路标点，例如线、角。前提是路标是可区分的，例如描述子。目前大部分的研究关注点特征的估计，也扩展到线、线段、圆弧[200]。\n\n- 低层次的原始稠密表达。可以提供3D物体的高分辨率模型，适用于机器人研究中的避障和路径规划或者可视化、渲染。原始表达使用点云或多边形、面元地图（surfels maps）描述3D几何物体。这种方式比较笨重，因为需要存储大量的数据信息。\n\n- 边界和空间划分密集表示。明确地表示surfaces (or boundaries) and volumes。空间划分表示方法最具代表性的是spatial-occupancy enumeration，该方法将三维空间划分为相同的立方体（体素）并排列在规则的3D网格中。其他方法还包括octree（应用于3D）、Polygonal Map octree和Binary Space-Partitioning tree等。\n\n  > vSLAM中关于稀疏（基于特征的）表达方式与稠密表达方式、直接法的比较。\n  >\n  > - 基于特征的方法取决于特征的类型。\n  > - 稠密、直接表达方式更适用于低纹理、散焦和运动模糊的场景，但需要高计算能力和实时性能。\n  >\n  > - 半稠密方法克服了稠密法高计算需求的缺点。\n  > - 半直接法一定程度上同时使用了稀疏特征和直接法（被证明更高效，SVO[113]），允许结构和运动同时估计。\n\n- 高层次的基于物体的表达。\nSLAM++。\n## VI. REPRESENTATION II: SEMANTIC REASONING\n\n基于视觉的拓扑地图SLAM系统综述[198]。\n\n### SLAM help Semantics\n比较早的关于分割度量地图的方法[215]，offline的方法，使用2D激光扫描器构建几何地图。\nonline语义地图构建系统[257、258]，将传感、分类、位置识别组合，使用激光和相机构建环境的语义地图。\n[41]使用了运动优化，将粗略的语义分割与不同的对象检测器互。\n[249]使用单目SLAM系统提高视频中对象识别任务的性能。\n### Semantics helps SLAM\n既然可以在SLAM构建的地图中识别物体，那也可以使用关于物体的几何先验知识去优化地图的估计。这方面的研究：\n[63、71]基于稀疏特征的单目SLAM系统，应用于小尺度环境中。\n[84]稠密的地图表达。\n[272]使用RGB-D传感器提出一个SLAM系统，该系统是基于对环境中的已知物体的检测。\n\n### Joint SLAM and Semantics inference\n\n将单目SLAM和地图分割联合。\n\nonline系统[106]构建模型，使用曼哈顿世界假设，针对室内环境分割主要平面部分的地图。\n\n[16]提出使用场景的几何和语义属性估计相机参数和场景点、物体标签，offline。\n\n[136、184、275]offline、[310]online。\n\n\n## 研究点思考\n\n首先，对于SLAM问题，我们需要考虑的四个方面：\n- 机器人\n- 环境\n- 传感器-环境组合\n- 性能需求\n\n因此可以考虑不同的机器人/环境/性能组合进行基础性研究的可能性。同时，在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易失败。此外，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。\n目前，针对SLAM系统的研究可以从下面几个方面中开展：\n- **鲁棒性性能研究**：故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择\n- 高层次的提升研究：超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；\n- **资源利用研究**：针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；\n- **任务驱动方向研究**：自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。\n\n具体的研究点思考如下。\n### 鲁棒性研究\n动态环境下的处理，如何检测、提出、追踪变化，可以将变化剔除[221]、考虑到模型[266, 312, 313]\n如何应对白天和晚上剧烈的光照变化、季节的变化、环境结构的变化（新建筑物->旧建筑物）白天、夜晚回环检测的应对方法[69, 213、223]\n对于数据异常情况（外点的出现）的处理，目前SLAM系统不具备提前感知即将面临的失败的能力、无法提供恢复机制应对已经发生的失败情况\n硬件环境、传感器异常情况的处理？如何检测？如何调整？\n极端环境下的研究，例如水下[20, 100, 102, 166]\n非刚性物体的应对方法，非刚性地图的研究[245, 246] 、[36] and [304]、[4, 5, 128]、[225]\n\n### 可扩展性研究\n因子图优化复杂性降低方法\n地图的存储[201、172]\n多机器人[271]\n多机器人回环检测的研究，机器人之间可能无法共享同一个参考图像帧，机器人传感器探测视角也有所不同[151]\n地图中哪些信息需要丢弃、更新、保存，该以怎样的频率更新地图信息？？？\n在面对严格的带宽限制和通信中断时，保证多机器人团队的可靠运行？？？ [70] \n\n### 度量表达研究\n基于路标的地图\n占用网格地图，地图标准[147]\n高层次的表达方式，机器人不能识别出自己所处的环境类型，例如room vs. corridor，当然可以使用更复杂的模型（如parameterized primitive instancing）解决这种问题。\n更紧凑的表达方法可以降低大尺度环境的地图大小。\n最佳的（可选择性的）表示，简单的室内环境使用参数化的原语、负责的室外环境选择mesh模型，如何比较不同的表达方式、如何选择最有的表达方式？？？[262、285]\n自动的自适应的表达方式，希望机器人可以根据人物和环境的复杂性自主地选择更复杂或更简单的表达方式。这将对长时间的导航带来很大的帮助。\n\n### 语义表达\n\n不仅仅是分类。\n\n## 引用文献\n14\n299\n298\n89\n94\n12\n220\n129\n115\n274\n271\n198\n282","slug":"论文阅读之《Past, Present, and Future of SLAM》","published":1,"updated":"2019-05-30T12:29:26.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc1w00f5qlcr178kl6a0","content":"<hr>\n<p>本篇文章记录SLAM综述性文章《Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age》，只对重点部分作详细翻译，其余为本人根据自己的理解对内容概括性的总结。</p>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>一、介绍SLAM现行制定的标准</p>\n<p>二、总结相关工作（包括一系列关于<strong>长时间建图中的鲁棒性和可扩展性</strong>、<strong>用于建图的度量和语义表示</strong>、理论上的性能保证、主动SLAM和探索、以及其他的前沿技术）</p>\n<p>三、介绍开放的挑战和新的研究问题</p>\n<p>四、作者对两个问题的看法，即机器人需要SLAM吗？SLAM问题解决了嘛？</p>\n<h2 id=\"Introduciton\"><a href=\"#Introduciton\" class=\"headerlink\" title=\"Introduciton\"></a><strong>Introduciton</strong></h2><p>SLAM包括同时的机器人状态估计和环境模型（地图）重建，机器人配置片上传感器，重建的环境是由机器人传感器感知到的。简单的情况下，机器人的状态使用其位姿（位置和方向/姿态）表示，当然机器人的状态还会包含其他的量，如机器人速度、传感器偏差、校准参数。地图是用于描述机器人所处环境的我们感兴趣部分（如路标点位置、障碍物）的表示。</p>\n<p>需要构建环境地图的原因包括两方面。首先，地图经常被用于支撑其他任务；例如，一个地图可以通知路径规划或者提供可供用户操作的直观的可视化。其次地图能够限制机器人状态估计中积累的误差。没有地图时轨迹估计很快就会发生漂移；如果由地图，机器人就可以通过再次访问已访问的区域对位置错误进行重置，即所谓的回环检测。SLAM适用于所有没有先验经验需要创建地图的场景应用。</p>\n<p>一些机器人的应用中环境地图是作为已知的先验经验。</p>\n<p>SLAM问题的普及源于移动机器人的室内应用的出现。室内的操作就要排除GPS的使用，GPS是可以用于限制位置偏差的。SLAM为用户构建的地图提供了一个吸引人的替代方案，显示出在没有专门的本地化基础架构的情况下，机器人操作是可能的。</p>\n<p><strong>古典时代</strong>（1986-2004）（<strong>the</strong> <strong>classical</strong> <strong>age</strong>）：对SLAM的主要概率公式进行了介绍，包括基于扩展卡尔曼滤波器的方法、RaoBlackwellised粒子滤波器和最大似然估计；而且还描绘了与效率和强大数据关联相关的基本挑战。[14、94、299、298]</p>\n<p><strong>算法分析时代</strong>（2004-2015）（<strong>the</strong> <strong>algorithmic-analysis</strong> <strong>age</strong>）：研究了SLAM的基本性质，包括可观测性、收敛性和一致性。该时期对稀疏性对于高效SLAM求解器的关键作用有了理解，并发展出主要的开源SLAM库。[89]</p>\n<ul>\n<li><p>底层SLAM（前端）涵盖了其他的研究领域，如机器视觉和信号处理；</p>\n</li>\n<li><p>在高层的后端，SLAM是几何学、图论、优化和概率的组合。而且，对于一个SLAM专家必须处理实际的从传感器建模到系统集成等各个方面的问题。</p>\n</li>\n</ul>\n<p><strong>Do autonomous robots really need SLAM?</strong></p>\n<p>本文对SLAM的现状进行了广泛的概述，并提供了部分社区对SLAM研究的开放性问题和未来发展方向的看法。其他关于SLAM的综述性文章：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Year</th>\n<th>Topic</th>\n<th style=\"text-align:center\">Reference</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2006</td>\n<td>Probabilistic approaches and data association</td>\n<td style=\"text-align:center\">Durrant-Whyte and Bailey [14, 94]</td>\n</tr>\n<tr>\n<td>2008</td>\n<td>Filtering approaches</td>\n<td style=\"text-align:center\">Aulinas et al. [12]</td>\n</tr>\n<tr>\n<td>2008</td>\n<td>Visual SLAM</td>\n<td style=\"text-align:center\">Neira et al. (special issue) [220]</td>\n</tr>\n<tr>\n<td>2011</td>\n<td>SLAM back-end</td>\n<td style=\"text-align:center\">Grisetti et al. [129]</td>\n</tr>\n<tr>\n<td>2011</td>\n<td>Observability, consistency and convergence</td>\n<td style=\"text-align:center\">Dissanayake et al. [89]</td>\n</tr>\n<tr>\n<td>2012</td>\n<td>Visual odometry</td>\n<td style=\"text-align:center\">Scaramuzza and Fraundofer [115, 274]</td>\n</tr>\n<tr>\n<td>2016</td>\n<td>Multi robot SLAM</td>\n<td style=\"text-align:center\">Saeedi et al. [271]</td>\n</tr>\n<tr>\n<td>2016</td>\n<td>Visual place recognition</td>\n<td style=\"text-align:center\">Lowry et al. [198]</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"Do-autonomous-robots-really-need-SLAM\"><a href=\"#Do-autonomous-robots-really-need-SLAM\" class=\"headerlink\" title=\"Do autonomous robots really need SLAM?\"></a><strong>Do autonomous robots really need SLAM?</strong></h3><p>回答这个问题需要理解SLAM特殊在哪。SLAM旨在利用自身运动的测量和回环检测建立场景的全局一致的表示。关键点在于回环检测：如果忽略了回环检测，SLAM退化为里程计。在早期的应用中，里程计是通过整合在车轮上的编码器获取到的，通过车轮里程计获取到的位姿检测很快就会发生漂移，使得估计在运动数米后就不可用。这也是推动SLAM发展的主要原因之一：外界场景路标点的观测对于消除轨迹漂移是有帮助的，能够尽可能的矫正轨迹。然而，目前更多的里程计算法都是基于视觉和惯性信息，具有很少的漂移（&lt;轨迹长度的0.5%）。这种情况下是否需要SLAM呢？分三方面回答。</p>\n<ul>\n<li>过去十年中完成的SLAM研究工作是产生目前代表现有技术状态的视觉-惯性里程计算法；在这个意义上，视觉惯性导航（VIN）就是SLAM：VIN可以看作是忽略掉回环检测或者位置识别模块的简化SLAM系统。更一般意义上，SLAM导致在比其他知识领域（例如，航天工程中的惯性导航）更早地考虑到的更具挑战性配置（即，没有GPS，低质量传感器）下研究传感器融合。</li>\n<li>关于回环检测。忽略回环检测执行里程计的情况下，机器人会把世界解释成一个没有尽头的走廊，机器人在里面一直无限地对新的区域进行探测。回环检测事件能够告诉机器人该走廊是保持相交的。这样回环检测的好处就清楚了：通过回环检测，机器人能够理解环境真实的拓扑结构，并且能够找到位置间的快捷/最短路径。因此，如果得到正确的环境拓扑结构是SLAM的优点之一，为什么不简单地忽略度量信息，只是做位置识别/回环检测呢？答案是：度量信息使得位置识别更简单、更健壮；度量重建使得机器人有闭环检测的机会，并允许丢弃虚假闭环。因此，SLAM在原则上是多余的（一个oracle位置识别模块就足以进行拓扑映射），SLAM为错误的数据关联和感知别名提供了一个自然的防御，与环境中的不同位置相对应的相似的场景会欺骗位置识别模块。SLAM地图提供了一种预测并验证未来的测量的机制：该机制对于健壮性测量是关键的。</li>\n<li>由于许多应用隐式或显式地需要全局一致的地图，因此需要使用SLAM。例如在很多军事和民用应用中，机器人的目标是探测环境，并提供一个可供用户操作的地图。另一个例子是，机器人必须执行结构检测（例如建筑、桥梁等）；还有需要进行全局一致的3D重建时。</li>\n</ul>\n<p>因此，机器人研究者需要设计一个SLAM系统时，他将面对多种设计选择。例如，一个拓扑地图能够用于分析给定地点的可达性，但是并不适合于路径规划和底层的控制；一个局部一致的度量地图非常适合用于避障以及局部与环境的交互作用，但牺牲了精确性；一个全局一致的度量地图允许机器人执行全局的路径规划，但是计算和维护地图又是高计算复杂度性的。一个更通用的选择更合适的SLAM系统的方法是将SLAM看作是一种机制，完成足够的统计计算来总结机器人的所有已观测到的数据，在这种情况下，在这个压缩表示中保留哪些信息是非常依赖于任务本身的。</p>\n<h3 id=\"Is-SLAM-solved\"><a href=\"#Is-SLAM-solved\" class=\"headerlink\" title=\"Is SLAM solved?\"></a><strong>Is SLAM solved?</strong></h3><p>这是机器人社区经常被问到的问题。回答该问题的难度在于问题本身：SLAM是一个非常开放的话题，这个问题只适用于给定的机器人/环境/性能组合。尤其是，一旦下面几方面内容明确了，我们就可以评估SLAM问题的成熟度：</p>\n<ul>\n<li><strong>机器人</strong>(<strong>robot</strong>)：运动的类型（例如动态、最大速度）、可用传感器（例如分辨率、采样率）、可用的计算资源；</li>\n<li><strong>场景</strong>/<strong>环境</strong>（<strong>environment</strong>）：平面或三维空间、自然或人造路标点的存在、动态元素的数量、对称性的量和感知混叠的风险。请注意，这些中的许多方面实际上取决于传感器-环境对：例如，对于2D激光扫描仪，两个房间可能看起来相同（感知别名），而相机可能会根据外观线索辨别；</li>\n<li><strong>性能要求</strong>（<strong>performance requirements</strong>）：机器人状态估计中的精确性要求、环境表示的精确性和类型（例如基于路标点的或稠密的）、成功率（满足精度范围的测试的百分比）、估计延迟、最大可操作时间、建图区域的最大尺寸范围。</li>\n</ul>\n<p>例如，在保证足够的精确性（&lt;10cm）以及足够的健壮性（即低错误率）的前提下，使用一个装有车轮编码器和激光扫描器的机器人构建2D室内场景的地图，可以认为是基本可以解决的（一个工业系统执行SLAM的例子是the <em>Kuka Navigation Solution</em>）。同样地，基于缓慢移动的机器人的视觉SLAM和视觉-惯性测量法都可以认为是成熟的研究领域。另一方面，其他的机器人/环境/性能组合仍需要大量的基础性研究。在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易就会失败。同时，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。本文将提供这些公开问题的综合概述，等等。</p>\n<p>我们在这一节最后对SLAM的未来进行更广泛的考虑。我们认为，SLAM正在进入第三个时代，即<strong>鲁棒感知时代</strong>（<strong>the</strong> <strong>robust-perception</strong> <strong>age</strong>），其特点是具有以下关键要求：</p>\n<ul>\n<li><strong>性能强劲</strong>（<strong>robust performance</strong>）：SLAM系统能够在广泛的环境中以较低的故障率长时间运行；系统具备故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择；</li>\n<li><strong>高层次的理解力</strong>（<strong>high-level understanding</strong>）：SLAM系统超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；</li>\n<li><strong>资源意识</strong>（<strong>resource awareness</strong>）：SLAM系统可以针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；</li>\n<li><strong>任务驱动推理</strong>（<strong>task-driven inference</strong>）：SLAM系统产生自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。</li>\n</ul>\n<h3 id=\"论文组织结构\"><a href=\"#论文组织结构\" class=\"headerlink\" title=\"论文组织结构\"></a>论文组织结构</h3><p><strong>SectionII：</strong>SLAM标准的制定和体系结构</p>\n<p><strong>Section III：</strong>解决终身（长时间）SLAM中的鲁棒性</p>\n<p><strong>Section IV：</strong>处理可扩展性</p>\n<p><strong>Section V：</strong>讨论如何表示环境的几何形状</p>\n<p><strong>Section VI：</strong>将环境表征的问题扩展到语义信息的建模。</p>\n<p><strong>Section VII：</strong>提供了关于SLAM的理论方面的当前成就的概述</p>\n<p><strong>Section VIII：</strong>扩大了讨论范围，并回顾了使用决策来改善SLAM结果质量的活动SLAM问题</p>\n<p><strong>Section IX：</strong>概述了SLAM的最新趋势，包括非常规传感器的使用</p>\n<p><strong>Section X：</strong>提供最后的评论 </p>\n<p>尽管SLAM有其独特的特性，但它是与计算机视觉、计算几何、控制理论中有关问题相关的，这些领域的交叉使用是实现快速发展的必要条件。</p>\n<h2 id=\"III-LONG-TERM-AUTONOMY-I-ROBUSTNESS\"><a href=\"#III-LONG-TERM-AUTONOMY-I-ROBUSTNESS\" class=\"headerlink\" title=\"III. LONG-TERM AUTONOMY I: ROBUSTNESS\"></a>III. LONG-TERM AUTONOMY I: ROBUSTNESS</h2><p>影响SLAM系统鲁棒性因素：算法层面、硬件层面、软件层面。</p>\n<h3 id=\"算法层面\"><a href=\"#算法层面\" class=\"headerlink\" title=\"算法层面\"></a>算法层面</h3><p>现有SLAM算法的限制，如无法处理动态环境、极端场景。</p>\n<h4 id=\"数据关联（data-association）与感知混淆\"><a href=\"#数据关联（data-association）与感知混淆\" class=\"headerlink\" title=\"数据关联（data association）与感知混淆\"></a>数据关联（data association）与感知混淆</h4><p>涉及的一个重要原因就是数据关联错误。如基于特征的vSLAM需要关联每一个视觉特征点到确定的路标点，<strong>感知混淆（Perceptual aliasing）</strong>（即对于不同的传感器输入引起相同的传感器信号）会使得问题解决变得困难，导致产生错误测量状态匹配（外点、错误匹配等），进一步影响后端优化；另外，数据关联如果错误地将测量数据判断为错误测量，就只能以估算的精度为代价，使用较少的测量值进行估算了。</p>\n<h5 id=\"short-term数据关联\"><a href=\"#short-term数据关联\" class=\"headerlink\" title=\"short-term数据关联\"></a>short-term数据关联</h5><p>传感器采样速率相对于机器人运动变化足够大，直观上可以认为传感器视角不会发生剧烈的变化，因此可以完成诸如特征匹配或光流法，从而避免错误的数据关联。</p>\n<h5 id=\"long-term数据关联\"><a href=\"#long-term数据关联\" class=\"headerlink\" title=\"long-term数据关联\"></a>long-term数据关联</h5><p>更具挑战性，涉及到闭合回环检测及验证。<br>蛮力的方法处理回环检测是不切实际的。基于视觉特征的Bag-of-words方法[282]通过引入分层的词汇树、量化特征空间，使得搜索更加高效。但是不能处理严重的照明变化。因此提出了一些新的方式，如匹配序列[213]，将不同的视觉外观聚集成统一的表示[69]，或使用空间和外观信息[140]，关于此类的综述见[198]。<br>闭合回环验证使用几何验证的方法确定闭合回环的质量。基于视觉的应用中，RANSAC[274]用于几何验证和异常值剔除。基于激光的方法可以通过检测当前scan与已有的地图的匹配度验证闭合回环，例如<strong>残差</strong>。<br>当然，错误的闭合回环也是无法避免的。</p>\n<h4 id=\"动态场景\"><a href=\"#动态场景\" class=\"headerlink\" title=\"动态场景\"></a>动态场景</h4><p>挑战一：SLAM系统必须要检测、剔除、追踪环境的变化，主流的方法就是剔除场景的动态变化部分，一些方法将动态元素一同建模。<br>挑战二：SLAM系统必须对永久性或半永久性变化进行建模，并理解如何、何时更新地图。</p>\n<h3 id=\"硬件层面\"><a href=\"#硬件层面\" class=\"headerlink\" title=\"硬件层面\"></a>硬件层面</h3><p>传感器本身、执行器退化引起。如何检测降级的传感器操作？ 如何调整传感器噪声统计数据（协方差，偏见）？</p>\n<h3 id=\"软件层面\"><a href=\"#软件层面\" class=\"headerlink\" title=\"软件层面\"></a>软件层面</h3><p>集成和测试是SLAM和机器人技术的关键方面，它们同样会引起误差。</p>\n<h2 id=\"V-REPRESENTATION-I-METRIC-REASONING\"><a href=\"#V-REPRESENTATION-I-METRIC-REASONING\" class=\"headerlink\" title=\"V. REPRESENTATION I: METRIC REASONING\"></a>V. REPRESENTATION I: METRIC REASONING</h2><p>介绍SLAM中的模型几何，即度量表达方法。2D情况有基于路标的地图表达和占用网格地图表达。</p>\n<ul>\n<li><p>基于路标的稀疏表达方式。可以是环境中可分辨特征相关联的3D路标点，例如线、角。前提是路标是可区分的，例如描述子。目前大部分的研究关注点特征的估计，也扩展到线、线段、圆弧[200]。</p>\n</li>\n<li><p>低层次的原始稠密表达。可以提供3D物体的高分辨率模型，适用于机器人研究中的避障和路径规划或者可视化、渲染。原始表达使用点云或多边形、面元地图（surfels maps）描述3D几何物体。这种方式比较笨重，因为需要存储大量的数据信息。</p>\n</li>\n<li><p>边界和空间划分密集表示。明确地表示surfaces (or boundaries) and volumes。空间划分表示方法最具代表性的是spatial-occupancy enumeration，该方法将三维空间划分为相同的立方体（体素）并排列在规则的3D网格中。其他方法还包括octree（应用于3D）、Polygonal Map octree和Binary Space-Partitioning tree等。</p>\n<blockquote>\n<p>vSLAM中关于稀疏（基于特征的）表达方式与稠密表达方式、直接法的比较。</p>\n<ul>\n<li>基于特征的方法取决于特征的类型。</li>\n<li><p>稠密、直接表达方式更适用于低纹理、散焦和运动模糊的场景，但需要高计算能力和实时性能。</p>\n</li>\n<li><p>半稠密方法克服了稠密法高计算需求的缺点。</p>\n</li>\n<li>半直接法一定程度上同时使用了稀疏特征和直接法（被证明更高效，SVO[113]），允许结构和运动同时估计。</li>\n</ul>\n</blockquote>\n</li>\n<li><p>高层次的基于物体的表达。<br>SLAM++。</p>\n<h2 id=\"VI-REPRESENTATION-II-SEMANTIC-REASONING\"><a href=\"#VI-REPRESENTATION-II-SEMANTIC-REASONING\" class=\"headerlink\" title=\"VI. REPRESENTATION II: SEMANTIC REASONING\"></a>VI. REPRESENTATION II: SEMANTIC REASONING</h2></li>\n</ul>\n<p>基于视觉的拓扑地图SLAM系统综述[198]。</p>\n<h3 id=\"SLAM-help-Semantics\"><a href=\"#SLAM-help-Semantics\" class=\"headerlink\" title=\"SLAM help Semantics\"></a>SLAM help Semantics</h3><p>比较早的关于分割度量地图的方法[215]，offline的方法，使用2D激光扫描器构建几何地图。<br>online语义地图构建系统[257、258]，将传感、分类、位置识别组合，使用激光和相机构建环境的语义地图。<br>[41]使用了运动优化，将粗略的语义分割与不同的对象检测器互。<br>[249]使用单目SLAM系统提高视频中对象识别任务的性能。</p>\n<h3 id=\"Semantics-helps-SLAM\"><a href=\"#Semantics-helps-SLAM\" class=\"headerlink\" title=\"Semantics helps SLAM\"></a>Semantics helps SLAM</h3><p>既然可以在SLAM构建的地图中识别物体，那也可以使用关于物体的几何先验知识去优化地图的估计。这方面的研究：<br>[63、71]基于稀疏特征的单目SLAM系统，应用于小尺度环境中。<br>[84]稠密的地图表达。<br>[272]使用RGB-D传感器提出一个SLAM系统，该系统是基于对环境中的已知物体的检测。</p>\n<h3 id=\"Joint-SLAM-and-Semantics-inference\"><a href=\"#Joint-SLAM-and-Semantics-inference\" class=\"headerlink\" title=\"Joint SLAM and Semantics inference\"></a>Joint SLAM and Semantics inference</h3><p>将单目SLAM和地图分割联合。</p>\n<p>online系统[106]构建模型，使用曼哈顿世界假设，针对室内环境分割主要平面部分的地图。</p>\n<p>[16]提出使用场景的几何和语义属性估计相机参数和场景点、物体标签，offline。</p>\n<p>[136、184、275]offline、[310]online。</p>\n<h2 id=\"研究点思考\"><a href=\"#研究点思考\" class=\"headerlink\" title=\"研究点思考\"></a>研究点思考</h2><p>首先，对于SLAM问题，我们需要考虑的四个方面：</p>\n<ul>\n<li>机器人</li>\n<li>环境</li>\n<li>传感器-环境组合</li>\n<li>性能需求</li>\n</ul>\n<p>因此可以考虑不同的机器人/环境/性能组合进行基础性研究的可能性。同时，在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易失败。此外，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。<br>目前，针对SLAM系统的研究可以从下面几个方面中开展：</p>\n<ul>\n<li><strong>鲁棒性性能研究</strong>：故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择</li>\n<li>高层次的提升研究：超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；</li>\n<li><strong>资源利用研究</strong>：针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；</li>\n<li><strong>任务驱动方向研究</strong>：自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。</li>\n</ul>\n<p>具体的研究点思考如下。</p>\n<h3 id=\"鲁棒性研究\"><a href=\"#鲁棒性研究\" class=\"headerlink\" title=\"鲁棒性研究\"></a>鲁棒性研究</h3><p>动态环境下的处理，如何检测、提出、追踪变化，可以将变化剔除[221]、考虑到模型[266, 312, 313]<br>如何应对白天和晚上剧烈的光照变化、季节的变化、环境结构的变化（新建筑物-&gt;旧建筑物）白天、夜晚回环检测的应对方法[69, 213、223]<br>对于数据异常情况（外点的出现）的处理，目前SLAM系统不具备提前感知即将面临的失败的能力、无法提供恢复机制应对已经发生的失败情况<br>硬件环境、传感器异常情况的处理？如何检测？如何调整？<br>极端环境下的研究，例如水下[20, 100, 102, 166]<br>非刚性物体的应对方法，非刚性地图的研究[245, 246] 、[36] and [304]、[4, 5, 128]、[225]</p>\n<h3 id=\"可扩展性研究\"><a href=\"#可扩展性研究\" class=\"headerlink\" title=\"可扩展性研究\"></a>可扩展性研究</h3><p>因子图优化复杂性降低方法<br>地图的存储[201、172]<br>多机器人[271]<br>多机器人回环检测的研究，机器人之间可能无法共享同一个参考图像帧，机器人传感器探测视角也有所不同[151]<br>地图中哪些信息需要丢弃、更新、保存，该以怎样的频率更新地图信息？？？<br>在面对严格的带宽限制和通信中断时，保证多机器人团队的可靠运行？？？ [70] </p>\n<h3 id=\"度量表达研究\"><a href=\"#度量表达研究\" class=\"headerlink\" title=\"度量表达研究\"></a>度量表达研究</h3><p>基于路标的地图<br>占用网格地图，地图标准[147]<br>高层次的表达方式，机器人不能识别出自己所处的环境类型，例如room vs. corridor，当然可以使用更复杂的模型（如parameterized primitive instancing）解决这种问题。<br>更紧凑的表达方法可以降低大尺度环境的地图大小。<br>最佳的（可选择性的）表示，简单的室内环境使用参数化的原语、负责的室外环境选择mesh模型，如何比较不同的表达方式、如何选择最有的表达方式？？？[262、285]<br>自动的自适应的表达方式，希望机器人可以根据人物和环境的复杂性自主地选择更复杂或更简单的表达方式。这将对长时间的导航带来很大的帮助。</p>\n<h3 id=\"语义表达\"><a href=\"#语义表达\" class=\"headerlink\" title=\"语义表达\"></a>语义表达</h3><p>不仅仅是分类。</p>\n<h2 id=\"引用文献\"><a href=\"#引用文献\" class=\"headerlink\" title=\"引用文献\"></a>引用文献</h2><p>14<br>299<br>298<br>89<br>94<br>12<br>220<br>129<br>115<br>274<br>271<br>198<br>282</p>\n","site":{"data":{}},"excerpt":"<hr>\n<p>本篇文章记录SLAM综述性文章《Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age》，只对重点部分作详细翻译，其余为本人根据自己的理解对内容概括性的总结。</p>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>一、介绍SLAM现行制定的标准</p>\n<p>二、总结相关工作（包括一系列关于<strong>长时间建图中的鲁棒性和可扩展性</strong>、<strong>用于建图的度量和语义表示</strong>、理论上的性能保证、主动SLAM和探索、以及其他的前沿技术）</p>\n<p>三、介绍开放的挑战和新的研究问题</p>\n<p>四、作者对两个问题的看法，即机器人需要SLAM吗？SLAM问题解决了嘛？</p>\n<h2 id=\"Introduciton\"><a href=\"#Introduciton\" class=\"headerlink\" title=\"Introduciton\"></a><strong>Introduciton</strong></h2><p>SLAM包括同时的机器人状态估计和环境模型（地图）重建，机器人配置片上传感器，重建的环境是由机器人传感器感知到的。简单的情况下，机器人的状态使用其位姿（位置和方向/姿态）表示，当然机器人的状态还会包含其他的量，如机器人速度、传感器偏差、校准参数。地图是用于描述机器人所处环境的我们感兴趣部分（如路标点位置、障碍物）的表示。</p>\n<p>需要构建环境地图的原因包括两方面。首先，地图经常被用于支撑其他任务；例如，一个地图可以通知路径规划或者提供可供用户操作的直观的可视化。其次地图能够限制机器人状态估计中积累的误差。没有地图时轨迹估计很快就会发生漂移；如果由地图，机器人就可以通过再次访问已访问的区域对位置错误进行重置，即所谓的回环检测。SLAM适用于所有没有先验经验需要创建地图的场景应用。</p>\n<p>一些机器人的应用中环境地图是作为已知的先验经验。</p>\n<p>SLAM问题的普及源于移动机器人的室内应用的出现。室内的操作就要排除GPS的使用，GPS是可以用于限制位置偏差的。SLAM为用户构建的地图提供了一个吸引人的替代方案，显示出在没有专门的本地化基础架构的情况下，机器人操作是可能的。</p>\n<p><strong>古典时代</strong>（1986-2004）（<strong>the</strong> <strong>classical</strong> <strong>age</strong>）：对SLAM的主要概率公式进行了介绍，包括基于扩展卡尔曼滤波器的方法、RaoBlackwellised粒子滤波器和最大似然估计；而且还描绘了与效率和强大数据关联相关的基本挑战。[14、94、299、298]</p>\n<p><strong>算法分析时代</strong>（2004-2015）（<strong>the</strong> <strong>algorithmic-analysis</strong> <strong>age</strong>）：研究了SLAM的基本性质，包括可观测性、收敛性和一致性。该时期对稀疏性对于高效SLAM求解器的关键作用有了理解，并发展出主要的开源SLAM库。[89]</p>\n<ul>\n<li><p>底层SLAM（前端）涵盖了其他的研究领域，如机器视觉和信号处理；</p>\n</li>\n<li><p>在高层的后端，SLAM是几何学、图论、优化和概率的组合。而且，对于一个SLAM专家必须处理实际的从传感器建模到系统集成等各个方面的问题。</p>\n</li>\n</ul>\n<p><strong>Do autonomous robots really need SLAM?</strong></p>\n<p>本文对SLAM的现状进行了广泛的概述，并提供了部分社区对SLAM研究的开放性问题和未来发展方向的看法。其他关于SLAM的综述性文章：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Year</th>\n<th>Topic</th>\n<th style=\"text-align:center\">Reference</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2006</td>\n<td>Probabilistic approaches and data association</td>\n<td style=\"text-align:center\">Durrant-Whyte and Bailey [14, 94]</td>\n</tr>\n<tr>\n<td>2008</td>\n<td>Filtering approaches</td>\n<td style=\"text-align:center\">Aulinas et al. [12]</td>\n</tr>\n<tr>\n<td>2008</td>\n<td>Visual SLAM</td>\n<td style=\"text-align:center\">Neira et al. (special issue) [220]</td>\n</tr>\n<tr>\n<td>2011</td>\n<td>SLAM back-end</td>\n<td style=\"text-align:center\">Grisetti et al. [129]</td>\n</tr>\n<tr>\n<td>2011</td>\n<td>Observability, consistency and convergence</td>\n<td style=\"text-align:center\">Dissanayake et al. [89]</td>\n</tr>\n<tr>\n<td>2012</td>\n<td>Visual odometry</td>\n<td style=\"text-align:center\">Scaramuzza and Fraundofer [115, 274]</td>\n</tr>\n<tr>\n<td>2016</td>\n<td>Multi robot SLAM</td>\n<td style=\"text-align:center\">Saeedi et al. [271]</td>\n</tr>\n<tr>\n<td>2016</td>\n<td>Visual place recognition</td>\n<td style=\"text-align:center\">Lowry et al. [198]</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"Do-autonomous-robots-really-need-SLAM\"><a href=\"#Do-autonomous-robots-really-need-SLAM\" class=\"headerlink\" title=\"Do autonomous robots really need SLAM?\"></a><strong>Do autonomous robots really need SLAM?</strong></h3><p>回答这个问题需要理解SLAM特殊在哪。SLAM旨在利用自身运动的测量和回环检测建立场景的全局一致的表示。关键点在于回环检测：如果忽略了回环检测，SLAM退化为里程计。在早期的应用中，里程计是通过整合在车轮上的编码器获取到的，通过车轮里程计获取到的位姿检测很快就会发生漂移，使得估计在运动数米后就不可用。这也是推动SLAM发展的主要原因之一：外界场景路标点的观测对于消除轨迹漂移是有帮助的，能够尽可能的矫正轨迹。然而，目前更多的里程计算法都是基于视觉和惯性信息，具有很少的漂移（&lt;轨迹长度的0.5%）。这种情况下是否需要SLAM呢？分三方面回答。</p>\n<ul>\n<li>过去十年中完成的SLAM研究工作是产生目前代表现有技术状态的视觉-惯性里程计算法；在这个意义上，视觉惯性导航（VIN）就是SLAM：VIN可以看作是忽略掉回环检测或者位置识别模块的简化SLAM系统。更一般意义上，SLAM导致在比其他知识领域（例如，航天工程中的惯性导航）更早地考虑到的更具挑战性配置（即，没有GPS，低质量传感器）下研究传感器融合。</li>\n<li>关于回环检测。忽略回环检测执行里程计的情况下，机器人会把世界解释成一个没有尽头的走廊，机器人在里面一直无限地对新的区域进行探测。回环检测事件能够告诉机器人该走廊是保持相交的。这样回环检测的好处就清楚了：通过回环检测，机器人能够理解环境真实的拓扑结构，并且能够找到位置间的快捷/最短路径。因此，如果得到正确的环境拓扑结构是SLAM的优点之一，为什么不简单地忽略度量信息，只是做位置识别/回环检测呢？答案是：度量信息使得位置识别更简单、更健壮；度量重建使得机器人有闭环检测的机会，并允许丢弃虚假闭环。因此，SLAM在原则上是多余的（一个oracle位置识别模块就足以进行拓扑映射），SLAM为错误的数据关联和感知别名提供了一个自然的防御，与环境中的不同位置相对应的相似的场景会欺骗位置识别模块。SLAM地图提供了一种预测并验证未来的测量的机制：该机制对于健壮性测量是关键的。</li>\n<li>由于许多应用隐式或显式地需要全局一致的地图，因此需要使用SLAM。例如在很多军事和民用应用中，机器人的目标是探测环境，并提供一个可供用户操作的地图。另一个例子是，机器人必须执行结构检测（例如建筑、桥梁等）；还有需要进行全局一致的3D重建时。</li>\n</ul>\n<p>因此，机器人研究者需要设计一个SLAM系统时，他将面对多种设计选择。例如，一个拓扑地图能够用于分析给定地点的可达性，但是并不适合于路径规划和底层的控制；一个局部一致的度量地图非常适合用于避障以及局部与环境的交互作用，但牺牲了精确性；一个全局一致的度量地图允许机器人执行全局的路径规划，但是计算和维护地图又是高计算复杂度性的。一个更通用的选择更合适的SLAM系统的方法是将SLAM看作是一种机制，完成足够的统计计算来总结机器人的所有已观测到的数据，在这种情况下，在这个压缩表示中保留哪些信息是非常依赖于任务本身的。</p>\n<h3 id=\"Is-SLAM-solved\"><a href=\"#Is-SLAM-solved\" class=\"headerlink\" title=\"Is SLAM solved?\"></a><strong>Is SLAM solved?</strong></h3><p>这是机器人社区经常被问到的问题。回答该问题的难度在于问题本身：SLAM是一个非常开放的话题，这个问题只适用于给定的机器人/环境/性能组合。尤其是，一旦下面几方面内容明确了，我们就可以评估SLAM问题的成熟度：</p>\n<ul>\n<li><strong>机器人</strong>(<strong>robot</strong>)：运动的类型（例如动态、最大速度）、可用传感器（例如分辨率、采样率）、可用的计算资源；</li>\n<li><strong>场景</strong>/<strong>环境</strong>（<strong>environment</strong>）：平面或三维空间、自然或人造路标点的存在、动态元素的数量、对称性的量和感知混叠的风险。请注意，这些中的许多方面实际上取决于传感器-环境对：例如，对于2D激光扫描仪，两个房间可能看起来相同（感知别名），而相机可能会根据外观线索辨别；</li>\n<li><strong>性能要求</strong>（<strong>performance requirements</strong>）：机器人状态估计中的精确性要求、环境表示的精确性和类型（例如基于路标点的或稠密的）、成功率（满足精度范围的测试的百分比）、估计延迟、最大可操作时间、建图区域的最大尺寸范围。</li>\n</ul>\n<p>例如，在保证足够的精确性（&lt;10cm）以及足够的健壮性（即低错误率）的前提下，使用一个装有车轮编码器和激光扫描器的机器人构建2D室内场景的地图，可以认为是基本可以解决的（一个工业系统执行SLAM的例子是the <em>Kuka Navigation Solution</em>）。同样地，基于缓慢移动的机器人的视觉SLAM和视觉-惯性测量法都可以认为是成熟的研究领域。另一方面，其他的机器人/环境/性能组合仍需要大量的基础性研究。在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易就会失败。同时，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。本文将提供这些公开问题的综合概述，等等。</p>\n<p>我们在这一节最后对SLAM的未来进行更广泛的考虑。我们认为，SLAM正在进入第三个时代，即<strong>鲁棒感知时代</strong>（<strong>the</strong> <strong>robust-perception</strong> <strong>age</strong>），其特点是具有以下关键要求：</p>\n<ul>\n<li><strong>性能强劲</strong>（<strong>robust performance</strong>）：SLAM系统能够在广泛的环境中以较低的故障率长时间运行；系统具备故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择；</li>\n<li><strong>高层次的理解力</strong>（<strong>high-level understanding</strong>）：SLAM系统超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；</li>\n<li><strong>资源意识</strong>（<strong>resource awareness</strong>）：SLAM系统可以针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；</li>\n<li><strong>任务驱动推理</strong>（<strong>task-driven inference</strong>）：SLAM系统产生自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。</li>\n</ul>\n<h3 id=\"论文组织结构\"><a href=\"#论文组织结构\" class=\"headerlink\" title=\"论文组织结构\"></a>论文组织结构</h3><p><strong>SectionII：</strong>SLAM标准的制定和体系结构</p>\n<p><strong>Section III：</strong>解决终身（长时间）SLAM中的鲁棒性</p>\n<p><strong>Section IV：</strong>处理可扩展性</p>\n<p><strong>Section V：</strong>讨论如何表示环境的几何形状</p>\n<p><strong>Section VI：</strong>将环境表征的问题扩展到语义信息的建模。</p>\n<p><strong>Section VII：</strong>提供了关于SLAM的理论方面的当前成就的概述</p>\n<p><strong>Section VIII：</strong>扩大了讨论范围，并回顾了使用决策来改善SLAM结果质量的活动SLAM问题</p>\n<p><strong>Section IX：</strong>概述了SLAM的最新趋势，包括非常规传感器的使用</p>\n<p><strong>Section X：</strong>提供最后的评论 </p>\n<p>尽管SLAM有其独特的特性，但它是与计算机视觉、计算几何、控制理论中有关问题相关的，这些领域的交叉使用是实现快速发展的必要条件。</p>\n<h2 id=\"III-LONG-TERM-AUTONOMY-I-ROBUSTNESS\"><a href=\"#III-LONG-TERM-AUTONOMY-I-ROBUSTNESS\" class=\"headerlink\" title=\"III. LONG-TERM AUTONOMY I: ROBUSTNESS\"></a>III. LONG-TERM AUTONOMY I: ROBUSTNESS</h2><p>影响SLAM系统鲁棒性因素：算法层面、硬件层面、软件层面。</p>\n<h3 id=\"算法层面\"><a href=\"#算法层面\" class=\"headerlink\" title=\"算法层面\"></a>算法层面</h3><p>现有SLAM算法的限制，如无法处理动态环境、极端场景。</p>\n<h4 id=\"数据关联（data-association）与感知混淆\"><a href=\"#数据关联（data-association）与感知混淆\" class=\"headerlink\" title=\"数据关联（data association）与感知混淆\"></a>数据关联（data association）与感知混淆</h4><p>涉及的一个重要原因就是数据关联错误。如基于特征的vSLAM需要关联每一个视觉特征点到确定的路标点，<strong>感知混淆（Perceptual aliasing）</strong>（即对于不同的传感器输入引起相同的传感器信号）会使得问题解决变得困难，导致产生错误测量状态匹配（外点、错误匹配等），进一步影响后端优化；另外，数据关联如果错误地将测量数据判断为错误测量，就只能以估算的精度为代价，使用较少的测量值进行估算了。</p>\n<h5 id=\"short-term数据关联\"><a href=\"#short-term数据关联\" class=\"headerlink\" title=\"short-term数据关联\"></a>short-term数据关联</h5><p>传感器采样速率相对于机器人运动变化足够大，直观上可以认为传感器视角不会发生剧烈的变化，因此可以完成诸如特征匹配或光流法，从而避免错误的数据关联。</p>\n<h5 id=\"long-term数据关联\"><a href=\"#long-term数据关联\" class=\"headerlink\" title=\"long-term数据关联\"></a>long-term数据关联</h5><p>更具挑战性，涉及到闭合回环检测及验证。<br>蛮力的方法处理回环检测是不切实际的。基于视觉特征的Bag-of-words方法[282]通过引入分层的词汇树、量化特征空间，使得搜索更加高效。但是不能处理严重的照明变化。因此提出了一些新的方式，如匹配序列[213]，将不同的视觉外观聚集成统一的表示[69]，或使用空间和外观信息[140]，关于此类的综述见[198]。<br>闭合回环验证使用几何验证的方法确定闭合回环的质量。基于视觉的应用中，RANSAC[274]用于几何验证和异常值剔除。基于激光的方法可以通过检测当前scan与已有的地图的匹配度验证闭合回环，例如<strong>残差</strong>。<br>当然，错误的闭合回环也是无法避免的。</p>\n<h4 id=\"动态场景\"><a href=\"#动态场景\" class=\"headerlink\" title=\"动态场景\"></a>动态场景</h4><p>挑战一：SLAM系统必须要检测、剔除、追踪环境的变化，主流的方法就是剔除场景的动态变化部分，一些方法将动态元素一同建模。<br>挑战二：SLAM系统必须对永久性或半永久性变化进行建模，并理解如何、何时更新地图。</p>\n<h3 id=\"硬件层面\"><a href=\"#硬件层面\" class=\"headerlink\" title=\"硬件层面\"></a>硬件层面</h3><p>传感器本身、执行器退化引起。如何检测降级的传感器操作？ 如何调整传感器噪声统计数据（协方差，偏见）？</p>\n<h3 id=\"软件层面\"><a href=\"#软件层面\" class=\"headerlink\" title=\"软件层面\"></a>软件层面</h3><p>集成和测试是SLAM和机器人技术的关键方面，它们同样会引起误差。</p>\n<h2 id=\"V-REPRESENTATION-I-METRIC-REASONING\"><a href=\"#V-REPRESENTATION-I-METRIC-REASONING\" class=\"headerlink\" title=\"V. REPRESENTATION I: METRIC REASONING\"></a>V. REPRESENTATION I: METRIC REASONING</h2><p>介绍SLAM中的模型几何，即度量表达方法。2D情况有基于路标的地图表达和占用网格地图表达。</p>\n<ul>\n<li><p>基于路标的稀疏表达方式。可以是环境中可分辨特征相关联的3D路标点，例如线、角。前提是路标是可区分的，例如描述子。目前大部分的研究关注点特征的估计，也扩展到线、线段、圆弧[200]。</p>\n</li>\n<li><p>低层次的原始稠密表达。可以提供3D物体的高分辨率模型，适用于机器人研究中的避障和路径规划或者可视化、渲染。原始表达使用点云或多边形、面元地图（surfels maps）描述3D几何物体。这种方式比较笨重，因为需要存储大量的数据信息。</p>\n</li>\n<li><p>边界和空间划分密集表示。明确地表示surfaces (or boundaries) and volumes。空间划分表示方法最具代表性的是spatial-occupancy enumeration，该方法将三维空间划分为相同的立方体（体素）并排列在规则的3D网格中。其他方法还包括octree（应用于3D）、Polygonal Map octree和Binary Space-Partitioning tree等。</p>\n<blockquote>\n<p>vSLAM中关于稀疏（基于特征的）表达方式与稠密表达方式、直接法的比较。</p>\n<ul>\n<li>基于特征的方法取决于特征的类型。</li>\n<li><p>稠密、直接表达方式更适用于低纹理、散焦和运动模糊的场景，但需要高计算能力和实时性能。</p>\n</li>\n<li><p>半稠密方法克服了稠密法高计算需求的缺点。</p>\n</li>\n<li>半直接法一定程度上同时使用了稀疏特征和直接法（被证明更高效，SVO[113]），允许结构和运动同时估计。</li>\n</ul>\n</blockquote>\n</li>\n<li><p>高层次的基于物体的表达。<br>SLAM++。</p>\n<h2 id=\"VI-REPRESENTATION-II-SEMANTIC-REASONING\"><a href=\"#VI-REPRESENTATION-II-SEMANTIC-REASONING\" class=\"headerlink\" title=\"VI. REPRESENTATION II: SEMANTIC REASONING\"></a>VI. REPRESENTATION II: SEMANTIC REASONING</h2></li>\n</ul>\n<p>基于视觉的拓扑地图SLAM系统综述[198]。</p>\n<h3 id=\"SLAM-help-Semantics\"><a href=\"#SLAM-help-Semantics\" class=\"headerlink\" title=\"SLAM help Semantics\"></a>SLAM help Semantics</h3><p>比较早的关于分割度量地图的方法[215]，offline的方法，使用2D激光扫描器构建几何地图。<br>online语义地图构建系统[257、258]，将传感、分类、位置识别组合，使用激光和相机构建环境的语义地图。<br>[41]使用了运动优化，将粗略的语义分割与不同的对象检测器互。<br>[249]使用单目SLAM系统提高视频中对象识别任务的性能。</p>\n<h3 id=\"Semantics-helps-SLAM\"><a href=\"#Semantics-helps-SLAM\" class=\"headerlink\" title=\"Semantics helps SLAM\"></a>Semantics helps SLAM</h3><p>既然可以在SLAM构建的地图中识别物体，那也可以使用关于物体的几何先验知识去优化地图的估计。这方面的研究：<br>[63、71]基于稀疏特征的单目SLAM系统，应用于小尺度环境中。<br>[84]稠密的地图表达。<br>[272]使用RGB-D传感器提出一个SLAM系统，该系统是基于对环境中的已知物体的检测。</p>\n<h3 id=\"Joint-SLAM-and-Semantics-inference\"><a href=\"#Joint-SLAM-and-Semantics-inference\" class=\"headerlink\" title=\"Joint SLAM and Semantics inference\"></a>Joint SLAM and Semantics inference</h3><p>将单目SLAM和地图分割联合。</p>\n<p>online系统[106]构建模型，使用曼哈顿世界假设，针对室内环境分割主要平面部分的地图。</p>\n<p>[16]提出使用场景的几何和语义属性估计相机参数和场景点、物体标签，offline。</p>\n<p>[136、184、275]offline、[310]online。</p>\n<h2 id=\"研究点思考\"><a href=\"#研究点思考\" class=\"headerlink\" title=\"研究点思考\"></a>研究点思考</h2><p>首先，对于SLAM问题，我们需要考虑的四个方面：</p>\n<ul>\n<li>机器人</li>\n<li>环境</li>\n<li>传感器-环境组合</li>\n<li>性能需求</li>\n</ul>\n<p>因此可以考虑不同的机器人/环境/性能组合进行基础性研究的可能性。同时，在机器人移动或者环境极具挑战性时（例如快速机器人动态、高度动态的环境），目前的SLAM算法很容易失败。此外，SLAM算法经常无法应对严格的性能要求，例如，快速闭环控制的高速率估计。<br>目前，针对SLAM系统的研究可以从下面几个方面中开展：</p>\n<ul>\n<li><strong>鲁棒性性能研究</strong>：故障安全机制和自我调整功能，这样能够做出适应不同场景的系统参数的选择</li>\n<li>高层次的提升研究：超越基础的几何重建，能够获取到对环境的一个更高层次的理解，例如语义、可用性、高级几何、物理；</li>\n<li><strong>资源利用研究</strong>：针对可用的传感和计算资源量身定制，并可以提供根据可用资源调整计算负载的方法；</li>\n<li><strong>任务驱动方向研究</strong>：自适应地图表示，其复杂性可以根据机器人必须执行的任务而改变。</li>\n</ul>\n<p>具体的研究点思考如下。</p>\n<h3 id=\"鲁棒性研究\"><a href=\"#鲁棒性研究\" class=\"headerlink\" title=\"鲁棒性研究\"></a>鲁棒性研究</h3><p>动态环境下的处理，如何检测、提出、追踪变化，可以将变化剔除[221]、考虑到模型[266, 312, 313]<br>如何应对白天和晚上剧烈的光照变化、季节的变化、环境结构的变化（新建筑物-&gt;旧建筑物）白天、夜晚回环检测的应对方法[69, 213、223]<br>对于数据异常情况（外点的出现）的处理，目前SLAM系统不具备提前感知即将面临的失败的能力、无法提供恢复机制应对已经发生的失败情况<br>硬件环境、传感器异常情况的处理？如何检测？如何调整？<br>极端环境下的研究，例如水下[20, 100, 102, 166]<br>非刚性物体的应对方法，非刚性地图的研究[245, 246] 、[36] and [304]、[4, 5, 128]、[225]</p>\n<h3 id=\"可扩展性研究\"><a href=\"#可扩展性研究\" class=\"headerlink\" title=\"可扩展性研究\"></a>可扩展性研究</h3><p>因子图优化复杂性降低方法<br>地图的存储[201、172]<br>多机器人[271]<br>多机器人回环检测的研究，机器人之间可能无法共享同一个参考图像帧，机器人传感器探测视角也有所不同[151]<br>地图中哪些信息需要丢弃、更新、保存，该以怎样的频率更新地图信息？？？<br>在面对严格的带宽限制和通信中断时，保证多机器人团队的可靠运行？？？ [70] </p>\n<h3 id=\"度量表达研究\"><a href=\"#度量表达研究\" class=\"headerlink\" title=\"度量表达研究\"></a>度量表达研究</h3><p>基于路标的地图<br>占用网格地图，地图标准[147]<br>高层次的表达方式，机器人不能识别出自己所处的环境类型，例如room vs. corridor，当然可以使用更复杂的模型（如parameterized primitive instancing）解决这种问题。<br>更紧凑的表达方法可以降低大尺度环境的地图大小。<br>最佳的（可选择性的）表示，简单的室内环境使用参数化的原语、负责的室外环境选择mesh模型，如何比较不同的表达方式、如何选择最有的表达方式？？？[262、285]<br>自动的自适应的表达方式，希望机器人可以根据人物和环境的复杂性自主地选择更复杂或更简单的表达方式。这将对长时间的导航带来很大的帮助。</p>\n<h3 id=\"语义表达\"><a href=\"#语义表达\" class=\"headerlink\" title=\"语义表达\"></a>语义表达</h3><p>不仅仅是分类。</p>\n<h2 id=\"引用文献\"><a href=\"#引用文献\" class=\"headerlink\" title=\"引用文献\"></a>引用文献</h2><p>14<br>299<br>298<br>89<br>94<br>12<br>220<br>129<br>115<br>274<br>271<br>198<br>282</p>"},{"title":"ROS学习之catkin CMakeList.txt介绍（译）","date":"2018-03-21T14:04:00.000Z","copyright":true,"_content":"\n***\n\n这篇文章是有关ROS中catkin CMakeLists.txt使用的内容。\n\n<!--more-->\n\n​\t本文翻译自ROS官网关于catkin CMakeList.txt的介绍，**[官网原文链接](http://wiki.ros.org/catkin/CMakeLists.txt)**，由于直接阅读英文文档感觉自己理解不透彻、收获不多，所以决定一边翻译一边学习。其中零星的加入了一些译者个人使用过程中的体会以及在阅读《机器人操作系统（ROS）浅析》（Jason M.O’Kane著 肖军浩译）一书时学习到的内容，帮助自己更好地理解catkin编译生成的过程，留作今后复习完善。\n\n## 概况\n\n​\tCMakeList.txt文件是CMake编译系统编译软件包过程的输入文件。任何CMake兼容包都包含一个或多个CMakeLists.txt文件，这些文件描述了如何编译代码以及将其安装到哪里。将CMakeLists.txt文件应用于一个catkin项目时，它就作为**一个标准的附带一些限制条件的vanilla CMakeLists.txt文件。**使用CMake编译程序时，`cmake`指令依据CMakeLists.txt 文件生成makefiles文件，`make`命令再依据makefiles文件编译链接生成可执行文件。\n\n​\tcatkin是ROS官方的一个编译构建系统，是原本的ROS的编译构建系统rosbuild的发展。`catkin_make`是将`cmake`与`make`的编译方式做了一个封装的指令工具，规范了工作路径与生成文件路径。\n\n\n\n ## 总体结构和顺序\n\n​\tCMakeList.txt文件必须遵循如下的格式，不然就无法正确地编译（译者遇到一些编译ros软件包时提示“ros未定义的引用”的错误，原因就是CMakeList.txt文件中命令顺序不正确）。\n\n- 必需的CMake版本：`cmake_minimum_required()`\n- 软件包名：`project()`\n- 查找编译依赖的其他CMake/Catkin包（声明依赖库）：`find_package()`\n- 启动Python模块支持：`catkin_python_package()`\n- 消息/服务/操作(Message/Service/Action)生成器：`add_message_files()`,`add_service_files()`,`add_action_files()`\n- 调用消息/服务/操作生成：`generate_messages()`\n- 指定包编译信息导出：`catkin_package()`\n- 添加要编译的库和可执行文件：`add_library()`/`add_executable()`/`target_link_libraries()`\n- 测试编译：`catkin_add_gtest()`\n- 安装规则：`install()`\n\n## CMake版本\n\n​\t每一个catkin CMakeList.txt文件必须以所需的CMake版本说明语句开始，Catkin需要2.8.3或者更高的版本\n\n~~~cmake\ncmake_minimum_required(VERSION 2.8.3)\n~~~\n\n## 软件包包名\n\n​\t软件包报名使用CMake的   `project()`函数指明，例如以robot_brain命名一个软件包：\n\n~~~cmake\nproject(robot_brain)\n~~~\n\n​\tCMake中，可以通过使用变量\t  `${PROJECT_NAME}`在CMake脚本后面的任何位置引用项目名称。\n\n## 查找编译依赖的CMake包\n\n​\t编译一个项目，需要使用CMake 的   `find_package`函数确定依赖的其他CMake包并找到它们，一般情况下至少会有一个catkin依赖：\n\n~~~cmake\nfind_package(catkin REQUIRED)\n~~~\n\n​\t除此之外，项目依赖的其他软件包，都会自动成为catkin的组件（components）（就CMake而言）。因此可以将这些依赖包指定为catkin的组件，而不必再使用`find_package`，这样将会变得简单，例如依赖包nodelet：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS nodelet)\n~~~\n\n​\t**注意：只能`find_package`那些想要编译标志的组件，不能添加运行时（runtime）依赖。**\n\n​\t当然也可以写成下面的方式，但不方便:\n\n~~~cmake\nfind_package(catkin REQUIRED)\nfind_package(nodelet REQUIRED)- ? \n~~~\n\n### find_package()做了什么？\n\n​\t如果CMake通过  `find_package()`查找到一个软件包，它就会创建几个CMake环境变量，以提供有关已查找到的软件包的信息。这些环境变量可以在后面的CMake脚本中使用，它们表示软件包导出的头文件所在的位置、源文件所在的位置、软件包依赖的库以及这些库的查找路径，环境变量的名字遵循`<PACKAGENAME>_<PROPERTY>`，即包名-属性：\n\n- `<NAME>_FOUND`：当库被查找到时置为true，否则为false\n- `<NAME>_INCLUDE_DIRS`或`<NAME>_INCLUDES`：软件包导出的头文件路径\n- `<NAME>_LIBRARIES`或`<NAME>_LIBS`：软件包导出的库的路径\n- `<NAME>_DEFINITIONS`：？\n\n### 为何将Catkin软件包指定为组件？\n\n​\tCatkin软件包严格意义上并不是catkin的组件，而且，CMake的功能组件功能被用于catkin的设计，以节省大量的打字时间。\n\n​\t对于catkin软件包，以catkin的组件的方式  `find_package`它们是有好处的，因为这个过程以catkin_prefix的形式创建了一组环境变量。例如，在程序中要使用nodelet软件包，推荐查找软件包的方式是：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS nodelet)\n~~~\n\n​\t这就意味着nodelet导出的头文件路径、库等都会附加到  `catkin_variables`上，比如，`catkin_INCLUDE_DIRS`不仅包含catkin的头文件路径，也包含了nodelet软件包的头文件路径，这在后面会派上用场。\n\n​\t如果单独的`find_package nodelet`：\n\n~~~cmake\nfind_package(nodelet)\n~~~\n\n​\t这意味着nodelet的头文件路径、库及其他文件都不会包含在  `catkin_variables`中，对于`nodelet_INCLUDE_DIRS`,` nodelet_LIBRARIES`及其他变量也是如此。相同的变量也可以通过下面的方式创建：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS nodelet)\n~~~\n\n### Boost库\n\n​\t如果使用C++和Boost库，需要在Boost上调用  `find_package()`，并指定Boost中将要作为组件的那部分。例如，如果想要使用Boost的线程，可以用：\n\n~~~cmake\nfind_package(Boost REQUIRED COMPONENTS thread)\n~~~\n\n## catkin_package()\n\n​\t`catkin_package()`是一个由catkin提供的CMake宏。需要指定特定的catkin信息到编译系统，而这些信息又会被用于生成pkg-config和CMake文件。\n\n​\t该函数必须在使用     `add_library()`或`add_executable()`声明任何targets之前调用。其5个可选参数：\n\n- `INCLUDE_DIRS`：软件包导出的头文件路径（例如cflags）\n- `LIBRARIES`：项目导出的库\n- `CATKIN_DEPENDS`：当前项目依赖的其他catkin项目\n- `DEPENDS`：当前项目依赖的非catkin CMake项目，详细解释参见[这里](answers.ros.org/question/58498/what-is-the-purpose-of-catkin_depends/)\n- `CFG_EXTRAS`：其他的配置选项\n\n\t\t完整的宏文件参见[这里](#catkin-package)。\n\n\t例子：\n\n~~~cmake\ncatkin_package( INCLUDE_DIRS include  \n                LIBRARIES ${PROJECT_NAME}   \n                CATKIN_DEPENDS roscpp nodelet   \n                DEPENDS eigen opencv)\n~~~\n\n​\t这里表明软件包文件夹中的include文件夹是导出头文件的位置，CMake环境变量   `${PROJECT_NAME}`将会鉴定之前传递给`project()`函数的所有内容，在这种情况下它作为“robot_brain”。“roscpp”+“nodelet”是编译/运行此程序包需要存在的软件包，“eigen”+“opencv”是编译/运行此程序包时需要存在的系统依赖项（ROS packages有时会需要操作系统提供一些外部函数库，这些函数库就是所谓的“系统依赖项”）。\n\n## 明确编译的目标\n\n​\t编译目标可以采取多种形式，但通常它们代表两种可能性之一：\t\n\n- 可执行目标：可以运行的程序\n- 库目标：在编译和/或运行时可以由可执行目标使用的库\n\n### 目标命名\n\n​\t非常重要的一点是，不管编译/安装到哪个文件夹中，编译目标在catkin中的名称都必须是唯一的。这是CMake的一项要求，但目标唯一的名称又只是在CMake内部是必需的。可以使用`set_target_properties()`函数对目标重命名，例子：\n\n~~~cmake\nset_target_properties(rviz_image_view \n\t\t      \t\t  PROPERTIES OUTPUT_NAME image_view\n                      PREFIX \"\")\n~~~\n\n​\t这会在编译和安装输出中将目标     `rviz_image_view`的名称改为`image_view`。\n\n### 自定义输出目录\n\n​\t可执行文件和库的默认输出目录通常设置为了合理的值，但在某些情况下必须进行自定义，例如，包含Python绑定的库必须放置在不同的文件夹中才能在Python中导入。\n\n​\t例子：\n\n~~~cmake\nset_target_properties(python_module_library  PROPERTIES LIBRARY_OUTPUT_DIRECTORY \t\t\t\t\t\t\t\t  {CATKIN_DEVEL_PREFIX}/{CATKIN_PACKAGE_PYTHON_DESTINATION})\n~~~\n\n### 头文件和库路径\n\n​\t在指定目标之前，需要指定可以为所述目标找到资源的位置，特别是头文件和库：\n\n- 头文件目录：将要编译的代码（C/C++）所需的头文件路径\t\n- 库目录：可执行目标编译指向的库路径\n- `include_directories(<dir1>, <dir2>, ..., <dirN>)`\n- `link_directories(<dir1>, <dir2>, ..., <dirN>)`\n\n#### include_directories()\n\n​\t`include_directories`的参数应该是由调用`find_package`生成的`* _INCLUDE_DIRS`变量以及需要包含的任何其他目录。如果使用`catkin`和`Boost`，`include_directories()`的调用为：\n\n~~~cmake\ninclude_directories(include {Boost_INCLUDE_DIRS} {catkin_INCLUDE_DIRS})\n~~~\n\n​\t第一个参数“include”表示包中的include/目录也是路径的一部分。\n\n#### link_directories()\n\n​\tCMake的   `link_directories()`函数可以添加其他的库目录，然而，并不推荐这么做。所有的catkin和CMake包在`find_package`时都会自动添加链接信息。只需链接到`target_link_libraries()`中的库。\n\n​\t例子：\n\n~~~cmake\nlink_directories(~/my_libs)\n~~~\n\n​\t详细信息参加[这里](http://www.cmake.org/pipermail/cmake/2011-May/044295.html)。\n\n### 可执行目标\n\n​\t要指定必须编译的可执行目标，必须使用CMake函数   `add_executable()`。声明想要的可执行文件的文件名，以此生成此可执行文件所需的源文件列表，如果有多个源文件，用空格区分开。例如：\n\n~~~cmake\nadd_executable(myProgram src/main.cpp src/some_file.cpp src/another_file.cpp)\n~~~\n\n​\t该命令会编译名为   `myProgram`的可执行文件，它是由后面的三个源文件共同编译生成的。\n\n### 库目标\n\n​\tCMake函数   `add_library()`指定用于编译的库文件，默认情况下，catkin编译共享库。\t\n\n~~~cmake\nadd_library({PROJECT_NAME} {${PROJECT_NAME}_SRCS})\n~~~\n\n## target_link_libraries\n\n​\t使用   `target_link_libraries()`函数指定可执行目标所要链接的库，即告诉CMake当链接此可执行文件时需要链接哪些库（这些库在上面的`find_package`中定义），通常在调用完`add_executable()`后被调用。如果出现[ros未定义的引用](#post-id-63674)错误，则添加`${catkin_LIBRARIES}`。\n\n​\t语法：\n\n~~~cmake\ntarget_link_libraries(<executableTargetName>, <lib1>, <lib2>, ... <libN>)\n~~~\n\n​\t例子:\n\n~~~cmake\nadd_executable(foo src/foo.cpp)\nadd_library(moo src/moo.cpp)\ntarget_link_libraries(foo moo) \n~~~\n\n​\t上面的例子将     `foo`与`libmoo.so`链接起来\n\n​\t**注意，在大多数使用情况下，没有必要使用`link_directories()`，因为该信息通过`find_package()`已经自动提取到了。** \n\n## 消息、服务和操作目标\n\n​\t在被ROS软件包编译和使用之前，ROS中的消息（.msg）、服务（.srv）和操作（.action）文件需要特殊的预处理器编译步骤。这些宏的要点是生成编程语言特定的文件，以便可以在编程语言中使用消息、服务和操作。编译系统将使用所有可用的生成器（例如gencpp、genpy、genlisp）生成绑定。\n\n​\t提供了三个宏来分别处理消息，服务和操作：\n\n- add_message_files\n- add_service_files\n- add_action_files\n\n\t\t这些宏后面必须调用一个调用生成的宏：\n\n~~~cmake\ngenerate_messages()\n~~~\n\n### 重要的前提和限制\n\n1. 这些宏必须在调用`catkin_package()`之前被调用，以正确地完成生成工作。\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS ...) \nadd_message_files(...) \nadd_service_files(...) \nadd_action_files(...) \ngenerate_messages(...) \ncatkin_package(...) ...\n~~~\n\n2. `catkin_package()`宏必须包含一个在`message_runtime`上的`CATKIN_DEPENDS`依赖。\n\n~~~cmake\ncatkin_package( ... \n                CATKIN_DEPENDS message_runtime ... \n                ...)\n~~~\n\n3. 必须对软件包`message_generation`使用`find_package()`，可单独或者作为catkin的组件使用：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS message_generation)\n~~~\n\n4. `package.xml`文件必须包含一个在`message_generation`上的编译依赖和一个在`message_runtime`上的运行时依赖，如果从其他包中传递依赖关系，则这不是必需的。\n5. 如果有一个目标（甚至是过渡性的）依赖于需要建立消息/服务/动作的其他目标，需要在目标`catkin_EXPORTED_TARGETS`上添加显式依赖项，以使它们按照正确的顺序编译。这种情况几乎总是适用，除非你的软件包真的不使用ROS的任何部分。不幸的是，这种依赖不能自动传播。（some_target是由`add_executable()`设置的目标的名字）\n\n~~~cmake\nadd_dependencies(some_target ${catkin_EXPORTED_TARGETS})\n~~~\n\n6. 如果有编译消息和/或服务的软件包以及使用这些软件的可执行文件，则需要在自动生成的消息目标上创建明确的依赖关系，以便它们按正确的顺序编译。（some_target是由`add_executable()`设置的目标的名字）\n\n~~~cmake\nadd_dependencies(some_target ${${PROJECT_NAME}_EXPORTED_TARGETS})\n~~~\n\n7. 如果软件包满足上述两个条件，则需要添加两个依赖项，即：\n\n~~~cmake\nadd_dependencies(some_target {${PROJECT_NAME}_EXPORTED_TARGETS}   \t\t      \t {catkin_EXPORTED_TARGETS})\n~~~\n\n### 例子\n\n​\t如果在msg目录下有两个消息文件       `MyMessage1.msg`和`MyMessage2.msg`，并且这些消息依赖于`std_msgs`和`sensor_msgs`，另外在srv目录下有一个服务文件`MyService.srv`，就可以使用这些消息、服务定义可执行`message_program`，和可执行的程序`does_not_use_local_messages_program`，这个过程使用了ROS的某些部分，但不包含此包中定义的消息/服务。需要在CMakeList.txt文件中加上一下内容：\n\n~~~cmake\n# Get the information about this package's buildtime dependencies  find_package(catkin REQUIRED    COMPONENTS message_generation std_msgs sensor_msgs)  \n# Declare the message files to be built  \nadd_message_files(FILES    MyMessage1.msg    MyMessage2.msg  )  \n# Declare the service files to be built  add_service_files(FILES    MyService.srv  )  \n# Actually generate the language-specific message and service files  generate_messages(DEPENDENCIES std_msgs sensor_msgs)  \n# Declare that this catkin package's runtime dependencies  catkin_package(   CATKIN_DEPENDS message_runtime std_msgs sensor_msgs  )  \n# define executable using MyMessage1 etc.  add_executable(message_program src/main.cpp)  add_dependencies(message_program {${PROJECT_NAME}_EXPORTED_TARGETS} {catkin_EXPORTED_TARGETS})  \n# define executable not using any messages/services provided by this package  \nadd_executable(does_not_use_local_messages_program src/main.cpp)  add_dependencies(does_not_use_local_messages_program ${catkin_EXPORTED_TARGETS})\n~~~\n\n​\t另外如果需要编译actionlib操作，并且在action目录下有一个名为`MyAction.action`的操作规范文件，就必须要添加`actionlib_msgs`到组件列表中，该组件列表就是`find_package`中catkin的组件，并在调用`generate_messages()`之前调用：\n\n~~~cmake\nadd_action_files(FILES MyAction.action)\n~~~\n\n​\t此外，该包必须对   `actionlib_msgs`具有编译依赖关系。\n\n## 启动Python模块支持\n\n​\t如果ROS软件包提供了一些Python模块，就要创建一个`setup.py`文件并调用：\n\n~~~cmake\ncatkin_python_setup()\n~~~\n\n​\t该调用要在`generate_message()`和`catkin_package()`的调用之前。\n\n## 单元测试\n\n​\t特定的catkin宏   `catkin_add_gtest()`用于处理基于gtest的单元测试：\n\n~~~cmake\ncatkin_add_gtest(myUnitTest test/utest.cpp)\n~~~\n\n## 可选步骤：明确安装目标\n\n​\t编译完成后，目标被放入catkin工作空间下的devel目录。一般希望将目标安装到系统上，以使其他用户使用，或者安装到本地目录来测试系统级别的安装。也就是说，如果希望能够对代码进行`make install`，就需要明确目标结束的位置。\n\n​\t上述过程可以使用CMake的   `install()`函数实现，该函数的参数有：\n\n- `TARGETS`：要安装的目标\n- `ARCHIVE DESTINATION`：静态库和动态链接库DLL(Windows).lib存根\n- `LIBRARY DESTINATION`：非DLL共享库和模块\n- `RUNTIME DESTINATION`：可执行目标和DLL(Windows)模式共享库\n\n\t\t例子：\n\n~~~cmake\ninstall(TARGETS ${PROJECT_NAME}  \n        ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}  \n        LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}  \n        RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION})\n~~~\n\n​\t除了这些标准的目标，还要安装一些文件到特定的目录下，即一个包含Python绑定的库必须要安装到另外的不同的目录下，这对Python是重要的：\n\n~~~cmake\ninstall(TARGETS python_module_library  \n        ARCHIVE DESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION}  \n        LIBRARY DESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION})\n~~~\n\n### 安装Python可执行脚本\n\n​\tPython代码的安装规则有些不同，它不需要使用     `add_library()`和`add_executable()`函数来告知CMake哪个文件是目标文件、目标文件是什么类型的。而是使用如下的CMakeList.txt文件：\n\n~~~cmake\ncatkin_install_python(PROGRAMS scripts/myscript  \n\t\t\t\t\t  DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION})\n~~~\n\n​\t如果只是安装了Python的脚本，不提供任何模块的话，就不用创建上文提到的   `setup.py`文件，也不用调用`catkin_python_setup()`。\n\n### 安装头文件\n\n​\t头文件必须安装到include目录下，这通常通过安装整个文件夹的文件来完成（可以根据文件名模式进行过滤，并排除SVN子文件夹）。可以通过一下安装规则实现：\n\n~~~cmake\ninstall(DIRECTORY include/${PROJECT_NAME}/  \n        DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}  \n        PATTERN \".svn\" EXCLUDE)\n~~~\n\n​\t或者如果include目录下的子文件夹无法和软件包名匹配时：\n\n~~~cmake\ninstall(DIRECTORY include/  \n        DESTINATION ${CATKIN_GLOBAL_INCLUDE_DESTINATION}  \n        PATTERN \".svn\" EXCLUDE)\n~~~\n\n### 安装roslaunch文件或其他源\n\n​\t其他像launchfiles的资源可以安装到   `${CATKIN_PACKAGE_SHARE_DESTINATION}`：\n\n~~~cmake\ninstall(DIRECTORY launch/  \n        DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}/launch  \n        PATTERN \".svn\" EXCLUDE)\n~~~\n## CMakeLists.txt文件书写模板\n\n~~~cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(my_p)\n\n## Compile as C++11, supported in ROS Kinetic and newer\n# add_compile_options(-std=c++11)\n\n## Find catkin macros and libraries\n## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)\n## is used, also find other catkin packages\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  rospy\n  std_msgs\n)\n\n## System dependencies are found with CMake's conventions\n# find_package(Boost REQUIRED COMPONENTS system)\n\n\n## Uncomment this if the package has a setup.py. This macro ensures\n## modules and global scripts declared therein get installed\n## See http://ros.org/doc/api/catkin/html/user_guide/setup_dot_py.html\n# catkin_python_setup()\n\n################################################\n## Declare ROS messages, services and actions ##\n################################################\n\n## To declare and build messages, services or actions from within this\n## package, follow these steps:\n## * Let MSG_DEP_SET be the set of packages whose message types you use in\n##   your messages/services/actions (e.g. std_msgs, actionlib_msgs, ...).\n## * In the file package.xml:\n##   * add a build_depend tag for \"message_generation\"\n##   * add a build_depend and a run_depend tag for each package in MSG_DEP_SET\n##   * If MSG_DEP_SET isn't empty the following dependency has been pulled in\n##     but can be declared for certainty nonetheless:\n##     * add a run_depend tag for \"message_runtime\"\n## * In this file (CMakeLists.txt):\n##   * add \"message_generation\" and every package in MSG_DEP_SET to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * add \"message_runtime\" and every package in MSG_DEP_SET to\n##     catkin_package(CATKIN_DEPENDS ...)\n##   * uncomment the add_*_files sections below as needed\n##     and list every .msg/.srv/.action file to be processed\n##   * uncomment the generate_messages entry below\n##   * add every package in MSG_DEP_SET to generate_messages(DEPENDENCIES ...)\n\n## Generate messages in the 'msg' folder\n# add_message_files(\n#   FILES\n#   Message1.msg\n#   Message2.msg\n# )\n\n## Generate services in the 'srv' folder\n# add_service_files(\n#   FILES\n#   Service1.srv\n#   Service2.srv\n# )\n\n## Generate actions in the 'action' folder\n# add_action_files(\n#   FILES\n#   Action1.action\n#   Action2.action\n# )\n\n## Generate added messages and services with any dependencies listed here\n# generate_messages(\n#   DEPENDENCIES\n#   std_msgs\n# )\n\n################################################\n## Declare ROS dynamic reconfigure parameters ##\n################################################\n\n## To declare and build dynamic reconfigure parameters within this\n## package, follow these steps:\n## * In the file package.xml:\n##   * add a build_depend and a run_depend tag for \"dynamic_reconfigure\"\n## * In this file (CMakeLists.txt):\n##   * add \"dynamic_reconfigure\" to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * uncomment the \"generate_dynamic_reconfigure_options\" section below\n##     and list every .cfg file to be processed\n\n## Generate dynamic reconfigure parameters in the 'cfg' folder\n# generate_dynamic_reconfigure_options(\n#   cfg/DynReconf1.cfg\n#   cfg/DynReconf2.cfg\n# )\n\n###################################\n## catkin specific configuration ##\n###################################\n## The catkin_package macro generates cmake config files for your package\n## Declare things to be passed to dependent projects\n## INCLUDE_DIRS: uncomment this if your package contains header files\n## LIBRARIES: libraries you create in this project that dependent projects also need\n## CATKIN_DEPENDS: catkin_packages dependent projects also need\n## DEPENDS: system dependencies of this project that dependent projects also need\ncatkin_package(\n#  INCLUDE_DIRS include\n#  LIBRARIES my_p\n#  CATKIN_DEPENDS roscpp rospy std_msgs\n#  DEPENDS system_lib\n)\n\n###########\n## Build ##\n###########\n\n## Specify additional locations of header files\n## Your package locations should be listed before other locations\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\n## Declare a C++ library\n# add_library(${PROJECT_NAME}\n#   src/${PROJECT_NAME}/my_p.cpp\n# )\n\n## Add cmake target dependencies of the library\n## as an example, code may need to be generated before libraries\n## either from message generation or dynamic reconfigure\n# add_dependencies(${PROJECT_NAME} ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Declare a C++ executable\n## With catkin_make all packages are built within a single CMake context\n## The recommended prefix ensures that target names across packages don't collide\n# add_executable(${PROJECT_NAME}_node src/my_p_node.cpp)\n\n## Rename C++ executable without prefix\n## The above recommended prefix causes long target names, the following renames the\n## target back to the shorter version for ease of user use\n## e.g. \"rosrun someones_pkg node\" instead of \"rosrun someones_pkg someones_pkg_node\"\n# set_target_properties(${PROJECT_NAME}_node PROPERTIES OUTPUT_NAME node PREFIX \"\")\n\n## Add cmake target dependencies of the executable\n## same as for the library above\n# add_dependencies(${PROJECT_NAME}_node ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Specify libraries to link a library or executable target against\n# target_link_libraries(${PROJECT_NAME}_node\n#   ${catkin_LIBRARIES}\n# )\n\n#############\n## Install ##\n#############\n\n# all install targets should use catkin DESTINATION variables\n# See http://ros.org/doc/api/catkin/html/adv_user_guide/variables.html\n\n## Mark executable scripts (Python etc.) for installation\n## in contrast to setup.py, you can choose the destination\n# install(PROGRAMS\n#   scripts/my_python_script\n#   DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark executables and/or libraries for installation\n# install(TARGETS ${PROJECT_NAME} ${PROJECT_NAME}_node\n#   ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark cpp header files for installation\n# install(DIRECTORY include/${PROJECT_NAME}/\n#   DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}\n#   FILES_MATCHING PATTERN \"*.h\"\n#   PATTERN \".svn\" EXCLUDE\n# )\n\n## Mark other files for installation (e.g. launch and bag files, etc.)\n# install(FILES\n#   # myfile1\n#   # myfile2\n#   DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n# )\n\n#############\n## Testing ##\n#############\n\n## Add gtest based cpp test target and link libraries\n# catkin_add_gtest(${PROJECT_NAME}-test test/test_my_p.cpp)\n# if(TARGET ${PROJECT_NAME}-test)\n#   target_link_libraries(${PROJECT_NAME}-test ${PROJECT_NAME})\n# endif()\n\n## Add folders to be run by python nosetests\n# catkin_add_nosetests(test)\n~~~\n\n\n\n","source":"_posts/ROS学习之catkin CMakeList.txt介绍（译）.md","raw":"---\ntitle: ROS学习之catkin CMakeList.txt介绍（译）\ndate: 2018-03-21 22:04:00\ntags: \n  - ROS \n  - CMake\ncategories: \n  - 机器人\n  - ROS\ncopyright: true\n---\n\n***\n\n这篇文章是有关ROS中catkin CMakeLists.txt使用的内容。\n\n<!--more-->\n\n​\t本文翻译自ROS官网关于catkin CMakeList.txt的介绍，**[官网原文链接](http://wiki.ros.org/catkin/CMakeLists.txt)**，由于直接阅读英文文档感觉自己理解不透彻、收获不多，所以决定一边翻译一边学习。其中零星的加入了一些译者个人使用过程中的体会以及在阅读《机器人操作系统（ROS）浅析》（Jason M.O’Kane著 肖军浩译）一书时学习到的内容，帮助自己更好地理解catkin编译生成的过程，留作今后复习完善。\n\n## 概况\n\n​\tCMakeList.txt文件是CMake编译系统编译软件包过程的输入文件。任何CMake兼容包都包含一个或多个CMakeLists.txt文件，这些文件描述了如何编译代码以及将其安装到哪里。将CMakeLists.txt文件应用于一个catkin项目时，它就作为**一个标准的附带一些限制条件的vanilla CMakeLists.txt文件。**使用CMake编译程序时，`cmake`指令依据CMakeLists.txt 文件生成makefiles文件，`make`命令再依据makefiles文件编译链接生成可执行文件。\n\n​\tcatkin是ROS官方的一个编译构建系统，是原本的ROS的编译构建系统rosbuild的发展。`catkin_make`是将`cmake`与`make`的编译方式做了一个封装的指令工具，规范了工作路径与生成文件路径。\n\n\n\n ## 总体结构和顺序\n\n​\tCMakeList.txt文件必须遵循如下的格式，不然就无法正确地编译（译者遇到一些编译ros软件包时提示“ros未定义的引用”的错误，原因就是CMakeList.txt文件中命令顺序不正确）。\n\n- 必需的CMake版本：`cmake_minimum_required()`\n- 软件包名：`project()`\n- 查找编译依赖的其他CMake/Catkin包（声明依赖库）：`find_package()`\n- 启动Python模块支持：`catkin_python_package()`\n- 消息/服务/操作(Message/Service/Action)生成器：`add_message_files()`,`add_service_files()`,`add_action_files()`\n- 调用消息/服务/操作生成：`generate_messages()`\n- 指定包编译信息导出：`catkin_package()`\n- 添加要编译的库和可执行文件：`add_library()`/`add_executable()`/`target_link_libraries()`\n- 测试编译：`catkin_add_gtest()`\n- 安装规则：`install()`\n\n## CMake版本\n\n​\t每一个catkin CMakeList.txt文件必须以所需的CMake版本说明语句开始，Catkin需要2.8.3或者更高的版本\n\n~~~cmake\ncmake_minimum_required(VERSION 2.8.3)\n~~~\n\n## 软件包包名\n\n​\t软件包报名使用CMake的   `project()`函数指明，例如以robot_brain命名一个软件包：\n\n~~~cmake\nproject(robot_brain)\n~~~\n\n​\tCMake中，可以通过使用变量\t  `${PROJECT_NAME}`在CMake脚本后面的任何位置引用项目名称。\n\n## 查找编译依赖的CMake包\n\n​\t编译一个项目，需要使用CMake 的   `find_package`函数确定依赖的其他CMake包并找到它们，一般情况下至少会有一个catkin依赖：\n\n~~~cmake\nfind_package(catkin REQUIRED)\n~~~\n\n​\t除此之外，项目依赖的其他软件包，都会自动成为catkin的组件（components）（就CMake而言）。因此可以将这些依赖包指定为catkin的组件，而不必再使用`find_package`，这样将会变得简单，例如依赖包nodelet：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS nodelet)\n~~~\n\n​\t**注意：只能`find_package`那些想要编译标志的组件，不能添加运行时（runtime）依赖。**\n\n​\t当然也可以写成下面的方式，但不方便:\n\n~~~cmake\nfind_package(catkin REQUIRED)\nfind_package(nodelet REQUIRED)- ? \n~~~\n\n### find_package()做了什么？\n\n​\t如果CMake通过  `find_package()`查找到一个软件包，它就会创建几个CMake环境变量，以提供有关已查找到的软件包的信息。这些环境变量可以在后面的CMake脚本中使用，它们表示软件包导出的头文件所在的位置、源文件所在的位置、软件包依赖的库以及这些库的查找路径，环境变量的名字遵循`<PACKAGENAME>_<PROPERTY>`，即包名-属性：\n\n- `<NAME>_FOUND`：当库被查找到时置为true，否则为false\n- `<NAME>_INCLUDE_DIRS`或`<NAME>_INCLUDES`：软件包导出的头文件路径\n- `<NAME>_LIBRARIES`或`<NAME>_LIBS`：软件包导出的库的路径\n- `<NAME>_DEFINITIONS`：？\n\n### 为何将Catkin软件包指定为组件？\n\n​\tCatkin软件包严格意义上并不是catkin的组件，而且，CMake的功能组件功能被用于catkin的设计，以节省大量的打字时间。\n\n​\t对于catkin软件包，以catkin的组件的方式  `find_package`它们是有好处的，因为这个过程以catkin_prefix的形式创建了一组环境变量。例如，在程序中要使用nodelet软件包，推荐查找软件包的方式是：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS nodelet)\n~~~\n\n​\t这就意味着nodelet导出的头文件路径、库等都会附加到  `catkin_variables`上，比如，`catkin_INCLUDE_DIRS`不仅包含catkin的头文件路径，也包含了nodelet软件包的头文件路径，这在后面会派上用场。\n\n​\t如果单独的`find_package nodelet`：\n\n~~~cmake\nfind_package(nodelet)\n~~~\n\n​\t这意味着nodelet的头文件路径、库及其他文件都不会包含在  `catkin_variables`中，对于`nodelet_INCLUDE_DIRS`,` nodelet_LIBRARIES`及其他变量也是如此。相同的变量也可以通过下面的方式创建：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS nodelet)\n~~~\n\n### Boost库\n\n​\t如果使用C++和Boost库，需要在Boost上调用  `find_package()`，并指定Boost中将要作为组件的那部分。例如，如果想要使用Boost的线程，可以用：\n\n~~~cmake\nfind_package(Boost REQUIRED COMPONENTS thread)\n~~~\n\n## catkin_package()\n\n​\t`catkin_package()`是一个由catkin提供的CMake宏。需要指定特定的catkin信息到编译系统，而这些信息又会被用于生成pkg-config和CMake文件。\n\n​\t该函数必须在使用     `add_library()`或`add_executable()`声明任何targets之前调用。其5个可选参数：\n\n- `INCLUDE_DIRS`：软件包导出的头文件路径（例如cflags）\n- `LIBRARIES`：项目导出的库\n- `CATKIN_DEPENDS`：当前项目依赖的其他catkin项目\n- `DEPENDS`：当前项目依赖的非catkin CMake项目，详细解释参见[这里](answers.ros.org/question/58498/what-is-the-purpose-of-catkin_depends/)\n- `CFG_EXTRAS`：其他的配置选项\n\n\t\t完整的宏文件参见[这里](#catkin-package)。\n\n\t例子：\n\n~~~cmake\ncatkin_package( INCLUDE_DIRS include  \n                LIBRARIES ${PROJECT_NAME}   \n                CATKIN_DEPENDS roscpp nodelet   \n                DEPENDS eigen opencv)\n~~~\n\n​\t这里表明软件包文件夹中的include文件夹是导出头文件的位置，CMake环境变量   `${PROJECT_NAME}`将会鉴定之前传递给`project()`函数的所有内容，在这种情况下它作为“robot_brain”。“roscpp”+“nodelet”是编译/运行此程序包需要存在的软件包，“eigen”+“opencv”是编译/运行此程序包时需要存在的系统依赖项（ROS packages有时会需要操作系统提供一些外部函数库，这些函数库就是所谓的“系统依赖项”）。\n\n## 明确编译的目标\n\n​\t编译目标可以采取多种形式，但通常它们代表两种可能性之一：\t\n\n- 可执行目标：可以运行的程序\n- 库目标：在编译和/或运行时可以由可执行目标使用的库\n\n### 目标命名\n\n​\t非常重要的一点是，不管编译/安装到哪个文件夹中，编译目标在catkin中的名称都必须是唯一的。这是CMake的一项要求，但目标唯一的名称又只是在CMake内部是必需的。可以使用`set_target_properties()`函数对目标重命名，例子：\n\n~~~cmake\nset_target_properties(rviz_image_view \n\t\t      \t\t  PROPERTIES OUTPUT_NAME image_view\n                      PREFIX \"\")\n~~~\n\n​\t这会在编译和安装输出中将目标     `rviz_image_view`的名称改为`image_view`。\n\n### 自定义输出目录\n\n​\t可执行文件和库的默认输出目录通常设置为了合理的值，但在某些情况下必须进行自定义，例如，包含Python绑定的库必须放置在不同的文件夹中才能在Python中导入。\n\n​\t例子：\n\n~~~cmake\nset_target_properties(python_module_library  PROPERTIES LIBRARY_OUTPUT_DIRECTORY \t\t\t\t\t\t\t\t  {CATKIN_DEVEL_PREFIX}/{CATKIN_PACKAGE_PYTHON_DESTINATION})\n~~~\n\n### 头文件和库路径\n\n​\t在指定目标之前，需要指定可以为所述目标找到资源的位置，特别是头文件和库：\n\n- 头文件目录：将要编译的代码（C/C++）所需的头文件路径\t\n- 库目录：可执行目标编译指向的库路径\n- `include_directories(<dir1>, <dir2>, ..., <dirN>)`\n- `link_directories(<dir1>, <dir2>, ..., <dirN>)`\n\n#### include_directories()\n\n​\t`include_directories`的参数应该是由调用`find_package`生成的`* _INCLUDE_DIRS`变量以及需要包含的任何其他目录。如果使用`catkin`和`Boost`，`include_directories()`的调用为：\n\n~~~cmake\ninclude_directories(include {Boost_INCLUDE_DIRS} {catkin_INCLUDE_DIRS})\n~~~\n\n​\t第一个参数“include”表示包中的include/目录也是路径的一部分。\n\n#### link_directories()\n\n​\tCMake的   `link_directories()`函数可以添加其他的库目录，然而，并不推荐这么做。所有的catkin和CMake包在`find_package`时都会自动添加链接信息。只需链接到`target_link_libraries()`中的库。\n\n​\t例子：\n\n~~~cmake\nlink_directories(~/my_libs)\n~~~\n\n​\t详细信息参加[这里](http://www.cmake.org/pipermail/cmake/2011-May/044295.html)。\n\n### 可执行目标\n\n​\t要指定必须编译的可执行目标，必须使用CMake函数   `add_executable()`。声明想要的可执行文件的文件名，以此生成此可执行文件所需的源文件列表，如果有多个源文件，用空格区分开。例如：\n\n~~~cmake\nadd_executable(myProgram src/main.cpp src/some_file.cpp src/another_file.cpp)\n~~~\n\n​\t该命令会编译名为   `myProgram`的可执行文件，它是由后面的三个源文件共同编译生成的。\n\n### 库目标\n\n​\tCMake函数   `add_library()`指定用于编译的库文件，默认情况下，catkin编译共享库。\t\n\n~~~cmake\nadd_library({PROJECT_NAME} {${PROJECT_NAME}_SRCS})\n~~~\n\n## target_link_libraries\n\n​\t使用   `target_link_libraries()`函数指定可执行目标所要链接的库，即告诉CMake当链接此可执行文件时需要链接哪些库（这些库在上面的`find_package`中定义），通常在调用完`add_executable()`后被调用。如果出现[ros未定义的引用](#post-id-63674)错误，则添加`${catkin_LIBRARIES}`。\n\n​\t语法：\n\n~~~cmake\ntarget_link_libraries(<executableTargetName>, <lib1>, <lib2>, ... <libN>)\n~~~\n\n​\t例子:\n\n~~~cmake\nadd_executable(foo src/foo.cpp)\nadd_library(moo src/moo.cpp)\ntarget_link_libraries(foo moo) \n~~~\n\n​\t上面的例子将     `foo`与`libmoo.so`链接起来\n\n​\t**注意，在大多数使用情况下，没有必要使用`link_directories()`，因为该信息通过`find_package()`已经自动提取到了。** \n\n## 消息、服务和操作目标\n\n​\t在被ROS软件包编译和使用之前，ROS中的消息（.msg）、服务（.srv）和操作（.action）文件需要特殊的预处理器编译步骤。这些宏的要点是生成编程语言特定的文件，以便可以在编程语言中使用消息、服务和操作。编译系统将使用所有可用的生成器（例如gencpp、genpy、genlisp）生成绑定。\n\n​\t提供了三个宏来分别处理消息，服务和操作：\n\n- add_message_files\n- add_service_files\n- add_action_files\n\n\t\t这些宏后面必须调用一个调用生成的宏：\n\n~~~cmake\ngenerate_messages()\n~~~\n\n### 重要的前提和限制\n\n1. 这些宏必须在调用`catkin_package()`之前被调用，以正确地完成生成工作。\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS ...) \nadd_message_files(...) \nadd_service_files(...) \nadd_action_files(...) \ngenerate_messages(...) \ncatkin_package(...) ...\n~~~\n\n2. `catkin_package()`宏必须包含一个在`message_runtime`上的`CATKIN_DEPENDS`依赖。\n\n~~~cmake\ncatkin_package( ... \n                CATKIN_DEPENDS message_runtime ... \n                ...)\n~~~\n\n3. 必须对软件包`message_generation`使用`find_package()`，可单独或者作为catkin的组件使用：\n\n~~~cmake\nfind_package(catkin REQUIRED COMPONENTS message_generation)\n~~~\n\n4. `package.xml`文件必须包含一个在`message_generation`上的编译依赖和一个在`message_runtime`上的运行时依赖，如果从其他包中传递依赖关系，则这不是必需的。\n5. 如果有一个目标（甚至是过渡性的）依赖于需要建立消息/服务/动作的其他目标，需要在目标`catkin_EXPORTED_TARGETS`上添加显式依赖项，以使它们按照正确的顺序编译。这种情况几乎总是适用，除非你的软件包真的不使用ROS的任何部分。不幸的是，这种依赖不能自动传播。（some_target是由`add_executable()`设置的目标的名字）\n\n~~~cmake\nadd_dependencies(some_target ${catkin_EXPORTED_TARGETS})\n~~~\n\n6. 如果有编译消息和/或服务的软件包以及使用这些软件的可执行文件，则需要在自动生成的消息目标上创建明确的依赖关系，以便它们按正确的顺序编译。（some_target是由`add_executable()`设置的目标的名字）\n\n~~~cmake\nadd_dependencies(some_target ${${PROJECT_NAME}_EXPORTED_TARGETS})\n~~~\n\n7. 如果软件包满足上述两个条件，则需要添加两个依赖项，即：\n\n~~~cmake\nadd_dependencies(some_target {${PROJECT_NAME}_EXPORTED_TARGETS}   \t\t      \t {catkin_EXPORTED_TARGETS})\n~~~\n\n### 例子\n\n​\t如果在msg目录下有两个消息文件       `MyMessage1.msg`和`MyMessage2.msg`，并且这些消息依赖于`std_msgs`和`sensor_msgs`，另外在srv目录下有一个服务文件`MyService.srv`，就可以使用这些消息、服务定义可执行`message_program`，和可执行的程序`does_not_use_local_messages_program`，这个过程使用了ROS的某些部分，但不包含此包中定义的消息/服务。需要在CMakeList.txt文件中加上一下内容：\n\n~~~cmake\n# Get the information about this package's buildtime dependencies  find_package(catkin REQUIRED    COMPONENTS message_generation std_msgs sensor_msgs)  \n# Declare the message files to be built  \nadd_message_files(FILES    MyMessage1.msg    MyMessage2.msg  )  \n# Declare the service files to be built  add_service_files(FILES    MyService.srv  )  \n# Actually generate the language-specific message and service files  generate_messages(DEPENDENCIES std_msgs sensor_msgs)  \n# Declare that this catkin package's runtime dependencies  catkin_package(   CATKIN_DEPENDS message_runtime std_msgs sensor_msgs  )  \n# define executable using MyMessage1 etc.  add_executable(message_program src/main.cpp)  add_dependencies(message_program {${PROJECT_NAME}_EXPORTED_TARGETS} {catkin_EXPORTED_TARGETS})  \n# define executable not using any messages/services provided by this package  \nadd_executable(does_not_use_local_messages_program src/main.cpp)  add_dependencies(does_not_use_local_messages_program ${catkin_EXPORTED_TARGETS})\n~~~\n\n​\t另外如果需要编译actionlib操作，并且在action目录下有一个名为`MyAction.action`的操作规范文件，就必须要添加`actionlib_msgs`到组件列表中，该组件列表就是`find_package`中catkin的组件，并在调用`generate_messages()`之前调用：\n\n~~~cmake\nadd_action_files(FILES MyAction.action)\n~~~\n\n​\t此外，该包必须对   `actionlib_msgs`具有编译依赖关系。\n\n## 启动Python模块支持\n\n​\t如果ROS软件包提供了一些Python模块，就要创建一个`setup.py`文件并调用：\n\n~~~cmake\ncatkin_python_setup()\n~~~\n\n​\t该调用要在`generate_message()`和`catkin_package()`的调用之前。\n\n## 单元测试\n\n​\t特定的catkin宏   `catkin_add_gtest()`用于处理基于gtest的单元测试：\n\n~~~cmake\ncatkin_add_gtest(myUnitTest test/utest.cpp)\n~~~\n\n## 可选步骤：明确安装目标\n\n​\t编译完成后，目标被放入catkin工作空间下的devel目录。一般希望将目标安装到系统上，以使其他用户使用，或者安装到本地目录来测试系统级别的安装。也就是说，如果希望能够对代码进行`make install`，就需要明确目标结束的位置。\n\n​\t上述过程可以使用CMake的   `install()`函数实现，该函数的参数有：\n\n- `TARGETS`：要安装的目标\n- `ARCHIVE DESTINATION`：静态库和动态链接库DLL(Windows).lib存根\n- `LIBRARY DESTINATION`：非DLL共享库和模块\n- `RUNTIME DESTINATION`：可执行目标和DLL(Windows)模式共享库\n\n\t\t例子：\n\n~~~cmake\ninstall(TARGETS ${PROJECT_NAME}  \n        ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}  \n        LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}  \n        RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION})\n~~~\n\n​\t除了这些标准的目标，还要安装一些文件到特定的目录下，即一个包含Python绑定的库必须要安装到另外的不同的目录下，这对Python是重要的：\n\n~~~cmake\ninstall(TARGETS python_module_library  \n        ARCHIVE DESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION}  \n        LIBRARY DESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION})\n~~~\n\n### 安装Python可执行脚本\n\n​\tPython代码的安装规则有些不同，它不需要使用     `add_library()`和`add_executable()`函数来告知CMake哪个文件是目标文件、目标文件是什么类型的。而是使用如下的CMakeList.txt文件：\n\n~~~cmake\ncatkin_install_python(PROGRAMS scripts/myscript  \n\t\t\t\t\t  DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION})\n~~~\n\n​\t如果只是安装了Python的脚本，不提供任何模块的话，就不用创建上文提到的   `setup.py`文件，也不用调用`catkin_python_setup()`。\n\n### 安装头文件\n\n​\t头文件必须安装到include目录下，这通常通过安装整个文件夹的文件来完成（可以根据文件名模式进行过滤，并排除SVN子文件夹）。可以通过一下安装规则实现：\n\n~~~cmake\ninstall(DIRECTORY include/${PROJECT_NAME}/  \n        DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}  \n        PATTERN \".svn\" EXCLUDE)\n~~~\n\n​\t或者如果include目录下的子文件夹无法和软件包名匹配时：\n\n~~~cmake\ninstall(DIRECTORY include/  \n        DESTINATION ${CATKIN_GLOBAL_INCLUDE_DESTINATION}  \n        PATTERN \".svn\" EXCLUDE)\n~~~\n\n### 安装roslaunch文件或其他源\n\n​\t其他像launchfiles的资源可以安装到   `${CATKIN_PACKAGE_SHARE_DESTINATION}`：\n\n~~~cmake\ninstall(DIRECTORY launch/  \n        DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}/launch  \n        PATTERN \".svn\" EXCLUDE)\n~~~\n## CMakeLists.txt文件书写模板\n\n~~~cmake\ncmake_minimum_required(VERSION 2.8.3)\nproject(my_p)\n\n## Compile as C++11, supported in ROS Kinetic and newer\n# add_compile_options(-std=c++11)\n\n## Find catkin macros and libraries\n## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)\n## is used, also find other catkin packages\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  rospy\n  std_msgs\n)\n\n## System dependencies are found with CMake's conventions\n# find_package(Boost REQUIRED COMPONENTS system)\n\n\n## Uncomment this if the package has a setup.py. This macro ensures\n## modules and global scripts declared therein get installed\n## See http://ros.org/doc/api/catkin/html/user_guide/setup_dot_py.html\n# catkin_python_setup()\n\n################################################\n## Declare ROS messages, services and actions ##\n################################################\n\n## To declare and build messages, services or actions from within this\n## package, follow these steps:\n## * Let MSG_DEP_SET be the set of packages whose message types you use in\n##   your messages/services/actions (e.g. std_msgs, actionlib_msgs, ...).\n## * In the file package.xml:\n##   * add a build_depend tag for \"message_generation\"\n##   * add a build_depend and a run_depend tag for each package in MSG_DEP_SET\n##   * If MSG_DEP_SET isn't empty the following dependency has been pulled in\n##     but can be declared for certainty nonetheless:\n##     * add a run_depend tag for \"message_runtime\"\n## * In this file (CMakeLists.txt):\n##   * add \"message_generation\" and every package in MSG_DEP_SET to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * add \"message_runtime\" and every package in MSG_DEP_SET to\n##     catkin_package(CATKIN_DEPENDS ...)\n##   * uncomment the add_*_files sections below as needed\n##     and list every .msg/.srv/.action file to be processed\n##   * uncomment the generate_messages entry below\n##   * add every package in MSG_DEP_SET to generate_messages(DEPENDENCIES ...)\n\n## Generate messages in the 'msg' folder\n# add_message_files(\n#   FILES\n#   Message1.msg\n#   Message2.msg\n# )\n\n## Generate services in the 'srv' folder\n# add_service_files(\n#   FILES\n#   Service1.srv\n#   Service2.srv\n# )\n\n## Generate actions in the 'action' folder\n# add_action_files(\n#   FILES\n#   Action1.action\n#   Action2.action\n# )\n\n## Generate added messages and services with any dependencies listed here\n# generate_messages(\n#   DEPENDENCIES\n#   std_msgs\n# )\n\n################################################\n## Declare ROS dynamic reconfigure parameters ##\n################################################\n\n## To declare and build dynamic reconfigure parameters within this\n## package, follow these steps:\n## * In the file package.xml:\n##   * add a build_depend and a run_depend tag for \"dynamic_reconfigure\"\n## * In this file (CMakeLists.txt):\n##   * add \"dynamic_reconfigure\" to\n##     find_package(catkin REQUIRED COMPONENTS ...)\n##   * uncomment the \"generate_dynamic_reconfigure_options\" section below\n##     and list every .cfg file to be processed\n\n## Generate dynamic reconfigure parameters in the 'cfg' folder\n# generate_dynamic_reconfigure_options(\n#   cfg/DynReconf1.cfg\n#   cfg/DynReconf2.cfg\n# )\n\n###################################\n## catkin specific configuration ##\n###################################\n## The catkin_package macro generates cmake config files for your package\n## Declare things to be passed to dependent projects\n## INCLUDE_DIRS: uncomment this if your package contains header files\n## LIBRARIES: libraries you create in this project that dependent projects also need\n## CATKIN_DEPENDS: catkin_packages dependent projects also need\n## DEPENDS: system dependencies of this project that dependent projects also need\ncatkin_package(\n#  INCLUDE_DIRS include\n#  LIBRARIES my_p\n#  CATKIN_DEPENDS roscpp rospy std_msgs\n#  DEPENDS system_lib\n)\n\n###########\n## Build ##\n###########\n\n## Specify additional locations of header files\n## Your package locations should be listed before other locations\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\n## Declare a C++ library\n# add_library(${PROJECT_NAME}\n#   src/${PROJECT_NAME}/my_p.cpp\n# )\n\n## Add cmake target dependencies of the library\n## as an example, code may need to be generated before libraries\n## either from message generation or dynamic reconfigure\n# add_dependencies(${PROJECT_NAME} ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Declare a C++ executable\n## With catkin_make all packages are built within a single CMake context\n## The recommended prefix ensures that target names across packages don't collide\n# add_executable(${PROJECT_NAME}_node src/my_p_node.cpp)\n\n## Rename C++ executable without prefix\n## The above recommended prefix causes long target names, the following renames the\n## target back to the shorter version for ease of user use\n## e.g. \"rosrun someones_pkg node\" instead of \"rosrun someones_pkg someones_pkg_node\"\n# set_target_properties(${PROJECT_NAME}_node PROPERTIES OUTPUT_NAME node PREFIX \"\")\n\n## Add cmake target dependencies of the executable\n## same as for the library above\n# add_dependencies(${PROJECT_NAME}_node ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n\n## Specify libraries to link a library or executable target against\n# target_link_libraries(${PROJECT_NAME}_node\n#   ${catkin_LIBRARIES}\n# )\n\n#############\n## Install ##\n#############\n\n# all install targets should use catkin DESTINATION variables\n# See http://ros.org/doc/api/catkin/html/adv_user_guide/variables.html\n\n## Mark executable scripts (Python etc.) for installation\n## in contrast to setup.py, you can choose the destination\n# install(PROGRAMS\n#   scripts/my_python_script\n#   DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark executables and/or libraries for installation\n# install(TARGETS ${PROJECT_NAME} ${PROJECT_NAME}_node\n#   ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n#   RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n# )\n\n## Mark cpp header files for installation\n# install(DIRECTORY include/${PROJECT_NAME}/\n#   DESTINATION ${CATKIN_PACKAGE_INCLUDE_DESTINATION}\n#   FILES_MATCHING PATTERN \"*.h\"\n#   PATTERN \".svn\" EXCLUDE\n# )\n\n## Mark other files for installation (e.g. launch and bag files, etc.)\n# install(FILES\n#   # myfile1\n#   # myfile2\n#   DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n# )\n\n#############\n## Testing ##\n#############\n\n## Add gtest based cpp test target and link libraries\n# catkin_add_gtest(${PROJECT_NAME}-test test/test_my_p.cpp)\n# if(TARGET ${PROJECT_NAME}-test)\n#   target_link_libraries(${PROJECT_NAME}-test ${PROJECT_NAME})\n# endif()\n\n## Add folders to be run by python nosetests\n# catkin_add_nosetests(test)\n~~~\n\n\n\n","slug":"ROS学习之catkin CMakeList.txt介绍（译）","published":1,"updated":"2019-05-30T12:29:26.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjzdedc3600fmqlcrhczh4xd1","content":"<hr>\n<p>这篇文章是有关ROS中catkin CMakeLists.txt使用的内容。</p>\n<a id=\"more\"></a>\n<p>​    本文翻译自ROS官网关于catkin CMakeList.txt的介绍，<strong><a href=\"http://wiki.ros.org/catkin/CMakeLists.txt\" target=\"_blank\" rel=\"noopener\">官网原文链接</a></strong>，由于直接阅读英文文档感觉自己理解不透彻、收获不多，所以决定一边翻译一边学习。其中零星的加入了一些译者个人使用过程中的体会以及在阅读《机器人操作系统（ROS）浅析》（Jason M.O’Kane著 肖军浩译）一书时学习到的内容，帮助自己更好地理解catkin编译生成的过程，留作今后复习完善。</p>\n<h2 id=\"概况\"><a href=\"#概况\" class=\"headerlink\" title=\"概况\"></a>概况</h2><p>​    CMakeList.txt文件是CMake编译系统编译软件包过程的输入文件。任何CMake兼容包都包含一个或多个CMakeLists.txt文件，这些文件描述了如何编译代码以及将其安装到哪里。将CMakeLists.txt文件应用于一个catkin项目时，它就作为<strong>一个标准的附带一些限制条件的vanilla CMakeLists.txt文件。</strong>使用CMake编译程序时，<code>cmake</code>指令依据CMakeLists.txt 文件生成makefiles文件，<code>make</code>命令再依据makefiles文件编译链接生成可执行文件。</p>\n<p>​    catkin是ROS官方的一个编译构建系统，是原本的ROS的编译构建系统rosbuild的发展。<code>catkin_make</code>是将<code>cmake</code>与<code>make</code>的编译方式做了一个封装的指令工具，规范了工作路径与生成文件路径。</p>\n<h2 id=\"总体结构和顺序\"><a href=\"#总体结构和顺序\" class=\"headerlink\" title=\"总体结构和顺序\"></a>总体结构和顺序</h2><p>​    CMakeList.txt文件必须遵循如下的格式，不然就无法正确地编译（译者遇到一些编译ros软件包时提示“ros未定义的引用”的错误，原因就是CMakeList.txt文件中命令顺序不正确）。</p>\n<ul>\n<li>必需的CMake版本：<code>cmake_minimum_required()</code></li>\n<li>软件包名：<code>project()</code></li>\n<li>查找编译依赖的其他CMake/Catkin包（声明依赖库）：<code>find_package()</code></li>\n<li>启动Python模块支持：<code>catkin_python_package()</code></li>\n<li>消息/服务/操作(Message/Service/Action)生成器：<code>add_message_files()</code>,<code>add_service_files()</code>,<code>add_action_files()</code></li>\n<li>调用消息/服务/操作生成：<code>generate_messages()</code></li>\n<li>指定包编译信息导出：<code>catkin_package()</code></li>\n<li>添加要编译的库和可执行文件：<code>add_library()</code>/<code>add_executable()</code>/<code>target_link_libraries()</code></li>\n<li>测试编译：<code>catkin_add_gtest()</code></li>\n<li>安装规则：<code>install()</code></li>\n</ul>\n<h2 id=\"CMake版本\"><a href=\"#CMake版本\" class=\"headerlink\" title=\"CMake版本\"></a>CMake版本</h2><p>​    每一个catkin CMakeList.txt文件必须以所需的CMake版本说明语句开始，Catkin需要2.8.3或者更高的版本</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.8</span>.<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"软件包包名\"><a href=\"#软件包包名\" class=\"headerlink\" title=\"软件包包名\"></a>软件包包名</h2><p>​    软件包报名使用CMake的   <code>project()</code>函数指明，例如以robot_brain命名一个软件包：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">project</span>(robot_brain)</span><br></pre></td></tr></table></figure>\n<p>​    CMake中，可以通过使用变量      <code>${PROJECT_NAME}</code>在CMake脚本后面的任何位置引用项目名称。</p>\n<h2 id=\"查找编译依赖的CMake包\"><a href=\"#查找编译依赖的CMake包\" class=\"headerlink\" title=\"查找编译依赖的CMake包\"></a>查找编译依赖的CMake包</h2><p>​    编译一个项目，需要使用CMake 的   <code>find_package</code>函数确定依赖的其他CMake包并找到它们，一般情况下至少会有一个catkin依赖：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED)</span><br></pre></td></tr></table></figure>\n<p>​    除此之外，项目依赖的其他软件包，都会自动成为catkin的组件（components）（就CMake而言）。因此可以将这些依赖包指定为catkin的组件，而不必再使用<code>find_package</code>，这样将会变得简单，例如依赖包nodelet：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS nodelet)</span><br></pre></td></tr></table></figure>\n<p>​    <strong>注意：只能<code>find_package</code>那些想要编译标志的组件，不能添加运行时（runtime）依赖。</strong></p>\n<p>​    当然也可以写成下面的方式，但不方便:</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED)</span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(nodelet REQUIRED)- ?</span><br></pre></td></tr></table></figure>\n<h3 id=\"find-package-做了什么？\"><a href=\"#find-package-做了什么？\" class=\"headerlink\" title=\"find_package()做了什么？\"></a>find_package()做了什么？</h3><p>​    如果CMake通过  <code>find_package()</code>查找到一个软件包，它就会创建几个CMake环境变量，以提供有关已查找到的软件包的信息。这些环境变量可以在后面的CMake脚本中使用，它们表示软件包导出的头文件所在的位置、源文件所在的位置、软件包依赖的库以及这些库的查找路径，环境变量的名字遵循<code>&lt;PACKAGENAME&gt;_&lt;PROPERTY&gt;</code>，即包名-属性：</p>\n<ul>\n<li><code>&lt;NAME&gt;_FOUND</code>：当库被查找到时置为true，否则为false</li>\n<li><code>&lt;NAME&gt;_INCLUDE_DIRS</code>或<code>&lt;NAME&gt;_INCLUDES</code>：软件包导出的头文件路径</li>\n<li><code>&lt;NAME&gt;_LIBRARIES</code>或<code>&lt;NAME&gt;_LIBS</code>：软件包导出的库的路径</li>\n<li><code>&lt;NAME&gt;_DEFINITIONS</code>：？</li>\n</ul>\n<h3 id=\"为何将Catkin软件包指定为组件？\"><a href=\"#为何将Catkin软件包指定为组件？\" class=\"headerlink\" title=\"为何将Catkin软件包指定为组件？\"></a>为何将Catkin软件包指定为组件？</h3><p>​    Catkin软件包严格意义上并不是catkin的组件，而且，CMake的功能组件功能被用于catkin的设计，以节省大量的打字时间。</p>\n<p>​    对于catkin软件包，以catkin的组件的方式  <code>find_package</code>它们是有好处的，因为这个过程以catkin_prefix的形式创建了一组环境变量。例如，在程序中要使用nodelet软件包，推荐查找软件包的方式是：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS nodelet)</span><br></pre></td></tr></table></figure>\n<p>​    这就意味着nodelet导出的头文件路径、库等都会附加到  <code>catkin_variables</code>上，比如，<code>catkin_INCLUDE_DIRS</code>不仅包含catkin的头文件路径，也包含了nodelet软件包的头文件路径，这在后面会派上用场。</p>\n<p>​    如果单独的<code>find_package nodelet</code>：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(nodelet)</span><br></pre></td></tr></table></figure>\n<p>​    这意味着nodelet的头文件路径、库及其他文件都不会包含在  <code>catkin_variables</code>中，对于<code>nodelet_INCLUDE_DIRS</code>,<code>nodelet_LIBRARIES</code>及其他变量也是如此。相同的变量也可以通过下面的方式创建：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS nodelet)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Boost库\"><a href=\"#Boost库\" class=\"headerlink\" title=\"Boost库\"></a>Boost库</h3><p>​    如果使用C++和Boost库，需要在Boost上调用  <code>find_package()</code>，并指定Boost中将要作为组件的那部分。例如，如果想要使用Boost的线程，可以用：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(Boost REQUIRED COMPONENTS thread)</span><br></pre></td></tr></table></figure>\n<h2 id=\"catkin-package\"><a href=\"#catkin-package\" class=\"headerlink\" title=\"catkin_package()\"></a>catkin_package()</h2><p>​    <code>catkin_package()</code>是一个由catkin提供的CMake宏。需要指定特定的catkin信息到编译系统，而这些信息又会被用于生成pkg-config和CMake文件。</p>\n<p>​    该函数必须在使用     <code>add_library()</code>或<code>add_executable()</code>声明任何targets之前调用。其5个可选参数：</p>\n<ul>\n<li><code>INCLUDE_DIRS</code>：软件包导出的头文件路径（例如cflags）</li>\n<li><code>LIBRARIES</code>：项目导出的库</li>\n<li><code>CATKIN_DEPENDS</code>：当前项目依赖的其他catkin项目</li>\n<li><code>DEPENDS</code>：当前项目依赖的非catkin CMake项目，详细解释参见<a href=\"answers.ros.org/question/58498/what-is-the-purpose-of-catkin_depends/\">这里</a></li>\n<li><p><code>CFG_EXTRAS</code>：其他的配置选项</p>\n<pre><code>  完整的宏文件参见[这里](#catkin-package)。\n</code></pre><p>  例子：</p>\n</li>\n</ul>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_package( INCLUDE_DIRS <span class=\"keyword\">include</span>  </span><br><span class=\"line\">                LIBRARIES <span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>   </span><br><span class=\"line\">                CATKIN_DEPENDS roscpp nodelet   </span><br><span class=\"line\">                DEPENDS eigen opencv)</span><br></pre></td></tr></table></figure>\n<p>​    这里表明软件包文件夹中的include文件夹是导出头文件的位置，CMake环境变量   <code>${PROJECT_NAME}</code>将会鉴定之前传递给<code>project()</code>函数的所有内容，在这种情况下它作为“robot_brain”。“roscpp”+“nodelet”是编译/运行此程序包需要存在的软件包，“eigen”+“opencv”是编译/运行此程序包时需要存在的系统依赖项（ROS packages有时会需要操作系统提供一些外部函数库，这些函数库就是所谓的“系统依赖项”）。</p>\n<h2 id=\"明确编译的目标\"><a href=\"#明确编译的目标\" class=\"headerlink\" title=\"明确编译的目标\"></a>明确编译的目标</h2><p>​    编译目标可以采取多种形式，但通常它们代表两种可能性之一：    </p>\n<ul>\n<li>可执行目标：可以运行的程序</li>\n<li>库目标：在编译和/或运行时可以由可执行目标使用的库</li>\n</ul>\n<h3 id=\"目标命名\"><a href=\"#目标命名\" class=\"headerlink\" title=\"目标命名\"></a>目标命名</h3><p>​    非常重要的一点是，不管编译/安装到哪个文件夹中，编译目标在catkin中的名称都必须是唯一的。这是CMake的一项要求，但目标唯一的名称又只是在CMake内部是必需的。可以使用<code>set_target_properties()</code>函数对目标重命名，例子：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set_target_properties</span>(rviz_image_view </span><br><span class=\"line\">\t\t      \t\t  PROPERTIES OUTPUT_NAME image_view</span><br><span class=\"line\">                      PREFIX <span class=\"string\">\"\"</span>)</span><br></pre></td></tr></table></figure>\n<p>​    这会在编译和安装输出中将目标     <code>rviz_image_view</code>的名称改为<code>image_view</code>。</p>\n<h3 id=\"自定义输出目录\"><a href=\"#自定义输出目录\" class=\"headerlink\" title=\"自定义输出目录\"></a>自定义输出目录</h3><p>​    可执行文件和库的默认输出目录通常设置为了合理的值，但在某些情况下必须进行自定义，例如，包含Python绑定的库必须放置在不同的文件夹中才能在Python中导入。</p>\n<p>​    例子：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set_target_properties</span>(python_module_library  PROPERTIES LIBRARY_OUTPUT_DIRECTORY \t\t\t\t\t\t\t\t  &#123;CATKIN_DEVEL_PREFIX&#125;/&#123;CATKIN_PACKAGE_PYTHON_DESTINATION&#125;)</span><br></pre></td></tr></table></figure>\n<h3 id=\"头文件和库路径\"><a href=\"#头文件和库路径\" class=\"headerlink\" title=\"头文件和库路径\"></a>头文件和库路径</h3><p>​    在指定目标之前，需要指定可以为所述目标找到资源的位置，特别是头文件和库：</p>\n<ul>\n<li>头文件目录：将要编译的代码（C/C++）所需的头文件路径    </li>\n<li>库目录：可执行目标编译指向的库路径</li>\n<li><code>include_directories(&lt;dir1&gt;, &lt;dir2&gt;, ..., &lt;dirN&gt;)</code></li>\n<li><code>link_directories(&lt;dir1&gt;, &lt;dir2&gt;, ..., &lt;dirN&gt;)</code></li>\n</ul>\n<h4 id=\"include-directories\"><a href=\"#include-directories\" class=\"headerlink\" title=\"include_directories()\"></a>include_directories()</h4><p>​    <code>include_directories</code>的参数应该是由调用<code>find_package</code>生成的<code>* _INCLUDE_DIRS</code>变量以及需要包含的任何其他目录。如果使用<code>catkin</code>和<code>Boost</code>，<code>include_directories()</code>的调用为：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"keyword\">include</span> &#123;Boost_INCLUDE_DIRS&#125; &#123;catkin_INCLUDE_DIRS&#125;)</span><br></pre></td></tr></table></figure>\n<p>​    第一个参数“include”表示包中的include/目录也是路径的一部分。</p>\n<h4 id=\"link-directories\"><a href=\"#link-directories\" class=\"headerlink\" title=\"link_directories()\"></a>link_directories()</h4><p>​    CMake的   <code>link_directories()</code>函数可以添加其他的库目录，然而，并不推荐这么做。所有的catkin和CMake包在<code>find_package</code>时都会自动添加链接信息。只需链接到<code>target_link_libraries()</code>中的库。</p>\n<p>​    例子：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">link_directories</span>(~/my_libs)</span><br></pre></td></tr></table></figure>\n<p>​    详细信息参加<a href=\"http://www.cmake.org/pipermail/cmake/2011-May/044295.html\" target=\"_blank\" rel=\"noopener\">这里</a>。</p>\n<h3 id=\"可执行目标\"><a href=\"#可执行目标\" class=\"headerlink\" title=\"可执行目标\"></a>可执行目标</h3><p>​    要指定必须编译的可执行目标，必须使用CMake函数   <code>add_executable()</code>。声明想要的可执行文件的文件名，以此生成此可执行文件所需的源文件列表，如果有多个源文件，用空格区分开。例如：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(myProgram src/main.cpp src/some_file.cpp src/another_file.cpp)</span><br></pre></td></tr></table></figure>\n<p>​    该命令会编译名为   <code>myProgram</code>的可执行文件，它是由后面的三个源文件共同编译生成的。</p>\n<h3 id=\"库目标\"><a href=\"#库目标\" class=\"headerlink\" title=\"库目标\"></a>库目标</h3><p>​    CMake函数   <code>add_library()</code>指定用于编译的库文件，默认情况下，catkin编译共享库。    </p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_library</span>(&#123;PROJECT_NAME&#125; &#123;<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n<h2 id=\"target-link-libraries\"><a href=\"#target-link-libraries\" class=\"headerlink\" title=\"target_link_libraries\"></a>target_link_libraries</h2><p>​    使用   <code>target_link_libraries()</code>函数指定可执行目标所要链接的库，即告诉CMake当链接此可执行文件时需要链接哪些库（这些库在上面的<code>find_package</code>中定义），通常在调用完<code>add_executable()</code>后被调用。如果出现<a href=\"#post-id-63674\">ros未定义的引用</a>错误，则添加<code>${catkin_LIBRARIES}</code>。</p>\n<p>​    语法：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(&lt;executableTargetName&gt;, &lt;lib1&gt;, &lt;lib2&gt;, ... &lt;libN&gt;)</span><br></pre></td></tr></table></figure>\n<p>​    例子:</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_executable</span>(foo src/foo.cpp)</span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(moo src/moo.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(foo moo)</span><br></pre></td></tr></table></figure>\n<p>​    上面的例子将     <code>foo</code>与<code>libmoo.so</code>链接起来</p>\n<p>​    <strong>注意，在大多数使用情况下，没有必要使用<code>link_directories()</code>，因为该信息通过<code>find_package()</code>已经自动提取到了。</strong> </p>\n<h2 id=\"消息、服务和操作目标\"><a href=\"#消息、服务和操作目标\" class=\"headerlink\" title=\"消息、服务和操作目标\"></a>消息、服务和操作目标</h2><p>​    在被ROS软件包编译和使用之前，ROS中的消息（.msg）、服务（.srv）和操作（.action）文件需要特殊的预处理器编译步骤。这些宏的要点是生成编程语言特定的文件，以便可以在编程语言中使用消息、服务和操作。编译系统将使用所有可用的生成器（例如gencpp、genpy、genlisp）生成绑定。</p>\n<p>​    提供了三个宏来分别处理消息，服务和操作：</p>\n<ul>\n<li>add_message_files</li>\n<li>add_service_files</li>\n<li><p>add_action_files</p>\n<pre><code>  这些宏后面必须调用一个调用生成的宏：\n</code></pre></li>\n</ul>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">generate_messages()</span><br></pre></td></tr></table></figure>\n<h3 id=\"重要的前提和限制\"><a href=\"#重要的前提和限制\" class=\"headerlink\" title=\"重要的前提和限制\"></a>重要的前提和限制</h3><ol>\n<li>这些宏必须在调用<code>catkin_package()</code>之前被调用，以正确地完成生成工作。</li>\n</ol>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS ...) </span><br><span class=\"line\">add_message_files(...) </span><br><span class=\"line\">add_service_files(...) </span><br><span class=\"line\">add_action_files(...) </span><br><span class=\"line\">generate_messages(...) </span><br><span class=\"line\">catkin_package(...) ...</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>catkin_package()</code>宏必须包含一个在<code>message_runtime</code>上的<code>CATKIN_DEPENDS</code>依赖。</li>\n</ol>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_package( ... </span><br><span class=\"line\">                CATKIN_DEPENDS message_runtime ... </span><br><span class=\"line\">                ...)</span><br></pre></td></tr></table></figure>\n<ol>\n<li>必须对软件包<code>message_generation</code>使用<code>find_package()</code>，可单独或者作为catkin的组件使用：</li>\n</ol>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS message_generation)</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>package.xml</code>文件必须包含一个在<code>message_generation</code>上的编译依赖和一个在<code>message_runtime</code>上的运行时依赖，如果从其他包中传递依赖关系，则这不是必需的。</li>\n<li>如果有一个目标（甚至是过渡性的）依赖于需要建立消息/服务/动作的其他目标，需要在目标<code>catkin_EXPORTED_TARGETS</code>上添加显式依赖项，以使它们按照正确的顺序编译。这种情况几乎总是适用，除非你的软件包真的不使用ROS的任何部分。不幸的是，这种依赖不能自动传播。（some_target是由<code>add_executable()</code>设置的目标的名字）</li>\n</ol>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(some_target <span class=\"variable\">$&#123;catkin_EXPORTED_TARGETS&#125;</span>)</span><br></pre></td></tr></table></figure>\n<ol>\n<li>如果有编译消息和/或服务的软件包以及使用这些软件的可执行文件，则需要在自动生成的消息目标上创建明确的依赖关系，以便它们按正确的顺序编译。（some_target是由<code>add_executable()</code>设置的目标的名字）</li>\n</ol>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(some_target <span class=\"variable\">$&#123;$&#123;PROJECT_NAME&#125;</span>_EXPORTED_TARGETS&#125;)</span><br></pre></td></tr></table></figure>\n<ol>\n<li>如果软件包满足上述两个条件，则需要添加两个依赖项，即：</li>\n</ol>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">add_dependencies</span>(some_target &#123;<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>_EXPORTED_TARGETS&#125;   \t\t      \t &#123;catkin_EXPORTED_TARGETS&#125;)</span><br></pre></td></tr></table></figure>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><p>​    如果在msg目录下有两个消息文件       <code>MyMessage1.msg</code>和<code>MyMessage2.msg</code>，并且这些消息依赖于<code>std_msgs</code>和<code>sensor_msgs</code>，另外在srv目录下有一个服务文件<code>MyService.srv</code>，就可以使用这些消息、服务定义可执行<code>message_program</code>，和可执行的程序<code>does_not_use_local_messages_program</code>，这个过程使用了ROS的某些部分，但不包含此包中定义的消息/服务。需要在CMakeList.txt文件中加上一下内容：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get the information about this package's buildtime dependencies  find_package(catkin REQUIRED    COMPONENTS message_generation std_msgs sensor_msgs)  </span></span><br><span class=\"line\"><span class=\"comment\"># Declare the message files to be built  </span></span><br><span class=\"line\">add_message_files(FILES    MyMessage1.msg    MyMessage2.msg  )  </span><br><span class=\"line\"><span class=\"comment\"># Declare the service files to be built  add_service_files(FILES    MyService.srv  )  </span></span><br><span class=\"line\"><span class=\"comment\"># Actually generate the language-specific message and service files  generate_messages(DEPENDENCIES std_msgs sensor_msgs)  </span></span><br><span class=\"line\"><span class=\"comment\"># Declare that this catkin package's runtime dependencies  catkin_package(   CATKIN_DEPENDS message_runtime std_msgs sensor_msgs  )  </span></span><br><span class=\"line\"><span class=\"comment\"># define executable using MyMessage1 etc.  add_executable(message_program src/main.cpp)  add_dependencies(message_program &#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; &#123;catkin_EXPORTED_TARGETS&#125;)  </span></span><br><span class=\"line\"><span class=\"comment\"># define executable not using any messages/services provided by this package  </span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(does_not_use_local_messages_program src/main.cpp)  <span class=\"keyword\">add_dependencies</span>(does_not_use_local_messages_program <span class=\"variable\">$&#123;catkin_EXPORTED_TARGETS&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>​    另外如果需要编译actionlib操作，并且在action目录下有一个名为<code>MyAction.action</code>的操作规范文件，就必须要添加<code>actionlib_msgs</code>到组件列表中，该组件列表就是<code>find_package</code>中catkin的组件，并在调用<code>generate_messages()</code>之前调用：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_action_files(FILES MyAction.action)</span><br></pre></td></tr></table></figure>\n<p>​    此外，该包必须对   <code>actionlib_msgs</code>具有编译依赖关系。</p>\n<h2 id=\"启动Python模块支持\"><a href=\"#启动Python模块支持\" class=\"headerlink\" title=\"启动Python模块支持\"></a>启动Python模块支持</h2><p>​    如果ROS软件包提供了一些Python模块，就要创建一个<code>setup.py</code>文件并调用：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_python_setup()</span><br></pre></td></tr></table></figure>\n<p>​    该调用要在<code>generate_message()</code>和<code>catkin_package()</code>的调用之前。</p>\n<h2 id=\"单元测试\"><a href=\"#单元测试\" class=\"headerlink\" title=\"单元测试\"></a>单元测试</h2><p>​    特定的catkin宏   <code>catkin_add_gtest()</code>用于处理基于gtest的单元测试：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_add_gtest(myUnitTest test/utest.cpp)</span><br></pre></td></tr></table></figure>\n<h2 id=\"可选步骤：明确安装目标\"><a href=\"#可选步骤：明确安装目标\" class=\"headerlink\" title=\"可选步骤：明确安装目标\"></a>可选步骤：明确安装目标</h2><p>​    编译完成后，目标被放入catkin工作空间下的devel目录。一般希望将目标安装到系统上，以使其他用户使用，或者安装到本地目录来测试系统级别的安装。也就是说，如果希望能够对代码进行<code>make install</code>，就需要明确目标结束的位置。</p>\n<p>​    上述过程可以使用CMake的   <code>install()</code>函数实现，该函数的参数有：</p>\n<ul>\n<li><code>TARGETS</code>：要安装的目标</li>\n<li><code>ARCHIVE DESTINATION</code>：静态库和动态链接库DLL(Windows).lib存根</li>\n<li><code>LIBRARY DESTINATION</code>：非DLL共享库和模块</li>\n<li><p><code>RUNTIME DESTINATION</code>：可执行目标和DLL(Windows)模式共享库</p>\n<pre><code>  例子：\n</code></pre></li>\n</ul>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS <span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>  </span><br><span class=\"line\">        ARCHIVE DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;</span>  </span><br><span class=\"line\">        LIBRARY DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;</span>  </span><br><span class=\"line\">        RUNTIME DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>​    除了这些标准的目标，还要安装一些文件到特定的目录下，即一个包含Python绑定的库必须要安装到另外的不同的目录下，这对Python是重要的：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS python_module_library  </span><br><span class=\"line\">        ARCHIVE DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_PYTHON_DESTINATION&#125;</span>  </span><br><span class=\"line\">        LIBRARY DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_PYTHON_DESTINATION&#125;</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装Python可执行脚本\"><a href=\"#安装Python可执行脚本\" class=\"headerlink\" title=\"安装Python可执行脚本\"></a>安装Python可执行脚本</h3><p>​    Python代码的安装规则有些不同，它不需要使用     <code>add_library()</code>和<code>add_executable()</code>函数来告知CMake哪个文件是目标文件、目标文件是什么类型的。而是使用如下的CMakeList.txt文件：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">catkin_install_python(PROGRAMS scripts/myscript  </span><br><span class=\"line\">\t\t\t\t\t  DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;</span>)</span><br></pre></td></tr></table></figure>\n<p>​    如果只是安装了Python的脚本，不提供任何模块的话，就不用创建上文提到的   <code>setup.py</code>文件，也不用调用<code>catkin_python_setup()</code>。</p>\n<h3 id=\"安装头文件\"><a href=\"#安装头文件\" class=\"headerlink\" title=\"安装头文件\"></a>安装头文件</h3><p>​    头文件必须安装到include目录下，这通常通过安装整个文件夹的文件来完成（可以根据文件名模式进行过滤，并排除SVN子文件夹）。可以通过一下安装规则实现：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY <span class=\"keyword\">include</span>/<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>/  </span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_INCLUDE_DESTINATION&#125;</span>  </span><br><span class=\"line\">        PATTERN <span class=\"string\">\".svn\"</span> EXCLUDE)</span><br></pre></td></tr></table></figure>\n<p>​    或者如果include目录下的子文件夹无法和软件包名匹配时：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY <span class=\"keyword\">include</span>/  </span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CATKIN_GLOBAL_INCLUDE_DESTINATION&#125;</span>  </span><br><span class=\"line\">        PATTERN <span class=\"string\">\".svn\"</span> EXCLUDE)</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装roslaunch文件或其他源\"><a href=\"#安装roslaunch文件或其他源\" class=\"headerlink\" title=\"安装roslaunch文件或其他源\"></a>安装roslaunch文件或其他源</h3><p>​    其他像launchfiles的资源可以安装到   <code>${CATKIN_PACKAGE_SHARE_DESTINATION}</code>：</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY launch/  </span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125;</span>/launch  </span><br><span class=\"line\">        PATTERN <span class=\"string\">\".svn\"</span> EXCLUDE)</span><br></pre></td></tr></table></figure>\n<h2 id=\"CMakeLists-txt文件书写模板\"><a href=\"#CMakeLists-txt文件书写模板\" class=\"headerlink\" title=\"CMakeLists.txt文件书写模板\"></a>CMakeLists.txt文件书写模板</h2><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">2.8</span>.<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(my_p)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Compile as C++11, supported in ROS Kinetic and newer</span></span><br><span class=\"line\"><span class=\"comment\"># add_compile_options(-std=c++11)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Find catkin macros and libraries</span></span><br><span class=\"line\"><span class=\"comment\">## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)</span></span><br><span class=\"line\"><span class=\"comment\">## is used, also find other catkin packages</span></span><br><span class=\"line\"><span class=\"keyword\">find_package</span>(catkin REQUIRED COMPONENTS</span><br><span class=\"line\">  roscpp</span><br><span class=\"line\">  rospy</span><br><span class=\"line\">  std_msgs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## System dependencies are found with CMake's conventions</span></span><br><span class=\"line\"><span class=\"comment\"># find_package(Boost REQUIRED COMPONENTS system)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Uncomment this if the package has a setup.py. This macro ensures</span></span><br><span class=\"line\"><span class=\"comment\">## modules and global scripts declared therein get installed</span></span><br><span class=\"line\"><span class=\"comment\">## See http://ros.org/doc/api/catkin/html/user_guide/setup_dot_py.html</span></span><br><span class=\"line\"><span class=\"comment\"># catkin_python_setup()</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">################################################</span></span><br><span class=\"line\"><span class=\"comment\">## Declare ROS messages, services and actions ##</span></span><br><span class=\"line\"><span class=\"comment\">################################################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## To declare and build messages, services or actions from within this</span></span><br><span class=\"line\"><span class=\"comment\">## package, follow these steps:</span></span><br><span class=\"line\"><span class=\"comment\">## * Let MSG_DEP_SET be the set of packages whose message types you use in</span></span><br><span class=\"line\"><span class=\"comment\">##   your messages/services/actions (e.g. std_msgs, actionlib_msgs, ...).</span></span><br><span class=\"line\"><span class=\"comment\">## * In the file package.xml:</span></span><br><span class=\"line\"><span class=\"comment\">##   * add a build_depend tag for \"message_generation\"</span></span><br><span class=\"line\"><span class=\"comment\">##   * add a build_depend and a run_depend tag for each package in MSG_DEP_SET</span></span><br><span class=\"line\"><span class=\"comment\">##   * If MSG_DEP_SET isn't empty the following dependency has been pulled in</span></span><br><span class=\"line\"><span class=\"comment\">##     but can be declared for certainty nonetheless:</span></span><br><span class=\"line\"><span class=\"comment\">##     * add a run_depend tag for \"message_runtime\"</span></span><br><span class=\"line\"><span class=\"comment\">## * In this file (CMakeLists.txt):</span></span><br><span class=\"line\"><span class=\"comment\">##   * add \"message_generation\" and every package in MSG_DEP_SET to</span></span><br><span class=\"line\"><span class=\"comment\">##     find_package(catkin REQUIRED COMPONENTS ...)</span></span><br><span class=\"line\"><span class=\"comment\">##   * add \"message_runtime\" and every package in MSG_DEP_SET to</span></span><br><span class=\"line\"><span class=\"comment\">##     catkin_package(CATKIN_DEPENDS ...)</span></span><br><span class=\"line\"><span class=\"comment\">##   * uncomment the add_*_files sections below as needed</span></span><br><span class=\"line\"><span class=\"comment\">##     and list every .msg/.srv/.action file to be processed</span></span><br><span class=\"line\"><span class=\"comment\">##   * uncomment the generate_messages entry below</span></span><br><span class=\"line\"><span class=\"comment\">##   * add every package in MSG_DEP_SET to generate_messages(DEPENDENCIES ...)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Generate messages in the 'msg' folder</span></span><br><span class=\"line\"><span class=\"comment\"># add_message_files(</span></span><br><span class=\"line\"><span class=\"comment\">#   FILES</span></span><br><span class=\"line\"><span class=\"comment\">#   Message1.msg</span></span><br><span class=\"line\"><span class=\"comment\">#   Message2.msg</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Generate services in the 'srv' folder</span></span><br><span class=\"line\"><span class=\"comment\"># add_service_files(</span></span><br><span class=\"line\"><span class=\"comment\">#   FILES</span></span><br><span class=\"line\"><span class=\"comment\">#   Service1.srv</span></span><br><span class=\"line\"><span class=\"comment\">#   Service2.srv</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Generate actions in the 'action' folder</span></span><br><span class=\"line\"><span class=\"comment\"># add_action_files(</span></span><br><span class=\"line\"><span class=\"comment\">#   FILES</span></span><br><span class=\"line\"><span class=\"comment\">#   Action1.action</span></span><br><span class=\"line\"><span class=\"comment\">#   Action2.action</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Generate added messages and services with any dependencies listed here</span></span><br><span class=\"line\"><span class=\"comment\"># generate_messages(</span></span><br><span class=\"line\"><span class=\"comment\">#   DEPENDENCIES</span></span><br><span class=\"line\"><span class=\"comment\">#   std_msgs</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">################################################</span></span><br><span class=\"line\"><span class=\"comment\">## Declare ROS dynamic reconfigure parameters ##</span></span><br><span class=\"line\"><span class=\"comment\">################################################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## To declare and build dynamic reconfigure parameters within this</span></span><br><span class=\"line\"><span class=\"comment\">## package, follow these steps:</span></span><br><span class=\"line\"><span class=\"comment\">## * In the file package.xml:</span></span><br><span class=\"line\"><span class=\"comment\">##   * add a build_depend and a run_depend tag for \"dynamic_reconfigure\"</span></span><br><span class=\"line\"><span class=\"comment\">## * In this file (CMakeLists.txt):</span></span><br><span class=\"line\"><span class=\"comment\">##   * add \"dynamic_reconfigure\" to</span></span><br><span class=\"line\"><span class=\"comment\">##     find_package(catkin REQUIRED COMPONENTS ...)</span></span><br><span class=\"line\"><span class=\"comment\">##   * uncomment the \"generate_dynamic_reconfigure_options\" section below</span></span><br><span class=\"line\"><span class=\"comment\">##     and list every .cfg file to be processed</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Generate dynamic reconfigure parameters in the 'cfg' folder</span></span><br><span class=\"line\"><span class=\"comment\"># generate_dynamic_reconfigure_options(</span></span><br><span class=\"line\"><span class=\"comment\">#   cfg/DynReconf1.cfg</span></span><br><span class=\"line\"><span class=\"comment\">#   cfg/DynReconf2.cfg</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###################################</span></span><br><span class=\"line\"><span class=\"comment\">## catkin specific configuration ##</span></span><br><span class=\"line\"><span class=\"comment\">###################################</span></span><br><span class=\"line\"><span class=\"comment\">## The catkin_package macro generates cmake config files for your package</span></span><br><span class=\"line\"><span class=\"comment\">## Declare things to be passed to dependent projects</span></span><br><span class=\"line\"><span class=\"comment\">## INCLUDE_DIRS: uncomment this if your package contains header files</span></span><br><span class=\"line\"><span class=\"comment\">## LIBRARIES: libraries you create in this project that dependent projects also need</span></span><br><span class=\"line\"><span class=\"comment\">## CATKIN_DEPENDS: catkin_packages dependent projects also need</span></span><br><span class=\"line\"><span class=\"comment\">## DEPENDS: system dependencies of this project that dependent projects also need</span></span><br><span class=\"line\">catkin_package(</span><br><span class=\"line\"><span class=\"comment\">#  INCLUDE_DIRS include</span></span><br><span class=\"line\"><span class=\"comment\">#  LIBRARIES my_p</span></span><br><span class=\"line\"><span class=\"comment\">#  CATKIN_DEPENDS roscpp rospy std_msgs</span></span><br><span class=\"line\"><span class=\"comment\">#  DEPENDS system_lib</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###########</span></span><br><span class=\"line\"><span class=\"comment\">## Build ##</span></span><br><span class=\"line\"><span class=\"comment\">###########</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Specify additional locations of header files</span></span><br><span class=\"line\"><span class=\"comment\">## Your package locations should be listed before other locations</span></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(</span><br><span class=\"line\"><span class=\"comment\"># include</span></span><br><span class=\"line\">  <span class=\"variable\">$&#123;catkin_INCLUDE_DIRS&#125;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Declare a C++ library</span></span><br><span class=\"line\"><span class=\"comment\"># add_library($&#123;PROJECT_NAME&#125;</span></span><br><span class=\"line\"><span class=\"comment\">#   src/$&#123;PROJECT_NAME&#125;/my_p.cpp</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Add cmake target dependencies of the library</span></span><br><span class=\"line\"><span class=\"comment\">## as an example, code may need to be generated before libraries</span></span><br><span class=\"line\"><span class=\"comment\">## either from message generation or dynamic reconfigure</span></span><br><span class=\"line\"><span class=\"comment\"># add_dependencies($&#123;PROJECT_NAME&#125; $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Declare a C++ executable</span></span><br><span class=\"line\"><span class=\"comment\">## With catkin_make all packages are built within a single CMake context</span></span><br><span class=\"line\"><span class=\"comment\">## The recommended prefix ensures that target names across packages don't collide</span></span><br><span class=\"line\"><span class=\"comment\"># add_executable($&#123;PROJECT_NAME&#125;_node src/my_p_node.cpp)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Rename C++ executable without prefix</span></span><br><span class=\"line\"><span class=\"comment\">## The above recommended prefix causes long target names, the following renames the</span></span><br><span class=\"line\"><span class=\"comment\">## target back to the shorter version for ease of user use</span></span><br><span class=\"line\"><span class=\"comment\">## e.g. \"rosrun someones_pkg node\" instead of \"rosrun someones_pkg someones_pkg_node\"</span></span><br><span class=\"line\"><span class=\"comment\"># set_target_properties($&#123;PROJECT_NAME&#125;_node PROPERTIES OUTPUT_NAME node PREFIX \"\")</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Add cmake target dependencies of the executable</span></span><br><span class=\"line\"><span class=\"comment\">## same as for the library above</span></span><br><span class=\"line\"><span class=\"comment\"># add_dependencies($&#123;PROJECT_NAME&#125;_node $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Specify libraries to link a library or executable target against</span></span><br><span class=\"line\"><span class=\"comment\"># target_link_libraries($&#123;PROJECT_NAME&#125;_node</span></span><br><span class=\"line\"><span class=\"comment\">#   $&#123;catkin_LIBRARIES&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############</span></span><br><span class=\"line\"><span class=\"comment\">## Install ##</span></span><br><span class=\"line\"><span class=\"comment\">#############</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># all install targets should use catkin DESTINATION variables</span></span><br><span class=\"line\"><span class=\"comment\"># See http://ros.org/doc/api/catkin/html/adv_user_guide/variables.html</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Mark executable scripts (Python etc.) for installation</span></span><br><span class=\"line\"><span class=\"comment\">## in contrast to setup.py, you can choose the destination</span></span><br><span class=\"line\"><span class=\"comment\"># install(PROGRAMS</span></span><br><span class=\"line\"><span class=\"comment\">#   scripts/my_python_script</span></span><br><span class=\"line\"><span class=\"comment\">#   DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Mark executables and/or libraries for installation</span></span><br><span class=\"line\"><span class=\"comment\"># install(TARGETS $&#123;PROJECT_NAME&#125; $&#123;PROJECT_NAME&#125;_node</span></span><br><span class=\"line\"><span class=\"comment\">#   ARCHIVE DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;</span></span><br><span class=\"line\"><span class=\"comment\">#   LIBRARY DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;</span></span><br><span class=\"line\"><span class=\"comment\">#   RUNTIME DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Mark cpp header files for installation</span></span><br><span class=\"line\"><span class=\"comment\"># install(DIRECTORY include/$&#123;PROJECT_NAME&#125;/</span></span><br><span class=\"line\"><span class=\"comment\">#   DESTINATION $&#123;CATKIN_PACKAGE_INCLUDE_DESTINATION&#125;</span></span><br><span class=\"line\"><span class=\"comment\">#   FILES_MATCHING PATTERN \"*.h\"</span></span><br><span class=\"line\"><span class=\"comment\">#   PATTERN \".svn\" EXCLUDE</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Mark other files for installation (e.g. launch and bag files, etc.)</span></span><br><span class=\"line\"><span class=\"comment\"># install(FILES</span></span><br><span class=\"line\"><span class=\"comment\">#   # myfile1</span></span><br><span class=\"line\"><span class=\"comment\">#   # myfile2</span></span><br><span class=\"line\"><span class=\"comment\">#   DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############</span></span><br><span class=\"line\"><span class=\"comment\">## Testing ##</span></span><br><span class=\"line\"><span class=\"comment\">#############</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Add gtest based cpp test target and link libraries</span></span><br><span class=\"line\"><span class=\"comment\"># catkin_add_gtest($&#123;PROJECT_NAME&#125;-test test/test_my_p.cpp)</span></span><br><span class=\"line\"><span class=\"comment\"># if(TARGET $&#123;PROJECT_NAME&#125;-test)</span></span><br><span class=\"line\"><span class=\"comment\">#   target_link_libraries($&#123;PROJECT_NAME&#125;-test $&#123;PROJECT_NAME&#125;)</span></span><br><span class=\"line\"><span class=\"comment\"># endif()</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Add folders to be run by python nosetests</span></span><br><span class=\"line\"><span class=\"comment\"># catkin_add_nosetests(test)</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<hr>\n<p>这篇文章是有关ROS中catkin CMakeLists.txt使用的内容。</p>","more":"<p>​    本文翻译自ROS官网关于catkin CMakeList.txt的介绍，<strong><a href=\"http://wiki.ros.org/catkin/CMakeLists.txt\" target=\"_blank\" rel=\"noopener\">官网原文链接</a></strong>，由于直接阅读英文文档感觉自己理解不透彻、收获不多，所以决定一边翻译一边学习。其中零星的加入了一些译者个人使用过程中的体会以及在阅读《机器人操作系统（ROS）浅析》（Jason M.O’Kane著 肖军浩译）一书时学习到的内容，帮助自己更好地理解catkin编译生成的过程，留作今后复习完善。</p>\n<h2 id=\"概况\"><a href=\"#概况\" class=\"headerlink\" title=\"概况\"></a>概况</h2><p>​    CMakeList.txt文件是CMake编译系统编译软件包过程的输入文件。任何CMake兼容包都包含一个或多个CMakeLists.txt文件，这些文件描述了如何编译代码以及将其安装到哪里。将CMakeLists.txt文件应用于一个catkin项目时，它就作为<strong>一个标准的附带一些限制条件的vanilla CMakeLists.txt文件。</strong>使用CMake编译程序时，<code>cmake</code>指令依据CMakeLists.txt 文件生成makefiles文件，<code>make</code>命令再依据makefiles文件编译链接生成可执行文件。</p>\n<p>​    catkin是ROS官方的一个编译构建系统，是原本的ROS的编译构建系统rosbuild的发展。<code>catkin_make</code>是将<code>cmake</code>与<code>make</code>的编译方式做了一个封装的指令工具，规范了工作路径与生成文件路径。</p>\n<h2 id=\"总体结构和顺序\"><a href=\"#总体结构和顺序\" class=\"headerlink\" title=\"总体结构和顺序\"></a>总体结构和顺序</h2><p>​    CMakeList.txt文件必须遵循如下的格式，不然就无法正确地编译（译者遇到一些编译ros软件包时提示“ros未定义的引用”的错误，原因就是CMakeList.txt文件中命令顺序不正确）。</p>\n<ul>\n<li>必需的CMake版本：<code>cmake_minimum_required()</code></li>\n<li>软件包名：<code>project()</code></li>\n<li>查找编译依赖的其他CMake/Catkin包（声明依赖库）：<code>find_package()</code></li>\n<li>启动Python模块支持：<code>catkin_python_package()</code></li>\n<li>消息/服务/操作(Message/Service/Action)生成器：<code>add_message_files()</code>,<code>add_service_files()</code>,<code>add_action_files()</code></li>\n<li>调用消息/服务/操作生成：<code>generate_messages()</code></li>\n<li>指定包编译信息导出：<code>catkin_package()</code></li>\n<li>添加要编译的库和可执行文件：<code>add_library()</code>/<code>add_executable()</code>/<code>target_link_libraries()</code></li>\n<li>测试编译：<code>catkin_add_gtest()</code></li>\n<li>安装规则：<code>install()</code></li>\n</ul>\n<h2 id=\"CMake版本\"><a href=\"#CMake版本\" class=\"headerlink\" title=\"CMake版本\"></a>CMake版本</h2><p>​    每一个catkin CMakeList.txt文件必须以所需的CMake版本说明语句开始，Catkin需要2.8.3或者更高的版本</p>\n<!--�354-->\n<h2 id=\"软件包包名\"><a href=\"#软件包包名\" class=\"headerlink\" title=\"软件包包名\"></a>软件包包名</h2><p>​    软件包报名使用CMake的   <code>project()</code>函数指明，例如以robot_brain命名一个软件包：</p>\n<!--�355-->\n<p>​    CMake中，可以通过使用变量      <code>${PROJECT_NAME}</code>在CMake脚本后面的任何位置引用项目名称。</p>\n<h2 id=\"查找编译依赖的CMake包\"><a href=\"#查找编译依赖的CMake包\" class=\"headerlink\" title=\"查找编译依赖的CMake包\"></a>查找编译依赖的CMake包</h2><p>​    编译一个项目，需要使用CMake 的   <code>find_package</code>函数确定依赖的其他CMake包并找到它们，一般情况下至少会有一个catkin依赖：</p>\n<!--�356-->\n<p>​    除此之外，项目依赖的其他软件包，都会自动成为catkin的组件（components）（就CMake而言）。因此可以将这些依赖包指定为catkin的组件，而不必再使用<code>find_package</code>，这样将会变得简单，例如依赖包nodelet：</p>\n<!--�357-->\n<p>​    <strong>注意：只能<code>find_package</code>那些想要编译标志的组件，不能添加运行时（runtime）依赖。</strong></p>\n<p>​    当然也可以写成下面的方式，但不方便:</p>\n<!--�358-->\n<h3 id=\"find-package-做了什么？\"><a href=\"#find-package-做了什么？\" class=\"headerlink\" title=\"find_package()做了什么？\"></a>find_package()做了什么？</h3><p>​    如果CMake通过  <code>find_package()</code>查找到一个软件包，它就会创建几个CMake环境变量，以提供有关已查找到的软件包的信息。这些环境变量可以在后面的CMake脚本中使用，它们表示软件包导出的头文件所在的位置、源文件所在的位置、软件包依赖的库以及这些库的查找路径，环境变量的名字遵循<code>&lt;PACKAGENAME&gt;_&lt;PROPERTY&gt;</code>，即包名-属性：</p>\n<ul>\n<li><code>&lt;NAME&gt;_FOUND</code>：当库被查找到时置为true，否则为false</li>\n<li><code>&lt;NAME&gt;_INCLUDE_DIRS</code>或<code>&lt;NAME&gt;_INCLUDES</code>：软件包导出的头文件路径</li>\n<li><code>&lt;NAME&gt;_LIBRARIES</code>或<code>&lt;NAME&gt;_LIBS</code>：软件包导出的库的路径</li>\n<li><code>&lt;NAME&gt;_DEFINITIONS</code>：？</li>\n</ul>\n<h3 id=\"为何将Catkin软件包指定为组件？\"><a href=\"#为何将Catkin软件包指定为组件？\" class=\"headerlink\" title=\"为何将Catkin软件包指定为组件？\"></a>为何将Catkin软件包指定为组件？</h3><p>​    Catkin软件包严格意义上并不是catkin的组件，而且，CMake的功能组件功能被用于catkin的设计，以节省大量的打字时间。</p>\n<p>​    对于catkin软件包，以catkin的组件的方式  <code>find_package</code>它们是有好处的，因为这个过程以catkin_prefix的形式创建了一组环境变量。例如，在程序中要使用nodelet软件包，推荐查找软件包的方式是：</p>\n<!--�359-->\n<p>​    这就意味着nodelet导出的头文件路径、库等都会附加到  <code>catkin_variables</code>上，比如，<code>catkin_INCLUDE_DIRS</code>不仅包含catkin的头文件路径，也包含了nodelet软件包的头文件路径，这在后面会派上用场。</p>\n<p>​    如果单独的<code>find_package nodelet</code>：</p>\n<!--�360-->\n<p>​    这意味着nodelet的头文件路径、库及其他文件都不会包含在  <code>catkin_variables</code>中，对于<code>nodelet_INCLUDE_DIRS</code>,<code>nodelet_LIBRARIES</code>及其他变量也是如此。相同的变量也可以通过下面的方式创建：</p>\n<!--�361-->\n<h3 id=\"Boost库\"><a href=\"#Boost库\" class=\"headerlink\" title=\"Boost库\"></a>Boost库</h3><p>​    如果使用C++和Boost库，需要在Boost上调用  <code>find_package()</code>，并指定Boost中将要作为组件的那部分。例如，如果想要使用Boost的线程，可以用：</p>\n<!--�362-->\n<h2 id=\"catkin-package\"><a href=\"#catkin-package\" class=\"headerlink\" title=\"catkin_package()\"></a>catkin_package()</h2><p>​    <code>catkin_package()</code>是一个由catkin提供的CMake宏。需要指定特定的catkin信息到编译系统，而这些信息又会被用于生成pkg-config和CMake文件。</p>\n<p>​    该函数必须在使用     <code>add_library()</code>或<code>add_executable()</code>声明任何targets之前调用。其5个可选参数：</p>\n<ul>\n<li><code>INCLUDE_DIRS</code>：软件包导出的头文件路径（例如cflags）</li>\n<li><code>LIBRARIES</code>：项目导出的库</li>\n<li><code>CATKIN_DEPENDS</code>：当前项目依赖的其他catkin项目</li>\n<li><code>DEPENDS</code>：当前项目依赖的非catkin CMake项目，详细解释参见<a href=\"answers.ros.org/question/58498/what-is-the-purpose-of-catkin_depends/\">这里</a></li>\n<li><p><code>CFG_EXTRAS</code>：其他的配置选项</p>\n<pre><code>  完整的宏文件参见[这里](#catkin-package)。\n</code></pre><p>  例子：</p>\n</li>\n</ul>\n<!--�363-->\n<p>​    这里表明软件包文件夹中的include文件夹是导出头文件的位置，CMake环境变量   <code>${PROJECT_NAME}</code>将会鉴定之前传递给<code>project()</code>函数的所有内容，在这种情况下它作为“robot_brain”。“roscpp”+“nodelet”是编译/运行此程序包需要存在的软件包，“eigen”+“opencv”是编译/运行此程序包时需要存在的系统依赖项（ROS packages有时会需要操作系统提供一些外部函数库，这些函数库就是所谓的“系统依赖项”）。</p>\n<h2 id=\"明确编译的目标\"><a href=\"#明确编译的目标\" class=\"headerlink\" title=\"明确编译的目标\"></a>明确编译的目标</h2><p>​    编译目标可以采取多种形式，但通常它们代表两种可能性之一：    </p>\n<ul>\n<li>可执行目标：可以运行的程序</li>\n<li>库目标：在编译和/或运行时可以由可执行目标使用的库</li>\n</ul>\n<h3 id=\"目标命名\"><a href=\"#目标命名\" class=\"headerlink\" title=\"目标命名\"></a>目标命名</h3><p>​    非常重要的一点是，不管编译/安装到哪个文件夹中，编译目标在catkin中的名称都必须是唯一的。这是CMake的一项要求，但目标唯一的名称又只是在CMake内部是必需的。可以使用<code>set_target_properties()</code>函数对目标重命名，例子：</p>\n<!--�364-->\n<p>​    这会在编译和安装输出中将目标     <code>rviz_image_view</code>的名称改为<code>image_view</code>。</p>\n<h3 id=\"自定义输出目录\"><a href=\"#自定义输出目录\" class=\"headerlink\" title=\"自定义输出目录\"></a>自定义输出目录</h3><p>​    可执行文件和库的默认输出目录通常设置为了合理的值，但在某些情况下必须进行自定义，例如，包含Python绑定的库必须放置在不同的文件夹中才能在Python中导入。</p>\n<p>​    例子：</p>\n<!--�365-->\n<h3 id=\"头文件和库路径\"><a href=\"#头文件和库路径\" class=\"headerlink\" title=\"头文件和库路径\"></a>头文件和库路径</h3><p>​    在指定目标之前，需要指定可以为所述目标找到资源的位置，特别是头文件和库：</p>\n<ul>\n<li>头文件目录：将要编译的代码（C/C++）所需的头文件路径    </li>\n<li>库目录：可执行目标编译指向的库路径</li>\n<li><code>include_directories(&lt;dir1&gt;, &lt;dir2&gt;, ..., &lt;dirN&gt;)</code></li>\n<li><code>link_directories(&lt;dir1&gt;, &lt;dir2&gt;, ..., &lt;dirN&gt;)</code></li>\n</ul>\n<h4 id=\"include-directories\"><a href=\"#include-directories\" class=\"headerlink\" title=\"include_directories()\"></a>include_directories()</h4><p>​    <code>include_directories</code>的参数应该是由调用<code>find_package</code>生成的<code>* _INCLUDE_DIRS</code>变量以及需要包含的任何其他目录。如果使用<code>catkin</code>和<code>Boost</code>，<code>include_directories()</code>的调用为：</p>\n<!--�366-->\n<p>​    第一个参数“include”表示包中的include/目录也是路径的一部分。</p>\n<h4 id=\"link-directories\"><a href=\"#link-directories\" class=\"headerlink\" title=\"link_directories()\"></a>link_directories()</h4><p>​    CMake的   <code>link_directories()</code>函数可以添加其他的库目录，然而，并不推荐这么做。所有的catkin和CMake包在<code>find_package</code>时都会自动添加链接信息。只需链接到<code>target_link_libraries()</code>中的库。</p>\n<p>​    例子：</p>\n<!--�367-->\n<p>​    详细信息参加<a href=\"http://www.cmake.org/pipermail/cmake/2011-May/044295.html\" target=\"_blank\" rel=\"noopener\">这里</a>。</p>\n<h3 id=\"可执行目标\"><a href=\"#可执行目标\" class=\"headerlink\" title=\"可执行目标\"></a>可执行目标</h3><p>​    要指定必须编译的可执行目标，必须使用CMake函数   <code>add_executable()</code>。声明想要的可执行文件的文件名，以此生成此可执行文件所需的源文件列表，如果有多个源文件，用空格区分开。例如：</p>\n<!--�368-->\n<p>​    该命令会编译名为   <code>myProgram</code>的可执行文件，它是由后面的三个源文件共同编译生成的。</p>\n<h3 id=\"库目标\"><a href=\"#库目标\" class=\"headerlink\" title=\"库目标\"></a>库目标</h3><p>​    CMake函数   <code>add_library()</code>指定用于编译的库文件，默认情况下，catkin编译共享库。    </p>\n<!--�369-->\n<h2 id=\"target-link-libraries\"><a href=\"#target-link-libraries\" class=\"headerlink\" title=\"target_link_libraries\"></a>target_link_libraries</h2><p>​    使用   <code>target_link_libraries()</code>函数指定可执行目标所要链接的库，即告诉CMake当链接此可执行文件时需要链接哪些库（这些库在上面的<code>find_package</code>中定义），通常在调用完<code>add_executable()</code>后被调用。如果出现<a href=\"#post-id-63674\">ros未定义的引用</a>错误，则添加<code>${catkin_LIBRARIES}</code>。</p>\n<p>​    语法：</p>\n<!--�370-->\n<p>​    例子:</p>\n<!--�371-->\n<p>​    上面的例子将     <code>foo</code>与<code>libmoo.so</code>链接起来</p>\n<p>​    <strong>注意，在大多数使用情况下，没有必要使用<code>link_directories()</code>，因为该信息通过<code>find_package()</code>已经自动提取到了。</strong> </p>\n<h2 id=\"消息、服务和操作目标\"><a href=\"#消息、服务和操作目标\" class=\"headerlink\" title=\"消息、服务和操作目标\"></a>消息、服务和操作目标</h2><p>​    在被ROS软件包编译和使用之前，ROS中的消息（.msg）、服务（.srv）和操作（.action）文件需要特殊的预处理器编译步骤。这些宏的要点是生成编程语言特定的文件，以便可以在编程语言中使用消息、服务和操作。编译系统将使用所有可用的生成器（例如gencpp、genpy、genlisp）生成绑定。</p>\n<p>​    提供了三个宏来分别处理消息，服务和操作：</p>\n<ul>\n<li>add_message_files</li>\n<li>add_service_files</li>\n<li><p>add_action_files</p>\n<pre><code>  这些宏后面必须调用一个调用生成的宏：\n</code></pre></li>\n</ul>\n<!--�372-->\n<h3 id=\"重要的前提和限制\"><a href=\"#重要的前提和限制\" class=\"headerlink\" title=\"重要的前提和限制\"></a>重要的前提和限制</h3><ol>\n<li>这些宏必须在调用<code>catkin_package()</code>之前被调用，以正确地完成生成工作。</li>\n</ol>\n<!--�373-->\n<ol>\n<li><code>catkin_package()</code>宏必须包含一个在<code>message_runtime</code>上的<code>CATKIN_DEPENDS</code>依赖。</li>\n</ol>\n<!--�374-->\n<ol>\n<li>必须对软件包<code>message_generation</code>使用<code>find_package()</code>，可单独或者作为catkin的组件使用：</li>\n</ol>\n<!--�375-->\n<ol>\n<li><code>package.xml</code>文件必须包含一个在<code>message_generation</code>上的编译依赖和一个在<code>message_runtime</code>上的运行时依赖，如果从其他包中传递依赖关系，则这不是必需的。</li>\n<li>如果有一个目标（甚至是过渡性的）依赖于需要建立消息/服务/动作的其他目标，需要在目标<code>catkin_EXPORTED_TARGETS</code>上添加显式依赖项，以使它们按照正确的顺序编译。这种情况几乎总是适用，除非你的软件包真的不使用ROS的任何部分。不幸的是，这种依赖不能自动传播。（some_target是由<code>add_executable()</code>设置的目标的名字）</li>\n</ol>\n<!--�376-->\n<ol>\n<li>如果有编译消息和/或服务的软件包以及使用这些软件的可执行文件，则需要在自动生成的消息目标上创建明确的依赖关系，以便它们按正确的顺序编译。（some_target是由<code>add_executable()</code>设置的目标的名字）</li>\n</ol>\n<!--�377-->\n<ol>\n<li>如果软件包满足上述两个条件，则需要添加两个依赖项，即：</li>\n</ol>\n<!--�378-->\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><p>​    如果在msg目录下有两个消息文件       <code>MyMessage1.msg</code>和<code>MyMessage2.msg</code>，并且这些消息依赖于<code>std_msgs</code>和<code>sensor_msgs</code>，另外在srv目录下有一个服务文件<code>MyService.srv</code>，就可以使用这些消息、服务定义可执行<code>message_program</code>，和可执行的程序<code>does_not_use_local_messages_program</code>，这个过程使用了ROS的某些部分，但不包含此包中定义的消息/服务。需要在CMakeList.txt文件中加上一下内容：</p>\n<!--�379-->\n<p>​    另外如果需要编译actionlib操作，并且在action目录下有一个名为<code>MyAction.action</code>的操作规范文件，就必须要添加<code>actionlib_msgs</code>到组件列表中，该组件列表就是<code>find_package</code>中catkin的组件，并在调用<code>generate_messages()</code>之前调用：</p>\n<!--�380-->\n<p>​    此外，该包必须对   <code>actionlib_msgs</code>具有编译依赖关系。</p>\n<h2 id=\"启动Python模块支持\"><a href=\"#启动Python模块支持\" class=\"headerlink\" title=\"启动Python模块支持\"></a>启动Python模块支持</h2><p>​    如果ROS软件包提供了一些Python模块，就要创建一个<code>setup.py</code>文件并调用：</p>\n<!--�381-->\n<p>​    该调用要在<code>generate_message()</code>和<code>catkin_package()</code>的调用之前。</p>\n<h2 id=\"单元测试\"><a href=\"#单元测试\" class=\"headerlink\" title=\"单元测试\"></a>单元测试</h2><p>​    特定的catkin宏   <code>catkin_add_gtest()</code>用于处理基于gtest的单元测试：</p>\n<!--�382-->\n<h2 id=\"可选步骤：明确安装目标\"><a href=\"#可选步骤：明确安装目标\" class=\"headerlink\" title=\"可选步骤：明确安装目标\"></a>可选步骤：明确安装目标</h2><p>​    编译完成后，目标被放入catkin工作空间下的devel目录。一般希望将目标安装到系统上，以使其他用户使用，或者安装到本地目录来测试系统级别的安装。也就是说，如果希望能够对代码进行<code>make install</code>，就需要明确目标结束的位置。</p>\n<p>​    上述过程可以使用CMake的   <code>install()</code>函数实现，该函数的参数有：</p>\n<ul>\n<li><code>TARGETS</code>：要安装的目标</li>\n<li><code>ARCHIVE DESTINATION</code>：静态库和动态链接库DLL(Windows).lib存根</li>\n<li><code>LIBRARY DESTINATION</code>：非DLL共享库和模块</li>\n<li><p><code>RUNTIME DESTINATION</code>：可执行目标和DLL(Windows)模式共享库</p>\n<pre><code>  例子：\n</code></pre></li>\n</ul>\n<!--�383-->\n<p>​    除了这些标准的目标，还要安装一些文件到特定的目录下，即一个包含Python绑定的库必须要安装到另外的不同的目录下，这对Python是重要的：</p>\n<!--�384-->\n<h3 id=\"安装Python可执行脚本\"><a href=\"#安装Python可执行脚本\" class=\"headerlink\" title=\"安装Python可执行脚本\"></a>安装Python可执行脚本</h3><p>​    Python代码的安装规则有些不同，它不需要使用     <code>add_library()</code>和<code>add_executable()</code>函数来告知CMake哪个文件是目标文件、目标文件是什么类型的。而是使用如下的CMakeList.txt文件：</p>\n<!--�385-->\n<p>​    如果只是安装了Python的脚本，不提供任何模块的话，就不用创建上文提到的   <code>setup.py</code>文件，也不用调用<code>catkin_python_setup()</code>。</p>\n<h3 id=\"安装头文件\"><a href=\"#安装头文件\" class=\"headerlink\" title=\"安装头文件\"></a>安装头文件</h3><p>​    头文件必须安装到include目录下，这通常通过安装整个文件夹的文件来完成（可以根据文件名模式进行过滤，并排除SVN子文件夹）。可以通过一下安装规则实现：</p>\n<!--�386-->\n<p>​    或者如果include目录下的子文件夹无法和软件包名匹配时：</p>\n<!--�387-->\n<h3 id=\"安装roslaunch文件或其他源\"><a href=\"#安装roslaunch文件或其他源\" class=\"headerlink\" title=\"安装roslaunch文件或其他源\"></a>安装roslaunch文件或其他源</h3><p>​    其他像launchfiles的资源可以安装到   <code>${CATKIN_PACKAGE_SHARE_DESTINATION}</code>：</p>\n<!--�388-->\n<h2 id=\"CMakeLists-txt文件书写模板\"><a href=\"#CMakeLists-txt文件书写模板\" class=\"headerlink\" title=\"CMakeLists.txt文件书写模板\"></a>CMakeLists.txt文件书写模板</h2><!--�389-->"}],"PostAsset":[{"_id":"source/_posts/Cartographer学习二源码分析之核心代码/Cartographer系统框架图.png","slug":"Cartographer系统框架图.png","post":"cjzdedbu9000jqlcr3ez65lsa","modified":1,"renderable":0},{"_id":"source/_posts/ROS学习之actionlib库（１）-actionlib库的介绍/节点图.png","slug":"节点图.png","post":"cjzdedbz600bnqlcr2audx4n6","modified":1,"renderable":0},{"_id":"source/_posts/ROS学习之actionlib库（２）-使用Execute Callback编写一个简单的行为服务器/节点图.png","slug":"节点图.png","post":"cjzdedbzg00brqlcrtafj6pf7","modified":1,"renderable":0},{"_id":"source/_posts/ROS学习之pluginlib/pluginlib.png","slug":"pluginlib.png","post":"cjzdedbzp00bxqlcrkrzzb4wp","modified":1,"renderable":0},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/pcl点云显示.png","slug":"pcl点云显示.png","post":"cjzdedbun0017qlcra7hg137z","modified":1,"renderable":0},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/运行结果.png","slug":"运行结果.png","post":"cjzdedbun0017qlcra7hg137z","modified":1,"renderable":0},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形/节点图.png","slug":"节点图.png","post":"cjzdedbzw00c0qlcrc64a54zr","modified":1,"renderable":0},{"_id":"source/_posts/ROS学习之actionlib库（３）-使用目标回调方法编写一个简单的行为服务器/节点图.png","slug":"节点图.png","post":"cjzdedbzh00buqlcrp0ot2qrt","modified":1,"renderable":0},{"_id":"source/_posts/ORB-SLAM2学习之源码分析七-LocalClosing/LocalClosing.png","post":"cjzdedbuh000xqlcreih2ab4e","slug":"LocalClosing.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM基础学习之非线性最小二乘问题求解方法/newton.png","post":"cjzdedbvu003cqlcr49wb6pc9","slug":"newton.png","modified":1,"renderable":1},{"_id":"source/_posts/跨平台可视化库Pangolin/三角形.png","post":"cjzdedbvx003fqlcrst97z8gc","slug":"三角形.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习二源码分析之核心代码/整体流程.png","slug":"整体流程.png","post":"cjzdedbu9000jqlcr3ez65lsa","modified":1,"renderable":0},{"_id":"source/_posts/Cartographer学习三源码分析之ROS应用/ROS框架.png","post":"cjzdedbuc000nqlcr296gyn4f","slug":"ROS框架.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习三源码分析之ROS应用/cartographer_old.png","slug":"cartographer_old.png","post":"cjzdedbuc000nqlcr296gyn4f","modified":1,"renderable":0},{"_id":"source/_posts/ORB-SLAM2学习之源码分析六-LocalMapping/LocalMapping.png","post":"cjzdedbul0014qlcrzqzz4r0g","slug":"LocalMapping.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2学习之源码分析六-LocalMapping/slam框架.png","post":"cjzdedbul0014qlcrzqzz4r0g","slug":"slam框架.png","modified":1,"renderable":1},{"_id":"source/_posts/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/git.png","post":"cjzdedbus001gqlcrozwo1eli","slug":"git.png","modified":1,"renderable":1},{"_id":"source/_posts/ROS学习之OpenCV图像、ROS Image转换接口cv_bridge/git2.png","post":"cjzdedbus001gqlcrozwo1eli","slug":"git2.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记八-图像表示与存储/图像坐标示意图.png","post":"cjzdedbvo0033qlcr1wvlejsu","slug":"图像坐标示意图.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记八-图像表示与存储/表示和存储.png","post":"cjzdedbvo0033qlcr1wvlejsu","slug":"表示和存储.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记四-三角测量/三角测量.png","post":"cjzdedbvq0036qlcrfgtde0rb","slug":"三角测量.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记四-三角测量/三角测量的矛盾.png","post":"cjzdedbvq0036qlcrfgtde0rb","slug":"三角测量的矛盾.png","modified":1,"renderable":1},{"_id":"source/_posts/Docker学习之基础知识/bootfs.jpg","slug":"bootfs.jpg","post":"cjzdedbub000mqlcrc4a7wkqs","modified":1,"renderable":0},{"_id":"source/_posts/Docker学习之基础知识/docker-filesystems-multilayer.png","post":"cjzdedbub000mqlcrc4a7wkqs","slug":"docker-filesystems-multilayer.png","modified":1,"renderable":1},{"_id":"source/_posts/Docker学习之基础知识/flocker.jpg","post":"cjzdedbub000mqlcrc4a7wkqs","slug":"flocker.jpg","modified":1,"renderable":1},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/删除前.png","post":"cjzdedbvf002nqlcryqpdgnsa","slug":"删除前.png","modified":1,"renderable":1},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/删除后.png","post":"cjzdedbvf002nqlcryqpdgnsa","slug":"删除后.png","modified":1,"renderable":1},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/磁盘分析.png","post":"cjzdedbvf002nqlcryqpdgnsa","slug":"磁盘分析.png","modified":1,"renderable":1},{"_id":"source/_posts/ubuntu系统提示磁盘空间不足问题解决/错误提示.png","post":"cjzdedbvf002nqlcryqpdgnsa","slug":"错误提示.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/ORB世界坐标系.png","post":"cjzdedbun0017qlcra7hg137z","slug":"ORB世界坐标系.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/Rviz世界坐标系.png","post":"cjzdedbun0017qlcra7hg137z","slug":"Rviz世界坐标系.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2系统Rviz可视化方案/相机坐标系.png","post":"cjzdedbun0017qlcra7hg137z","slug":"相机坐标系.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/SLAM视觉里程计特征点法.png","slug":"SLAM视觉里程计特征点法.png","post":"cjzdedbys00bgqlcr1z4a9o3v","modified":1,"renderable":0},{"_id":"source/_posts/ORB-SLAM2学习之源码分析九-ORB特征匹配/直方图.png","post":"cjzdedbyn00b1qlcr3ha7lq9a","slug":"直方图.png","modified":1,"renderable":1},{"_id":"source/_posts/lightweight_mapping学习之LocalMeshing/Delanunay三角剖分.png","post":"cjzdedc0700cdqlcrg753r2gp","slug":"Delanunay三角剖分.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记二-SLAM的数学表述/视觉SLAM经典框架.png","post":"cjzdedc0b00crqlcrkvnsv84c","slug":"视觉SLAM经典框架.png","modified":1,"renderable":1},{"_id":"source/_posts/论文阅读之《Parallel Tracking and Mapping for Small AR Workspaces》/patchsearch.png","post":"cjzdedc0d00cyqlcr14q6b7ob","slug":"patchsearch.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2学习之源码分析八-单目初始化再学习/得分计算公式.png","post":"cjzdedbyp00b9qlcrhvvirpkf","slug":"得分计算公式.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2学习之源码分析八-单目初始化再学习/模型打分公式.png","post":"cjzdedbyp00b9qlcrhvvirpkf","slug":"模型打分公式.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化/ExtractORB.png","post":"cjzdedbyo00b6qlcrku22ge65","slug":"ExtractORB.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化/单目初始化.png","post":"cjzdedbyo00b6qlcrku22ge65","slug":"单目初始化.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB-SLAM2学习之源码分析二-初始化/双目初始化.png","post":"cjzdedbyo00b6qlcrku22ge65","slug":"双目初始化.png","modified":1,"renderable":1},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形/五边形.png","post":"cjzdedbzw00c0qlcrc64a54zr","slug":"五边形.png","modified":1,"renderable":1},{"_id":"source/_posts/ROS学习之actionlib库（４）-实践之小乌龟画五边形/交互图.png","post":"cjzdedbzw00c0qlcrc64a54zr","slug":"交互图.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何/对极几何约束.png","post":"cjzdedc0900cnqlcrfpb95n1r","slug":"对极几何约束.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何/归一化坐标.png","post":"cjzdedc0900cnqlcrfpb95n1r","slug":"归一化坐标.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记三-对极几何/本质矩阵的解.png","post":"cjzdedc0900cnqlcrfpb95n1r","slug":"本质矩阵的解.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型/像素坐标系.png","post":"cjzdedc0c00cvqlcrdhqa5s2w","slug":"像素坐标系.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型/相机坐标系.png","post":"cjzdedc0c00cvqlcrdhqa5s2w","slug":"相机坐标系.png","modified":1,"renderable":1},{"_id":"source/_posts/视觉SLAM十四讲阅读笔记六-针孔相机模型/针孔相机模型.png","post":"cjzdedc0c00cvqlcrdhqa5s2w","slug":"针孔相机模型.png","modified":1,"renderable":1},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/SVO追踪与建图.png","post":"cjzdedbyi00arqlcrqu4ltoyh","slug":"SVO追踪与建图.png","modified":1,"renderable":1},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/a.png","post":"cjzdedbyi00arqlcrqu4ltoyh","slug":"a.png","modified":1,"renderable":1},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/b.png","post":"cjzdedbyi00arqlcrqu4ltoyh","slug":"b.png","modified":1,"renderable":1},{"_id":"source/_posts/论文阅读之《SVO-Fast-Semi-Direct-Monocular-Visual-Odometry》/c.png","post":"cjzdedbyi00arqlcrqu4ltoyh","slug":"c.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/Sim3上的位姿优化.png","post":"cjzdedbyt00bkqlcrrpknhfqn","slug":"Sim3上的位姿优化.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/全局优化.png","post":"cjzdedbyt00bkqlcrrpknhfqn","slug":"全局优化.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/局部优化.png","post":"cjzdedbyt00bkqlcrrpknhfqn","slug":"局部优化.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析三-优化/闭环处优化.png","post":"cjzdedbyt00bkqlcrrpknhfqn","slug":"闭环处优化.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/SLAM视觉里程计.png","post":"cjzdedbys00bgqlcr1z4a9o3v","slug":"SLAM视觉里程计.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/Track.png","post":"cjzdedbys00bgqlcr1z4a9o3v","slug":"Track.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/Tracking跟踪模型.png","post":"cjzdedbys00bgqlcr1z4a9o3v","slug":"Tracking跟踪模型.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/Tracking重点环节.png","post":"cjzdedbys00bgqlcr1z4a9o3v","slug":"Tracking重点环节.png","modified":1,"renderable":1},{"_id":"source/_posts/ORB_SLAM2学习之源码分析一-追踪/局部地图示意图.png","post":"cjzdedbys00bgqlcr1z4a9o3v","slug":"局部地图示意图.png","modified":1,"renderable":1},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA.png","post":"cjzdedbym00ayqlcr21hg03hb","slug":"CUDA.png","modified":1,"renderable":1},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA9安装.png","slug":"CUDA9安装.png","post":"cjzdedbym00ayqlcr21hg03hb","modified":1,"renderable":0},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA和驱动版本对应.png","post":"cjzdedbym00ayqlcr21hg03hb","slug":"CUDA和驱动版本对应.png","modified":1,"renderable":1},{"_id":"source/_posts/Caffe的GPU模式安装/CUDA测试.png","post":"cjzdedbym00ayqlcr21hg03hb","slug":"CUDA测试.png","modified":1,"renderable":1},{"_id":"source/_posts/Caffe的GPU模式安装/cuDNN.png","post":"cjzdedbym00ayqlcr21hg03hb","slug":"cuDNN.png","modified":1,"renderable":1},{"_id":"source/_posts/Caffe的GPU模式安装/nvidia安装成功.png","post":"cjzdedbym00ayqlcr21hg03hb","slug":"nvidia安装成功.png","modified":1,"renderable":1},{"_id":"source/_posts/Caffe的GPU模式安装/samples.png","slug":"samples.png","post":"cjzdedbym00ayqlcr21hg03hb","modified":1,"renderable":0},{"_id":"source/_posts/Cartographer学习一论文阅读/submap.png","post":"cjzdedc1h00f0qlcrp4bcab1x","slug":"submap.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习一论文阅读/暴力搜索.png","post":"cjzdedc1h00f0qlcrp4bcab1x","slug":"暴力搜索.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习一论文阅读/算法2.png","post":"cjzdedc1h00f0qlcrp4bcab1x","slug":"算法2.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习一论文阅读/算法3.png","post":"cjzdedc1h00f0qlcrp4bcab1x","slug":"算法3.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习一论文阅读/系统图.png","post":"cjzdedc1h00f0qlcrp4bcab1x","slug":"系统图.png","modified":1,"renderable":1},{"_id":"source/_posts/Cartographer学习一论文阅读/网格点和相关像素.png","post":"cjzdedc1h00f0qlcrp4bcab1x","slug":"网格点和相关像素.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cjzdedbtr0006qlcrkdi91pkk","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbug000vqlcrsneu99om"},{"post_id":"cjzdedbtr0006qlcrkdi91pkk","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedbui000yqlcrg94at91z"},{"post_id":"cjzdedbtf0001qlcrvbcmemo0","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbuk0012qlcr99m8ifnf"},{"post_id":"cjzdedbtf0001qlcrvbcmemo0","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedbum0015qlcrsr6ibu03"},{"post_id":"cjzdedbtt0007qlcr1bmpyzvf","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbuo0018qlcrym1fia8s"},{"post_id":"cjzdedbtt0007qlcr1bmpyzvf","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedbuq001cqlcry99e08v4"},{"post_id":"cjzdedbtk0002qlcrmvqn5s5o","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbuu001kqlcr0ljw93hu"},{"post_id":"cjzdedbtk0002qlcrmvqn5s5o","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedbuv001nqlcrkb64h2q6"},{"post_id":"cjzdedbtp0005qlcrcrkpoifm","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbv30020qlcrlqvkwtwk"},{"post_id":"cjzdedbtp0005qlcrcrkpoifm","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedbv50024qlcrwhvdz1rv"},{"post_id":"cjzdedbv30021qlcrkj6lxdoh","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbv8002aqlcr7j5w2yt3"},{"post_id":"cjzdedbv50025qlcrbe04tu6e","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbva002dqlcrcs5hskdp"},{"post_id":"cjzdedbub000mqlcrc4a7wkqs","category_id":"cjzdedbv40022qlcrp3cih2wk","_id":"cjzdedbvc002hqlcrcihf0rll"},{"post_id":"cjzdedbvl002xqlcrpqczn1qo","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbvr0037qlcr88x3g1ix"},{"post_id":"cjzdedbtz000bqlcr5cdoa4ez","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbvz003jqlcroz1ogf3z"},{"post_id":"cjzdedbtz000bqlcr5cdoa4ez","category_id":"cjzdedbvs0038qlcr1qy5o07l","_id":"cjzdedbw0003kqlcrf5xiqiq9"},{"post_id":"cjzdedbu4000dqlcr2dgsgpbu","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbw50040qlcrd3ofooee"},{"post_id":"cjzdedbu4000dqlcr2dgsgpbu","category_id":"cjzdedbvs0038qlcr1qy5o07l","_id":"cjzdedbw50042qlcruzhpqo0i"},{"post_id":"cjzdedbu7000hqlcrvn8x0yi2","category_id":"cjzdedbuu001jqlcr39a18ir4","_id":"cjzdedbw9004eqlcrurdk2k75"},{"post_id":"cjzdedbu7000hqlcrvn8x0yi2","category_id":"cjzdedbw70046qlcrtqwsuf9e","_id":"cjzdedbwa004gqlcrdrk5kcli"},{"post_id":"cjzdedbv2001zqlcralky9u3w","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbwd004pqlcr4oyenst4"},{"post_id":"cjzdedbv2001zqlcralky9u3w","category_id":"cjzdedbwc004lqlcrfxhiqt5q","_id":"cjzdedbwe004rqlcrmadkjvfi"},{"post_id":"cjzdedbv80029qlcrfyykdafy","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbwi0052qlcrpflk3xk7"},{"post_id":"cjzdedbv80029qlcrfyykdafy","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbwi0054qlcrk72go1cy"},{"post_id":"cjzdedbv9002cqlcrg9q9x1v8","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbwl005bqlcri864ippa"},{"post_id":"cjzdedbv9002cqlcrg9q9x1v8","category_id":"cjzdedbwi0051qlcrlgazyy3r","_id":"cjzdedbwl005dqlcrsp6h2lav"},{"post_id":"cjzdedbvb002gqlcruy22yfcc","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedbwm005fqlcr7qa6qpmo"},{"post_id":"cjzdedbvb002gqlcruy22yfcc","category_id":"cjzdedbwc004lqlcrfxhiqt5q","_id":"cjzdedbwn005jqlcrmt714xyj"},{"post_id":"cjzdedbue000qqlcry10frh6h","category_id":"cjzdedbva002eqlcr4sn1wbtm","_id":"cjzdedbwn005lqlcrmfuzi053"},{"post_id":"cjzdedbue000qqlcry10frh6h","category_id":"cjzdedbwl005aqlcrlvldn9v4","_id":"cjzdedbwo005pqlcr2t4js5hz"},{"post_id":"cjzdedbvd002kqlcrwx05hmw2","category_id":"cjzdedbuu001jqlcr39a18ir4","_id":"cjzdedbwp005sqlcrkl4gu5hh"},{"post_id":"cjzdedbvd002kqlcrwx05hmw2","category_id":"cjzdedbwm005hqlcrywr8sk04","_id":"cjzdedbwp005tqlcrdfmw21ni"},{"post_id":"cjzdedbvf002nqlcryqpdgnsa","category_id":"cjzdedbva002eqlcr4sn1wbtm","_id":"cjzdedbwr005vqlcriym0rqr5"},{"post_id":"cjzdedbvf002nqlcryqpdgnsa","category_id":"cjzdedbwl005aqlcrlvldn9v4","_id":"cjzdedbwr005xqlcrripvds3x"},{"post_id":"cjzdedbvg002pqlcr7cx8juc7","category_id":"cjzdedbwq005uqlcrxxh7yker","_id":"cjzdedbwu0063qlcrp59zii4v"},{"post_id":"cjzdedbvi002sqlcrb92jh2nt","category_id":"cjzdedbva002eqlcr4sn1wbtm","_id":"cjzdedbww0068qlcrv85w3mw9"},{"post_id":"cjzdedbvi002sqlcrb92jh2nt","category_id":"cjzdedbwl005aqlcrlvldn9v4","_id":"cjzdedbwx006bqlcr99vkma8v"},{"post_id":"cjzdedbuq001eqlcrqn0ajb23","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxd007dqlcrvygrxl1s"},{"post_id":"cjzdedbuq001eqlcrqn0ajb23","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxd007fqlcrnjp0rnti"},{"post_id":"cjzdedbus001gqlcrozwo1eli","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxd007jqlcrvybuhh3p"},{"post_id":"cjzdedbus001gqlcrozwo1eli","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxe007kqlcrn82vluwj"},{"post_id":"cjzdedbut001iqlcrfb1n1xow","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxe007nqlcrnecg0zpu"},{"post_id":"cjzdedbut001iqlcrfb1n1xow","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxe007oqlcrz2mgz8j8"},{"post_id":"cjzdedbuu001lqlcrb9417eyv","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxe007rqlcrcsa7gnev"},{"post_id":"cjzdedbuu001lqlcrb9417eyv","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxf007tqlcrsjr97wj2"},{"post_id":"cjzdedbuw001oqlcrkow70gfo","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxf007xqlcrw2a855xi"},{"post_id":"cjzdedbuw001oqlcrkow70gfo","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxg007zqlcrvm91rd65"},{"post_id":"cjzdedbux001rqlcrlrl97z21","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxh0083qlcra45utdht"},{"post_id":"cjzdedbux001rqlcrlrl97z21","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxi0085qlcrxea2dh7u"},{"post_id":"cjzdedbuz001uqlcrzz3632oz","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxi0089qlcrdjayci9k"},{"post_id":"cjzdedbuz001uqlcrzz3632oz","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxi008aqlcr3hlurqw5"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxj008cqlcredrnq5i4"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedbxj008eqlcr4thkrssh"},{"post_id":"cjzdedbu9000jqlcr3ez65lsa","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxj008gqlcr2ap3xvgl"},{"post_id":"cjzdedbu9000jqlcr3ez65lsa","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxj008jqlcrf631mkjm"},{"post_id":"cjzdedbu9000jqlcr3ez65lsa","category_id":"cjzdedbxi0088qlcrd47mc7ne","_id":"cjzdedbxk008lqlcr7aqcf0h4"},{"post_id":"cjzdedbv60026qlcrf55pwv32","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxk008pqlcr8h1zzu7h"},{"post_id":"cjzdedbv60026qlcrf55pwv32","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxk008qqlcrtc6qp7i8"},{"post_id":"cjzdedbv60026qlcrf55pwv32","category_id":"cjzdedbxj008dqlcrx7sdjli5","_id":"cjzdedbxk008tqlcrcyo50n7u"},{"post_id":"cjzdedbuc000nqlcr296gyn4f","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxl008uqlcr6xxz1ubl"},{"post_id":"cjzdedbuc000nqlcr296gyn4f","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxl008xqlcr9rkijo32"},{"post_id":"cjzdedbuc000nqlcr296gyn4f","category_id":"cjzdedbxi0088qlcrd47mc7ne","_id":"cjzdedbxl008zqlcr1j2y7ae7"},{"post_id":"cjzdedbuf000sqlcrbgz0w9h5","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxm0093qlcr93podfjc"},{"post_id":"cjzdedbuf000sqlcrbgz0w9h5","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxm0095qlcr27t1bc1b"},{"post_id":"cjzdedbuf000sqlcrbgz0w9h5","category_id":"cjzdedbxk008nqlcrb6kk2icj","_id":"cjzdedbxn0098qlcrcnvn6unx"},{"post_id":"cjzdedbuh000xqlcreih2ab4e","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxo009aqlcrugnlgogb"},{"post_id":"cjzdedbuh000xqlcreih2ab4e","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxo009dqlcro79aq3r8"},{"post_id":"cjzdedbuh000xqlcreih2ab4e","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedbxp009gqlcr5ml09u3w"},{"post_id":"cjzdedbvj002uqlcr2js1alsv","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxp009iqlcrb46av2et"},{"post_id":"cjzdedbvj002uqlcr2js1alsv","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxq009kqlcrh5bktu4e"},{"post_id":"cjzdedbvj002uqlcr2js1alsv","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedbxq009mqlcr19abp6ok"},{"post_id":"cjzdedbuj0010qlcrwdy845p3","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxq009nqlcru6eba3d7"},{"post_id":"cjzdedbuj0010qlcrwdy845p3","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxq009pqlcr6fr7heji"},{"post_id":"cjzdedbuj0010qlcrwdy845p3","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedbxq009qqlcrr3hk5q30"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxr009rqlcrmhhgvi6p"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxr009tqlcrvt1iro0n"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedbxr009uqlcrd7ql224l"},{"post_id":"cjzdedbvo0033qlcr1wvlejsu","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxs009wqlcr2e69tnbz"},{"post_id":"cjzdedbvo0033qlcr1wvlejsu","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxs009xqlcrcyi63azv"},{"post_id":"cjzdedbvo0033qlcr1wvlejsu","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedbxs009zqlcr5lvonrpx"},{"post_id":"cjzdedbul0014qlcrzqzz4r0g","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxs00a0qlcrt2ac9xc9"},{"post_id":"cjzdedbul0014qlcrzqzz4r0g","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxt00a2qlcrft1ouft0"},{"post_id":"cjzdedbul0014qlcrzqzz4r0g","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedbxt00a3qlcrryuoye1h"},{"post_id":"cjzdedbvq0036qlcrfgtde0rb","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxt00a5qlcr6eogbp86"},{"post_id":"cjzdedbvq0036qlcrfgtde0rb","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxt00a6qlcriszqyicp"},{"post_id":"cjzdedbvq0036qlcrfgtde0rb","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedbxt00a7qlcrnrfiz5mt"},{"post_id":"cjzdedbvs003aqlcrfkd1sl8i","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxt00a8qlcr9wfpbv90"},{"post_id":"cjzdedbvs003aqlcrfkd1sl8i","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxt00a9qlcrk36cl970"},{"post_id":"cjzdedbvs003aqlcrfkd1sl8i","category_id":"cjzdedbxq009oqlcrdhmiv6xe","_id":"cjzdedbxu00aaqlcrey6v6ebo"},{"post_id":"cjzdedbvu003cqlcr49wb6pc9","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxu00abqlcr2w0wsvey"},{"post_id":"cjzdedbvu003cqlcr49wb6pc9","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxu00acqlcr0casplgt"},{"post_id":"cjzdedbvu003cqlcr49wb6pc9","category_id":"cjzdedbxr009sqlcrtorvnqze","_id":"cjzdedbxu00adqlcrspq2pxl9"},{"post_id":"cjzdedbvx003fqlcrst97z8gc","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxu00aeqlcr11o3g4f5"},{"post_id":"cjzdedbvx003fqlcrst97z8gc","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxu00afqlcrm7h2yvxn"},{"post_id":"cjzdedbvx003fqlcrst97z8gc","category_id":"cjzdedbxr009vqlcr67ei99om","_id":"cjzdedbxu00agqlcr7xh89t8k"},{"post_id":"cjzdedbun0017qlcra7hg137z","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxu00ahqlcrcaj5uo7b"},{"post_id":"cjzdedbun0017qlcra7hg137z","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxu00aiqlcrp9wbz3b1"},{"post_id":"cjzdedbun0017qlcra7hg137z","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedbxu00ajqlcr0c8icuqj"},{"post_id":"cjzdedbvy003hqlcrjpjbj762","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxu00akqlcr6sul8z4f"},{"post_id":"cjzdedbvy003hqlcrjpjbj762","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxu00alqlcr66yoj93p"},{"post_id":"cjzdedbvy003hqlcrjpjbj762","category_id":"cjzdedbxq009oqlcrdhmiv6xe","_id":"cjzdedbxu00amqlcrb3hpa9ar"},{"post_id":"cjzdedbup001bqlcrzgaaxcv6","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbxu00anqlcriqtfq7f1"},{"post_id":"cjzdedbup001bqlcrzgaaxcv6","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbxu00aoqlcrvezgqxr5"},{"post_id":"cjzdedbup001bqlcrzgaaxcv6","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedbxu00apqlcrm2kozw2x"},{"post_id":"cjzdedbyi00arqlcrqu4ltoyh","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbyn00azqlcrq8vhnyza"},{"post_id":"cjzdedbyi00arqlcrqu4ltoyh","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbyo00b4qlcr4pqn6n9i"},{"post_id":"cjzdedbyi00arqlcrqu4ltoyh","category_id":"cjzdedbxq009oqlcrdhmiv6xe","_id":"cjzdedbyp00b7qlcrwl0q6sk3"},{"post_id":"cjzdedbyj00atqlcronu7u4dv","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbyq00bbqlcrosq8ocz4"},{"post_id":"cjzdedbyj00atqlcronu7u4dv","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedbyr00beqlcrqgeziyc5"},{"post_id":"cjzdedbym00ayqlcr21hg03hb","category_id":"cjzdedbuu001jqlcr39a18ir4","_id":"cjzdedbyt00bhqlcr0r7sf5dx"},{"post_id":"cjzdedbym00ayqlcr21hg03hb","category_id":"cjzdedbw70046qlcrtqwsuf9e","_id":"cjzdedbz500blqlcr3u9tdxu4"},{"post_id":"cjzdedbyn00b1qlcr3ha7lq9a","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedbzg00boqlcrthj1klf8"},{"post_id":"cjzdedbyn00b1qlcr3ha7lq9a","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedbzh00bsqlcrtgx4a4ie"},{"post_id":"cjzdedbyn00b1qlcr3ha7lq9a","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedbzo00bvqlcrf4i95d9k"},{"post_id":"cjzdedbyl00awqlcr4iq6gct1","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedbzw00byqlcrmacxqgsz"},{"post_id":"cjzdedbyl00awqlcr4iq6gct1","category_id":"cjzdedbyn00b2qlcrjr90plxj","_id":"cjzdedc0300c1qlcrpgkgp05y"},{"post_id":"cjzdedbyo00b6qlcrku22ge65","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0400c4qlcrux4o2a0n"},{"post_id":"cjzdedbyo00b6qlcrku22ge65","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0500c7qlcrso3um1j3"},{"post_id":"cjzdedbyo00b6qlcrku22ge65","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedc0600cbqlcrhhnpzbrc"},{"post_id":"cjzdedbyp00b9qlcrhvvirpkf","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0700ceqlcr5b39m36h"},{"post_id":"cjzdedbyp00b9qlcrhvvirpkf","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0800chqlcr55et8x21"},{"post_id":"cjzdedbyp00b9qlcrhvvirpkf","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedc0900clqlcrmwvrwptk"},{"post_id":"cjzdedbyq00bdqlcrdz3tlrjh","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedc0a00cpqlcridet4pvt"},{"post_id":"cjzdedbyq00bdqlcrdz3tlrjh","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedc0b00csqlcr1befg6yv"},{"post_id":"cjzdedbys00bgqlcr1z4a9o3v","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0d00cwqlcrvnd5y8rc"},{"post_id":"cjzdedbys00bgqlcr1z4a9o3v","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0e00czqlcr9t9ax0hy"},{"post_id":"cjzdedbys00bgqlcr1z4a9o3v","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedc0f00d2qlcr5kgifm9t"},{"post_id":"cjzdedbyt00bkqlcrrpknhfqn","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0f00d4qlcr8fgbqoib"},{"post_id":"cjzdedbyt00bkqlcrrpknhfqn","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0f00d7qlcr0n6zwk6x"},{"post_id":"cjzdedbyt00bkqlcrrpknhfqn","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedc0f00d9qlcr8n3flals"},{"post_id":"cjzdedbz600bnqlcr2audx4n6","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0g00dcqlcrcllizdiv"},{"post_id":"cjzdedbz600bnqlcr2audx4n6","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0g00deqlcrmfpzwzsm"},{"post_id":"cjzdedbzg00brqlcrtafj6pf7","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0g00dgqlcra9plundy"},{"post_id":"cjzdedbzg00brqlcrtafj6pf7","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0g00diqlcrsh7wciec"},{"post_id":"cjzdedbzh00buqlcrp0ot2qrt","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0g00dkqlcrw2r6561c"},{"post_id":"cjzdedbzh00buqlcrp0ot2qrt","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0g00dmqlcrw1z433le"},{"post_id":"cjzdedbzp00bxqlcrkrzzb4wp","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0g00doqlcri5l6xjf8"},{"post_id":"cjzdedbzp00bxqlcrkrzzb4wp","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0g00dqqlcrgkq8u3q6"},{"post_id":"cjzdedbzw00c0qlcrc64a54zr","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0g00dsqlcrfzido7qy"},{"post_id":"cjzdedbzw00c0qlcrc64a54zr","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0g00duqlcrv71mussc"},{"post_id":"cjzdedc0400c3qlcrifvh6oky","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0g00dwqlcrgmko7l4v"},{"post_id":"cjzdedc0400c3qlcrifvh6oky","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0g00dyqlcrnv2s2n72"},{"post_id":"cjzdedc0500c6qlcrtop5fjy5","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00e0qlcrh05yyng7"},{"post_id":"cjzdedc0500c6qlcrtop5fjy5","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc0h00e2qlcry3vgf50k"},{"post_id":"cjzdedc0600caqlcr65vxhlaq","category_id":"cjzdedbuk0011qlcruwsbwpup","_id":"cjzdedc0h00e4qlcrey79ws4j"},{"post_id":"cjzdedc0700cdqlcrg753r2gp","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00e6qlcrcw7r35sa"},{"post_id":"cjzdedc0700cdqlcrg753r2gp","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00e8qlcrzx07q7u1"},{"post_id":"cjzdedc0700cdqlcrg753r2gp","category_id":"cjzdedbxj008dqlcrx7sdjli5","_id":"cjzdedc0h00eaqlcrczw7wusy"},{"post_id":"cjzdedc0900ckqlcrrogphqzq","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00ecqlcr1sl14s3u"},{"post_id":"cjzdedc0900ckqlcrrogphqzq","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00eeqlcrhb8gkxu4"},{"post_id":"cjzdedc0900ckqlcrrogphqzq","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedc0h00egqlcr217oz4oj"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00eiqlcr112uxd0k"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00ejqlcrzmp706j4"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedc0h00ekqlcrdvx85mhm"},{"post_id":"cjzdedc0b00crqlcrkvnsv84c","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00elqlcrk0wyqmqq"},{"post_id":"cjzdedc0b00crqlcrkvnsv84c","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00emqlcr9lktisdt"},{"post_id":"cjzdedc0b00crqlcrkvnsv84c","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedc0h00enqlcr0nmcvzv7"},{"post_id":"cjzdedc0800cgqlcrqt0dwvre","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00eoqlcrwcakjjbg"},{"post_id":"cjzdedc0800cgqlcrqt0dwvre","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00epqlcrdm8a140v"},{"post_id":"cjzdedc0800cgqlcrqt0dwvre","category_id":"cjzdedc0a00coqlcr2rtyklys","_id":"cjzdedc0h00eqqlcrz0bgbd1r"},{"post_id":"cjzdedc0c00cvqlcrdhqa5s2w","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00erqlcrn8shlb9t"},{"post_id":"cjzdedc0c00cvqlcrdhqa5s2w","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00esqlcr6somt6u7"},{"post_id":"cjzdedc0c00cvqlcrdhqa5s2w","category_id":"cjzdedbxl008wqlcrhcjwq2xo","_id":"cjzdedc0h00etqlcrcxgrqs3n"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc0h00euqlcr0ya5xxar"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc0h00evqlcrj0yyt258"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","category_id":"cjzdedbxq009oqlcrdhmiv6xe","_id":"cjzdedc0h00ewqlcrgeql1v2m"},{"post_id":"cjzdedc1e00exqlcrtvof17sk","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedc1p00f3qlcrnldz9pk0"},{"post_id":"cjzdedc1e00exqlcrtvof17sk","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedc1x00f6qlcra7w4axlv"},{"post_id":"cjzdedc1f00eyqlcr78z7kgbk","category_id":"cjzdedbtn0003qlcr9emda53j","_id":"cjzdedc2800f8qlcrqzdp42uk"},{"post_id":"cjzdedc1f00eyqlcr78z7kgbk","category_id":"cjzdedbua000kqlcrdjze054a","_id":"cjzdedc2f00faqlcrbkaqij83"},{"post_id":"cjzdedc1h00f0qlcrp4bcab1x","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc2m00fcqlcrom00jegm"},{"post_id":"cjzdedc1h00f0qlcrp4bcab1x","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc2m00feqlcrriwjl8hb"},{"post_id":"cjzdedc1h00f0qlcrp4bcab1x","category_id":"cjzdedbxi0088qlcrd47mc7ne","_id":"cjzdedc2m00ffqlcrm62ldbsk"},{"post_id":"cjzdedc1o00f2qlcrjvgtwfgp","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc2m00fgqlcr2ofx6lkn"},{"post_id":"cjzdedc1o00f2qlcrjvgtwfgp","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc2n00fhqlcrrho5x1xz"},{"post_id":"cjzdedc1o00f2qlcrjvgtwfgp","category_id":"cjzdedbxk008sqlcryb6r7c0r","_id":"cjzdedc2n00fiqlcrrlkb01sf"},{"post_id":"cjzdedc1w00f5qlcr178kl6a0","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc2n00fjqlcrze43k0xr"},{"post_id":"cjzdedc1w00f5qlcr178kl6a0","category_id":"cjzdedbwc004nqlcrl67k1642","_id":"cjzdedc2n00fkqlcrcoew1f27"},{"post_id":"cjzdedc1w00f5qlcr178kl6a0","category_id":"cjzdedbxq009oqlcrdhmiv6xe","_id":"cjzdedc2n00flqlcrhhqddogp"},{"post_id":"cjzdedc3600fmqlcrhczh4xd1","category_id":"cjzdedbv0001wqlcrinnwfi82","_id":"cjzdedc3a00fpqlcrjskdgyb4"},{"post_id":"cjzdedc3600fmqlcrhczh4xd1","category_id":"cjzdedbwe004tqlcrq7hugm7w","_id":"cjzdedc3b00fqqlcr9fr6u0ku"}],"PostTag":[{"post_id":"cjzdedbtr0006qlcrkdi91pkk","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbtz000aqlcrkr3ebtla"},{"post_id":"cjzdedbtf0001qlcrvbcmemo0","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbu3000cqlcrs13i87v1"},{"post_id":"cjzdedbtt0007qlcr1bmpyzvf","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbu7000gqlcrejpx34gx"},{"post_id":"cjzdedbtk0002qlcrmvqn5s5o","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbu9000iqlcrqqy1ln3m"},{"post_id":"cjzdedbtp0005qlcrcrkpoifm","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbuf000rqlcri8t6p08c"},{"post_id":"cjzdedbtp0005qlcrcrkpoifm","tag_id":"cjzdedbua000lqlcr645qd6id","_id":"cjzdedbug000tqlcrvw66ifrx"},{"post_id":"cjzdedbtz000bqlcr5cdoa4ez","tag_id":"cjzdedbud000pqlcrcrtjccc0","_id":"cjzdedbui000zqlcrhm8nxpzi"},{"post_id":"cjzdedbu4000dqlcr2dgsgpbu","tag_id":"cjzdedbud000pqlcrcrtjccc0","_id":"cjzdedbum0016qlcr4ljliqbu"},{"post_id":"cjzdedbu7000hqlcrvn8x0yi2","tag_id":"cjzdedbuk0013qlcr5sqq691o","_id":"cjzdedbuq001dqlcrlo0l2de8"},{"post_id":"cjzdedbu9000jqlcr3ez65lsa","tag_id":"cjzdedbup001aqlcrgmlw424a","_id":"cjzdedbuw001pqlcr0r6v356b"},{"post_id":"cjzdedbu9000jqlcr3ez65lsa","tag_id":"cjzdedbut001hqlcr488mkn99","_id":"cjzdedbuy001sqlcryo1m6a83"},{"post_id":"cjzdedbub000mqlcrc4a7wkqs","tag_id":"cjzdedbuv001mqlcrckkn4513","_id":"cjzdedbv0001vqlcrsj3upoem"},{"post_id":"cjzdedbuc000nqlcr296gyn4f","tag_id":"cjzdedbup001aqlcrgmlw424a","_id":"cjzdedbv9002bqlcr7k84z6dv"},{"post_id":"cjzdedbuc000nqlcr296gyn4f","tag_id":"cjzdedbut001hqlcr488mkn99","_id":"cjzdedbvb002fqlcr152a2oz9"},{"post_id":"cjzdedbuc000nqlcr296gyn4f","tag_id":"cjzdedbv50023qlcrfkrg83r3","_id":"cjzdedbvc002jqlcry18cik26"},{"post_id":"cjzdedbue000qqlcry10frh6h","tag_id":"cjzdedbv80028qlcrs0r2s4vf","_id":"cjzdedbve002mqlcryehtvjky"},{"post_id":"cjzdedbvf002nqlcryqpdgnsa","tag_id":"cjzdedbv80028qlcrs0r2s4vf","_id":"cjzdedbvi002rqlcrj40of83a"},{"post_id":"cjzdedbuf000sqlcrbgz0w9h5","tag_id":"cjzdedbvc002iqlcrzg09utjf","_id":"cjzdedbvk002vqlcr6g0mzxmq"},{"post_id":"cjzdedbuf000sqlcrbgz0w9h5","tag_id":"cjzdedbvg002oqlcr146j0ukt","_id":"cjzdedbvm002yqlcray79lr3z"},{"post_id":"cjzdedbvi002sqlcrb92jh2nt","tag_id":"cjzdedbv80028qlcrs0r2s4vf","_id":"cjzdedbvn0031qlcrgfuc057c"},{"post_id":"cjzdedbuh000xqlcreih2ab4e","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbvp0034qlcri5rasqzp"},{"post_id":"cjzdedbuj0010qlcrwdy845p3","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbvs0039qlcrx36ia46x"},{"post_id":"cjzdedbul0014qlcrzqzz4r0g","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbvw003dqlcromgi9xf1"},{"post_id":"cjzdedbun0017qlcra7hg137z","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbw1003nqlcre7xryuuo"},{"post_id":"cjzdedbun0017qlcra7hg137z","tag_id":"cjzdedbvy003gqlcrm157c57o","_id":"cjzdedbw1003oqlcrb0iwrz8d"},{"post_id":"cjzdedbup001bqlcrzgaaxcv6","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbw2003rqlcr7lzbulv6"},{"post_id":"cjzdedbuq001eqlcrqn0ajb23","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbw3003uqlcr2lpalaed"},{"post_id":"cjzdedbus001gqlcrozwo1eli","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbw4003xqlcr90d7jvo2"},{"post_id":"cjzdedbut001iqlcrfb1n1xow","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbw50041qlcrdl6x9jg9"},{"post_id":"cjzdedbuu001lqlcrb9417eyv","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbw70047qlcrochprgwi"},{"post_id":"cjzdedbuu001lqlcrb9417eyv","tag_id":"cjzdedbv50023qlcrfkrg83r3","_id":"cjzdedbw70048qlcr2rvave3k"},{"post_id":"cjzdedbuw001oqlcrkow70gfo","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbw8004bqlcr2jv8gcke"},{"post_id":"cjzdedbux001rqlcrlrl97z21","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbw9004fqlcr79uczn5b"},{"post_id":"cjzdedbuz001uqlcrzz3632oz","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbwa004jqlcrvkzkr6ce"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedbwf004uqlcrh6foi8m7"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbwf004vqlcrnslatzxp"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","tag_id":"cjzdedbwb004kqlcrvsyzjcv1","_id":"cjzdedbwg004yqlcr8qz2dwh5"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","tag_id":"cjzdedbwc004mqlcru2yudac6","_id":"cjzdedbwh004zqlcrvey6f7aa"},{"post_id":"cjzdedbv0001xqlcr5mwxa4f4","tag_id":"cjzdedbwd004oqlcrj2z6yfhf","_id":"cjzdedbwi0053qlcrg7swh7z2"},{"post_id":"cjzdedbv2001zqlcralky9u3w","tag_id":"cjzdedbv80028qlcrs0r2s4vf","_id":"cjzdedbwk0057qlcrhdyzr1pp"},{"post_id":"cjzdedbv2001zqlcralky9u3w","tag_id":"cjzdedbwf004wqlcryflpq2h8","_id":"cjzdedbwl0058qlcrs19hblzc"},{"post_id":"cjzdedbv2001zqlcralky9u3w","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbwl005cqlcruiy3ok83"},{"post_id":"cjzdedbv2001zqlcralky9u3w","tag_id":"cjzdedbwi0050qlcrss0t52ib","_id":"cjzdedbwl005eqlcrvhtd6ret"},{"post_id":"cjzdedbv30021qlcrkj6lxdoh","tag_id":"cjzdedbwj0055qlcrwccfpqok","_id":"cjzdedbwm005iqlcrwyhl15w1"},{"post_id":"cjzdedbv50025qlcrbe04tu6e","tag_id":"cjzdedbwl0059qlcrqtoa03q6","_id":"cjzdedbwn005kqlcrnhsp6om8"},{"post_id":"cjzdedbv60026qlcrf55pwv32","tag_id":"cjzdedbwm005gqlcrnm1f8kte","_id":"cjzdedbwo005oqlcrgj9mkv5n"},{"post_id":"cjzdedbv80029qlcrfyykdafy","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbwt0060qlcrnn32npzm"},{"post_id":"cjzdedbv80029qlcrfyykdafy","tag_id":"cjzdedbwb004kqlcrvsyzjcv1","_id":"cjzdedbwt0061qlcrdxhpmpyy"},{"post_id":"cjzdedbv80029qlcrfyykdafy","tag_id":"cjzdedbwo005qqlcranaieknx","_id":"cjzdedbwv0065qlcrh5mjpyag"},{"post_id":"cjzdedbv80029qlcrfyykdafy","tag_id":"cjzdedbwr005wqlcrk1ag88kp","_id":"cjzdedbwv0066qlcrpwugja40"},{"post_id":"cjzdedbv9002cqlcrg9q9x1v8","tag_id":"cjzdedbws005zqlcrcj1373n8","_id":"cjzdedbwx006aqlcrej2unhrp"},{"post_id":"cjzdedbvb002gqlcruy22yfcc","tag_id":"cjzdedbv80028qlcrs0r2s4vf","_id":"cjzdedbwz006gqlcr80xxklnu"},{"post_id":"cjzdedbvb002gqlcruy22yfcc","tag_id":"cjzdedbwu0064qlcrvfaxufh7","_id":"cjzdedbx0006iqlcrjs95ndz3"},{"post_id":"cjzdedbvb002gqlcruy22yfcc","tag_id":"cjzdedbwx0069qlcrjosmd256","_id":"cjzdedbx0006kqlcrhjopaq8n"},{"post_id":"cjzdedbvb002gqlcruy22yfcc","tag_id":"cjzdedbwy006dqlcrai0gl2td","_id":"cjzdedbx0006mqlcr9nd24ynw"},{"post_id":"cjzdedbvd002kqlcrwx05hmw2","tag_id":"cjzdedbwz006fqlcr0oogockg","_id":"cjzdedbx1006oqlcrqcsh8pot"},{"post_id":"cjzdedbvg002pqlcr7cx8juc7","tag_id":"cjzdedbx0006jqlcrfj4tat5e","_id":"cjzdedbx1006qqlcr9r9z6cb8"},{"post_id":"cjzdedbvj002uqlcr2js1alsv","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedbx9006xqlcr7q9xbb3a"},{"post_id":"cjzdedbvj002uqlcr2js1alsv","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedbx9006zqlcrm8jy8x2c"},{"post_id":"cjzdedbvj002uqlcr2js1alsv","tag_id":"cjzdedbx2006uqlcrt2mz8dax","_id":"cjzdedbx90071qlcr9peo8qko"},{"post_id":"cjzdedbvl002xqlcrpqczn1qo","tag_id":"cjzdedbx3006wqlcr711pa9gc","_id":"cjzdedbxc0079qlcr5dbvw77x"},{"post_id":"cjzdedbvl002xqlcrpqczn1qo","tag_id":"cjzdedbx90070qlcrz2pu41dr","_id":"cjzdedbxc007aqlcr50voxvi7"},{"post_id":"cjzdedbvl002xqlcrpqczn1qo","tag_id":"cjzdedbxa0073qlcrh1qavqe0","_id":"cjzdedbxd007eqlcrmwcbe0mu"},{"post_id":"cjzdedbvl002xqlcrpqczn1qo","tag_id":"cjzdedbxb0075qlcr8vmk0lid","_id":"cjzdedbxd007gqlcr95s20yya"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedbxf007sqlcr3nqk9ffp"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedbxf007uqlcre88h0nam"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","tag_id":"cjzdedbxd007hqlcr9bedoomd","_id":"cjzdedbxg007yqlcr14ddulf4"},{"post_id":"cjzdedbvm0030qlcrttrhc7dr","tag_id":"cjzdedbxe007lqlcr4jhpcyja","_id":"cjzdedbxg0080qlcro961m85u"},{"post_id":"cjzdedbvo0033qlcr1wvlejsu","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedbxh0084qlcrxn05ozny"},{"post_id":"cjzdedbvo0033qlcr1wvlejsu","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedbxi0086qlcripveuoiu"},{"post_id":"cjzdedbvq0036qlcrfgtde0rb","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedbxj008iqlcrchnq4aqa"},{"post_id":"cjzdedbvq0036qlcrfgtde0rb","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedbxk008kqlcrhlygky52"},{"post_id":"cjzdedbvq0036qlcrfgtde0rb","tag_id":"cjzdedbxi008bqlcr0tm1vuwu","_id":"cjzdedbxk008oqlcru4ffhpnz"},{"post_id":"cjzdedbvs003aqlcrfkd1sl8i","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedbxl008yqlcrnw17xa7p"},{"post_id":"cjzdedbvs003aqlcrfkd1sl8i","tag_id":"cjzdedbxk008mqlcrj2agotjc","_id":"cjzdedbxl0090qlcrx6jtsbsp"},{"post_id":"cjzdedbvs003aqlcrfkd1sl8i","tag_id":"cjzdedbxk008rqlcrz1qjhsc3","_id":"cjzdedbxm0094qlcrgxwa9cla"},{"post_id":"cjzdedbvu003cqlcr49wb6pc9","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedbxo0099qlcrcyanzgk4"},{"post_id":"cjzdedbvu003cqlcr49wb6pc9","tag_id":"cjzdedbxm0091qlcr3ymf4ia8","_id":"cjzdedbxo009bqlcr21mbzstv"},{"post_id":"cjzdedbvx003fqlcrst97z8gc","tag_id":"cjzdedbxm0096qlcrand2xysd","_id":"cjzdedbxp009fqlcrwoo5i3my"},{"post_id":"cjzdedbvy003hqlcrjpjbj762","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedbxp009jqlcr67ebnx0k"},{"post_id":"cjzdedbyj00atqlcronu7u4dv","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbym00axqlcrh0vwptvy"},{"post_id":"cjzdedbyj00atqlcronu7u4dv","tag_id":"cjzdedbua000lqlcr645qd6id","_id":"cjzdedbyn00b0qlcr9el39ix0"},{"post_id":"cjzdedbym00ayqlcr21hg03hb","tag_id":"cjzdedbuk0013qlcr5sqq691o","_id":"cjzdedbyo00b5qlcr6oaqubpg"},{"post_id":"cjzdedbyn00b1qlcr3ha7lq9a","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbyp00b8qlcr538x5ict"},{"post_id":"cjzdedbyo00b6qlcrku22ge65","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbyq00bcqlcrqp6t0qpg"},{"post_id":"cjzdedbyi00arqlcrqu4ltoyh","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedbys00bfqlcrgjqusfth"},{"post_id":"cjzdedbyi00arqlcrqu4ltoyh","tag_id":"cjzdedbyk00auqlcrsjop63fk","_id":"cjzdedbyt00bjqlcrihd75j15"},{"post_id":"cjzdedbyi00arqlcrqu4ltoyh","tag_id":"cjzdedbyo00b3qlcresd57ix8","_id":"cjzdedbz500bmqlcrdwnr782w"},{"post_id":"cjzdedbyp00b9qlcrhvvirpkf","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbzg00bpqlcr52pwcihx"},{"post_id":"cjzdedbys00bgqlcr1z4a9o3v","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbzh00btqlcr1v81u93d"},{"post_id":"cjzdedbyt00bkqlcrrpknhfqn","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedbzp00bwqlcrn124s7dq"},{"post_id":"cjzdedbyl00awqlcr4iq6gct1","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedbzw00bzqlcrgfk48qt6"},{"post_id":"cjzdedbyl00awqlcr4iq6gct1","tag_id":"cjzdedbyq00baqlcrv8etz5o0","_id":"cjzdedc0300c2qlcr3pewx8wq"},{"post_id":"cjzdedbyl00awqlcr4iq6gct1","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0500c5qlcr6qghcgfc"},{"post_id":"cjzdedbyl00awqlcr4iq6gct1","tag_id":"cjzdedbyt00biqlcri6mb0e0h","_id":"cjzdedc0600c9qlcrjm958trv"},{"post_id":"cjzdedbz600bnqlcr2audx4n6","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0700ccqlcr8y15yxxz"},{"post_id":"cjzdedbzg00brqlcrtafj6pf7","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0800cfqlcr1mlrkdnj"},{"post_id":"cjzdedbzh00buqlcrp0ot2qrt","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0900cjqlcrndpdxaf0"},{"post_id":"cjzdedbyq00bdqlcrdz3tlrjh","tag_id":"cjzdedbzg00bqqlcrybhatgqt","_id":"cjzdedc0900cmqlcrrusviktb"},{"post_id":"cjzdedbyq00bdqlcrdz3tlrjh","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedc0b00cqqlcrmx9463n6"},{"post_id":"cjzdedbyq00bdqlcrdz3tlrjh","tag_id":"cjzdedbua000lqlcr645qd6id","_id":"cjzdedc0b00cuqlcrnkxh1b5o"},{"post_id":"cjzdedbzp00bxqlcrkrzzb4wp","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0d00cxqlcrqip8iaq0"},{"post_id":"cjzdedbzw00c0qlcrc64a54zr","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0e00d0qlcros50solz"},{"post_id":"cjzdedc0500c6qlcrtop5fjy5","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc0f00d3qlcr7m3q91qt"},{"post_id":"cjzdedc0600caqlcr65vxhlaq","tag_id":"cjzdedbx3006wqlcr711pa9gc","_id":"cjzdedc0f00d5qlcrciaeswjo"},{"post_id":"cjzdedc0600caqlcr65vxhlaq","tag_id":"cjzdedbx90070qlcrz2pu41dr","_id":"cjzdedc0f00d8qlcr4lz9l7lm"},{"post_id":"cjzdedc0600caqlcr65vxhlaq","tag_id":"cjzdedbxa0073qlcrh1qavqe0","_id":"cjzdedc0f00daqlcr5gfo5dey"},{"post_id":"cjzdedc0600caqlcr65vxhlaq","tag_id":"cjzdedbxb0075qlcr8vmk0lid","_id":"cjzdedc0g00ddqlcr7g7bmxdj"},{"post_id":"cjzdedc0400c3qlcrifvh6oky","tag_id":"cjzdedc0500c8qlcrvtjhbrno","_id":"cjzdedc0g00dfqlcrqu68url3"},{"post_id":"cjzdedc0800cgqlcrqt0dwvre","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedc0g00dhqlcr2dzuy64t"},{"post_id":"cjzdedc0900ckqlcrrogphqzq","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedc0g00djqlcrquxvf489"},{"post_id":"cjzdedc0900ckqlcrrogphqzq","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedc0g00dlqlcr0aoswng3"},{"post_id":"cjzdedc0700cdqlcrg753r2gp","tag_id":"cjzdedbwm005gqlcrnm1f8kte","_id":"cjzdedc0g00dnqlcrf4bqbipc"},{"post_id":"cjzdedc0700cdqlcrg753r2gp","tag_id":"cjzdedc0800ciqlcrm09fq729","_id":"cjzdedc0g00dpqlcr9zfi3vx9"},{"post_id":"cjzdedc0b00crqlcrkvnsv84c","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedc0g00drqlcruwc7hcwe"},{"post_id":"cjzdedc0b00crqlcrkvnsv84c","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedc0g00dtqlcr2s3lr0w1"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","tag_id":"cjzdedc0b00ctqlcruu9zbzv2","_id":"cjzdedc0g00dvqlcrsl5oez3z"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","tag_id":"cjzdedc0e00d1qlcrgnfrc2z3","_id":"cjzdedc0g00dxqlcr04cotcwl"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","tag_id":"cjzdedbxi008bqlcr0tm1vuwu","_id":"cjzdedc0g00dzqlcrlrvou7rw"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedc0h00e1qlcrsgcs360l"},{"post_id":"cjzdedc0900cnqlcrfpb95n1r","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedc0h00e3qlcrjesg22ag"},{"post_id":"cjzdedc0c00cvqlcrdhqa5s2w","tag_id":"cjzdedbx1006nqlcr1c06jbrl","_id":"cjzdedc0h00e5qlcrq8i2g9to"},{"post_id":"cjzdedc0c00cvqlcrdhqa5s2w","tag_id":"cjzdedbx1006rqlcrxoyl4nkj","_id":"cjzdedc0h00e7qlcr5abw94wf"},{"post_id":"cjzdedc0c00cvqlcrdhqa5s2w","tag_id":"cjzdedc0f00d6qlcru87mn3c9","_id":"cjzdedc0h00e9qlcr76i6kkvf"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedc0h00ebqlcrf96fbi3o"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","tag_id":"cjzdedbxk008mqlcrj2agotjc","_id":"cjzdedc0h00edqlcrk193fwm4"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","tag_id":"cjzdedc0f00dbqlcrvueqp9ua","_id":"cjzdedc0h00efqlcrwwjicrgu"},{"post_id":"cjzdedc0d00cyqlcr14q6b7ob","tag_id":"cjzdedbxi008bqlcr0tm1vuwu","_id":"cjzdedc0h00ehqlcr7c3qtsls"},{"post_id":"cjzdedc1f00eyqlcr78z7kgbk","tag_id":"cjzdedbtp0004qlcr42y23cjj","_id":"cjzdedc1o00f1qlcrcswq5d2o"},{"post_id":"cjzdedc1h00f0qlcrp4bcab1x","tag_id":"cjzdedbup001aqlcrgmlw424a","_id":"cjzdedc1w00f4qlcregneg0ep"},{"post_id":"cjzdedc1h00f0qlcrp4bcab1x","tag_id":"cjzdedbut001hqlcr488mkn99","_id":"cjzdedc2500f7qlcruyy8xzmb"},{"post_id":"cjzdedc1o00f2qlcrjvgtwfgp","tag_id":"cjzdedbvj002tqlcr65di2m57","_id":"cjzdedc2f00f9qlcrgx6nqynr"},{"post_id":"cjzdedc1e00exqlcrtvof17sk","tag_id":"cjzdedc1g00ezqlcr4m58i8nw","_id":"cjzdedc2l00fbqlcrdqawgejc"},{"post_id":"cjzdedc1w00f5qlcr178kl6a0","tag_id":"cjzdedbxj008fqlcrxtary8hg","_id":"cjzdedc2m00fdqlcr1y69159f"},{"post_id":"cjzdedc3600fmqlcrhczh4xd1","tag_id":"cjzdedbw1003pqlcr6z60v8bm","_id":"cjzdedc3900fnqlcrm5iug6sr"},{"post_id":"cjzdedc3600fmqlcrhczh4xd1","tag_id":"cjzdedbud000pqlcrcrtjccc0","_id":"cjzdedc3a00foqlcr2ofdx3eh"}],"Tag":[{"name":"C++","_id":"cjzdedbtp0004qlcr42y23cjj"},{"name":"面试","_id":"cjzdedbua000lqlcr645qd6id"},{"name":"CMake","_id":"cjzdedbud000pqlcrcrtjccc0"},{"name":"Caffe","_id":"cjzdedbuk0013qlcr5sqq691o"},{"name":"Lidar SLAM","_id":"cjzdedbup001aqlcrgmlw424a"},{"name":"Cartographer","_id":"cjzdedbut001hqlcr488mkn99"},{"name":"Docker","_id":"cjzdedbuv001mqlcrckkn4513"},{"name":"rviz","_id":"cjzdedbv50023qlcrfkrg83r3"},{"name":"ubuntu","_id":"cjzdedbv80028qlcrs0r2s4vf"},{"name":"Event-based Feature","_id":"cjzdedbvc002iqlcrzg09utjf"},{"name":"Event Camera","_id":"cjzdedbvg002oqlcr146j0ukt"},{"name":"ORB_SLAM2","_id":"cjzdedbvj002tqlcr65di2m57"},{"name":"Rviz","_id":"cjzdedbvy003gqlcrm157c57o"},{"name":"ROS","_id":"cjzdedbw1003pqlcr6z60v8bm"},{"name":"catkin","_id":"cjzdedbwb004kqlcrvsyzjcv1"},{"name":"ROS消息发布器","_id":"cjzdedbwc004mqlcru2yudac6"},{"name":"ROS消息订阅器","_id":"cjzdedbwd004oqlcrj2z6yfhf"},{"name":"VSCode","_id":"cjzdedbwf004wqlcryflpq2h8"},{"name":"Debug","_id":"cjzdedbwi0050qlcrss0t52ib"},{"name":"Git","_id":"cjzdedbwj0055qlcrwccfpqok"},{"name":"Zotero","_id":"cjzdedbwl0059qlcrqtoa03q6"},{"name":"lightweight_mapping","_id":"cjzdedbwm005gqlcrnm1f8kte"},{"name":"ROS服务器","_id":"cjzdedbwo005qqlcranaieknx"},{"name":"ROS客户端","_id":"cjzdedbwr005wqlcrk1ag88kp"},{"name":"Python","_id":"cjzdedbws005zqlcrcj1373n8"},{"name":"cmake","_id":"cjzdedbwu0064qlcrvfaxufh7"},{"name":"vscode","_id":"cjzdedbwx0069qlcrjosmd256"},{"name":"debug","_id":"cjzdedbwy006dqlcrai0gl2td"},{"name":"Tensorflow","_id":"cjzdedbwz006fqlcr0oogockg"},{"name":"图像处理","_id":"cjzdedbx0006jqlcrfj4tat5e"},{"name":"SLAM基础","_id":"cjzdedbx1006nqlcr1c06jbrl"},{"name":"读书笔记","_id":"cjzdedbx1006rqlcrxoyl4nkj"},{"name":"双目","_id":"cjzdedbx2006uqlcrt2mz8dax"},{"name":"ubuntu16.04","_id":"cjzdedbx3006wqlcr711pa9gc"},{"name":"Hexo","_id":"cjzdedbx90070qlcrz2pu41dr"},{"name":"Github","_id":"cjzdedbxa0073qlcrh1qavqe0"},{"name":"Typora","_id":"cjzdedbxb0075qlcr8vmk0lid"},{"name":"图优化","_id":"cjzdedbxd007hqlcr9bedoomd"},{"name":"g2o","_id":"cjzdedbxe007lqlcr4jhpcyja"},{"name":"单目SLAM","_id":"cjzdedbxi008bqlcr0tm1vuwu"},{"name":"SLAM","_id":"cjzdedbxj008fqlcrxtary8hg"},{"name":"PTAM","_id":"cjzdedbxk008mqlcrj2agotjc"},{"name":"直接法SLAM","_id":"cjzdedbxk008rqlcrz1qjhsc3"},{"name":"最小二乘","_id":"cjzdedbxm0091qlcr3ymf4ia8"},{"name":"Pangolin","_id":"cjzdedbxm0096qlcrand2xysd"},{"name":"SVO","_id":"cjzdedbyk00auqlcrsjop63fk"},{"name":"半直接法SLAM","_id":"cjzdedbyo00b3qlcresd57ix8"},{"name":"YAML","_id":"cjzdedbyq00baqlcrv8etz5o0"},{"name":"OpenCV","_id":"cjzdedbyt00biqlcri6mb0e0h"},{"name":"C","_id":"cjzdedbzg00bqqlcrybhatgqt"},{"name":"roslaunch","_id":"cjzdedc0500c8qlcrvtjhbrno"},{"name":"Delaunay三角剖分","_id":"cjzdedc0800ciqlcrm09fq729"},{"name":"对极几何","_id":"cjzdedc0b00ctqlcruu9zbzv2"},{"name":"2D-2D","_id":"cjzdedc0e00d1qlcrgnfrc2z3"},{"name":"单目","_id":"cjzdedc0f00d6qlcru87mn3c9"},{"name":"特征法SLAM","_id":"cjzdedc0f00dbqlcrvueqp9ua"},{"name":"STL","_id":"cjzdedc1g00ezqlcr4m58i8nw"}]}}